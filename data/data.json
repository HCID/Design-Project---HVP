[
    {
        "id": 1,
        "name": "Morphing Agency: Deconstruction of an Agent with Transformative Agential Triggers",
        "type": "altchi",
        "abstract": "This paper presents our vision of Human Computer Interaction (HCI) called the \"Morphing Agency.\" The Morphing Agency redefines the notion of an agent in HCI, and proposes separated use of all agential triggers that evoke a user as an agent. This paper describes three key levels of agential triggers that are humanlike, behavioral, and internal. We illustrate these concepts with three prototype systems – the morphExplainer, transExplainer and parasiticBelt – to identify underlying research issues.",
        "cbStatement": "This paper presents our vision called Morphing Agency that redefines the notion of an agent. We propose separated use of all agential triggers that evoke a user as an agent.",
        "bookmarks": 134,
        "keywords": [
            "Human-agent interaction",
            "anthropomorphization",
            "human interface",
            "human-robot interaction"
        ],
        "communities": [],
        "video": "alt0101-file5.mp4",
        "session": {
            "id": "s184",
            "name": "Nature and Nurture"
        },
        "room": "351",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth22074",
                "givenName": "Hirotaka",
                "familyName": "Osawa",
                "email": "osawa@ayu.ics.keio.ac.jp",
                "primary": {
                    "institution": "Keio University",
                    "city": "Yokohama City",
                    "state": "Kanagawa",
                    "country": "Japan"
                },
                "role": "presenter"
            },
            {
                "id": "auth7194",
                "givenName": "Michita",
                "familyName": "Imai",
                "email": "michita@ayu.ics.keio.ac.jp",
                "primary": {
                    "institution": "Keio University",
                    "city": "Yokohama City",
                    "state": "Kanagawa",
                    "country": "Japan"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 2,
        "name": "On Legitimacy: Designer as Minor Scientist",
        "type": "altchi",
        "abstract": "User experience research has recently been characterized in two camps, model-based and design-based, with contrasting approaches to measurement and evaluation. This paper argues that the two positions can be constructed in terms of Deleuze & Guattari’s “royal science” and “minor science”. It is argued that the “reinvention” of cultural probes is an example of a minor scientific methodology re-conceptualised as a royal scientific “technology”. The distinction between royal and minor science provides insights into the nature of legitimacy within contemporary HCI research practice.",
        "cbStatement": "Utilising Gilles Deleuze & Felix Guattari’s metaphysics, this paper contributes to discussion on the nature of legitimacy in User Experience research.",
        "bookmarks": 157,
        "keywords": [
            "Deleuze",
            "Guattari",
            "Design",
            "Legitimacy",
            "Cultural Probes",
            "User Experience."
        ],
        "communities": [
            "design"
        ],
        "session": {
            "id": "s183",
            "name": "Ethics"
        },
        "room": "351",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth31786",
                "givenName": "Aysar",
                "familyName": "Ghassan",
                "email": "aysar.ghassan@northumbria.ac.uk",
                "primary": {
                    "dept": "Department of Art, Design and Social Sciences",
                    "institution": "Northumbria University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth1332",
                "givenName": "Mark",
                "middleInitial": "A.",
                "familyName": "Blythe",
                "email": "mark.blythe@northumbria.ac.uk",
                "primary": {
                    "dept": "Department of Art, Design and Social Sciences",
                    "institution": "Northumbria University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 3,
        "name": "Critical InfoVis: Exploring the Politics of Visualization",
        "type": "altchi",
        "abstract": "As information visualization is increasingly used to raise awareness about social issues, difficult questions arise about the power of visualization. So far the research community has not given sufficient thought to how values and assumptions pervade information visualization. Taking engaging visualizations as a starting point, we outline a critical approach that promotes disclosure, plurality, contingency, and empowerment. Based on this approach, we pose some challenges and opportunities for visualization researchers and practitioners.",
        "cbStatement": "Building on experiences in related domains, we outline a critical approach to information visualization that promotes disclosure, plurality, contingency, and empowerment, and pose challenges and opportunities for the visualization community.",
        "bookmarks": 97,
        "keywords": [
            "Information visualization",
            "critical theory",
            "values"
        ],
        "communities": [
            "design"
        ],
        "session": {
            "id": "s183",
            "name": "Ethics"
        },
        "room": "351",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth15772",
                "givenName": "Marian",
                "familyName": "Dörk",
                "email": "marian.doerk@ncl.ac.uk",
                "primary": {
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth29131",
                "givenName": "Patrick",
                "familyName": "Feng",
                "email": "pfeng@ucalgary.ca",
                "primary": {
                    "dept": "Communication and Culture",
                    "institution": "University of Calgary",
                    "city": "Calgary",
                    "state": "Alberta",
                    "country": "Canada"
                }
            },
            {
                "id": "auth6042",
                "givenName": "Christopher",
                "middleInitial": "M",
                "familyName": "Collins",
                "email": "christopher.collins@uoit.ca",
                "primary": {
                    "institution": "University of Ontario Institute of Technology",
                    "city": "Oshawa",
                    "state": "Ontario",
                    "country": "Canada"
                }
            },
            {
                "id": "auth1434",
                "givenName": "Sheelagh",
                "familyName": "Carpendale",
                "email": "sheelagh@ucalgary.ca",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Calgary ",
                    "city": "Calgary",
                    "state": "Alberta",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 4,
        "name": "PIXEE: Pictures, Interaction and Emotional Expression",
        "type": "altchi",
        "abstract": "An interactive system, PIXEE, was developed to promote greater emotional expression in image-based social media.  Images shared on social media were projected onto a large interactive display at public events. A multimodal interface displayed the sentiment analysis of images and invited viewers to express their emotional responses. Viewers could adjust the emotional classification and thereby change the color and sound associated with a picture, and experiment with emotion-based composition. An interdisciplinary team deployed this system around the world to explore new ways for technology to catalyze emotional connectedness. This paper describes the system, design iterations, and observations about how people used it for self-expression and connection.",
        "cbStatement": "This paper demonstrates new means of promoting emotional connectedness in social media. It also provides new research methods. ",
        "bookmarks": 116,
        "keywords": [
            "Affect",
            "social media",
            "image sharing",
            "sentiment analysis",
            "emotion",
            "interpersonal connectedness",
            "interactive displays"
        ],
        "communities": [
            "design",
            "engineering",
            "ux",
            "games",
            "arts"
        ],
        "session": {
            "id": "s186",
            "name": "Spirit and Mind"
        },
        "room": "251",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth3197",
                "givenName": "Margaret",
                "middleInitial": "E",
                "familyName": "Morris",
                "email": "margaret.morris@intel.com",
                "primary": {
                    "dept": "Intel Labs",
                    "institution": "Intel Corporation",
                    "city": "Hillsboro",
                    "state": "Oregon",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30078",
                "givenName": "Carl",
                "middleInitial": "S",
                "familyName": "Marshall",
                "email": "carl.s.marshall@intel.com",
                "primary": {
                    "dept": "Intel Corporation",
                    "institution": "Intel Labs",
                    "city": "Hillsboro",
                    "state": "OR",
                    "country": "USA"
                }
            },
            {
                "id": "auth33569",
                "givenName": "Mira",
                "familyName": "calix",
                "email": "miracalix@mac.com",
                "primary": {
                    "dept": "create",
                    "institution": "Mira Calix",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth33504",
                "givenName": "Murad",
                "familyName": "Al Haj",
                "email": "malhaj@cvc.uab.es",
                "primary": {
                    "dept": "Universitat Autonoma de Barcelona",
                    "institution": "Centre de Visio per Computador",
                    "city": "Bellaterra",
                    "state": "Barcelona",
                    "country": "Spain"
                }
            },
            {
                "id": "auth34071",
                "givenName": "James",
                "middleInitial": "Scott",
                "familyName": "MacDougall",
                "email": "jamiemac@uvic.ca",
                "primary": {
                    "dept": "Computer Science Graphics Group",
                    "institution": "University of Victoria",
                    "city": "Victoria",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            },
            {
                "id": "auth30070",
                "givenName": "Douglas",
                "familyName": "Carmean",
                "email": "doug.m.carmean@intel.com",
                "primary": {
                    "dept": "Intel Labs",
                    "institution": "Intel Corporation",
                    "city": "Hillsboro",
                    "state": "Oregon",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 5,
        "name": "Spirituality: There’s an App for That! (But Not a Lot of Research)",
        "type": "altchi",
        "abstract": "The iTunes App Store contains over six thousand apps related to spirituality and religion. The ACM digital library, however, contains only 98 works that address this topic from an HCI perspective. Despite high-profile calls for research in the area, the HCI community has produced only 19 research papers focused on the topic, almost half of which are the work of one person and her colleagues. In this paper we provide an overview of the relevant HCI research in this area, a partial inventory of spiritually oriented apps in the iTunes US App Store, and a comparison of research and real-world developments. We discuss the gaps in the HCI literature on techno-spiritual practices and speculate about some of the difficulties and challenges that face the HCI community in conducting research in this area. ",
        "cbStatement": "Reviews HCI literature on techno-spirituality and provides preliminary analysis of relevant iPhone/iPad apps. Identifies gaps in research and explores some of the difficulties and challenges of researching techno-spirituality.",
        "bookmarks": 37,
        "keywords": [
            "Spirituality",
            "religion",
            "techno-spirituality"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "session": {
            "id": "s186",
            "name": "Spirit and Mind"
        },
        "room": "251",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth9178",
                "givenName": "Elizabeth",
                "middleInitial": "A",
                "familyName": "Buie",
                "email": "elizabeth.buie@northumbria.ac.uk",
                "primary": {
                    "dept": "School of Design",
                    "institution": "Northumbria University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth1332",
                "givenName": "Mark",
                "middleInitial": "A.",
                "familyName": "Blythe",
                "email": "mark.blythe@northumbria.ac.uk",
                "primary": {
                    "dept": "School of Design",
                    "institution": "Northumbria University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 6,
        "name": "Fillables: Everyday Vessels as Tangible Controllers with Adjustable Haptics",
        "type": "altchi",
        "abstract": "We introduce Fillables: low-cost and ubiquitous everyday vessels that are appropriated as tangible controllers whose haptics are tuned ad-hoc by filling, e.g., with water. We show how Fillables can assist users in video navigation and drawing tasks with physical controllers whose adjustable output granularity harmonizes with their haptic feedback. As proof of concept, we implemented a drawing application that uses vessels to control a virtual brush whose stroke width corresponds to the filling level. Furthermore, we found that humans can distinguish nine levels of haptic feedback when sliding water-filled paper cups (300 ml capacity) over a wooden surface. This discrimination follows Weber’s Law and was facilitated by sloshing of water.",
        "cbStatement": "Tuning TUIs ad-hoc by filling water into everyday objects. Reports how users can discriminate different filling levels that make virtual granularity (video navigation, virtual brush size) perceptible eyes-free.",
        "bookmarks": 72,
        "keywords": [
            "Tangible User Interfaces",
            "Ubiquitous Computing",
            "Appropriation",
            "Everyday Objects",
            "Up-and-Down Transformed Response (UDTR)",
            "Weber’s Law"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "session": {
            "id": "s182",
            "name": "Design and Design Lessons"
        },
        "room": "342a",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth15322",
                "givenName": "Christian",
                "familyName": "Corsten",
                "email": "corsten@cs.rwth-aachen.de",
                "primary": {
                    "institution": "RWTH Aachen University",
                    "city": "Aachen",
                    "state": "NRW",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth16712",
                "givenName": "Chat",
                "familyName": "Wacharamanotham",
                "email": "chat@cs.rwth-aachen.de",
                "primary": {
                    "institution": "RWTH Aachen University",
                    "city": "Aachen",
                    "state": "NRW",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1497",
                "givenName": "Jan",
                "familyName": "Borchers",
                "email": "borchers@cs.rwth-aachen.de",
                "primary": {
                    "institution": "RWTH Aachen University",
                    "city": "Aachen",
                    "state": "NRW",
                    "country": "Germany"
                }
            }
        ]
    },
    {
        "id": 7,
        "name": "Smart Pose: Mobile Posture-aware System for Lowering Physical Health Risk of Smartphone Users",
        "type": "altchi",
        "abstract": "With the widespread use of smartphones, users tend to use their smartphones for a long period of time with unhealthy postures, bending forward their upper body including the neck. If users keep such an unhealthy posture for a long time, their neck and back muscles get chronically strained, which might cause diseases such as cervical myalgia. To prevent these diseases, we propose a new methodology to monitor the posture of smartphone users with built-in sensors. The proposed mechanism estimates a value representing user postures like head/neck tilt angle by analyzing sensor data from a front-faced camera, 3-axis accelerometer, and orientation sensor. It then informs the user if the estimated value is maintained within the abnormal range over a pre-defined time.",
        "cbStatement": "This paper discusses health problems of the smartphone users which are usually overlooked, and presents a novel solution to overcome this difficulty for people's well being.",
        "bookmarks": 19,
        "keywords": [
            "Posture monitoring",
            "smartphone sensors",
            "neck tilt angle",
            "musculoskeletal disorders",
            "cervical myalgia"
        ],
        "communities": [
            "engineering"
        ],
        "video": "alt0158-file5.mp4",
        "session": {
            "id": "s184",
            "name": "Nature and Nurture"
        },
        "room": "351",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth17594",
                "givenName": "Hosub",
                "familyName": "Lee",
                "email": "horus.lee@samsung.com",
                "primary": {
                    "institution": "Samsung Advanced Institute of Technology (SAIT), Samsung Electronics",
                    "city": "Yongin-si",
                    "country": "Republic of Korea"
                },
                "role": "presenter"
            },
            {
                "id": "auth11722",
                "givenName": "Young Sang",
                "familyName": "Choi",
                "email": "macho@samsung.com",
                "primary": {
                    "institution": "Samsung Advanced Institute of Technology (SAIT), Samsung Electronics",
                    "city": "Yongin-si",
                    "country": "Republic of Korea"
                }
            },
            {
                "id": "auth28876",
                "givenName": "Sunjae",
                "familyName": "Lee",
                "email": "sunjae79.lee@samsung.com",
                "primary": {
                    "institution": "Samsung Advanced Institute of Technology (SAIT), Samsung Electronics",
                    "city": "Yongin-si",
                    "country": "Republic of Korea"
                }
            },
            {
                "id": "auth28877",
                "givenName": "Eunsoo",
                "familyName": "Shim",
                "email": "eunsoo.shim@samsung.com",
                "primary": {
                    "institution": "Samsung Advanced Institute of Technology (SAIT), Samsung Electronics",
                    "city": "Yongin-si",
                    "country": "Republic of Korea"
                }
            }
        ]
    },
    {
        "id": 8,
        "name": "Ethical Issues and Guidelines when Conducting HCI Studies with Animals",
        "type": "altchi",
        "abstract": "The number of studies in the field of Human-Computer Interaction (HCI) with animals has increased in recent years. When planning and carrying out the studies with animals, it is important and necessary to take into account the welfare of the animals as well as deal with the short- and long-term effects of the developed technology and related interventions on animal welfare. This paper addresses the ethical issues, presents the key concepts and provides guidelines for carrying out studies with animals based on a literature review. The guidelines cover the phases from planning of the studies, to carrying out and reporting the studies.",
        "cbStatement": "This paper addresses the ethical issues, presents the related key concepts and provides guidelines on planning, carrying out and reporting the studies with animals.",
        "bookmarks": 97,
        "keywords": [
            "Ethics",
            "Welfare",
            "Animal",
            "Pet",
            "Guideline",
            "Human-Animal Interaction",
            "Animal-Computer Interaction",
            "Technology."
        ],
        "communities": [
            "design",
            "ux",
            "games"
        ],
        "video": "alt0160-file5.mp4",
        "session": {
            "id": "s183",
            "name": "Ethics"
        },
        "room": "351",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth13720",
                "givenName": "Heli",
                "middleInitial": "K",
                "familyName": "Väätäjä",
                "email": "heli.vaataja@tut.fi",
                "primary": {
                    "institution": "Tampere University of Technology",
                    "city": "Tampere",
                    "country": "Finland"
                },
                "role": "presenter"
            },
            {
                "id": "auth35129",
                "givenName": "Emilia",
                "middleInitial": "K",
                "familyName": "Pesonen",
                "email": "emilia.pesonen@tut.fi",
                "primary": {
                    "institution": "Tampere University of Technology",
                    "city": "Tampere",
                    "country": "Finland"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 9,
        "name": "Mobile Interaction Does Not Exist",
        "type": "altchi",
        "abstract": "Most mobile systems are ‘stop-to-interact’; designed for active interaction only when a user is standing still, paying visual and mental attention to the device. However, people are increasingly carrying and using devices while undertaking a wide range of movement activities, such as walking, cycling, running. Some existing systems such as Apple’s Siri aim for hands and eyes free use, but they do not consider the wider challenges of interaction during movement. \\  \\ We describe the challenges of system design for active mobile interaction. These ‘interaction in motion’ challenges are discussed with reference to an extreme movement interaction situation – cold water swimming.",
        "cbStatement": "Few mobile devices are designed to be used when mobile. Describes challenges of designing truly mobile interactions.",
        "bookmarks": 42,
        "keywords": [
            "Motion",
            "interaction",
            "interaction in motion",
            "mobile",
            "swimming"
        ],
        "communities": [
            "design"
        ],
        "video": "alt0161-file5.mp4",
        "session": {
            "id": "s187",
            "name": "Experiences"
        },
        "room": "251",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth7924",
                "givenName": "Joe",
                "familyName": "Marshall",
                "email": "joe.marshall@nottingham.ac.uk",
                "primary": {
                    "dept": "Mixed Reality Lab",
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth17054",
                "givenName": "Paul",
                "middleInitial": "R",
                "familyName": "Tennent",
                "email": "pxt@cs.nott.ac.uk",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 10,
        "name": "“Sergey Brin is Batman”: Google’s Project Glass and the Instigation of Computer Adoption in Popular Culture",
        "type": "altchi",
        "abstract": "The emergence of Google Glass, a prototype for a transparent Heads-Up Display available for the everyday consumer, is the first public conceptualization of a mainstream augmented-reality wearable eye display.  Google's promotional material frames Glass as the brainchild of company co-founder Sergey Brin, who, by being associated with a state-of-the-art development lab, has been compared by the popular press to the iconic comic book character Batman.  We contend that the hype surrounding Google Glass and the resulting social responses to \"Brin-as-Batman\" is a phenomenon that warrants attention. Using a humanities focus, we argue that Glass’s birth is not only a marketing phenomenon heralding a technical prototype, we also argue and speculate that Glass’s popularization is an instigator for the adoption of a new paradigm in human-computer interaction, the wearable eye display, operating very much in mainstream and popular culture discourses.",
        "cbStatement": "This humanities paper argues that Google's Project Glass is an instigator for the adoption of a new HCI platform, the wearable eye display, operating in popular culture discourses.",
        "bookmarks": 10,
        "keywords": [
            "Computer adoption",
            "user experience",
            "wearable eye display",
            "computer platform",
            "augmented reality",
            "popular culture",
            "discourse analysis",
            "humanities",
            "Batman"
        ],
        "communities": [
            "ux",
            "games",
            "arts"
        ],
        "video": "alt0163-file5.mp4",
        "session": {
            "id": "s182",
            "name": "Design and Design Lessons"
        },
        "room": "342a",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth26698",
                "givenName": "Isabel",
                "familyName": "Pedersen",
                "email": "isabel.pedersen@uoit.ca",
                "primary": {
                    "dept": "DeCiMaL Digital Culture and Media Lab",
                    "institution": "University of Ontario Institute of Technology",
                    "city": "Oshawa",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth35136",
                "givenName": "Doug",
                "familyName": "Trueman",
                "email": "douglastrueman@gmail.com",
                "primary": {
                    "dept": "DeCiMaL Digital Culture and Media Lab ",
                    "institution": "University of Ontario Institute of Technology",
                    "city": "Oshawa",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 11,
        "name": "Talkative Objects in Need of Interpretation. Re-Thinking Digital Badges in Education",
        "type": "altchi",
        "abstract": "I examine current debates concerning digital badges in education, pointing to less remarked upon topics. By investigating badges as motivators, I conclude that a focus on badges as rewards has downplayed the importance of badge conditionalities ('tails') and entitlements ('antennae'), and their always situated effectiveness. Current discussions of badges as evidence-based credentials understate the interpretive work required to make sense of badge collections. I propose two heuristic definitions of badges as 'routes through an activity system' and as 'genres of hint-based multi-authored testimony of learning'. Alternative definitions are invited, as tools for thought.",
        "cbStatement": "I examine debates concerning digital badges in education, and I propose two definitions of badges as ‘routes through an activity system’ and as ‘genres of hint-based multi-authored testimony of learning’.",
        "bookmarks": 28,
        "keywords": [
            "Digital badges",
            "Motivation",
            "Education",
            "Interpretation"
        ],
        "communities": [
            "ux",
            "games"
        ],
        "video": "alt0164-file5.mp4",
        "session": {
            "id": "s182",
            "name": "Design and Design Lessons"
        },
        "room": "342a",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth27883",
                "givenName": "Razvan",
                "familyName": "Rughinis",
                "email": "razvan.rughinis@cs.pub.ro",
                "primary": {
                    "institution": "University POLITEHNICA of Bucharest",
                    "city": "Bucharest",
                    "country": "Romania"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 12,
        "name": "Devotional Gardening Tools",
        "type": "altchi",
        "abstract": "Gardening as an activity is devotional, built on the idea that through practice and effort, particular results can be obtained. Devotion is performative, taking time, skill, and repetition to get the results that you want. Human-scale farming depends on the labor of people to get things done, relying on hand tools and particular kinesthetic actions to change the earth in a plot.  \\  \\ Digital media technologies afford the creation of tools that can materialize rhetoric, creating alternate functionality emphasizing issues of practice through use. Creating gardening implements that build on the repetitive physical nature of gardening work allows  handwork to become something broader: representative of, more reflexive and meditative technological practice. \\ ",
        "cbStatement": "Devotional Gardening is a research-through-design project that examines possible tool use beyond functionality. Using 'devotion' as a guideline, prototype gardening tools are proposed that underscore the devotional nature of cultivation.",
        "bookmarks": 76,
        "keywords": [
            "Design",
            "Research through Design",
            "Tools",
            "Prototyping"
        ],
        "communities": [
            "design",
            "sustainability",
            "arts"
        ],
        "video": "alt0165-file5.mp4",
        "session": {
            "id": "s184",
            "name": "Nature and Nurture"
        },
        "room": "351",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth26937",
                "givenName": "Tom",
                "familyName": "Jenkins",
                "email": "tom.jenkins@gatech.edu",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "GA",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 13,
        "name": "Comparative Appraisal of Expressive Artifacts",
        "type": "altchi",
        "abstract": "This paper describes a form of comparative, structured appraisal of expressive artifacts that adds to the existing repertoire of HCI assessment techniques. Comparative appraisal uses a situationally defined procedure to be followed by multiple assessors in examining a group of artifacts. The conceptual basis for this method is drawn from writing assessment.",
        "cbStatement": "Describes a form of comparative, structured appraisal of expressive artifacts that adds to the existing repertoire of HCI assessment techniques.",
        "bookmarks": 164,
        "keywords": [
            "Evaluation",
            "criticism",
            "assessment "
        ],
        "communities": [
            "design"
        ],
        "video": "alt0166-file5.mp4",
        "session": {
            "id": "s185",
            "name": "Reflection and Evaluation"
        },
        "room": "242ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth22148",
                "givenName": "Melanie",
                "familyName": "Feinberg",
                "email": "feinberg@ischool.utexas.edu",
                "primary": {
                    "institution": "The University of Texas at Austin",
                    "city": "Austin",
                    "state": "Texas",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 14,
        "name": "Flying Head: A Head Motion Synchronization Mechanism for Unmanned Aerial Vehicle Control",
        "type": "altchi",
        "abstract": "We propose an unmanned aerial vehicle (UAV) control mechanism, called a “Flying Head” which synchronizes a human head and the UAV motions. The accurate manipulation of UAVs is difficult as their control typically involves hand-operated devices. We can incorporate the UAV control using human motions such as walking, looking around and crouching. The system synchronizes the operator and UAV positions in terms of the horizontal and vertical positions and the yaw orientation.  The operator can use the UAV more intuitively as such manipulations are more in accord with kinesthetic. Finally, we discuss flying telepresence applications.",
        "cbStatement": "The Flying Head: The system synchronizes human head motions with those of an unmanned aerial vehicle.",
        "bookmarks": 131,
        "keywords": [
            "Unmanned Aerial Vehicle",
            "Telepresence"
        ],
        "communities": [
            "engineering",
            "ux"
        ],
        "video": "alt0168-file5.mp4",
        "session": {
            "id": "s187",
            "name": "Experiences"
        },
        "room": "251",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth29664",
                "givenName": "Keita",
                "familyName": "Higuchi",
                "email": "khiguchi@acm.org",
                "primary": {
                    "dept": "The University of Tokyo",
                    "institution": "Meguro-ku",
                    "city": "Tokyo",
                    "country": "Japan"
                },
                "secondary": {
                    "dept": "Japan Society for the Promotion of Science",
                    "institution": "Chiyoda-ku",
                    "city": "Tokyo",
                    "country": "Japan"
                },
                "role": "presenter"
            },
            {
                "id": "auth2011",
                "givenName": "Jun",
                "familyName": "Rekimoto",
                "email": "rekimoto@acm.org",
                "primary": {
                    "institution": "The University of Tokyo",
                    "city": "Meguro-ku",
                    "state": "Tokyo",
                    "country": "Japan"
                },
                "secondary": {
                    "institution": "Sony CSL",
                    "city": "Tokyo",
                    "state": "Tokyo",
                    "country": "Japan"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 15,
        "name": "Experiences Before Things: A Primer for the (Yet) Unconvinced",
        "type": "altchi",
        "abstract": "While things (i.e., technologies) play a crucial role in creating and shaping meaningful, positive experiences, their true value lies only in the resulting experiences. It is about what we can do and experience with a thing, about the stories unfolding through using a technology, not about its styling, material, or impressive list of features. This paper explores the notion of \"experiences\" further: from the link between experiences, well-being, and people's developing post-materialistic stance to the challenges of the experience market and the experience-driven design of technology.",
        "cbStatement": "The true value of technology is only in the resulting experiences. Consequently, we must put experiences before things - treating experiences as objectives of design rather than as appreciated by-products.",
        "bookmarks": 58,
        "keywords": [
            "Experience Design",
            "User Experience",
            "Well-Being",
            "Happiness",
            "Design"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "session": {
            "id": "s187",
            "name": "Experiences"
        },
        "room": "251",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth16094",
                "givenName": "Marc",
                "familyName": "Hassenzahl",
                "email": "marc.hassenzahl@folkwang-uni.de",
                "primary": {
                    "institution": "Folkwang University of the Arts",
                    "city": "Essen",
                    "country": "Germany"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 16,
        "name": "Beyond the Basic Emotions: What Should Affective Computing Compute?",
        "type": "altchi",
        "abstract": "One of the primary goals of Affective Computing (AC) is to develop computer interfaces that automatically detect and respond to users’ emotions. Despite significant progress, “basic emotions” (e.g., anger, disgust, sadness) have been emphasized in AC at the expense of other non-basic emotions. The present paper questions this emphasis by analyzing data from five studies that systematically tracked both basic and non-basic emotions. The results indicate that engagement, boredom, confusion, and frustration (all non-basic emotions) occurred at five times the rate of basic emotions after generalizing across tasks, interfaces, and methodologies. Implications of these findings for AC are discussed",
        "cbStatement": "We show that non-basic emotions (engagement, boredom, confusion, and frustration) occurred at five times the rate of basic emotions after generalizing across tasks, interfaces, and methodologies (in 5 studies). ",
        "bookmarks": 179,
        "keywords": [
            "Affective computing",
            "basic-emotions, non-basic emotions"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "alt0170-file5.mp4",
        "session": {
            "id": "s186",
            "name": "Spirit and Mind"
        },
        "room": "251",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth12828",
                "givenName": "Sidney",
                "familyName": "D'Mello",
                "email": "sdmello@nd.edu",
                "primary": {
                    "dept": "Departments of Computer Science and Psychology",
                    "institution": "University of Notre Dame",
                    "city": "Notre Dame",
                    "state": "IN",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29236",
                "givenName": "Rafael",
                "middleInitial": "A.",
                "familyName": "Calvo",
                "email": "rafael.calvo@sydney.edu.au",
                "primary": {
                    "dept": "School of Electrical and Information Engineering",
                    "institution": "The University of Sydney",
                    "city": "Sydney",
                    "state": "NSW",
                    "country": "Australia"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 17,
        "name": "Changing Perspectives on Evaluation in HCI: Past, Present, and Future",
        "type": "altchi",
        "abstract": "Evaluation has been a dominant theme in HCI for decades, but it is far from being a solved problem. As interactive systems and their uses change, the nature of evaluation must change as well. In this paper, we outline the challenges our community needs to address to develop adequate methods for evaluating systems in modern (and future) use contexts. We begin by tracing how evaluation efforts have been shaped by a continuous adaptation to technological and cultural changes and conclude by discussing important research directions that will shape evaluation’s future.",
        "cbStatement": "We review the history of evaluation and outline five research directions that will help researchers, practitioners, and educators adapt to meet new evaluation challenges.",
        "bookmarks": 71,
        "keywords": [
            "Evaluation",
            "usability",
            "user experience",
            "history"
        ],
        "communities": [
            "ux"
        ],
        "video": "alt0171-file5.mp4",
        "session": {
            "id": "s185",
            "name": "Reflection and Evaluation"
        },
        "room": "242ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth13588",
                "givenName": "Craig",
                "middleInitial": "M.",
                "familyName": "MacDonald",
                "email": "cmacdona@pratt.edu",
                "primary": {
                    "institution": "Pratt Institute",
                    "city": "New York",
                    "state": "NY",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth2932",
                "givenName": "Michael",
                "middleInitial": "E.",
                "familyName": "Atwood",
                "email": "michael.atwood@cis.drexel.edu",
                "primary": {
                    "institution": "Drexel University",
                    "city": "Philadelphia",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 18,
        "name": "Design Activism in the HCI Classroom",
        "type": "altchi",
        "abstract": "In HCI, design activism has been practiced but has not been well articulated or discussed. There are examples of activism in the HCI classroom, opening a new avenue of discussion and investigation for the role of design activism in HCI. We present two case studies that show design activism in the classroom as examples from which to learn. We highlight themes and observations that can allow for future articulation and practice of design activism in HCI and HCI education.",
        "cbStatement": "This paper allows for future articulation and practice of design activism in HCI and HCI education.",
        "bookmarks": 187,
        "keywords": [],
        "communities": [
            "design",
            "sustainability"
        ],
        "session": {
            "id": "s182",
            "name": "Design and Design Lessons"
        },
        "room": "342a",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth27649",
                "givenName": "Sabrina",
                "familyName": "Hauser",
                "email": "shauser@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth19949",
                "givenName": "Audrey",
                "familyName": "Desjardins",
                "email": "adesjard@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth3350",
                "givenName": "Ron",
                "familyName": "Wakkary",
                "email": "rwakkary@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey ",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 19,
        "name": "Performative Experience Design",
        "type": "altchi",
        "abstract": "This paper categorises key HCI literature that engages with performance theory or practice according to a taxonomy that puts the user at the centre of the analysis. This taxonomy reveals three strands of research that use performance to address HCI and interaction design at the most fundamental level. We use these strands of research to map out what we have identified as the emerging field of Performative Experience Design. This field, which lies between HCI and performance studies, presents an extraordinarily rich potential for the design of interactive systems.",
        "cbStatement": "A taxonomy of the key ways that HCI uses ‘performance’; resolving some confusions and contradictions, moving beyond restrictive assumptions, and pointing towards an emerging field of Performative Experience Design.",
        "bookmarks": 139,
        "keywords": [
            "performance",
            "performativity",
            "Performative Experience Design",
            "mixed reality performance",
            "Digital Live Art",
            "digitally augmented autobiographical performance"
        ],
        "communities": [
            "design",
            "arts"
        ],
        "session": {
            "id": "s187",
            "name": "Experiences"
        },
        "room": "251",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth27015",
                "givenName": "Jocelyn",
                "familyName": "Spence",
                "email": "j.spence@surrey.ac.uk",
                "primary": {
                    "dept": "Digital World Research Centre, School of Arts",
                    "institution": "University of Surrey",
                    "city": "Guildford",
                    "state": "Surrey",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth1547",
                "givenName": "David",
                "middleInitial": "M",
                "familyName": "Frohlich",
                "email": "d.frohlich@surrey.ac.uk",
                "primary": {
                    "dept": "Digital World Research Centre, School of Arts",
                    "institution": "University of Surrey",
                    "city": "Guildford",
                    "state": "Surrey",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30002",
                "givenName": "Stuart",
                "familyName": "Andrews",
                "email": "s.andrews@surrey.ac.uk",
                "primary": {
                    "dept": "Digital World Research Centre, School of Arts",
                    "institution": "University of Surrey",
                    "city": "Guildford",
                    "state": "Surrey",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 20,
        "name": "CHI and the Future Robot Enslavement of Humankind; A Retrospective",
        "type": "altchi",
        "abstract": "As robots from the future, we are compelled to present this important historical document which discusses how the systematic investigation of interactive technology facilitated and hastened the enslavement of mankind by robots during the 21st Century. We describe how the CHI community, in general, was largely responsible for this eventuality, as well as how specific strands of interaction design work were key to the enslavement. We also mention the futility of some reactionary work emergent in your time that sought to challenge the inevitable subjugation. We conclude by congratulating the CHI community for your tireless work in promoting and supporting our evil robot agenda.",
        "cbStatement": "Time travelling robots celebrate the CHI community for hastening the future enslavement of mankind by evil machines",
        "bookmarks": 171,
        "keywords": [
            "Maschinenweltherrschaftsangst",
            "changing perspectives",
            ""
        ],
        "communities": [
            "design"
        ],
        "video": "alt0176-file5.m4v",
        "session": {
            "id": "s183",
            "name": "Ethics"
        },
        "room": "351",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth10649",
                "givenName": "Ben",
                "familyName": "Kirman",
                "email": "bkirman@lincoln.ac.uk",
                "primary": {
                    "institution": "University of Lincoln",
                    "city": "Lincoln",
                    "state": "Lincolnshire",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth13937",
                "givenName": "Conor",
                "familyName": "Linehan",
                "email": "clinehan@lincoln.ac.uk",
                "primary": {
                    "institution": "University of Lincoln",
                    "city": "Lincoln",
                    "state": "Lincolnshire",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth3083",
                "givenName": "Shaun",
                "familyName": "Lawson",
                "email": "slawson@lincoln.ac.uk",
                "primary": {
                    "institution": "University of Lincoln",
                    "city": "Lincoln",
                    "state": "Lincolnshire",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth35267",
                "givenName": "Dan",
                "familyName": "O'Hara",
                "email": "dan.o-hara@uni-koeln.de",
                "primary": {
                    "dept": "CFAR",
                    "institution": "Birmingham City University",
                    "city": "Birmingham",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 21,
        "name": "Embodying Neuroplastic Change",
        "type": "altchi",
        "abstract": "Groundbreaking neuroplasticity research demonstrates how interactive technologies can be used to leverage and increase our brain’s capacity to learn. Importantly, unless specific physical pathologies are being addressed, this research remains screen-based, overlooking the rich multi-modal capacities of the human body. Embodied interaction affords multi-sensory experiences and heightened engagement. It allows for a broad palette of activities, as well as powerful leverage of the indelible intertwining of body and brain. This paper argues that embodied interaction, in particular poetic-kinaesthetic engagement in artistic activities, may powerfully compliment existing techniques for stimulating neuroplastic change.",
        "cbStatement": "Embodied engagement is gaining leverage in HCI. This paper poses the question whether enriched embodied engagement might stimulate neuroplastic change, relevant to broad cultural, design thinking and health contexts.",
        "bookmarks": 105,
        "keywords": [
            "Embodied engagement",
            "poetics",
            "neuroplasticity",
            "poetic-kinaesthetics",
            "health",
            "learning",
            "abilitation",
            "magical thinking",
            "design innovation",
            "design futures"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "session": {
            "id": "s186",
            "name": "Spirit and Mind"
        },
        "room": "251",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth15031",
                "givenName": "Danielle",
                "familyName": "Wilde",
                "email": "d@daniellewilde.com",
                "primary": {
                    "institution": "2013-2014 Sidney Myer Creative Fellow",
                    "city": "Melbourne",
                    "country": "Australia"
                },
                "secondary": {
                    "institution": "RMIT University",
                    "city": "Melbourne",
                    "country": "Australia"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 22,
        "name": "Pattern Language and HCI: Expectations and Experiences",
        "type": "altchi",
        "abstract": "Pattern Language (PL) has been researched and developed in HCI research since the mid-80s. Our research was initiated by the question why something like PL can create such enthusiasm and interest over the years, while at the same time not be more widespread and successful? In this paper, we examine the experiences and expectations that HCI researchers who have been involved in PL research have had and still have when it comes to PL. Based on the literature review and interview studies, we provide some overall reflections and several possible directions on the use of PL in HCI.",
        "cbStatement": "This paper examines the experiences and expectations that HCI researchers have had with Pattern Language and provides reflections and directions on the use of Pattern Language in HCI.",
        "bookmarks": 143,
        "keywords": [
            "Design",
            "Patterns",
            "Pattern Language",
            "Research"
        ],
        "communities": [],
        "session": {
            "id": "s185",
            "name": "Reflection and Evaluation"
        },
        "room": "242ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth35271",
                "givenName": "Yue",
                "familyName": "Pan",
                "email": "panyue@indiana.edu",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth5985",
                "givenName": "Erik",
                "familyName": "Stolterman",
                "email": "estolter@indiana.edu",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 23,
        "name": "Mediated Meditation: Cultivating Mindfulness with Sonic Cradle",
        "type": "altchi",
        "abstract": "Sonic Cradle enables users to shape sound with their breath while suspended in a completely dark chamber.  We conducted a qualitative investigation to understand 39 naïve participants’ subjective responses to this design artifact.  Systematic analysis with 3 independent data coders produced 11 findings which richly describe the Sonic Cradle experience as clearly comparable to mindfulness meditation (e.g. clarity of mind, loss of intention). This paper shows how persuasive media have the potential to promote long-term psychological health by experientially introducing a stress-relieving, contemplative practice to non-practitioners.",
        "cbStatement": "Qualitative investigation of \"Sonic Cradle\" - an artifact involving suspension, visual deprivation, and musical biofeedback - shows how persuasive media could promote mental health by introducing non-practitioners to mindfulness meditation.",
        "bookmarks": 198,
        "keywords": [
            "Biofeedback",
            "mindfulness",
            "meditation",
            "sound",
            "music",
            "stress",
            "deprivation",
            "persuasive",
            "qualitative",
            "respiration."
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "alt0180-file5.mp4",
        "session": {
            "id": "s186",
            "name": "Spirit and Mind"
        },
        "room": "251",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth18674",
                "givenName": "Jay",
                "familyName": "Vidyarthi",
                "email": "kvidyart@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth18172",
                "givenName": "Bernhard",
                "middleInitial": "E.",
                "familyName": "Riecke",
                "email": "ber1@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 24,
        "name": "AniThings: Animism and Heterogeneous Multiplicity",
        "type": "altchi",
        "abstract": "This paper explores the metaphor of animism as a methodological framework for interaction design and, in particular, advocates for a form of animism the authors term ‘heterogeneous multiplicity.’ Animism can make valuable contributions within ubiquitous computing contexts, where objects with designed behaviors tend to evoke a perception that they have autonomy, intention, personality and an inner life. Furthermore, animism that supports heterogeneous multiplicity offers unique opportunities to stimulate human creativity through embodied engagement with an ecology of things. To demonstrate the concept of heterogeneous multiplicity, the authors present a speculative design project, AniThings, that intertwines multiple animistic collaborators to position activities of digital resource discovery and curation beyond the narrow domain of recommendation engines and personal feeds. The project illustrates an ecology of six tangible, interactive objects that, respectively, draw from a variety of digital resources and inhabit a range of variously positioned stances towards their human collaborators and each other. This diversity of behaviors, resources, and positionality makes AniThings ideal for supporting open-ended ideation and collaborative imagining activities.",
        "cbStatement": "Contributes a novel interaction design framework by proposing animism as a design metaphor, employing a heterogeneous ecology of multiple animistic devices that collaborate with people in creative contexts.",
        "bookmarks": 83,
        "keywords": [
            "animism",
            "heterogeneous multiplicity",
            "ubiquitous computing",
            "speculative design",
            "design fiction",
            "creative collaboration",
            "ecology of things"
        ],
        "communities": [
            "design",
            "ux",
            "arts"
        ],
        "session": {
            "id": "s184",
            "name": "Nature and Nurture"
        },
        "room": "351",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth35273",
                "givenName": "Philip",
                "middleInitial": "A",
                "familyName": "van Allen",
                "email": "vanallen@artcenter.edu",
                "primary": {
                    "dept": "Media Design Practices",
                    "institution": "Art Center College of Design",
                    "city": "Pasadena",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth26781",
                "givenName": "Joshua",
                "familyName": "McVeigh-Schultz",
                "email": "jrmcveig@usc.edu",
                "primary": {
                    "dept": "create",
                    "institution": "School of Cinematic Arts, Media Arts and Practice, University of Southern California",
                    "city": "Los Angeles",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth35275",
                "givenName": "Brooklyn",
                "familyName": "Brown",
                "email": "brooklyno@gmail.com",
                "primary": {
                    "dept": "create",
                    "institution": "Media Design Practices, Art Center College of Design",
                    "city": "Pasadena",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth35276",
                "givenName": "Hye Mi",
                "familyName": "Kim",
                "email": "hyemikim7@gmail.com",
                "primary": {
                    "dept": "create",
                    "institution": "Media Design Practices, Art Center College of Design",
                    "city": "Pasadena",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth35277",
                "givenName": "Daniel",
                "familyName": "Lara",
                "email": "x@daniellara.com",
                "primary": {
                    "dept": "create",
                    "institution": "Media Design Practices, Art Center College of Design",
                    "city": "Pasadena",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 25,
        "name": "Neurodiversity & HCI",
        "type": "altchi",
        "abstract": "The objective of this paper is to introduce the an implicit notion of ‘user’ in the singular and has received criticism from Feminist HCI[5]. Neurodiversity suggests that even these approaches carry with them certain assumptions about the cognitive processing abilities of users which need to be challenged.  This paper is concerned with the design and evaluation of interactive systems that are imbued with an awareness of the central commitments of neurodiversity.  The paper seeks to identify and promote neurodiversity under the banner of neurodiversity HCI. This paper introduces neurodiversity and then critically evaluates aspects of HCI from the neurodiversity perspective. ",
        "cbStatement": "Neurodiversity is a self advocacy rights movement challenging our notion of the single cognitive model for users. How to we evolve HCI if we try to design for the gifted? \\ ",
        "bookmarks": 164,
        "keywords": [
            "Neurodiversity",
            "theory",
            "giftedness;HCI practice;social justice."
        ],
        "communities": [
            "ux"
        ],
        "session": {
            "id": "s186",
            "name": "Spirit and Mind"
        },
        "room": "251",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth10945",
                "givenName": "Nicholas",
                "middleInitial": "Sheep",
                "familyName": "Dalton",
                "email": "n.dalton@open.ac.uk",
                "primary": {
                    "institution": "The Open University",
                    "city": "Milton Keynes",
                    "state": "Buckinghamshire",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 26,
        "name": "Animal-Computer Interaction (ACI): Changing Perspective on HCI, Participation and Sustainability",
        "type": "altchi",
        "abstract": "In the spirit of this year’s conference theme ‘changing perspectives’, this paper invites the CHI community to glance at interaction design through the lense of Animal-Computer Interaction (ACI). In particular, I argue that such a perspective could have at least three benefits: strengthening HCI as a discipline; broadening participation in Interaction Design; and supporting CHI’s commitment to sustainability. I make the case that, far from being a niche research area, ACI is directly relevant to and even encompasses HCI. Thus ACI research firmly belongs at CHI.",
        "cbStatement": "Argues that ACI is directly relevant to CHI, discussing how it can strengthen HCI as a discipline, broaden participation in Interaction Design, and support CHI’s commitment to sustainability.",
        "bookmarks": 159,
        "keywords": [
            "Designing-with, multispecies communities and ecologies, systemic design, human and nonhuman animal computer interactions"
        ],
        "communities": [
            "design",
            "ux",
            "games",
            "sustainability",
            "cci"
        ],
        "video": "alt0183-file5.mp4",
        "session": {
            "id": "s184",
            "name": "Nature and Nurture"
        },
        "room": "351",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth14267",
                "givenName": "Clara",
                "familyName": "Mancini",
                "email": "C.Mancini@open.ac.uk",
                "primary": {
                    "institution": "The Open University",
                    "city": "Milton Keynes",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 27,
        "name": "Personal Informatics and Reflection: A Critical Examination of the Nature of Reflection",
        "type": "altchi",
        "abstract": "Personal informatics systems that help people both collect and reflect on various kinds of personal information are growing rapidly. Despite the importance of journaling and the main role it has in tracking one’s personal growth, a limited number of studies have examined journaling in the area of personal informatics in detail. In this paper, we critically examine the process of reflection on experiences, thoughts and evolving insights through a qualitative research study. We also present the design research process we conducted to develop the Wandering Mind as a support tool to help individuals record and reflect on their experiences.",
        "cbStatement": "This study critically examined the process of reflection on one’s experiences, thoughts, and insights through design research; and Wandering Mind was designed as a support tool to facilitate this process. ",
        "bookmarks": 104,
        "keywords": [
            "Personal informatics",
            "reflection",
            "journaling"
        ],
        "communities": [],
        "video": "alt0184-file5.mp4",
        "session": {
            "id": "s185",
            "name": "Reflection and Evaluation"
        },
        "room": "242ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth28431",
                "givenName": "Afarin",
                "familyName": "Pirzadeh",
                "email": "apirzade@iupui.edu",
                "primary": {
                    "institution": "IUPUI",
                    "city": "Indianapolis",
                    "state": "Indiana",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "IUPUI",
                    "city": "Indianapolis",
                    "state": "Indiana",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth24940",
                "givenName": "Li",
                "familyName": "He",
                "email": "lh6@umail.iu.edu",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth5985",
                "givenName": "Erik",
                "familyName": "Stolterman",
                "email": "estolter@indiana.edu",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 28,
        "name": "STALLTALK: GRAFFITI, TOILETS, AND ANONYMOUS LOCATION BASED MICRO BLOGGING",
        "type": "altchi",
        "abstract": "The ways in which we leave graffiti have not changed much in thousands of years. Humans have felt the need to anonymously leave messages to one another for centuries. In this paper, we introduce StallTalk (www.stalltalk.info), an anonymous location-based micro blogging website that uses QR codes posted in bathroom stalls. StallTalk allows users to leave digital graffiti on bathroom walls without actually causing permanent damage. Users scan the QR codes, which are unique to each stall, and write short messages to each other. We deployed StallTalk in over 500 locations and have had almost 9,000 unique visitors to our website.",
        "cbStatement": "Stalltalk is a anonymous location based microblogging system that is used in bathrooms to explore toilet humor and digital graffiti. You can visit our site and participate at www.stalltalk.info!",
        "bookmarks": 76,
        "keywords": [
            "Location-based micro blog",
            "graffiti",
            "QR codes",
            "toilets",
            "bathrooms"
        ],
        "communities": [
            "ux",
            "games",
            "arts"
        ],
        "video": "alt0185-file5.mp4",
        "session": {
            "id": "s183",
            "name": "Ethics"
        },
        "room": "351",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth35281",
                "givenName": "Jonathan",
                "familyName": "Friedman",
                "email": "friedmanj@u.northwestern.edu",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "Northwestern Univeristy",
                    "city": "Evanston",
                    "state": "Illinois",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth5057",
                "givenName": "Michael",
                "familyName": "Horn",
                "email": "michael-horn@northwestern.edu",
                "primary": {
                    "dept": "Computer Science and Learning Sciences",
                    "institution": "Northwestern University",
                    "city": "Chicago",
                    "state": "Illinois",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 29,
        "name": "A Load of Cobbler’s Children: Beyond the Model Designing Processor",
        "type": "altchi",
        "abstract": "HCI has developed rich understandings of people at work and at play with technology, moving beyond users’ minds to their moods, buddies and bodies. However, understandings of designers remain trapped within the information processing paradigm of first wave HCI, remaining focused on minds that execute design methods as if they were computer programs, and producing the same results on a range of architectures and hardware. Designers are people too, with minds, moods, buddies and bodies, which all interfere substantially (generally to good effects) with the ‘code’ of design methods. We need to take full account of designers’ humanity when assessing design and evaluation methods. This juried alt.chi paper moves from critique to a logocentric proposal based on resource function vocabularies as a more appropriate basis for understanding and assessing methods.",
        "cbStatement": "Critiques common criteria applied when assessing research on innovative design and evaluation methods, and proposes resource function vocabularies as better lenses for focusing assessment of method effectiveness in interaction design ",
        "bookmarks": 72,
        "keywords": [
            "Design methods",
            "validation",
            "resource functions"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "alt0186-file5.mp4",
        "session": {
            "id": "s182",
            "name": "Design and Design Lessons"
        },
        "room": "342a",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth2739",
                "givenName": "Gilbert",
                "familyName": "Cockton",
                "email": "Gilbert.Cockton@northumbria.ac.uk",
                "primary": {
                    "institution": "Northumbria University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 30,
        "name": "Crafting Against Robotic Fakelore: On the Critical Practice of ArtBot Artists",
        "type": "altchi",
        "abstract": "We report on topics raised in encounters with a series of robotics oriented artworks, which to us were interpreted as a general critique to what could be framed as robotic fakelore, or mythology. We do this based on interviews held with artists within the community of ArtBots, and discuss how their approach relates to and contributes to the discourse of HCI. In our analysis we outline a rough overview of issues emerging in the interviews and reflect on the broader questions they may pose to our research community.",
        "cbStatement": "We report on topics raised in encounters with robotics oriented artworks, which to us were interpreted as a general critique to what could be framed as robotic fakelore, or mythology.",
        "bookmarks": 32,
        "keywords": [
            "Human-Robot Interaction",
            "Interactive Art",
            "Robotic Materials",
            "Interaction Design",
            "Fakelore"
        ],
        "communities": [
            "design",
            "arts"
        ],
        "session": {
            "id": "s185",
            "name": "Reflection and Evaluation"
        },
        "room": "242ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth12447",
                "givenName": "Mattias",
                "familyName": "Jacobsson",
                "email": "majac@sics.se",
                "primary": {
                    "institution": "Mobile Life @ Stockholm University",
                    "city": "Kista",
                    "country": "Sweden"
                },
                "role": "presenter"
            },
            {
                "id": "auth11627",
                "givenName": "Ylva",
                "familyName": "Fernaeus",
                "email": "fernaeus@kth.se",
                "primary": {
                    "dept": "MID/CSC/IxD",
                    "institution": "KTH - Royal Institute of Technology",
                    "city": "Stockholm",
                    "country": "Sweden"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth6136",
                "givenName": "Henriette",
                "familyName": "Cramer",
                "email": "Henriette@yahoo-inc.com",
                "primary": {
                    "institution": "Yahoo! Labs",
                    "city": "Sunnyvale",
                    "country": "USA"
                }
            },
            {
                "id": "auth31597",
                "givenName": "Sara",
                "familyName": "Ljungblad",
                "email": "sara@lotsdesign.se",
                "primary": {
                    "dept": "LOTS Design",
                    "institution": "University of Gothenburg",
                    "city": "Gothenburg",
                    "state": "-",
                    "country": "Sweden"
                }
            }
        ]
    },
    {
        "id": 31,
        "name": "Beyond Recognition: Using Gesture Variation for Continuous Interaction",
        "type": "altchi",
        "abstract": "Gesture-based interaction is widespread in touch screen interfaces. The goal of this paper is to tap the richness of expressive variation in gesture to facilitate continuous interaction. We achieve this through novel techniques of adaptation and estimation of gesture characteristics. We describe two experiments. The first aims at understanding whether users can control certain gestural characteristics and if that control depends on gesture vocabulary. The second study uses a machine learning technique based on particle filtering to simultaneously recognize and measure variation in a gesture. With this technology, we create a gestural interface for a playful photo processing application. From these two studies, we show that 1) multiple characteristics can be varied independently in slower gestures (Study 1), and 2) users find gesture-only interaction less pragmatic but more stimulating than traditional menu-based systems (Study 2).",
        "cbStatement": "The goal of this paper is to tap the richness of expressive variation in gesture to facilitate continuous interaction through novel techniques of adaptation and estimation of gesture characteristics.",
        "bookmarks": 15,
        "keywords": [
            "Gestural Interaction",
            "Continuous Interaction",
            "Gesture Recognition",
            "Motor Control"
        ],
        "communities": [
            "engineering",
            "arts"
        ],
        "video": "alt0189-file5.mp4",
        "session": {
            "id": "s182",
            "name": "Design and Design Lessons"
        },
        "room": "342a",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth20242",
                "givenName": "Baptiste",
                "familyName": "Caramiaux",
                "email": "b.caramiaux@gold.ac.uk",
                "primary": {
                    "dept": "Department of Computing",
                    "institution": "Goldsmiths, University of London",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth23475",
                "givenName": "Frederic",
                "familyName": "Bevilacqua",
                "email": "frederic.bevilacqua@ircam.fr",
                "primary": {
                    "institution": "IRCAM",
                    "city": "Paris",
                    "country": "France"
                }
            },
            {
                "id": "auth6018",
                "givenName": "Atau",
                "familyName": "Tanaka",
                "email": "a.tanaka@gold.ac.uk",
                "primary": {
                    "dept": "Department of Computing",
                    "institution": "Goldsmiths, University of London",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 32,
        "name": "An Implicit Test Of UX: Individuals Differ In What They Associate With Computers",
        "type": "altchi",
        "abstract": "User experience research has made considerable progress in understanding subjective experience with interactive technology. Nevertheless, we argue, some blind spots have remained: individual differences are frequently ignored, the prevalent measures of self-report rarely undergo verification, and overly focus is on utilitarian and hedonic dimensions of experience. \\ A Stroop priming experiment was constructed to assess what people implicitly associate with a picture of a computing device. Three categories of target words were presented: hedonic, utilitarian and “geek” words. Longer response times were interpreted as stronger associations. Need-for-cognition and subject of undergraduate study (computer science vs. psychology) were taken as predictors for a hypothetical geek personality. The results suggest that persons with a geek predisposition tend to think of computers as objects of intellectual challenge and play, rather than tools or extensions of the self. \\ ",
        "cbStatement": "Do all users have the same associations when thinking of computers? We introduce a novel experimental approach and find that some users value geekism over utility or hedonic qualities.",
        "bookmarks": 86,
        "keywords": [
            "geekism",
            "hedonism",
            "usability",
            "user experience",
            "Stroop task",
            "priming",
            "multi-method",
            "implicit method",
            "mixed-effects models",
            "individual differences",
            "need for cognition"
        ],
        "communities": [
            "design",
            "engineering",
            "ux"
        ],
        "video": "alt0190-file5.mp4",
        "session": {
            "id": "s187",
            "name": "Experiences"
        },
        "room": "251",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth9122",
                "givenName": "Martin",
                "familyName": "Schmettow",
                "email": "m.schmettow@utwente.nl",
                "primary": {
                    "dept": "Cognitive Psychology & Ergonomics",
                    "institution": "University of Twente",
                    "city": "Enschede",
                    "country": "The Netherlands"
                },
                "role": "presenter"
            },
            {
                "id": "auth29150",
                "givenName": "Matthijs",
                "middleInitial": "L",
                "familyName": "Noordzij",
                "email": "m.l.noordzij@utwente.nl",
                "primary": {
                    "dept": "Cognitive Psychology & Ergonomics",
                    "institution": "University of Twente",
                    "city": "Enschede",
                    "country": "The Netherlands"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29149",
                "givenName": "Matthias",
                "familyName": "Mundt",
                "email": "m.mundt@student.utwente.nl",
                "primary": {
                    "institution": "University of Twente",
                    "city": "Enschede",
                    "country": "The Netherlands"
                }
            }
        ]
    },
    {
        "id": 33,
        "name": "A Biological Imperative for Interaction Design",
        "type": "altchi",
        "abstract": "This paper presents an emerging approach to the integration of biological systems- their matter, mechanisms, and metabolisms- into models of interaction design. By bringing together conceptual visions and initial experiments of alternative bio based approaches to sensing, display, fabrication, materiality, and energy, we seek to construct an inspirational discussion platform approaching non-living and living matter as a continuum for computational interaction. We also discuss the emergence of the DIY bio and open source biology movements, which allow non-biologists to gain access to the processes, tools, and infrastructure of this domain, and introduce Synbiota, an integrated, web-based platform for synthetic biology research.",
        "bookmarks": 179,
        "keywords": [
            "Interaction Design",
            "Biological Design",
            "DIY Bio",
            "Open Source",
            "Physical Computing",
            "Tangible Media",
            "Organic User Interfaces  "
        ],
        "communities": [
            "design"
        ],
        "session": {
            "id": "s184",
            "name": "Nature and Nurture"
        },
        "room": "351",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth3346",
                "givenName": "Amanda",
                "middleInitial": "J",
                "familyName": "Parkes",
                "email": "amanda@media.mit.edu",
                "primary": {
                    "dept": "School of Architecture",
                    "institution": "Columbia University",
                    "city": "New York City",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth2605",
                "givenName": "Connor",
                "familyName": "Dickie",
                "email": "connor@cs.queensu.ca",
                "primary": {
                    "institution": "Queen's University, Kingston",
                    "city": "Kingston",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 34,
        "name": "“Un-Googling” Publications: The Ethics and Problems of Anonymization",
        "type": "altchi",
        "abstract": "Digital tools of research dissemination make scholarly publications accessible to the public at large through simple search engines. As a result, the users that we study, interview, and cite may be at risk of exposure to unwelcome types of scrutiny and scholars must grapple with challenges to the ethics of exposure of our re-search participants. We present one approach to anonymization of research results with search engines in mind, which we call un-Googling, that we have developed to minimize risk to our participants. We discuss the considerations that this approach raises and pose a challenge to the HCI community to take up this discussion not only as an ethical consideration but also as a socio-technical research and design opportunity.",
        "cbStatement": "How to protect our study participants from inadvertent identification in the era of powerful indexing, search and retrieval algorithms? We propose a solution.",
        "bookmarks": 110,
        "keywords": [
            "un-Googling",
            "research ethics",
            "exposure",
            "anonymity",
            "publication."
        ],
        "communities": [],
        "session": {
            "id": "s183",
            "name": "Ethics"
        },
        "room": "351",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth1990",
                "givenName": "Irina",
                "middleInitial": "A",
                "familyName": "Shklovski",
                "email": "irsh@itu.dk",
                "primary": {
                    "institution": "IT University of Copenhagen",
                    "city": "Copenhagen",
                    "country": "Denmark"
                },
                "role": "presenter"
            },
            {
                "id": "auth8114",
                "givenName": "Janet",
                "familyName": "Vertesi",
                "email": "jvertesi@princeton.edu",
                "primary": {
                    "institution": "Princeton University",
                    "city": "Princeton",
                    "state": "New Jersey",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 35,
        "name": "The Elephant in the Conference Room: Let’s Talk About Experience Terminology",
        "type": "altchi",
        "abstract": "We reflect upon how the ambiguous and often conflicting definitions of experience terminology (e.g., HFE, Usability, IxD, HCI, UX, XD) are impacting our understanding of the field as well as our ability to communicate, collaborate and educate others. We analyze the history of relevant disciplines and discuss the findings of an online survey completed by academics and professionals, which indicates a high variety in interpretation of terms. Further, we discuss surveys of job descriptions and related academic programs, and provide our perspective on the impact of this problem, as well as suggestions on how to begin to solve it.",
        "cbStatement": "We reflect upon how conflicting definitions of experience terminology (HFE, Usability, IxD, HCI, UX, XD) impact our understanding of the field and our ability to communicate, collaborate and educate others. ",
        "bookmarks": 128,
        "keywords": [
            "Terminology",
            "confusion",
            "ambiguity",
            "XD",
            "UX",
            "IxD",
            "HFE",
            "ergonomics",
            "HCI",
            "HCC",
            "usability"
        ],
        "communities": [
            "design",
            "engineering",
            "ux",
            "arts"
        ],
        "session": {
            "id": "s187",
            "name": "Experiences"
        },
        "room": "251",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth34521",
                "givenName": "Analia",
                "familyName": "Ibargoyen",
                "email": "analia.ibargoyen@intel.com",
                "primary": {
                    "institution": "Intel",
                    "city": "Santa Clara",
                    "state": "CA",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth19574",
                "givenName": "Dalila",
                "familyName": "Szostak",
                "email": "dalila.szostak@intel.com",
                "primary": {
                    "institution": "Intel",
                    "city": "Hillsboro",
                    "state": "Portland",
                    "country": "United States"
                }
            },
            {
                "id": "auth34580",
                "givenName": "Miroslav",
                "familyName": "Bojic",
                "email": "miro.bojic@gmail.com",
                "primary": {
                    "institution": "sencha",
                    "city": "redwood city",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 36,
        "name": "Sound Design As Human Matter Interaction",
        "type": "altchi",
        "abstract": "Recently, terms like material computation or natural computing in foundations of computer science and engineering, and new materiality in cultural studies signal a broader turn to conceptions of the world that are not based on solely human categories.   While respecting the values of human-centered design, how can we begin to think about the design of responsive environments and computational media while paying as much attention to material qualities like elasticity, density, wear, and tension as to social and cognitive phenomena?   This question understands computation as a potential property of matter in a non-reductive way that plausibly spans formal divides between symbolic-semiotic, social, and physical processes.   Full investigation greatly exceeds one brief paper.  But we open this question in the concrete practices of computational sound and sound design.",
        "cbStatement": "Realtime responsive sound design provides models for non-anthropocentric approaches to interactions between humans and computational matter.  We approach this in light of new materiality and material computation.",
        "bookmarks": 19,
        "keywords": [
            "Materiality",
            "Material Computation",
            "Computational Media",
            "Computational Physics",
            "Digital Sound Synthesis"
        ],
        "communities": [
            "design",
            "engineering",
            "ux",
            "arts"
        ],
        "session": {
            "id": "s185",
            "name": "Reflection and Evaluation"
        },
        "room": "242ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth26813",
                "givenName": "Xin Wei",
                "familyName": "Sha",
                "email": "shaxinwei@gmail.com",
                "primary": {
                    "dept": "Topological Media Lab",
                    "institution": "Concordia University",
                    "city": "Montreal",
                    "state": "Quebec",
                    "country": "Canada"
                },
                "secondary": {
                    "dept": "Gray Center for Arts and Inquiry",
                    "institution": "University of Chicago",
                    "city": "Chicago",
                    "state": "Illinois",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth24892",
                "givenName": "Adrian",
                "familyName": "Freed",
                "email": "adrian@cnmat.berkeley.edu",
                "primary": {
                    "institution": "CNMAT UC Berkeley",
                    "city": "Berkeley",
                    "state": "CA",
                    "country": "USA"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth35295",
                "givenName": "Navid",
                "familyName": "Navab",
                "email": "navid.nav@gmail.com",
                "primary": {
                    "dept": "Topological Media Lab",
                    "institution": "Concordia University",
                    "city": "Montreal",
                    "state": "Quebec",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 37,
        "name": "Enhancing Company Communication: The Case of a Social Media Platform",
        "type": "casestudy",
        "abstract": "This case study reports on the pilot phase of a social media platform, based on Microsoft SharePoint 2010, which should enhance the communication between and within departments of an internationally operating semiconductor manufacturing company, which has different sites in Europe, the US, and Asia. Our research group monitored this pilot phase in order to increase the acceptability and usage among the employees of the company. Five different HCI actions have been undertaken for that: Information kick-off workshops to raise awareness, a survey on success criteria, an expert evaluation on usability problems, a collaborative use case definition, and a survey on benchmarking the tool in terms of user experience and acceptability. We demonstrate the benefits of HCI research for the introduction of this communication tool in the company.",
        "cbStatement": "This case study presents lessons learned from the introduction of a social media platform in an internationally operating company with five HCI actions to ensure a positive user experience. ",
        "bookmarks": 131,
        "keywords": [
            "Computer-Mediated Communication",
            "Office and Workplace",
            "Social Media",
            "Industrial Research"
        ],
        "communities": [
            "ux"
        ],
        "video": "cs0103-file5.mp4",
        "session": {
            "id": "s190",
            "name": "Communitites of practice"
        },
        "room": "342a",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth27669",
                "givenName": "Alina",
                "familyName": "Krischkowsky",
                "email": "alina.krischkowsky@sbg.ac.at",
                "primary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                },
                "secondary": {
                    "dept": "ICT&S Center",
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                },
                "role": "presenter"
            },
            {
                "id": "auth9831",
                "givenName": "Astrid",
                "familyName": "Weiss",
                "email": "astrid.weiss@sbg.ac.at",
                "primary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                },
                "secondary": {
                    "institution": "ICT&S Center University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                }
            },
            {
                "id": "auth15247",
                "givenName": "Sebastian",
                "familyName": "Osswald",
                "email": "sebastian.osswald@sbg.ac.at",
                "primary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                },
                "secondary": {
                    "dept": "ICT&S Center",
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                }
            },
            {
                "id": "auth3460",
                "givenName": "Manfred",
                "familyName": "Tscheligi",
                "email": "manfred.tscheligi@sbg.ac.at",
                "primary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                },
                "secondary": {
                    "dept": "ICT&S Center",
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 38,
        "name": "Counter Entropy: Visualizing Power Consumption in an Energy+ House",
        "type": "casestudy",
        "abstract": "This case study presents the design and evaluation of an end-user energy consumption display for an energy+ house.  \\ The goal of our application is to give an easy overview over the power balance and to provide the user with the necessary information to understand specific consumption patterns.  \\ We defined the unit of Counter Entropy points and used it to create several visualizations showing the consumption of appliances, climate control, and lighting.  \\ Our evaluation showed that users easily understand where the currently consumed power is sourced and which factors influence the overall power consumption.",
        "cbStatement": "This Case Study presents the design and evaluation of a home automation control application that supports easy understanding and analysis of household energy consumption.",
        "bookmarks": 33,
        "keywords": [
            "Energy consumption",
            "visualization",
            "home automation"
        ],
        "communities": [
            "sustainability"
        ],
        "video": "cs0107-file5.mp4",
        "session": {
            "id": "s191",
            "name": "Case Studies in Novel Settings"
        },
        "room": "342a",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth12608",
                "givenName": "Florian",
                "familyName": "Heller",
                "email": "flo@cs.rwth-aachen.de",
                "primary": {
                    "institution": "RWTH Aachen University",
                    "city": "Aachen",
                    "state": "NRW",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth31461",
                "givenName": "Konstantinos",
                "familyName": "Tsoleridis",
                "email": "konstantinos.tsoleridis@rwth-aachen.de",
                "primary": {
                    "institution": "RWTH Aachen University",
                    "city": "Aachen",
                    "state": "NRW",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1497",
                "givenName": "Jan",
                "familyName": "Borchers",
                "email": "borchers@cs.rwth-aachen.de",
                "primary": {
                    "institution": "RWTH Aachen University",
                    "city": "Aachen",
                    "state": "NRW",
                    "country": "Germany"
                }
            }
        ]
    },
    {
        "id": 39,
        "name": "A Software Development Methodology for Sustainable ICTD Solutions",
        "type": "casestudy",
        "abstract": "Information and Communication Technology continue to be increasingly used in social development and poverty alleviation projects, known as Information and Communication Technology for Development (ICTD) projects. However, most interventions either fail completely as a result of attempting to use inappropriate software development approaches and technology concepts in the different ICTD context or they only execute small scale prototypes without positive long-term social impact. We present a case study on how we combined and adapted, using an iterative action research refinement approach, established interaction design methods into a software development methodology supporting scalable long-term ICTD software projects: the Technical ICTD Methodology (TIM). Our case study is based on the experiences of a series of ICTD projects executed within a major software corporation over a period of more than five years.",
        "cbStatement": "Case study describing development of a software development methodology that supports development of sustainable and scalable long-term ICTD solutions. Can assist ICTD software development projects.  \\ ",
        "bookmarks": 61,
        "keywords": [
            "Software Development Methodology",
            "ICTD"
        ],
        "communities": [
            "hci4d"
        ],
        "video": "cs0112-file5.mp4",
        "session": {
            "id": "s191",
            "name": "Case Studies in Novel Settings"
        },
        "room": "342a",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth31176",
                "givenName": "Joerg",
                "familyName": "Doerflinger",
                "email": "joerg.doerflinger@sap.com",
                "primary": {
                    "institution": "SAP Research",
                    "city": "Karlsruhe",
                    "state": "Baden-Württemberg",
                    "country": "Germany"
                },
                "secondary": {
                    "institution": "SAP Research",
                    "city": "Karlsruhe",
                    "state": "Baden-Württemberg",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth2902",
                "givenName": "Andy",
                "familyName": "Dearden",
                "email": "a.m.dearden@shu.ac.uk",
                "primary": {
                    "institution": "Sheffield Hallam University",
                    "city": "Sheffield",
                    "country": "United Kingdom"
                },
                "secondary": {
                    "institution": "Sheffield Hallam University",
                    "city": "Sheffield",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth1413",
                "givenName": "Tom",
                "familyName": "Gross",
                "email": "tom.gross@uni-bamberg.de",
                "primary": {
                    "dept": "Human-Computer Interaction Group",
                    "institution": "University of Bamberg",
                    "city": "Bamberg",
                    "country": "Germany"
                },
                "secondary": {
                    "dept": "Human-Computer Interaction Group",
                    "institution": "University of Bamberg",
                    "city": "Bamberg",
                    "country": "Germany"
                }
            }
        ]
    },
    {
        "id": 40,
        "name": "UX Design with International Teams: Challenges and Best Practices",
        "type": "casestudy",
        "abstract": "International UX collaboration has become the necessity for producing great global products. Microsoft Windows Intune™, an IT management and security product in the cloud, consists of engineering groups in different parts of the world. \\  \\ Being a UX designer leading projects with multiple stakeholders, vendors and contractors from U.S., China and Israel, I would like to share my insights on the challenges and best practices – organizing seeding and recurring visits; having key remote UX champions; utilizing the right communication channels; sharing works early; and be sensitive of time zone and cultural differences.",
        "cbStatement": "Being a UX designer at Microsoft leading projects with multiple stakeholders from U.S., China and Israel, I would like to share my insights on the challenges and best practices.",
        "bookmarks": 14,
        "keywords": [
            "User Experience",
            "Design Management",
            "International Collaboration"
        ],
        "communities": [
            "management",
            "ux"
        ],
        "video": "cs0113-file5.mp4",
        "session": {
            "id": "s193",
            "name": "Case Studies in innovating UCD Process"
        },
        "room": "342a",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth31502",
                "givenName": "Charles",
                "familyName": "Yiu",
                "email": "cyiu@microsoft.com",
                "primary": {
                    "institution": "Microsoft Corporation",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 41,
        "name": "Multi-modal Location-Aware System  for Paratrooper Team Coordination",
        "type": "casestudy",
        "abstract": "Navigation and assembly are critical tasks for Soldiers in battlefield situations. Paratroopers, in particular, must be able to parachute into a battlefield and locate and assemble their equipment as quickly and quietly as possible. Current assembly methods rely on bulky and antiquated equipment that inhibit the speed and effectiveness of such operations. To address this we have created a multi-modal mobile navigation system that uses ruggedized to mark assembly points and smartphones to assist in navigating to these points while minimizing cognitive load and maximizing situational awareness. To achieve this task, we implemented a novel beacon receiver protocol that allows an infinite number of receivers to listen to the encrypted beaconing message using only ad-hoc Wi-Fi technologies. The system was evaluated by U.S. Army Paratroopers and proved quick to learn and efficient at moving Soldiers to navigation waypoints. Beyond military operations, this system could be applied to any task that requires the assembly and coordination of many individuals or teams, such as emergency evacuations, fighting wildfires or locating airdropped humanitarian aid.",
        "cbStatement": "Lessons learned through an ethnographic analysis of Paratroopers facilitated the development of a location-aware navigation system and helped to effectively address common battlefield constraints while capitalizing on users' expectations.",
        "bookmarks": 29,
        "keywords": [
            "User-centered design",
            "location-aware",
            "ad-hoc networks",
            "military applications"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "cs0114-file5.mp4",
        "session": {
            "id": "s192",
            "name": "Case Studies in the wild"
        },
        "room": "342a",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth23802",
                "givenName": "Danielle",
                "familyName": "Cummings",
                "email": "dcummings@cse.tamu.edu",
                "primary": {
                    "institution": "Texas A&M University",
                    "city": "College Station",
                    "state": "Texas",
                    "country": "United States"
                }
            },
            {
                "id": "auth14128",
                "givenName": "Manoj",
                "familyName": "Prasad",
                "email": "manoj.prasad@neo.tamu.edu",
                "primary": {
                    "institution": "Texas A&M University",
                    "city": "College Station",
                    "state": "Texas",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth20899",
                "givenName": "George",
                "familyName": "Lucchese",
                "email": "george_lucchese@tamu.edu",
                "primary": {
                    "institution": "Texas A&M University",
                    "city": "College Station",
                    "state": "Texas",
                    "country": "United States"
                }
            },
            {
                "id": "auth18696",
                "givenName": "Christopher",
                "familyName": "Aikens",
                "email": "chris_aikens@neo.tamu.edu",
                "primary": {
                    "institution": "Texas A&M University",
                    "city": "College Station",
                    "state": "Texas",
                    "country": "United States"
                }
            },
            {
                "id": "auth3390",
                "givenName": "Tracy",
                "familyName": "Hammond",
                "email": "hammond@cs.tamu.edu",
                "primary": {
                    "institution": "Texas A&M University",
                    "city": "College Station",
                    "state": "Texas",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 42,
        "name": "Biometric Interaction – a Case Study of Visual Feedback and Privacy Issues in New Face Recognition Solutions",
        "type": "casestudy",
        "abstract": "This case study describes how to convert a gate system from using magnetic keycards to face recognition. The gate is placed at one of Europe's biggest indoor training facilities, IKSU. The goal with this case study was to make the system efficient, easy to use and friendly.",
        "cbStatement": "This study brings a face recognition algorithm into a real-life gate system at an indoor training facility. The goal was to make the system efficient, easy to use and friendly.",
        "bookmarks": 188,
        "keywords": [
            "interaction",
            "user experience",
            "biometric interaction",
            "face recognition",
            "gate system",
            "case study"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "cs0119-file5.mp4",
        "session": {
            "id": "s191",
            "name": "Case Studies in Novel Settings"
        },
        "room": "342a",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth31540",
                "givenName": "Per",
                "familyName": "Kvarnbrink",
                "email": "per.kvarnbrink@tfe.umu.se",
                "primary": {
                    "institution": "Umea Universitet",
                    "city": "Umea",
                    "country": "Sweden"
                },
                "role": "presenter"
            },
            {
                "id": "auth31316",
                "givenName": "Karin",
                "familyName": "Fahlquist",
                "email": "karin.fahlquist@tfe.umu.se",
                "primary": {
                    "institution": "Umea Universitet",
                    "city": "Umea",
                    "country": "Sweden"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth31521",
                "givenName": "Thomas",
                "familyName": "Mejtoft",
                "email": "thomas.mejtoft@tfe.umu.se",
                "primary": {
                    "institution": "Umea Universitet",
                    "city": "Umea",
                    "country": "Sweden"
                }
            }
        ]
    },
    {
        "id": 43,
        "name": "Leverage User Experience through Social Networking to Improve Health Adherence",
        "type": "casestudy",
        "abstract": "Patient adherence is an important factor in improving health outcomes. However, as one of the causes of increasing population with chronic diseases, low adherence has become a major health care issue globally. Often, due to deferred benefits of treatment or lifestyle recommendations, many fail to adhere to their treatment regimen or health plans given by care providers until their conditions deteriorate. As poor adherence remains a significant yet inadequately addressed problem of severe health issues, it is critical to create effective interventions as part of the solutions.  \\  \\ Previous studies have suggested that peer supports be effective to improve adherence, and social cognitive theories have indicated that personal realization and confidence enhanced through entertaining gaming elements could encourage behavior change. To understand how different motivation factors affect user experience through social networking, a health care adherence website with built-in behavior analyses was constructed to conduct experiments. Users' health adherence levels can be reported to the website and shared among consenting social members for discussion or competition. Key design and development components are illustrated through the case study, including a social gaming and learning portal, an engineering approach to supporting different application scenarios, and information interventions based on predefined rules to achieve effective adherence. The preliminary analysis showed that people using social media for health care adherence may be motivated differently and act strategically during their social interactions. \\ ",
        "cbStatement": "This case study makes a contribution to Human-Computer and Human-Human Interactions and the use of social media/gaming in the health care sector. ",
        "bookmarks": 12,
        "keywords": [
            "User model",
            "psychological needs",
            "motivation",
            "social networking",
            "health adherence"
        ],
        "communities": [
            "ux",
            "health"
        ],
        "video": "cs0126-file5.mp4",
        "session": {
            "id": "s190",
            "name": "Communitites of practice"
        },
        "room": "342a",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth27396",
                "givenName": "Raymund",
                "familyName": "Lin",
                "email": "raymundl@tw.ibm.com",
                "primary": {
                    "institution": "IBM",
                    "city": "Taipei",
                    "country": "Taiwan"
                },
                "secondary": {
                    "institution": "IBM",
                    "city": "Taipei",
                    "country": "Taiwan"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth31387",
                "givenName": "Xinxin",
                "familyName": "Zhu",
                "email": "zhux@us.ibm.com",
                "primary": {
                    "institution": "IBM T.J. Watson Research ",
                    "city": "Yorktown Heights",
                    "state": "New York",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "IBM Watson Research Center",
                    "city": "Yorktown Heights",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 44,
        "name": "Don’t Talk to Strangers! Peer Tutoring versus Active Intervention methodologies in interviewing children",
        "type": "casestudy",
        "abstract": "Digital products designed for children should be validated by children. When it comes to usability testing, not all the available methods which work well with adults are equally applicable with child participants. In our study, we investigated two methods, Peer Tutoring which was developed for children, and Active Intervention which originates from the more traditional Think-Aloud methodology with adults. Our goal was to find out which of the two methods does elicit more comments by 8-10 years old boys when using a web application. The results showed that Peer Tutoring did elicit the greatest number of comments. At the same time the number of prompts provided by the test moderator was tendentially lower than during Active Intervention.",
        "cbStatement": "Based on our internal, qualitative studies, we found Peer Tutoring to be an appropriate method for usability testing with children.",
        "bookmarks": 18,
        "keywords": [
            "Peer Tutoring",
            "Active Intervention",
            "Usability evaluation",
            "Methodology",
            "Verbal comments",
            "Children"
        ],
        "communities": [
            "ux",
            "cci"
        ],
        "video": "cs0127-file5.mp4",
        "session": {
            "id": "s190",
            "name": "Communitites of practice"
        },
        "room": "342a",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth31389",
                "givenName": "Svetlana",
                "familyName": "Ognjanovic",
                "email": "svetlana.ognjanovic@LEGO.com",
                "primary": {
                    "dept": "The LEGO Group",
                    "institution": "Digital Solutions",
                    "city": "New York",
                    "state": "NY",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth31698",
                "givenName": "Jason",
                "familyName": "Ralls",
                "email": "Jason.Ralls@LEGO.com",
                "primary": {
                    "dept": "The LEGO Group",
                    "institution": "Digital Solutions",
                    "city": "Billund",
                    "country": "Denmark"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 45,
        "name": "Automotive HMI Test Package: An Exploitable Approach to Study In-Car HMIs",
        "type": "casestudy",
        "abstract": "This case study describes the development of a method package for evaluating in-car HMIs holistically. The goal is to provide a toolbox that is easy to replicate and allows evaluators to identify the effects of the system usage on the drivers’ state. Additionally it aims at finding interface flaws that cause distraction and negative experiences. We applied the toolbox in two example studies, which informed the further application of the HMI study approach. We learned that the combination of established expert and end user methods with a real test track leads to useful results that are easy to communicate to both scientific and public audiences.",
        "cbStatement": "This case study describes our approach on how to holistically evaluate multifunctional in-car HMIs of modern cars and how we addressed related challenges.",
        "bookmarks": 134,
        "keywords": [
            "Automotive HMI",
            "case study",
            "distraction",
            "evaluation."
        ],
        "communities": [
            "ux"
        ],
        "video": "cs0131-file5.mp4",
        "session": {
            "id": "s192",
            "name": "Case Studies in the wild"
        },
        "room": "342a",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth9854",
                "givenName": "David",
                "familyName": "Wilfinger",
                "email": "david.wilfinger@sbg.ac.at",
                "primary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                },
                "secondary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                },
                "role": "presenter"
            },
            {
                "id": "auth9353",
                "givenName": "Alexander",
                "familyName": "Meschtscherjakov",
                "email": "alexander.meschtscherjakov@sbg.ac.at",
                "primary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                },
                "secondary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth21293",
                "givenName": "Nicole",
                "familyName": "Perterer",
                "email": "nicole.perterer@sbg.ac.at",
                "primary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                },
                "secondary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                }
            },
            {
                "id": "auth16954",
                "givenName": "Martin",
                "familyName": "Murer",
                "email": "martin.murer@sbg.ac.at",
                "primary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                },
                "secondary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                }
            },
            {
                "id": "auth31437",
                "givenName": "Arno",
                "familyName": "Laminger",
                "email": "arno.laminger@sbg.ac.at",
                "primary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                },
                "secondary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                }
            },
            {
                "id": "auth3460",
                "givenName": "Manfred",
                "familyName": "Tscheligi",
                "email": "manfred.tscheligi@sbg.ac.at",
                "primary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                },
                "secondary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                }
            }
        ]
    },
    {
        "id": 46,
        "name": "Creating Small Products at a Big Company: Adobe's \"Pipeline\" Innovation Process",
        "type": "casestudy",
        "abstract": "Pipeline is a new development process at Adobe designed to rapidly prototype and evaluate new product offerings. Pipeline has user research at its core, and success is defined by how much is learned about a given problem, not by how much product is built. Starting ideas for new product directions are identified through Contextual Inquiry. Once a product direction is selected, an iterative process of development and evaluation is carried out over a 13-week period. Opportunities to pivot are built in at 3-week intervals, driven by evaluation results from laboratory studies. The Pipeline process is explained through an example product prototype, called \"Gadget\". Gadget is an application targeted at Web developers that helps them more easily experiment with and modify the visual layout of a Web page.",
        "cbStatement": "Pipeline is a new development process at Adobe designed to rapidly evaluate product ideas. We detail our adaption of lean approaches to the realities of a 10,000+ person company.",
        "bookmarks": 129,
        "keywords": [
            "User-centered design",
            "Innovation",
            "Agile"
        ],
        "communities": [
            "management",
            "ux"
        ],
        "video": "cs0133-file5.m4v",
        "session": {
            "id": "s193",
            "name": "Case Studies in innovating UCD Process"
        },
        "room": "342a",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth31608",
                "givenName": "Rob",
                "familyName": "Adams",
                "email": "adams@adobe.com",
                "primary": {
                    "institution": "Adobe Systems",
                    "city": "San Francisco",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth31609",
                "givenName": "Bradee",
                "familyName": "Evans",
                "email": "bevans@adobe.com",
                "primary": {
                    "institution": "Adobe Systems",
                    "city": "San Francisco",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth7461",
                "givenName": "Joel",
                "familyName": "Brandt",
                "email": "joel.brandt@adobe.com",
                "primary": {
                    "institution": "Adobe Research",
                    "city": "San Francisco",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 47,
        "name": "Data-driven Design Process in Adoption of Marking Menus for Large Scale Software",
        "type": "casestudy",
        "abstract": "This case study presents the iterative design process where usage data and feedback played key role in successful adoption of the marking menu to Autodesk’s major mechanical engineering software, Inventor.",
        "cbStatement": "This case study presents the user-centered design process that helped delivering the successful integration of marking menu into Autodesk Inventor, Autodesk’s flagship mechanical engineering software. ",
        "bookmarks": 25,
        "keywords": [
            "Marking Menus",
            "Autodesk Inventor",
            "User-Centered Design",
            "Agile",
            "Contextual Menus"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "cs0135-file5.mp4",
        "session": {
            "id": "s193",
            "name": "Case Studies in innovating UCD Process"
        },
        "room": "342a",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth31465",
                "givenName": "Ji-Young",
                "familyName": "Oh",
                "email": "ji-young.oh@autodesk.com",
                "primary": {
                    "dept": "User Experience Design",
                    "institution": "Autodesk, Inc.",
                    "city": "Lake Oswego",
                    "state": "Oregon",
                    "country": "United States"
                },
                "secondary": {
                    "dept": "User Experience Design",
                    "institution": "Autodesk, Inc.",
                    "city": "Lake Oswego",
                    "state": "Oregon",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth31466",
                "givenName": "Ananth",
                "familyName": "Uggirala",
                "email": "ananth.uggirala@autodesk.com",
                "primary": {
                    "dept": "User Experience Design",
                    "institution": "Autodesk, Inc.",
                    "city": "San Francisco",
                    "state": "California",
                    "country": "United States"
                },
                "secondary": {
                    "dept": "User Experience Design",
                    "institution": "Autodesk, Inc.",
                    "city": "San Francisco",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 48,
        "name": "The Democratization of Mission Control",
        "type": "casestudy",
        "abstract": "In 2002, at the Jet Propulsion Laboratory, during observations of space operations teams preparing for the 2003 Mars Exploration Rover Missions, the User Centered Technology Group from NASA Ames Research Center observed users coping with software interoperability issues. The packaging of software in multiple applications, each with its own pre-determined set of compartmentalized functions, forced users into the role of software integrators. \\  \\ In 2008 the Mission Control Technologies (MCT) project sought to address these issues by replacing multiple NASA Mission Control applications with composable user-objects. The primary stakeholders were NASA flight controllers and mission operations management. \\  \\ The feature that sold mission management on the project was that user objects modeled their real world counterparts. Once a user object was created, say for Space Station telemetry, that object could be reused. This meant that the association between a user object and it’s data needed to happen once, as opposed to previous software systems, which required data to be associated with on screen displays each time a new display was built.  \\  \\ While we sought to design and develop a new system, it was important to realize that the existing software was working, that users were familiar with that software from years of use, and the introduction of change was potentially disruptive to users.   \\  \\ At the request of our customer, the initial MCT user objects would be for telemetry and monitoring of the Space Station. To design the software, we used participatory design (PD), in which the users are the domain experts and the designers facilitate the sessions. In addition to creating the artifacts that the team needed to build design specifications, the PD sessions forged bonds between the teams. For the users, the PD sessions were often the first time that they created explicit representations of their work.  \\  \\ The team used agile development methods. Deliveries to the customer were made every three weeks, with a release every twelve weeks. A nightly build was available for download. A strategic road map guided priorities for design and development. \\  \\ The agile development cycle resulted in a multi-front set of engagements for the user experience team. The nightly build allowed the customer to provide daily feedback on features. The strategic road map guided priorities for the PD sessions. PD sessions typically lasted for several days and were planned. Daily feedback from nightly builds was often spontaneous. \\  \\ While participatory design was the core enabler for the developers and the customers to come together to create designs for which all felt a sense of ownership, agile development was the enabler that pushed the design specs into the world of real code and a working product. The constant availability of our product made our progress visible to all. This pushed everyone on the team to constantly improve it. ",
        "cbStatement": "This work is a real world example of putting together participatory design methods with agile development to develop new user interface technology.",
        "bookmarks": 74,
        "keywords": [
            "Participatory Design",
            "Agile UX",
            "UX Management Practice",
            "Object Oriented GUI Style",
            "User Experience"
        ],
        "communities": [
            "design",
            "management",
            "ux"
        ],
        "video": "cs0136-file5.mp4",
        "session": {
            "id": "s192",
            "name": "Case Studies in the wild"
        },
        "room": "342a",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth31474",
                "givenName": "Jay",
                "familyName": "Trimble",
                "email": "jaytrm@gmail.com",
                "primary": {
                    "dept": "Intelligent Systems Division",
                    "institution": "NASA Ames Research Center",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "NASA Ames Research Center",
                    "city": "Mountain View",
                    "state": "CA",
                    "country": "USA"
                },
                "role": "presenter"
            },
            {
                "id": "auth31627",
                "givenName": "Tom",
                "familyName": "Dayton",
                "email": "tom.dayton@nasa.gov",
                "primary": {
                    "dept": "University Affiliated Research Center",
                    "institution": "NASA Ames Research Center",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth31629",
                "givenName": "Alan",
                "familyName": "Crocker",
                "email": "alan.r.crocker@nasa.gov",
                "primary": {
                    "dept": "Mission Operations Directorate",
                    "institution": "NASA Johnson Space Center",
                    "city": "Houston",
                    "state": "Texas",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 49,
        "name": "Project Pokerface: Building User-Centered Culture at Scale",
        "type": "casestudy",
        "abstract": "We describe a project (‘Pokerface’) we ran at Google to increase our collective focus on the user. It involved hundreds of Eng/PM across multiple locations. This immersion project allowed non-UX professionals to feel firsthand the delight and, and at times, pain of our users when using our products. It strengthened the bond between colleagues and users and called to attention issues that needed immediate action.",
        "cbStatement": "Learn about a compact, lightweight user immersion process that engages entire teams in user research. It creates lasting impressions and therefore provides momentum for change with minimal time and resources.",
        "bookmarks": 162,
        "keywords": [
            "Empathy",
            "Immersion",
            "Usability",
            "Experience Strategy"
        ],
        "communities": [
            "management",
            "ux"
        ],
        "video": "cs0138-file5.mp4",
        "session": {
            "id": "s193",
            "name": "Case Studies in innovating UCD Process"
        },
        "room": "342a",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth31486",
                "givenName": "Asif",
                "familyName": "Baki",
                "email": "asifbaki@google.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth31686",
                "givenName": "Patrick",
                "familyName": "Bowen",
                "email": "jpbowen@google.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth31687",
                "givenName": "Brianna",
                "familyName": "Brekke",
                "email": "briannab@google.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Twitter",
                    "city": "San Francisco",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth34953",
                "givenName": "Elizabeth",
                "familyName": "Ferrall-Nunge",
                "email": "enunge@twitter.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth35004",
                "givenName": "Gueorgi",
                "familyName": "Kossinets",
                "email": "gkossinets.@google.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth35005",
                "givenName": "Jens",
                "familyName": "Riegelsberger",
                "email": "jensr@google.com",
                "primary": {
                    "institution": "Google, Inc",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth31688",
                "givenName": "Nina",
                "familyName": "Weber",
                "email": "nweber@google.com",
                "primary": {
                    "institution": "Google, Inc",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth35006",
                "givenName": "Marissa",
                "familyName": "Mayer",
                "email": "marissamayer@gmail.com",
                "primary": {
                    "institution": "Google, Inc",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Yahoo! Inc.",
                    "city": "Sunnyvale",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 50,
        "name": "The Fingerstroke-Level Model Strikes Back: A modified Keystroke-Level Model in developing a gaming UI for 4G networks",
        "type": "casestudy",
        "abstract": "With the 4G mobile technology, LG U+ established a new business model, inter-network mirroring game service, that allows PC and mobile game users to play against each other. However, due to an unsolicited input command design for touch-sensitive UIs, it is hard to adjust competitive levels between them. The traditional Keystroke-Level Model (KLM) was not applicable to predict the task performance in the touch-sensitive user interface. This case study thus proposed Fingerstroke Level Model (FLM), and analyzed the inter-network mirroring game - ‘Freestyle II™’ with FLM. The empirical study confirmed the effectiveness and efficiency of FLM, and suggested how HCI methods can improve the design of mobile gaming user interface.",
        "cbStatement": "we suggested a new gaming style with FLM, and confirmed that FLM serves well as the predictive model in the touch-sensitive mobile UIs.",
        "bookmarks": 166,
        "keywords": [
            "Tactile & Haptic UIs",
            "Input and Interaction Technologies",
            "Entertainment",
            "Empirical Methods",
            "Quantitative Prototyping"
        ],
        "communities": [
            "games"
        ],
        "video": "cs0141-file5.mp4",
        "session": {
            "id": "s194",
            "name": "Case Study of Changing the Way We Work"
        },
        "room": "342a",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth29235",
                "givenName": "Kiburm",
                "familyName": "Song",
                "email": "ksong@hanyang.ac.kr",
                "primary": {
                    "dept": "Research Institute for Serious Entertainment",
                    "institution": "Hanyang University",
                    "city": "Seoul",
                    "country": "Korea"
                },
                "secondary": {
                    "dept": "Research Institute for Serious Entertainment",
                    "institution": "Hanyang University",
                    "city": "Seoul",
                    "country": "Korea"
                },
                "role": "presenter"
            },
            {
                "id": "auth31509",
                "givenName": "Jihoon",
                "familyName": "Kim",
                "email": "hanulboli@hanyang.ac.kr",
                "primary": {
                    "dept": "Industrial Engineering",
                    "institution": "Hanyang University",
                    "city": "Seoul",
                    "country": "Korea"
                },
                "secondary": {
                    "dept": "Industrial Engineering",
                    "institution": "Hanyang University",
                    "city": "Seoul",
                    "country": "Korea"
                }
            },
            {
                "id": "auth31506",
                "givenName": "Yoon-Han",
                "familyName": "Cho",
                "email": "ryoonhan@hanyang.ac.kr",
                "primary": {
                    "dept": "Industrial Engineering",
                    "institution": "Hanyang University",
                    "city": "Seoul",
                    "country": "Korea"
                },
                "secondary": {
                    "dept": "Industrial Engineering",
                    "institution": "Hanyang University",
                    "city": "Seoul",
                    "country": "Korea"
                }
            },
            {
                "id": "auth31507",
                "givenName": "Ahreum",
                "familyName": "Lee",
                "email": "Ahrmlee@gmail.com",
                "primary": {
                    "dept": "Research Institute for Serious Entertainment",
                    "institution": "Hanyang University",
                    "city": "Seoul",
                    "country": "Korea"
                },
                "secondary": {
                    "dept": "Research Institute for Serious Entertainment",
                    "institution": "Hanyang University",
                    "city": "Seoul",
                    "country": "Korea"
                }
            },
            {
                "id": "auth28814",
                "givenName": "Hokyoung",
                "familyName": "Ryu",
                "email": "hryu@hanyang.ac.kr",
                "primary": {
                    "dept": "Research Institute for Serious Entertainment",
                    "institution": "Hanyang University",
                    "city": "Seoul",
                    "country": "Korea"
                },
                "secondary": {
                    "dept": "Research Institute for Serious Entertainment",
                    "institution": "Hanyang University",
                    "city": "Seoul",
                    "country": "Korea"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 51,
        "name": "The Needs of Early School Children and Their Parents with Respect to the Design of Mobile Service Offers",
        "type": "casestudy",
        "abstract": "The goal of the project was to investigate the needs of early school children and their parents to identify ingredients for a mobile service offer. The results showed a difference regarding such needs between children age 7-8 and age 9-10, and between girls and boys. We identified three categories of needs: safety, entertainment and communication. Based on the findings we proposed a number of implications for the design of mobile service offers for early school children.",
        "cbStatement": "We investigated needs of early school children and their parents to identify ingredients for mobile service offers. We identified three categories of needs: safety, entertainment and communication. ",
        "bookmarks": 3,
        "keywords": [
            "Service Design",
            "Children",
            "User Experience Design",
            "Experience Design, Mobile Service Offer"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "cs0146-file5.mp4",
        "session": {
            "id": "s190",
            "name": "Communitites of practice"
        },
        "room": "342a",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth19450",
                "givenName": "Agnieszka (Aga)",
                "familyName": "Szostek",
                "email": "aga.szostek@gmail.com",
                "primary": {
                    "dept": "School of Form",
                    "institution": "Warsaw School of Social Psychology",
                    "city": "Poznan",
                    "country": "Poland"
                },
                "role": "presenter"
            },
            {
                "id": "auth31537",
                "givenName": "Joanna",
                "familyName": "Kwiatkowska",
                "email": "joan.kwiatkowska@gmail.com",
                "primary": {
                    "institution": "Czestochowa University of Technology",
                    "city": "Czestochowa",
                    "country": "Poland"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth31538",
                "givenName": "Olga",
                "familyName": "Górnicka",
                "email": "gornicka.olga@gmail.com",
                "primary": {
                    "institution": "Warsaw School of Social Psychology",
                    "city": "Warsaw",
                    "country": "Poland"
                }
            }
        ]
    },
    {
        "id": 52,
        "name": "What Should I Read Next? Awareness of Relevant Publications Through a Community of Practice",
        "type": "casestudy",
        "abstract": "Due to the dramatic growth in the number of scientific publications, evaluating what is more or less relevant to read (and why) is becoming a more challenging task. This case study presents the design and findings of TiNYARM, a Science 2.0 tool that enables researchers to share and suggest reading activities with their peers. Social Awareness Streams, Personal Information Management and Gamification concepts are applied in order to generate awareness and engage users.",
        "cbStatement": "This case study presents the design and findings of TiNYARM, a Science 2.0 tool that enables researchers to share and suggest reading activities with their peers.",
        "bookmarks": 18,
        "keywords": [
            "(Self-)awareness",
            "motivation",
            "gamification",
            "personal information management",
            "sensemaking",
            "Science2.0"
        ],
        "communities": [
            "engineering"
        ],
        "video": "cs0154-file5.mp4",
        "session": {
            "id": "s191",
            "name": "Case Studies in Novel Settings"
        },
        "room": "342a",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth17399",
                "givenName": "Gonzalo",
                "familyName": "Parra",
                "email": "gonzalo.parra@cs.kuleuven.be",
                "primary": {
                    "institution": "KU Leuven - University of Leuven",
                    "city": "Leuven",
                    "state": "Flemish Brabant",
                    "country": "Belgium"
                },
                "secondary": {
                    "institution": "KU Leuven - University of Leuven",
                    "city": "Leuven",
                    "state": "Flemish Brabant",
                    "country": "Belgium"
                },
                "role": "presenter"
            },
            {
                "id": "auth31703",
                "givenName": "Joris",
                "familyName": "Klerkx",
                "email": "joris.klerkx@cs.kuleuven.be",
                "primary": {
                    "institution": "KU Leuven - University of Leuven",
                    "city": "Leuven",
                    "state": "Flemish Brabant",
                    "country": "Belgium"
                },
                "secondary": {
                    "institution": "KU Leuven - University of Leuven",
                    "city": "Leuven",
                    "state": "Flemish Brabant",
                    "country": "Belgium"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth17410",
                "givenName": "Erik",
                "familyName": "Duval",
                "email": "erik.duval@cs.kuleuven.be",
                "primary": {
                    "institution": "KU Leuven - University of Leuven",
                    "city": "Leuven",
                    "state": "Flemish Brabant",
                    "country": "Belgium"
                },
                "secondary": {
                    "institution": "KU Leuven - University of Leuven",
                    "city": "Leuven",
                    "country": "Belgium"
                }
            }
        ]
    },
    {
        "id": 53,
        "name": "Best Practices for Enterprise Social Software Adoption: A Case Study of Deploying IBM Connections within IBM",
        "type": "casestudy",
        "abstract": "In this case study, we present the results of a longitudinal study of the end-user adoption of social software within a large global enterprise. Existing Technology Adoption Models (e.g., UTAUT) were extended and used as a general framework for studying user adoption. Several “best practices” to promote end-user adoption are identified and discussed, including: integration with company intranet, email notifications, evangelism programs, executive support, mandatory migration and usage, and corporate-sponsored campaigns or events. ",
        "cbStatement": "Best-practices to drive enterprise social software adoption.",
        "bookmarks": 71,
        "keywords": [
            "Enterprise social software",
            "technology adoption",
            "technology acceptance models",
            "best practices"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "cs0158-file5.mp4",
        "session": {
            "id": "s194",
            "name": "Case Study of Changing the Way We Work"
        },
        "room": "342a",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth31670",
                "givenName": "Meng",
                "familyName": "Yang",
                "email": "yang080229@yahoo.com",
                "primary": {
                    "institution": "IBM",
                    "city": "Littleton",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth31669",
                "givenName": "Michael",
                "familyName": "Warner",
                "email": "mike_warner@us.ibm.com",
                "primary": {
                    "institution": "IBM",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth1440",
                "givenName": "David",
                "familyName": "Millen",
                "email": "david_r_millen@us.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 54,
        "name": "Do You Enjoy Getting Gifts? Keeping Personas Alive Through Marketing Materials",
        "type": "casestudy",
        "abstract": "Personas are a design tool to ensure a strong user-focus within projects. In this case study we compare and discuss seven different persona marketing materials used to increase the acceptance of the personas by the project team. The marketing materials are a mixture of consumables (e.g., wine or cake) and long-living marketing materials (e.g., posters or savings box). The insights gained are encouraging and confirm that marketing materials can be useful for increasing the acceptance and usage of personas.",
        "cbStatement": "This case study researches the potential of persona marketing materials to improve the persona method. We present and research the effects and likeability of long-living marketing materials and consumables.",
        "bookmarks": 115,
        "keywords": [
            "Personas",
            "Marketing Materials",
            "User-Centered Design"
        ],
        "communities": [
            "ux"
        ],
        "video": "cs0159-file5.mp4",
        "session": {
            "id": "s194",
            "name": "Case Study of Changing the Way We Work"
        },
        "room": "342a",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth13410",
                "givenName": "Christina",
                "familyName": "Hochleitner",
                "email": "hochleitner@cure.at",
                "primary": {
                    "institution": "CURE - Center for Usability Research & Engineering",
                    "city": "Vienna",
                    "country": "Austria"
                },
                "secondary": {
                    "dept": "ICT&S Center",
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "state": "Salzburg",
                    "country": "Austria"
                },
                "role": "presenter"
            },
            {
                "id": "auth16115",
                "givenName": "Cornelia",
                "familyName": "Graf",
                "email": "Conny_Graf@gmx.net",
                "primary": {
                    "institution": "CURE - Center for Usability Research & Engineering",
                    "city": "Vienna",
                    "country": "Austria"
                },
                "secondary": {
                    "institution": "AIM Software",
                    "city": "Vienna",
                    "country": "Austria"
                }
            },
            {
                "id": "auth3460",
                "givenName": "Manfred",
                "familyName": "Tscheligi",
                "email": "tscheligi@cure.at",
                "primary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "state": "Salzburg",
                    "country": "Austria"
                },
                "secondary": {
                    "institution": "CURE - Center for Usability Research & Engineering",
                    "city": "Vienna",
                    "state": "Vienna",
                    "country": "Austria"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 55,
        "name": "We'll Take It From Here: Letting the Users Take Charge of the Evaluation and Why That Turned Out Well",
        "type": "casestudy",
        "abstract": "The operational challenges faced by law enforcement and public safety personnel are constantly evolving, while the training and certification process has stayed the same. New technologies such as virtual reality, mixed reality, or game-based simulators are being researched as promising enhancements to traditional training methods. However, their widespread adoption, particularly by smaller units, faces barriers such as cost – due in no small part to the difficulties of developing and especially evaluating such large-scale interactive systems. In this case study, we present MINT – a low-cost mixed-reality Multimodal INteractive Training system, aimed at supporting the training of small- and medium-sized law enforcement and infantry units. We discuss the challenges and approaches taken in the participatory design of the training system, its agile-based development and implementation, and its qualitative evaluation with users and subject-matter experts.",
        "cbStatement": "A case study describing the challenges and approaches taken in conducting a qualitative evaluation of a mixed-reality training system with subject-matter experts under multiple stakeholder constraints.",
        "bookmarks": 146,
        "keywords": [
            "User studies",
            "evaluation methodology",
            "mixed-reality interaction",
            "immersive gaming"
        ],
        "communities": [],
        "video": "cs0170-file5.mp4",
        "session": {
            "id": "s192",
            "name": "Case Studies in the wild"
        },
        "room": "342a",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth6242",
                "givenName": "Cosmin",
                "familyName": "Munteanu",
                "email": "cosmin.munteanu@nrc-cnrc.gc.ca",
                "primary": {
                    "institution": "National Research Council Canada",
                    "city": "Fredericton",
                    "state": "New Brunswick",
                    "country": "Canada"
                },
                "secondary": {
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth31671",
                "givenName": "Helene",
                "familyName": "Fournier",
                "email": "Helene.Fournier@nrc-cnrc.gc.ca",
                "primary": {
                    "institution": "National Research Council Canada",
                    "city": "Moncton",
                    "state": "New Brunswick",
                    "country": "Canada"
                }
            },
            {
                "id": "auth1664",
                "givenName": "Jean-François",
                "familyName": "Lapointe",
                "email": "jean-francois.lapointe@nrc-cnrc.gc.ca",
                "primary": {
                    "institution": "National Research Council of Canada",
                    "city": "Ottawa",
                    "state": "Ontario",
                    "country": "Canada"
                }
            },
            {
                "id": "auth31672",
                "givenName": "Bruno",
                "familyName": "Emond",
                "email": "Bruno.Emond@nrc-cnrc.gc.ca",
                "primary": {
                    "institution": "National Research Council of Canada",
                    "city": "Ottawa",
                    "state": "Ontario",
                    "country": "Canada"
                }
            },
            {
                "id": "auth31673",
                "givenName": "Irina",
                "familyName": "Kondratova",
                "email": "Irina.Kondratova@nrc-cnrc.gc.ca",
                "primary": {
                    "institution": "National Research Council Canada",
                    "city": "Fredericton",
                    "state": "New Brunswick",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 56,
        "name": "Minimizing Change Aversion for the Google Drive Launch",
        "type": "casestudy",
        "abstract": "Change aversion is a natural response, which technology often exacerbates. Evolutionary changes can be subtle and occur over many generations. But Internet users must sometimes deal with sudden, significant product changes to applications they rely on and identify with. Despite the best intentions of designers and product managers, users often experience anxiety and confusion when faced with a new interface or changed functionality. While some change aversion is often inevitable, it can also be managed and minimized with the right steps. This case study describes how our understanding of change aversion helped minimize negative effects for the transition of the Google Docs List to Google Drive, a product for file storage in the cloud. We describe actions that allowed for a launch with no aversion.",
        "cbStatement": "Case study describing change aversion and the application of change management principles to the Google Drive launch. Can assist in launching interface changes to minimize user discomfort and effort.",
        "bookmarks": 118,
        "keywords": [
            "Case study",
            "satisfaction",
            "happiness",
            "change aversion",
            "UI design",
            "usability",
            "improvement",
            "user-centered design",
            "user experience",
            "user research",
            "product experience",
            "product launch."
        ],
        "communities": [
            "design",
            "engineering",
            "ux"
        ],
        "video": "cs0176-file5.mp4",
        "session": {
            "id": "s194",
            "name": "Case Study of Changing the Way We Work"
        },
        "room": "342a",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth31522",
                "givenName": "Aaron",
                "familyName": "Sedley",
                "email": "asedley@google.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth11109",
                "givenName": "Hendrik",
                "familyName": "Müller",
                "email": "hendrikm@google.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Sydney",
                    "state": "NSW",
                    "country": "Australia"
                },
                "secondary": {
                    "institution": "Google, Inc.",
                    "city": "Sydney",
                    "state": "NSW",
                    "country": "Australia"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 57,
        "name": "User Experience Evaluation Methods – Which Method to Choose?",
        "type": "course",
        "abstract": "High quality user experience (UX) has become a central competitive factor of products in mature consumer markets. Improving UX during product development and research requires evaluation, but traditional usability testing methods are not adequate for evaluating UX. The evaluation methods for investigating how users feel about the tested system are still less known in the HCI community. \\  \\ Since 2008, the instructors have been collecting a comprehensive set of 80 UX evaluation methods both from academia and industry, which is now available at www.allaboutux.org/all-methods. During this course, we will present an overview of the set of methods and present some methods in more detail. \\  \\ By the end of this course, you will be able to choose suitable methods for your specific user experience evaluation case. You will understand the difference between UX evaluation and traditional usability evaluation methods, as well as the variety of UX evaluation methods available. \\  \\ This course will cover the following topics: \\  \\ -\tthe general targets of UX evaluation \\  \\ -\tthe various kinds of UX evaluation methods available for different \\ purposes (an overview) \\  \\ -\thow to choose the right method for the purpose \\  \\ -\tthe basics of a sample of UX methods of different types \\  \\ -\tguidance on where to find more information on those methods \\  \\ Our target audience consists of researchers and practitioners who want to get acquainted with user experience evaluation methods. The participants should have basic understanding of the user-centered design process, and preferably experience on usability studies. \\  \\ The course was well-attended at CHI’12 – do not miss it this year! ",
        "cbStatement": "Helps to select the right user experience evaluation methods for different purposes. A collection of methods that investigate how people feel about the system under study is provided at www.allaboutux.org.",
        "bookmarks": 108,
        "keywords": [],
        "communities": [
            "ux"
        ],
        "video": "cr0105-file2.mp4",
        "authors": [
            {
                "id": "auth1950",
                "givenName": "Virpi",
                "familyName": "Roto",
                "email": "virpi.roto@aalto.fi",
                "primary": {
                    "institution": "Aalto University",
                    "city": "Helsinki",
                    "country": "Finland"
                },
                "role": "presenter"
            },
            {
                "id": "auth10692",
                "givenName": "Arnold",
                "familyName": "Vermeeren",
                "email": "a.p.o.s.vermeeren@tudelft.nl",
                "primary": {
                    "institution": "Delft University of Technology",
                    "city": "Delft",
                    "country": "The Netherlands"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth9076",
                "givenName": "Kaisa",
                "familyName": "Väänänen-Vainio-Mattila",
                "email": "kaisa.vaananen-vainio-mattila@tut.fi",
                "primary": {
                    "institution": "Tampere University of Technology",
                    "city": "Tampere",
                    "country": "Finland"
                }
            },
            {
                "id": "auth4890",
                "givenName": "Effie",
                "familyName": "Law",
                "email": "law@tik.ee.ethz.ch",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "University of Leicester",
                    "city": "Leicester",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth7742",
                "givenName": "Marianna",
                "familyName": "Obrist",
                "email": "marianna.obrist@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 58,
        "name": "Designing What to Design: A Task-Focused Conceptual Model",
        "type": "course",
        "abstract": "An important early step in designing a user interface for a software application is to design a coherent, task-focused conceptual model. Unfortunately, this step is often skipped in software development. Many designers jump right into sketching and prototyping the UI before they understand the application at a conceptual level.  The result is incoherent, overly-complex applications that expose concepts that are irrelevant to users’ tasks.  This course covers: \\  \\ • What conceptual models are, and how they can improve the UI design process, \\  \\ • Perils and pitfalls of not designing a conceptual model, \\  \\ • Object/actions analysis (part of designing a conceptual model), \\  \\ • An example conceptual model for a specific application, \\  \\ • Benefits of conceptual analysis: object taxonomy, lexicon, task scenarios, object-model, \\  \\ • A hands-on exercise in performing Object/Actions analysis for a simple application.",
        "cbStatement": "Participants will learn: \\  \\ • the benefits of designing a conceptual model (CM) before designing a UI. \\  \\ • the components of a CM,  \\  \\ • how to design a CM for an application.",
        "bookmarks": 107,
        "keywords": [],
        "communities": [
            "design",
            "engineering"
        ],
        "video": "cr0107-file2.mp4",
        "authors": [
            {
                "id": "auth1111",
                "givenName": "Jeff",
                "familyName": "Johnson",
                "email": "jeffjohnson@uiwizards.com",
                "primary": {
                    "institution": "UI Wizards, Inc",
                    "city": "San Francisco",
                    "state": "California",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Wiser Usability, Inc.",
                    "city": "Cupertino",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 59,
        "name": "Empirical Research Methods for Human-Computer Interaction",
        "type": "course",
        "abstract": "Title \\ Empirical Research Methods for Human-Computer Interaction \\  \\ Instructors \\ Scott MacKenzie and Steven Castellucci, York University, Canada \\  \\ Benefits \\ Attendees will learn how to conduct empirical research in human-computer interaction (HCI).  A \"user study\" is an experiment conforming to the \\ norms for empirical inquiry and the scientific method.  It is founded on \\ observation, measurement, and posing and answering testable research \\ questions.  This Course delivers an A-to-Z tutorial on conducting a user \\ study and demonstrates how to write a successful CHI paper. \\  \\ Features \\ -An overview of the definition, purpose, and method of empirical research \\ -A detailed description of experiment components, and their design \\ \t-Research questions will be posed and refined to highlight important \\ characteristics \\ \t-Experiment design issues will be addressed  \\ \t-Methods for data analysis and reporting will be outlined \\ -Participation in a real experiment \\ \t-Attendees will work in pairs and take turns acting as both participant \\ and investigator \\ -A demonstration on how to write a successful CHI paper, including \\ pitfalls to avoid \\  \\ Presentation \\ PowerPoint slides, real-time demos, group participation \\  \\ Instructor Backgrounds \\ Scott MacKenzie's research is in HCI with an emphasis on human \\ performance measurement and modeling, experimental methods and \\ evaluation, interaction devices and techniques, alphanumeric entry, \\ language modeling, and mobile computing.  He has more than 135 HCI \\ publications (including more than 35 from the SIGCHI conference) and has \\ given numerous invited talks over the past 20 years.  Since 1999, he has \\ been Associate Professor of Computer Science and Engineering at York \\ University, Canada. \\  \\ Steven Castellucci is a PhD student and research assistant in the \\ Department of Computer Science and Engineering at York University, \\ Canada.  His research interests include gesture-based text entry, mobile \\ text entry, and remote pointing techniques.  In addition to having SIGCHI \\ publications, he has lectured university courses on user interfaces and \\ HCI, and has served as course director.",
        "cbStatement": "This Course delivers an A-to-Z tutorial on conducting a user study and demonstrates how to write a successful CHI paper.",
        "bookmarks": 179,
        "keywords": [],
        "communities": [],
        "video": "cr0110-file2.mp4",
        "authors": [
            {
                "id": "auth9096",
                "givenName": "Scott",
                "familyName": "MacKenzie",
                "email": "mack@cse.yorku.ca",
                "primary": {
                    "institution": "York University",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth5947",
                "givenName": "Steven",
                "familyName": "Castellucci",
                "email": "stevenc@cse.yorku.ca",
                "primary": {
                    "institution": "York University",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 60,
        "name": "Designing Search Usability",
        "type": "course",
        "abstract": "Search is not just a box and ten blue links. Search is a journey: an exploration where what we encounter along the way changes what we seek. But in order to guide people along this journey, we must understand both the art and science of search usability. \\  \\ This course will provide an introduction to the basic principles of search usability with a focus on holistic solutions that integrate information seeking theory with the user interface design practice. Participants will: \\  \\ • Explore the fundamental concepts of human-centred design for information search and discovery \\  \\ • Learn how to differentiate between various types of search behaviour: known-item, exploratory, lookup, learning, investigation, etc. \\  \\ • Understand the dimensions of search user experience and how to apply them to different contexts \\  \\ • Explore design patterns and other key resources and their role in solving practical design problems \\  \\ The course will include both presentations and group work to enable delegates to analyse, evaluate and improve the effectiveness of search applications within their own organisation.  \\ ",
        "cbStatement": "This course weaves together the theories of information seeking with the practice of user interface design to deliver a practical guide to making search better.  ",
        "bookmarks": 86,
        "keywords": [],
        "communities": [
            "design",
            "ux"
        ],
        "video": "cr0112-file2.wmv",
        "authors": [
            {
                "id": "auth31183",
                "givenName": "Tony",
                "familyName": "Russell-Rose",
                "email": "tgr@uxlabs.co.uk",
                "primary": {
                    "institution": "UXLabs",
                    "city": "London",
                    "state": "London",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 61,
        "name": "Interaction Design for Social Development",
        "type": "course",
        "abstract": "This course is aimed at researchers or practitioners who wish to design solutions appropriate to the developing world. To meet this goal we present techniques and methods allowing attendants to design for people from different contexts, cultures and literacies. We also present case studies reporting successes and failures, along with reflections, insights and lessons to be learned. Finally, we discuss open design and ethical questions of doing this type of work in developing contexts.",
        "cbStatement": "Learn how to apply Interaction Design techniques to developing communities and engage users effectively in the creation of appropriate technologies for contexts beyond the developed world.",
        "bookmarks": 21,
        "keywords": [],
        "communities": [
            "design",
            "hci4d"
        ],
        "video": "cr0114-file2.mp4",
        "authors": [
            {
                "id": "auth3025",
                "givenName": "Gary",
                "familyName": "Marsden",
                "email": "gaz@acm.org",
                "primary": {
                    "institution": "University of Cape Town",
                    "city": "Cape Town",
                    "country": "South Africa"
                },
                "role": "presenter"
            },
            {
                "id": "auth1008",
                "givenName": "Matt",
                "familyName": "Jones",
                "email": "always@acm.org",
                "primary": {
                    "institution": "Swansea University",
                    "city": "Swansea",
                    "state": "W Glam",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 62,
        "name": "Card Sorting for Navigation Design",
        "type": "course",
        "abstract": "Benefits: This half-day hands-on course covers the theory and practice of card sorting. It includes hands-on experience of performing and evaluating a paper-based card sort of an e-commerce site (although the techniques are applicable to many other problem domains). \\  \\ Origins: This is a major update of an earlier course (‘Innovations in Card Sorting’) that has been run for several years at HCI and usability conferences (HCI 2006 & 2007, CADUI 2008, HCI 2009, CHI 2009-2012). A one-day version of this course was presented as part of Nielsen-Norman Group’s Usability Week in 2009. The updated, half-day version appeared at CHI 2011. \\  \\ Features: On completion of this tutorial you will be able to \\  \\     choose an appropriate card sorting method \\     explain cluster analysis and dendrograms to colleagues and clients \\     apply appropriate techniques for getting the best information from participants and the resulting data \\     perform quick and reliable data capture \\  \\ Audience: Web and intranet designers, information architects, usability and HCI professionals interested in the practical application of card sorting. No specialist skills or knowledge are required. \\  \\ Presentation: The course is approximately 60% tutorials and 40% practical card-sorting activities or group discussions. \\  \\ Instructor Background:: William Hudson has nearly 40 years’ experience in the development of interactive systems. He is the founder of Syntagm, a consultancy specializing in user-centered design and has conducted more than 300 intranet and web site expert evaluations. William has written over 30 articles, papers and studies including the InteractionDesign.org Encyclopedia entry on card sorting. He is also an Adjunct Professor at Hult International Business School. \\  \\ Web Site: Further information about the instructor and this course can be found at www.syntagm.co.uk/design \\ ",
        "cbStatement": "This half-day hands-on course covers the theory and practice of card sorting. It includes hands-on experience of performing a paper-based card sort, data capture and analysis.",
        "bookmarks": 192,
        "keywords": [],
        "communities": [
            "design",
            "ux"
        ],
        "video": "cr0115-file2.mp4",
        "authors": [
            {
                "id": "auth9174",
                "givenName": "William",
                "familyName": "Hudson",
                "email": "william.hudson@syntagm.co.uk",
                "primary": {
                    "institution": "Syntagm Ltd",
                    "city": "Abingdon",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 63,
        "name": "Agile User Experience and UCD",
        "type": "course",
        "abstract": "Benefits: This half-day course shows how to integrate User-Centered Design with Agile methods to create great user experiences. The course builds on the instructor’s research into empathizing skills and takes an ‘emotionally intelligent’ approach to engaging all team members in UCD. The course is a balanced combination of tutorials, group exercises and discussions, ensuring that participants gain a rich understanding of the problems presented by Agile and how they can be addressed. \\  \\ Origins: This is a half-day version of a popular one-day course that has been well-received within a major UK telecoms operator and at a number of public presentations in London, Brussels and Hamburg in 2010 and 2011. It was part of the CHI 2011 & 2012 course offerings. \\  \\ Features: \\  \\     Up-front versus Agile UCD \\     Empathetic design \\     User & Persona Stories \\     Agile usability testing \\     Adding value to the Agile team \\     Design maps \\  \\ Audience: Usability, UX and UCD practitioners trying to integrate UCD activities within Agile teams. (Some familiarity with UCD techniques is required.) \\  \\ Presentation: The course is approximately 60% tutorials and 40% activities or group discussions. \\  \\ Instructor Background: William Hudson has 40 years’ experience in the development of interactive systems. He has contributed material on user-centered design and user interface design to the Rational Unified Process and to Addison-Wesley’s Object Modeling and User Interface Design (van Harmelen, 2001). He is the founder of Syntagm, a consultancy specializing in user-centered design and has conducted more than 300 intranet and web site evaluations. William has written over 30 articles, papers and studies. He is an Adjunct Professor at Hult International Business School. \\  \\ Web Site: Further information about the instructor and this course can be found at www.syntagm.co.uk/design ",
        "cbStatement": "This course shows how to integrate UCD with Agile methods to create great user experiences. It takes an ‘emotionally intelligent’ approach to engaging all team members in UCD. ",
        "bookmarks": 195,
        "keywords": [],
        "communities": [
            "design",
            "ux"
        ],
        "video": "cr0117-file2.mp4",
        "authors": [
            {
                "id": "auth9174",
                "givenName": "William",
                "familyName": "Hudson",
                "email": "william.hudson@syntagm.co.uk",
                "primary": {
                    "institution": "Syntagm Ltd",
                    "city": "Abingdon",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 64,
        "name": "Interactive Walking in Virtual Environments",
        "type": "course",
        "abstract": "In recent years many advances have enabled users to more and more naturally navigate large-scale graphical worlds. The entertainment industry is increasingly providing visual and body-based cues to their users to increase the naturalness of their navigational experience. \\ However, so far none of the existing solutions fully supports the most natural ways of locomotion through virtual worlds, and thus techniques and technologies have to be considered, which take advantage of insights into human perceptual sensitivity. In this context, by far the most natural way to move through the real world is via a full body experience where we receive sensory stimulation to all of our senses, i.e., when walking, running, biking or driving. With some exciting technological advances, people are now beginning to get this same full body sensory experience when navigating computer generated three-dimensional environments. Enabling such an active and dynamic ability to navigate through large-scale virtual scenes is of great interest for many interactive 3D applications demanding locomotion, such as video games, edutainment, simulation, rehabilitation, military, tourism or architecture. \\  \\ In this course we will present an overview about the development of interactive locomotion interfaces for computer generated virtual environments ranging from desktop-based camera manipulations simulating walking, and different walking metaphors for the entertainment to state-of-the-art hardware-based solutions that enable omni-directional and unlimited real locomotion through virtual worlds. As the computer graphics industry advances towards increasingly more natural interaction, human-computer interaction researchers and professionals will benefit from this course by increasing their understanding of human perception and how this knowledge can be applied to enable the most natural interaction technique of all, i.e., navigating through the world by walking.",
        "cbStatement": "In this course we will present an overview about interactive locomotion interfaces for computer generated virtual environments using state-of-the-art technology and approaches.",
        "bookmarks": 14,
        "keywords": [],
        "communities": [
            "design",
            "ux",
            "games"
        ],
        "authors": [
            {
                "id": "auth13745",
                "givenName": "Frank",
                "familyName": "Steinicke",
                "email": "fsteini@math.uni-muenster.de",
                "primary": {
                    "dept": "Immersive Media Group",
                    "institution": "Institute of Computer Science",
                    "city": "Würzburg",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth14569",
                "givenName": "Yon",
                "familyName": "Visell",
                "email": "yon@cim.mcgill.ca",
                "primary": {
                    "dept": "Centre for Intelligent Machines",
                    "institution": "McGill University",
                    "city": "Montreal",
                    "state": "Quebec",
                    "country": "Canada"
                }
            },
            {
                "id": "auth31284",
                "givenName": "Jennifer",
                "familyName": "Campos",
                "email": "Jennifer.Campos@uhn.ca",
                "primary": {
                    "institution": "Toronto Rehab",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                }
            },
            {
                "id": "auth3039",
                "givenName": "Anatole",
                "familyName": "Lécuyer",
                "email": "anatole.lecuyer@irisa.fr",
                "primary": {
                    "institution": "INRIA",
                    "city": "Rennes",
                    "country": "France"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 65,
        "name": "Six Steps to Successful UX in an Agile World",
        "type": "course",
        "abstract": "Detailed Course Description  \\  \\ Duration: 80 minutes (1 course unit)  \\  \\ Linkage to Other Courses  \\ This course is intended to stand alone. \\  \\ Learning Objectives:  \\ Participants in this course will:  \\ 1. Learn the UX role and tasks at each point in an Agile project \\ 2. Learn specific, tested techniques for performing that role effectively: \\       •\tContribute to defining the right user stories \\       •\tWrite and prioritize user stories \\       •\tWork out low-level design details within sprints \\       •\tDrive iterations with real user feedback during each sprint \\       •\tMaintain a whole-system perspective on the UI \\       •\tDevelop a real, day-to-day collaboration with developers \\ 3. Practice one key skill—writing user stories \\ 4. Understand how UX skills contribute to an effective Agile project \\  \\ Justification \\ As Agile development becomes standard across the industry, UX groups are finding it necessary to redefine their relationships to the development projects they are a part of. UX groups are also finding that the constraints of Agile development are forcing them to rethink how UX work is done. On the one hand, the tight constrains of short sprints require that all slack be taken out of the process, so that work can be done in small increments at the last responsible moment. On the other, good UX design requires holistic thinking about the entire system and UX groups are challenged to maintain this focus even during the continual heads-down work of sprints. \\  \\ This course seeks to give UX designers specific, actionable techniques to handle this new situation. We briefly review why UX techniques are critical to delivering on the promise of Agile development—how UX techniques permit the initial project backlog to be developed effectively and ensure that project iterations evolve the product in a direction useful to its users. \\ The bulk of the course discusses the five key skills described above—what the UX designer should be doing, why that works in the context of an Agile project, and how the UX designer’s existing skills are critical to supporting Agile development. The discussion of each skill is supported with examples from Agile teams.  \\  \\ One critical skill—writing user stories—is practiced in the session. This is a core skill and requires that UX designers think about their design in a different way and break it up in counter-intuitive ways they may not be familiar with, so focused practice is useful.  \\ This course is informed by our years of experience working with Agile teams, so we can not only describe how UX designers should integrate with Agile teams in theory, but how things actually work in practice.  \\  \\ Content \\   \\ The course contains the following main parts: \\ First, we briefly summarize the origins of Agile development to provide shared context for all participants. We describe the problems developers faced and how these methods gave them control over some of their most intractable problems. We are honest about the shortcomings of the methods as well—being designed by developers, for developers, they are limited in the scope of the problems they attempt to address (the world begins and ends with coding) and in the techniques they use (none of the standard methods for involving users are part of the Agile toolbox). This section is short—the course is not intended as a general introduction to Agile. \\  \\ We then describe six industry best practices for incorporating UX work into an Agile team. These techniques are tried and tested, so new Agile teams can depend on them—they don’t have to pioneer them. We discuss: \\  \\ 1. Bring a user focus to “Phase 0” activities to help define the right user stories. \\  \\ Why a “Phase 0” or “Sprint 0” is needed to drive Agile development; how it is used to drive user story creation; making Phase 0 user-centered and Agile; validating concepts captured in user stories; how much is “just enough” to drive Agile development. \\  \\ 2. Write and prioritize user stories to deliver the most important user value while accommodating development needs. \\  \\ What a user story looks like; why they are valuable to development; how to split up larger stories into smaller ones; why stories should not be split along component lines but instead should deliver user value; how to balance competing goals when prioritizing stories into sprints.  \\ We practice writing user stories so participants can work with the different ways to structure a user story that delivers coherent user value while still being small enough for Agile development. \\  \\ 3. Work out low-level design details with users within the constrained timeframe of a sprint. \\  \\ The “no BDUF” value means low-level details will be worked out during sprints; when and why to design one sprint ahead and test one sprint behind; alternative methods of interleaving design and development work; “four users every Friday” as a method to bring user data into the process; how to use low-fidelity prototyping to work out design details.  \\  \\ 4. Gather real user feedback on the code as developed in each sprint and work that feedback into the Agile process. \\  \\ How to use user visits to test running code; how to run such user tests; how to design and communicate changes to the development team; alternative methods of working design changes into the backlog; how to maintain overall UI design coherence despite the focused, rapid nature of Agile development. \\  \\ 5. Maintain a coherent picture of the UI across user stories and sprints. \\ User stories and short sprints make it difficult to maintain a whole-system view of the product being created; how to maintain that view across sprints and across multiple teams working on the same system. \\  \\ 6. Be a full member of the development team with real collaboration with developers throughout the development process. \\  \\ What it means to be a full team member; where to sit, when to show up, when to have face-to-face discussions; how (and why) to involve developers in aspects of UI design; how to fit collaboration with developers into the tasks of a sprint; how and why to track UI tasks in the team’s tracking tools. \\  \\ Assumed Background of Attendees: \\  \\ This course is appropriate for all backgrounds. It is designed especially for UX designers and managers who are currently working with Agile teams and wish to improve their cooperation with those teams, or who expect to be in that situation soon. \\  \\ Presentation Format: \\  \\ The course will consist of lecture and an exercise done in pairs, followed by discussion.   \\  \\ Schedule \\  \\ Minutes Topic  \\ 5\tOverview of Agile development \\ 40 \tTechniques for UX involvement on an Agile team \\ 20\tExercise: Writing user stories \\ 15 \tSummary: The structure of an Agile project \\  \\ Audience Size: \\  \\ There is no limit to the number of people who can be in this course. We would only teach the course one time. \\  \\ Course History: \\  \\ This course is based on work done with clients in several industries, and on material previously presented at a highly-rated course at the 2011 CHI Conference. We have focused this course on practical, hands-on advice that participants can use immediately. \\  \\ Student Volunteers: \\  \\ We anticipate no unique student volunteer needs. \\  \\ Audio Visual Needs with Room Requirements: \\  \\ 1. Computer projector to be attached to instructor’s computer and large screen  \\ 2. One flipchart easel with paper  \\ 3. Wireless (lavaliere) microphone (so the instructor can move in the audience)   \\ ",
        "cbStatement": "Participants in this course will learn the UX role and tasks at each point in an Agile project. They will learn specific, tested techniques for performing that role effectively. \\ ",
        "bookmarks": 115,
        "keywords": [],
        "communities": [
            "design",
            "ux"
        ],
        "authors": [
            {
                "id": "auth11435",
                "givenName": "Hugh",
                "familyName": "Beyer",
                "email": "beyer@incontextdesign.com",
                "primary": {
                    "institution": "InContext Design",
                    "city": "Concord",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "InContext Design",
                    "city": "Concord",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth31489",
                "givenName": "Karen",
                "familyName": "Holtzblatt",
                "email": "karen@incontextdesign.com",
                "primary": {
                    "institution": "InContext Design",
                    "city": "Concord",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 66,
        "name": "Expert Reviews – For Experts",
        "type": "course",
        "abstract": "Title of the Course \\ Expert Reviews – For Experts \\  \\ Names and Affiliations of the Instructors \\ Rolf Molich, DialogDesign \\  \\ Benefits \\ Expert reviews, such as heuristic evaluations and other design inspections, are the second most widely used usability method. Nonetheless, they're often conducted with poor or unsystematic methodology and thus don't always live up to their full potential. This course teaches proven methods for conducting and reporting expert reviews of a user interface design. \\  \\ Origins \\ The instructor presented a similar course at CHI 2007, where 37 participants rated it 6.54 on a 7-point scale in response to the question \"The course was worth my time.\" \\ It is an updated version of two 90-minute sessions in the instructor’s popular full-day course “Expert Reviews - For Experts”, which has been highly rated by several hundred attendees at Nielsen-Norman Group conferences.  \\  \\ Features \\ - A survey of commonly used expert review techniques and resources accompanied by a discussion of their strengths and weaknesses. \\ - Two practical exercises in expert reviews. Participants do an expert review of a dialog and build consensus with their peers. Participants match their review skills with their peers and learn from them. \\  \\ Audience \\ Usability professionals who have usability testing experience and who have conducted some expert reviews. Although this course is not intended as an introduction to expert reviews, past participants with no expert review experience have rated it highly. \\  \\ Prerequisites \\ Basic understanding of usability and the benefits of usability evaluation. \\  \\ Presentation \\ Interactive lectures and exercises. The exercises takes about 50% of the total course time.  \\  \\ Instructor Background \\ Rolf Molich owns and manages DialogDesign, a small Danish usability consultancy. Rolf coordinates the Comparative Usability Evaluation (CUE) studies where more than 100 professional usability teams tested or reviewed the same applications. He is the co-inventor of the heuristic inspection method (with Jakob Nielsen).",
        "cbStatement": "Expert reviews are often conducted with poor or unsystematic methodology and thus don't always live up to their full potential. This course teaches proven methods for conducting expert reviews.",
        "bookmarks": 172,
        "keywords": [],
        "communities": [
            "engineering"
        ],
        "video": "cr0126-file2.mp4",
        "authors": [
            {
                "id": "auth9187",
                "givenName": "Rolf",
                "familyName": "Molich",
                "email": "chi2008@molich.dk",
                "primary": {
                    "institution": "DialogDesign",
                    "city": "Stenlose",
                    "country": "Denmark"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 67,
        "name": "Designing with and for Children in the 21st Century: Techniques and Practices",
        "type": "course",
        "abstract": "The CHI community has acknowledged children as important users by featuring a “Child-Computer Interaction” community. This course will offer a balance of traditional lecture and hands-on design activities, and will cover techniques that balance the voices and contributions of adults and children.  A version of this course was taught at CHI 2008 through 2012. In CHI 2008 the course received the highest survey ratings of any CHI course and has been rated highly in subsequent years.  We welcome and encourage attendance by industry professionals, academics, and students from a wide variety of communities. No prior experience is necessary. \\  \\ This course features a historical overview of co-designing with children, an overview of child development in relation to technology design, hands-on experiences using techniques for designing new technologies with and for children, and information about the role of the adult in co-design processes with children and practical issues of beginning a co-design team.  The presentation includes hands-on design activities, small and whole-group discussion, short presentations with slides and video. \\  \\ Allison Druin is a Professor at the University of Maryland’s HCIL. Since 1998, she has led interdisciplinary, intergenerational research teams to create new technologies for children. (http://www.umiacs.umd.edu/~allisond/).  Jerry Alan Fails is an Assistant Professor in Montclair State University’s Department of Computer Science. He has been working with children to design new technologies since 2003. His current focus is on technologies that support children and families. (http://hci.montclair.edu/fails/).  Mona Leigh Guha is a Research Associate at the University of Maryland’s HCIL. Since 2002, she has focused on the impacts of technology design processes on children who participate in them.  Greg Walsh is an Assistant Professor in the University of Baltimore’s Division of Science, Information Arts and Technologies. He focuses on creating new design techniques that include more voices in the design process. (http://research.gregwalsh.com/)",
        "cbStatement": "This course will offer a balance of traditional lecture and hands-on design activities, and will cover techniques that balance the voices and contributions of adults and children.",
        "bookmarks": 160,
        "keywords": [],
        "communities": [
            "cci"
        ],
        "video": "cr0130-file2.mp4",
        "authors": [
            {
                "id": "auth1070",
                "givenName": "Allison",
                "familyName": "Druin",
                "email": "allisond@umiacs.umd.edu",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth4981",
                "givenName": "Jerry",
                "familyName": "Fails",
                "email": "failsj@mail.montclair.edu",
                "primary": {
                    "institution": "Montclair State University",
                    "city": "Montclair",
                    "state": "New Jersey",
                    "country": "United States"
                }
            },
            {
                "id": "auth9212",
                "givenName": "Mona Leigh",
                "familyName": "Guha",
                "email": "mona@cs.umd.edu",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth12709",
                "givenName": "Greg",
                "familyName": "Walsh",
                "email": "gwalsh@umd.edu",
                "primary": {
                    "dept": "User Interface Lab",
                    "institution": "University of Baltimore",
                    "city": "Baltimore",
                    "state": "Maryland",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 68,
        "name": "HTML5 Game Development",
        "type": "course",
        "abstract": "A computer game is a microcosm of the user experience domain. UX and game design share some common aims, praxis, and theory. Although there are differences in perspective between UX designers and game designers, these are not as great as most believe, and it is certain that game designers have knowledge and skills that would be a benefit to UX designers, and vice versa. \\  \\ This course is intended for those interested in exploring games, either for themselves or as a workbench for exploring new ideas in UX. It features a practical approach, moving from initial design to a ‘first playable’ implementation. HTML5 is used so as to permit rapid dissemination using the web, and high level tools (EG Processing.js) will speed up the implementation. \\  \\ The course will be lecture based, but there will be a practical example built during the class, and the audience can play along on their laptops if they choose. Attendees should have experience using Java or C++ and should possess basic design skills.",
        "cbStatement": "This course will enable you to design and build basic games for HTML5/web deployment, and to proceed to next stages in game-like interface and game development.",
        "bookmarks": 188,
        "keywords": [],
        "communities": [
            "ux",
            "games",
            "cci"
        ],
        "video": "cr0134-file2.mp4",
        "authors": [
            {
                "id": "auth10908",
                "givenName": "Jim",
                "familyName": "Parker",
                "email": "jparker@ucalgary.ca",
                "primary": {
                    "dept": "Digital Media Lab, Art Department",
                    "institution": "University of Calgary",
                    "city": "Calgary",
                    "state": "Alberta",
                    "country": "Canada"
                },
                "secondary": {
                    "institution": "MinkHollow Media Ltd.",
                    "city": "Cochrane",
                    "state": "Alberta",
                    "country": "Canada"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 69,
        "name": "Designing Augmented Reality Experiences",
        "type": "course",
        "bookmarks": 41,
        "keywords": [],
        "communities": [
            "design",
            "ux"
        ],
        "authors": [
            {
                "id": "auth3486",
                "givenName": "Mark",
                "familyName": "Billinghurst",
                "email": "mark.billinghurst@canterbury.ac.nz",
                "primary": {
                    "dept": "HIT Lab NZ",
                    "institution": "University of Canterbury",
                    "city": "Christchurch",
                    "country": "New Zealand"
                }
            },
            {
                "id": "auth2365",
                "givenName": "Henry Been-Lirn",
                "familyName": "Duh",
                "email": "duhbl@acm.org",
                "primary": {
                    "institution": "National University of Singapore",
                    "city": "Singapore",
                    "country": "Singapore"
                }
            }
        ]
    },
    {
        "id": 70,
        "name": "The Past 100 Years of the Future: CHI/HCI/UX in Sci-Fi Movies and Television",
        "type": "course",
        "abstract": "The Past 100 Years of the Future: CHI/HCI/UX in Sci-Fi Movies and Television will summarize and analyze the past 100 years of human-computer interaction as incorporated into science-fiction cinema and video, beginning with the advent of movies in the early 1900s (Méliés' A Trip to the Moon, which was recently referenced in the movie Hugo).  \\  \\ For many decades movies have shown technology in advance of its commercialization (for example, video phones and wall-sized television displays, hand-gesture systems, and virtual-reality displays). In some cases mistaken views about what is usable, useful, and appealing seem to be adopted, perhaps because of their benefits to cinematic storytelling. In any case, these media have served as informal \"test-beds\" for new technologies of human-computer interaction and communication.  \\  \\ The course will explore issues of what is futuristic and what is not, gender-role differences, optimism/pessimism, and user-centered design characteristics in more than two dozen films and a half-dozen television shows. Examples from China, India, and Japan also will be referenced.  \\  \\ Participants will be informally informally about their recognition/understanding of the media examples shown. Discussion with participants throughout the presentation will be encouraged. \\ ",
        "cbStatement": "We examine CHI/HCI/UX in sci-fi movies/television from the last 100 years and consider usability, usefulness, and appeal.  Participants will learn how to analyze user-centered design in popular media.",
        "bookmarks": 171,
        "keywords": [],
        "communities": [
            "design",
            "engineering",
            "ux",
            "games",
            "cci",
            "arts"
        ],
        "video": "cr0139-file2.mp4",
        "authors": [
            {
                "id": "auth3392",
                "givenName": "Aaron",
                "familyName": "Marcus",
                "email": "aaron.marcus@amanda.com",
                "primary": {
                    "institution": "Aaron Marcus and Associates, Inc.",
                    "city": "Berkeley",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 71,
        "name": "Practical Statistics for User Experience Part I",
        "type": "course",
        "abstract": "If you don't measure it you can’t manage it. Usability analysis and user-research is about more than rules of thumb, good design and intuition: it’s about making better decisions with data. Is Product A faster than Product B? Will more users complete tasks on the new design?  Learn how to conduct and interpret appropriate statistical tests on small and large sample usability data then communicate your results in easy to understand terms to stakeholders. \\  \\ Features \\  \\ 1. Get a visual introduction or refresher to the most important statistical concepts for applied use. \\ 2. Be able to compare two interfaces or versions (A/B Testing) by showing statistical significance (e.g. Product A takes 20% less time to complete a task than Product B p <.05).   \\ 3. Clearly understand both the limits and data available from small sample usability data through use of confidence intervals. \\  \\ Audience \\ Open to anyone who’s interested in quantitative usability tests. Participants should be familiar with the process of conducting usability tests as well as basic descriptive statistics such as the mean, median and standard deviation and have access to Microsoft Excel. \\  \\ ",
        "cbStatement": "Learn to generate confidence intervals and compare two designs using rating scale data, binary measures and task times for large and small sample sizes.",
        "bookmarks": 21,
        "keywords": [],
        "communities": [
            "ux"
        ],
        "video": "cr0140-file2.mp4",
        "authors": [
            {
                "id": "auth10058",
                "givenName": "Jeff",
                "familyName": "Sauro",
                "email": "jeff@measuringusability.com",
                "primary": {
                    "institution": "Measuring Usability LLC",
                    "city": "Denver",
                    "state": "Colorado",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Oracle",
                    "city": "Denver",
                    "state": "Colorado",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth10259",
                "givenName": "James",
                "familyName": "Lewis",
                "email": "jimlewis@us.ibm.com",
                "primary": {
                    "institution": "IBM",
                    "city": "Boca Raton",
                    "state": "Florida",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 72,
        "name": "Storyboarding for Designers and Design Researchers",
        "type": "course",
        "abstract": "Storyboards are becoming popular techniques for visualising human-product interaction. Not only in design education, but also in design practice. They can help the design team focus on the user's actions, understanding, and experience instead of the appliance's physical form; they can be used to highlight the context, e.g., place, situation, social setting, in which the appliance is used. Their appearance can range from very sketchy to very detailed, depending on whether they are used to explore new ideas, report existing situations, or present design concepts for criticism and discussion. \\  \\ In this workshop we will use examples of storyboards from product design, movies, and comics to demonstrate the possibilities of their visual language. In the hands-on exercises, we develop a storyboard from scratch using the photoboarding technique. We explore the relation between storyboards and other design techniques (role-playing, sketching, quick-and-dirty modelling, scenarios of use, video scenarios). Special attention will be given to the visualisation of suggestive situations, social interactions, emotions, causal relations, and how to set up a story line by integrating situations. \\  \\ The material that will be covered \\ •\tThe Linguistics of storyboards: syntax, semantics, and pragmatics \\ •\tThe origins of storyboards \\ •\tStoryboards in related disciplines \\ •\tStoryboards and related design tools (personas, video, infographics) \\ •\tUses of storyboards (conceptualization, concept testing) \\ •\tCase examples showing how storyboards are used in practice \\ •\tTools and techniques to help create storyboards \\ ",
        "cbStatement": "Storyboards allow expressing the context of interactions by showing users, experiences, situation, motivations, etc. In the course we practice a hands-on technique photoboarding, for creating photoboards in a team. ",
        "bookmarks": 175,
        "keywords": [],
        "communities": [
            "design",
            "ux",
            "cci"
        ],
        "video": "cr0143-file2.mp4",
        "authors": [
            {
                "id": "auth12197",
                "givenName": "Pieter Jan",
                "familyName": "Stappers",
                "email": "p.j.stappers@tudelft.nl",
                "primary": {
                    "institution": "Delft University of Technology",
                    "city": "Delft",
                    "country": "The Netherlands"
                },
                "role": "presenter"
            },
            {
                "id": "auth26183",
                "givenName": "Gert",
                "familyName": "Pasman",
                "email": "g.j.pasman@tudelft.nl",
                "primary": {
                    "institution": "Delft University of Technology",
                    "city": "Delft",
                    "country": "The Netherlands"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 73,
        "name": "User Interface Design and Adaptation for Multi-Device Environments",
        "type": "course",
        "abstract": "Program Description: \\  \\ Benefits: This tutorial aims to help user interface designers and developers to understand the issues involved in multi-device interactive applications, which can be accessed through mobile and stationary devices even exploiting different interaction modalities (graphical, vocal, …). It will provide a discussion of the possible solutions in terms of concepts, techniques, languages, and tools, with particular attention to Web environments. The tutorial will deal with the various strategies in order to adapt, distribute, and migrate the user interface according to the context of use. \\  \\ Origins: This tutorial is an updated and more extended version of a tutorial given at CHI 2012, Mobile HCI 2010, and INTERACT 2011 \\  \\ Features: \\  \\     Issues in multi-device interfaces \\     The influence of the interaction platforms on the suitability of the possible tasks and their structure \\     Authoring multi-device interfaces \\     Model-based design of multi-device interfaces \\     Approaches to automatic adaptation \\     How to address adaptation to various platforms with different modalities (graphical, vocal, …) \\     Distributed user interfaces \\     User interfaces able to migrate and preserve their state \\  \\ Audience: The tutorial will be interesting for interactive software developers and designers who want to understand the issues involved in multi-device interactive applications and the space of the possible solutions. In addition, other researchers who would like to have an update on the state of art and research results in the field will find the tutorial of interest. \\  \\ Presentation: Lectures, demonstrations, exercises, videos, group discussions \\  \\ Instructor background: Fabio Paternò is Research Director at CNR-ISTI, where his main research interests are in user interfaces for ubiquitous environments, model-based design and development, tools and methods for multi-device interactive applications, migratory interfaces. In these areas he has coordinated several projects and the development of various tools.",
        "cbStatement": "This course provides a discussion of the possible solutions in terms of concepts, techniques, and tools for multi-device interactive applications, accessed by mobile and stationary devices even through different modalities ",
        "bookmarks": 196,
        "keywords": [],
        "communities": [
            "engineering"
        ],
        "video": "cr0150-file2.mp4",
        "authors": [
            {
                "id": "auth1464",
                "givenName": "Fabio",
                "familyName": "Paternò",
                "email": "fabio.paterno@isti.cnr.it",
                "primary": {
                    "institution": "CNR-ISTI",
                    "city": "Pisa",
                    "country": "Italy"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 74,
        "name": "Cognitive Crash Dummies: Predicting Performance from Early Prototypes",
        "type": "course",
        "abstract": "Prototyping tools are making it easier to explore a design space so many different ideas can be generated and discussed, but evaluating those ideas to understand whether they are better, as opposed to just different, is still an intensely human task. User testing, concept validation, focus groups, design walkthroughs, all are expensive in both people’s time and real dollars. \\  \\ Just as crash dummies in the automotive industry save lives by testing the physical safety of automobiles before they are brought to market, cognitive crash dummies save time, money, and potentially even lives, by allowing designers to automatically test their design ideas before implementing them. Cognitive crash dummies are models of human performance that make quantitative predictions of human behavior on proposed systems without the expense of empirical studies on running prototypes. \\  \\ When cognitive crash dummies are built into prototyping tools, design ideas can be rapidly expressed and easily evaluated. \\  \\ This course reviews the state of the art of predictive modeling and presents a tool that integrates rapid prototyping with modeling. Participants will use their own laptops to mock-up an interactive system and create a model of skilled performance on that mock-up. The course ends with a review of other tools and a look to the future of predictive modeling. \\ ",
        "cbStatement": "Presents a free tool that integrates rapid UI prototyping with predictive human performance modeling. Participants use their own laptop, learn to mock-up interactive systems, and create models of skilled performance.",
        "bookmarks": 106,
        "keywords": [],
        "communities": [
            "engineering",
            "ux"
        ],
        "authors": [
            {
                "id": "auth2393",
                "givenName": "Bonnie",
                "familyName": "John",
                "email": "bejohn@us.ibm.com",
                "primary": {
                    "institution": "IBM T.J. Watson Research Center",
                    "city": "Yorktown Heights",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 75,
        "name": "Practical Statistics for User Experience Part II",
        "type": "course",
        "abstract": "If you don't measure it you can't manage it. User-research is about more than rules of thumb, good design and intuition: it’s about making better decisions with data. Did we meet our goal of a 75% completion rate? What sample size should we plan on for a survey, or for comparing products? Will five users really find 85% of all problems? \\  \\ Learn how to conduct and interpret appropriate statistical tests on usability data, compute sample sizes and communicate your results in easy to understand terms to stakeholders. \\  \\  \\ Features \\  \\ -- Determine your sample size for comparing two designs, a benchmarking study, survey analysis or finding problems in an interface. \\  \\ -- Determine if a usability test has met or exceeded a goal (e.g. users can complete the transaction is less than 2 minutes). \\  \\ -- Get practice knowing what statistical test to perform and how to interpret the results (p-values and confidence intervals). \\  \\ Audience \\ Open to anyone who's interested in quantitative usability tests. Participants should be familiar with the process of conducting usability tests as well as be familiar with major statistical topics such as normal theory, confidence intervals and t-tests. Participants should also have access to Microsoft Excel to use the provided calculators.",
        "cbStatement": "Learn how to: compute sample sizes for user research studies (comparing designs, finding usability problems and surveys); determine if a benchmark was exceeded; and practice conducting and interpreting statistical tests.",
        "bookmarks": 130,
        "keywords": [],
        "communities": [
            "ux"
        ],
        "video": "cr0153-file2.mp4",
        "authors": [
            {
                "id": "auth10058",
                "givenName": "Jeff",
                "familyName": "Sauro",
                "email": "jeff@measuringusability.com",
                "primary": {
                    "institution": "Measuring Usability LLC",
                    "city": "Denver",
                    "state": "Colorado",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Oracle",
                    "city": "Denver",
                    "state": "Colorado",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth10259",
                "givenName": "James",
                "familyName": "Lewis",
                "email": "jimlewis@us.ibm.com",
                "primary": {
                    "institution": "IBM",
                    "city": "Boca Raton",
                    "state": "Florida",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 76,
        "name": "Analyzing Social Media Data",
        "type": "course",
        "bookmarks": 31,
        "keywords": [],
        "communities": [
            "ux"
        ],
        "authors": [
            {
                "id": "auth1985",
                "givenName": "Shelly",
                "familyName": "Farnham",
                "email": "shellyfa@microsoft.com",
                "primary": {
                    "institution": "FUSE Labs",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth23109",
                "givenName": "Emre",
                "familyName": "Kiciman",
                "email": "emrek@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "WA",
                    "country": "USA"
                }
            }
        ]
    },
    {
        "id": 77,
        "name": "Speech-based Interaction: Myths, Challenges, and Opportunities",
        "type": "course",
        "abstract": "Speech remains the \"holy grail\" of interaction, as this is the most natural form of communication that humans employ. Unfortunately, it is also one of the most difficult modalities to be understood by machines – despite, and perhaps, because it is the highest-bandwidth communication channel we possess. While significant research effort, in engineering, linguistics and psychology, have been spent on improving machines’ ability to understand and synthesize speech, the HCI community has been relatively timid in embracing this modality as a central focus of research. This can be attributed in part to the relatively discouraging levels of accuracy in understanding speech, in contrast with often-unfounded claims of success from industry, but also to the intrinsic difficulty of designing and especially evaluating interfaces that use speech and natural language as an input or output modality. While the accuracies of understanding speech input are still discouraging for many applications under less-than-ideal conditions, several interesting areas have yet to be explored that could make speech-based interaction truly hands-free. The goal of this course is to inform the HCI community of the current state of speech and natural language research, to dispel some of the myths surrounding speech-based interaction, as well as to provide an opportunity for HCI researchers and practitioners to learn more about how speech recognition and synthesis work, what are their limitations, and how these could be used to enhance current interaction paradigms.",
        "cbStatement": "Learn how speech recognition and synthesis works, what are its limitations and usability challenges, how can it enhance interaction paradigms, and what is the current research and commercial state-of-the-art. \\ ",
        "bookmarks": 98,
        "keywords": [],
        "communities": [],
        "authors": [
            {
                "id": "auth6242",
                "givenName": "Cosmin",
                "familyName": "Munteanu",
                "email": "cosmin.munteanu@nrc-cnrc.gc.ca",
                "primary": {
                    "institution": "National Research Council Canada",
                    "city": "Fredericton",
                    "state": "New Brunswick",
                    "country": "Canada"
                },
                "secondary": {
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth8487",
                "givenName": "Gerald",
                "familyName": "Penn",
                "email": "gpenn@cs.toronto.edu",
                "primary": {
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 78,
        "name": "Rapid Design Labs—A Tool to Turbocharge Design-Led Innovation",
        "type": "course",
        "abstract": "Have you ever had a big idea that got crushed? You know, one of those inspiring ideas that could change the world? If you work in a product or design group in a corporation or design firm, you have probably experienced what happens after you share one those ideas.  \\  \\ In the real world, coming up with a breakthrough idea or transformative design doesn’t mean it will automatically get to market. By definition, innovative ideas represent new ways of thinking. Organizations by nature seem to have anti-innovation antibodies that often kill new ideas—even disruptive innovations that could help companies differentiate themselves from their competition. As difficult as coming up with a game-changing idea can be, getting an organization to act on the idea often seems impossible.  \\  \\ The course Rapid Design Labs- A Tool to Turbocharge Design-Led Innovation gives you new tools for this challenge, tools that empower designers and UX teams to get breakthrough ideas and designs accepted. Learn how UX can act as a catalyst to systemically identify and drive game-changing ideas to market. Rapid design labs are a design-led, facilitative, cross-functional, iterative approach to innovation that aligns organizations and generates business value each step of the way.",
        "cbStatement": "Jim Nieters, Carola Thompson, and Amit Pande will empower designers and UX teams to act as a catalyst to systemically identify and drive game-changing ideas to market with rapid design labs.",
        "bookmarks": 95,
        "keywords": [],
        "communities": [
            "design",
            "management",
            "ux"
        ],
        "authors": [
            {
                "id": "auth11405",
                "givenName": "Jim",
                "familyName": "Nieters",
                "email": "jnieters@mac.com",
                "primary": {
                    "dept": "Consumer Travel",
                    "institution": "Hewlett Packard",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth14979",
                "givenName": "Carola",
                "familyName": "Thompson",
                "email": "carolafthompson@gmail.com",
                "primary": {
                    "institution": "zSpace, Inc",
                    "city": "Sunnyvale",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth31665",
                "givenName": "Amit",
                "familyName": "Pande",
                "email": "pande.amit@gmail.com",
                "primary": {
                    "institution": "Hewlett Packard",
                    "city": "Bangalore",
                    "country": "India"
                }
            }
        ]
    },
    {
        "id": 79,
        "name": "Make This! Introduction to Electronics Prototyping Using Arduino",
        "type": "course",
        "bookmarks": 147,
        "keywords": [],
        "communities": [
            "design"
        ],
        "authors": [
            {
                "id": "auth1438",
                "givenName": "Wendy",
                "familyName": "Ju",
                "email": "wendyju@gmail.com",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Stanford",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth16330",
                "givenName": "David",
                "familyName": "Sirkin",
                "email": "sirkin@cdr.stanford.edu",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Stanford",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 80,
        "name": "Body, Whys & Videotape: Applying Somatic Techniques to User Experience in HCI",
        "type": "course",
        "bookmarks": 59,
        "keywords": [],
        "communities": [
            "design",
            "ux",
            "health",
            "games",
            "sustainability",
            "arts"
        ],
        "authors": [
            {
                "id": "auth3338",
                "givenName": "Thecla",
                "familyName": "Schiphorst",
                "email": "thecla@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            },
            {
                "id": "auth5378",
                "givenName": "Lian",
                "familyName": "Loke",
                "email": "lian.loke@sydney.edu.au",
                "primary": {
                    "institution": "Design Lab, University of Sydney",
                    "city": "Sydney",
                    "state": "NSW",
                    "country": "Australia"
                }
            }
        ]
    },
    {
        "id": 81,
        "name": "Choice and Decision Making for HCI",
        "type": "course",
        "bookmarks": 138,
        "keywords": [],
        "communities": [],
        "authors": [
            {
                "id": "auth1660",
                "givenName": "Anthony",
                "familyName": "Jameson",
                "email": "jameson@dfki.de",
                "primary": {
                    "dept": "German Research Institute for Artificial Intelligence (DFKI), Saarbrucken, Saarland, Germany"
                }
            }
        ]
    },
    {
        "id": 82,
        "name": "Gamification @ Work",
        "type": "panel",
        "abstract": "Gamification is a buzz word in the businesses these \\ days. Is this just the latest hype, or a meaningful trend \\ worth paying attention to, or a bit of both? Most \\ importantly, what promises or benefits does \\ gamification hold for the enterprise, and what are the \\ challenges or dangers? \\ We will address these questions and more in this \\ interactive panel discussion on “Gamification @ Work”. \\ We have assembled a distinguished and diverse panel \\ of gamification experts who will share industry, \\ academic and vendor perspectives.",
        "bookmarks": 13,
        "keywords": [
            "Gamification",
            "enterprise software",
            "design",
            "user experience"
        ],
        "communities": [
            "design",
            "management",
            "ux",
            "games"
        ],
        "session": {
            "id": "s149",
            "name": "Gamification @ Work"
        },
        "room": "252b",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth14090",
                "givenName": "Janaki",
                "familyName": "Kumar",
                "email": "janaki.kumar@sap.com",
                "primary": {
                    "institution": "SAP Labs",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth31060",
                "givenName": "Mario",
                "familyName": "Herger",
                "email": "Mario.herger@sap.com",
                "primary": {
                    "institution": "SAP Labs",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth19020",
                "givenName": "Sebastian",
                "familyName": "Deterding",
                "email": "sebastian@codingconduct.cc",
                "primary": {
                    "institution": "Hans Bredow Institute for Media Research",
                    "city": "Hamburg",
                    "country": "Germany"
                },
                "secondary": {
                    "institution": "Research Center Media and Communication, Hamburg University",
                    "city": "Hamburg",
                    "country": "Germany"
                }
            },
            {
                "id": "auth31061",
                "givenName": "Scott",
                "familyName": "Schnaars",
                "email": "scott@badgeville.com",
                "primary": {
                    "institution": "Badgeville",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth31062",
                "givenName": "Matt",
                "familyName": "Landes",
                "email": "mlandes@google.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth19156",
                "givenName": "Erika",
                "familyName": "Webb",
                "email": "erika.webb@oracle.com",
                "primary": {
                    "institution": "Oracle Corporation",
                    "city": "Broomfield",
                    "state": "Colorado",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 83,
        "name": "Call All Game Changers: BYOD (Bring Your Own Disruption)",
        "type": "panel",
        "abstract": "This panel welcomes provocateurs who challenge conventional wisdom, take risks, and want to create new products and services. We are focused on looking at disruptive innovation from various key vantage points: education, cultural shift, social networking, and the corporate landscape. Join us if you want to enlist in a successful culture of disruption, and learn how to influence and propagate change throughout your organization.",
        "bookmarks": 80,
        "keywords": [
            "change",
            "disruption",
            "innovation",
            "cultural shift",
            "design thinking",
            "risk takers",
            "influence change",
            "reinvent"
        ],
        "communities": [
            "design",
            "management",
            "ux"
        ],
        "session": {
            "id": "s153",
            "name": "Call All Game Changers: BYOD (Bring Your Own Disruption)"
        },
        "room": "252b",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth24211",
                "givenName": "Iram",
                "familyName": "Mirza",
                "email": "iram.mirza@citrix.com",
                "primary": {
                    "institution": "Citrix",
                    "city": "Santa Clara",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth16363",
                "givenName": "Jannie",
                "familyName": "Lai",
                "email": "jannie_lai@yahoo.com",
                "primary": {
                    "institution": "Citrix",
                    "city": "Santa Clara",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth31654",
                "givenName": "Chris",
                "familyName": "Maliwat",
                "email": "chris@maliwat.com",
                "primary": {
                    "institution": "Facebook, Inc.",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 84,
        "name": "Digital Arts: Did You Feel That?",
        "type": "panel",
        "abstract": "This panel considers the relationships between the interactive arts, audience engagement and experience design. What might each offer the other? Engagement and experience are central to current HCI thinking. We will present and argue about the research issues of defining and understanding audience/user engagement and experience in the context of art.",
        "bookmarks": 80,
        "keywords": [
            "Digital Art",
            "Interactive Art",
            "Experience Design",
            "User Engagement"
        ],
        "communities": [
            "arts"
        ],
        "video": "pl0107-file3.mp4",
        "session": {
            "id": "s150",
            "name": "Digital Arts: Did You Feel That?"
        },
        "room": "252b",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth1938",
                "givenName": "ernest",
                "familyName": "edmonds",
                "email": "ernest@ernestedmonds.com",
                "primary": {
                    "institution": "De Montfort University",
                    "city": "Leicester",
                    "state": "Leicestershire",
                    "country": "United Kingdom"
                },
                "secondary": {
                    "institution": "University of Technology, Sydney",
                    "city": "Sydney",
                    "state": "NSW",
                    "country": "Australia"
                }
            },
            {
                "id": "auth29796",
                "givenName": "Steve",
                "familyName": "Benford",
                "email": "steve.benford@nottingham.ac.uk",
                "primary": {
                    "dept": "create",
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth31523",
                "givenName": "Zafer",
                "familyName": "Bilda",
                "email": "zafer.bilda@gmail.com",
                "primary": {
                    "institution": "Commonwealth Bank",
                    "city": "Sydney",
                    "country": "Australia"
                }
            },
            {
                "id": "auth9911",
                "givenName": "Jill",
                "familyName": "Fantauzzacoffin",
                "email": "jill@gatech.edu",
                "primary": {
                    "dept": "Digital Media Department ",
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            },
            {
                "id": "auth31525",
                "givenName": "Roger",
                "familyName": "Malina",
                "email": "rmalina@alum.mit.edu",
                "primary": {
                    "institution": "UTDallas",
                    "city": "Dallas",
                    "state": "Texas",
                    "country": "United States"
                }
            },
            {
                "id": "auth34937",
                "givenName": "Hugues",
                "familyName": "Vinet",
                "email": "hugues.vinet@ircam.fr",
                "primary": {
                    "institution": "IRCAM",
                    "city": "Paris",
                    "country": "France"
                }
            }
        ]
    },
    {
        "id": 85,
        "name": "Theory and Practice in UX Research: Uneasy Bedfellows?",
        "type": "panel",
        "abstract": "We believe that it is time to talk about user experience and its theoretical roots as well as about the relationship between theory and practice in UX research. Although user experience is overused as a buzzword, it defines a main step change in the evolvement of the HCI field and deserves a proper (theoretical) attention. Within this panel we follow up on discussions on the theoretical foundations and the value of theory for HCI and UX research from over the last years. In particular we want to go a step further and strengthen the interdisciplinary dialogue on the relationship between theory and practice when talking about user experience. We invited panelists from academia and industry to join a fruitful dialogue talking about the different perspectives on user experience, theoretical roots, and the relevance of theory for practice and vice versa. Two moderators will ensure that the audience gets their beliefs and thoughts across to the panelists as well. ",
        "bookmarks": 29,
        "keywords": [
            "User Experience",
            "Dialogue",
            "Theory",
            "Practice",
            "Design Practice",
            "Interdisciplinary",
            "Relationship Theory-Practice",
            "Theoretical Roots."
        ],
        "communities": [
            "ux"
        ],
        "video": "pl0109-file3.mp4",
        "session": {
            "id": "s151",
            "name": "Theory and Practice in UX Research: Uneasy Bedfellows?"
        },
        "room": "252b",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth7742",
                "givenName": "Marianna",
                "familyName": "Obrist",
                "email": "marianna.obrist@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth9063",
                "givenName": "Peter",
                "familyName": "Wright",
                "email": "p.c.wright@newcastle.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth1208",
                "givenName": "Kari",
                "familyName": "Kuutti",
                "email": "kari.kuutti@oulu.fi",
                "primary": {
                    "institution": "University of Oulu",
                    "city": "Oulu",
                    "country": "Finland"
                }
            },
            {
                "id": "auth2879",
                "givenName": "Yvonne",
                "familyName": "Rogers",
                "email": "y.rogers@ucl.ac.uk",
                "primary": {
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth3543",
                "givenName": "Kristina",
                "familyName": "Höök",
                "email": "kia@sics.se",
                "primary": {
                    "institution": "KTH - Royal Institute of Technology",
                    "city": "Stockholm",
                    "country": "Sweden"
                }
            },
            {
                "id": "auth8111",
                "givenName": "Pardha",
                "familyName": "Pyla",
                "email": "ppyla@vt.edu",
                "primary": {
                    "institution": "Bloomberg LP",
                    "city": "New York",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth23481",
                "givenName": "Jean-Louis",
                "familyName": "Frechin",
                "email": "studio@nodesign.net",
                "primary": {
                    "institution": "NoDesign",
                    "city": "Paris",
                    "country": "France"
                }
            }
        ]
    },
    {
        "id": 86,
        "name": "Will Massive Online Open Courses (MOOCs) Change Education?",
        "type": "panel",
        "abstract": "As has been apparent for the past several months, MOOCs  (Massive Online Open Courseware) have emerged as a powerful contender for the next new education technology.  Yet the landscape of education technology is littered with the remains of previous technological breakthroughs that have failed to live up to their initial promise, or at least their initial rhetoric.   \\  \\ Is anything different this time?  \\  \\ We strongly believe the answer is yes—this time really is different.  Several MOOCs have been run during 2012 that have taught many thousands of students in a variety of topics.  \\   \\ This panel will be a chance to review and discuss the short but engaging history of MOOCs, reviewing data from several MOOC instances, critically assessing what’s happening and why things are different.   Are MOOCs really a qualitative change in the way education can be delivered, or is it merely another new wrapper for old content.  We believe the human experience of online education is about to change; we should understand the issues behind the phenomena \\ ",
        "bookmarks": 70,
        "keywords": [
            "Education",
            "MOOC",
            "online learning",
            "collaborative learning"
        ],
        "communities": [
            "ux"
        ],
        "video": "pl0110-file3.mp4",
        "session": {
            "id": "s152",
            "name": "Will Massive Online Open Courses (MOOCs) Change Education?"
        },
        "room": "252b",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth2212",
                "givenName": "Daniel",
                "familyName": "Russell",
                "email": "drussell@google.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth1104",
                "givenName": "Scott",
                "familyName": "Klemmer",
                "email": "srk@cs.stanford.edu",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 87,
        "name": "UX Management:  Current and Future Trends",
        "type": "panel",
        "abstract": "User Experience (UX) leaders and managers are required to continually adapt to changes in: organizational strategies and re-structuring, resources, technology, economic pressures, and other factors.  Simultaneously, more companies are realizing that they need UX expertise to ensure that they are competitive in today’s marketplace.  This panel is comprised of UX leaders who have created strategies and tactics to succeed both in spite of and with the aid of the past and current trends.  The panel will focus on the current trends, what strategies and tactics have and have not worked in addressing these trends, and also discuss which future trends they think will impact UX departments, companies, and the field, and how they are preparing for these future trends. \\ The panel will be of interest to managers, practitioners and those who work closely with these teams, including developers, project managers, market researchers, test managers, and executives. \\ ",
        "bookmarks": 129,
        "keywords": [
            "User Experience",
            "Management",
            "Organizations",
            "Design",
            "Research",
            "Practice",
            "Method",
            "Technique"
        ],
        "communities": [
            "design",
            "management",
            "ux"
        ],
        "session": {
            "id": "s154",
            "name": "UX Management:  Current and Future Trends"
        },
        "room": "252b",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth13615",
                "givenName": "Janice",
                "familyName": "Rohn",
                "email": "janicerohn@yahoo.com",
                "primary": {
                    "institution": "Leads360",
                    "city": "El Segundo",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth5922",
                "givenName": "Kathy",
                "familyName": "Baxter",
                "email": "kathyb@google.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth24264",
                "givenName": "Catherine",
                "familyName": "Courage",
                "email": "catherine.courage@citrix.com",
                "primary": {
                    "institution": "Cisco System, Inc.",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth14090",
                "givenName": "Janaki",
                "familyName": "Kumar",
                "email": "janaki.kumar@sap.com",
                "primary": {
                    "institution": "SAP Labs",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth14979",
                "givenName": "Carola",
                "familyName": "Thompson",
                "email": "carolafthompson@gmail.com",
                "primary": {
                    "institution": "zSpace",
                    "city": "Sunnyvale",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth32539",
                "givenName": "Steve",
                "familyName": "Rogers",
                "email": "steverogers@google.com",
                "primary": {
                    "dept": "create",
                    "institution": "Google",
                    "city": "Charing",
                    "state": "Kent",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 88,
        "name": "We Need to Talk: HCI and the Delicate Topic of Spoken Language Interaction",
        "type": "panel",
        "abstract": "Speech and natural language remain our most natural form of interaction; yet the HCI community have been very timid about focusing their attention on designing and developing spoken language interaction techniques. This may be due to a widespread perception that perfect domain-independent speech recognition is an unattainable goal.  Progress is continuously being made in the engineering and science of speech and natural language processing, however, and there is also recent research that suggests that many applications of speech require far less than 100% accuracy to be useful in many contexts. Engaging the CHI community now is timely – many recent commercial applications, especially in the mobile space, are already tapping the increased interest in and need for natural user interfaces (NUIs) by enabling speech interaction in their products. As such, the goal of this panel is to bring together interaction designers, usability researchers, and general HCI practitioners to discuss the opportunities and directions to take in designing more natural interactions based on spoken language, and to look at how we can leverage recent advances in speech processing in order to gain widespread acceptance of speech and natural language interaction.",
        "bookmarks": 60,
        "keywords": [
            "Automatic Speech Recognition",
            "Speech Interaction"
        ],
        "communities": [],
        "video": "pl0112-file3.mp4",
        "session": {
            "id": "s155",
            "name": "We Need to Talk: HCI and the Delicate Topic of Spoken Language Interaction"
        },
        "room": "252b",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth6242",
                "givenName": "Cosmin",
                "familyName": "Munteanu",
                "email": "cosmin.munteanu@nrc-cnrc.gc.ca",
                "primary": {
                    "institution": "National Research Council Canada",
                    "city": "Fredericton",
                    "state": "New Brunswick",
                    "country": "Canada"
                },
                "secondary": {
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                }
            },
            {
                "id": "auth1008",
                "givenName": "Matt",
                "familyName": "Jones",
                "email": "always@acm.org",
                "primary": {
                    "institution": "Swansea University",
                    "city": "Swansea",
                    "state": "Wales",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth13221",
                "givenName": "Steve",
                "familyName": "Whittaker",
                "email": "swhittak@ucsc.edu",
                "primary": {
                    "dept": "HCI Lab",
                    "institution": "University of California at Santa Cruz",
                    "city": "Santa Cruz",
                    "state": "California",
                    "country": "USA"
                }
            },
            {
                "id": "auth1170",
                "givenName": "Sharon",
                "familyName": "Oviatt",
                "email": "oviatt@incaadesigns.org",
                "primary": {
                    "institution": "Incaa Designs",
                    "city": "Winslow",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth9368",
                "givenName": "Nitendra",
                "familyName": "Rajput",
                "email": "rnitendra@in.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "New Delhi",
                    "state": "Delhi",
                    "country": "India"
                }
            },
            {
                "id": "auth8487",
                "givenName": "Gerald",
                "familyName": "Penn",
                "email": "gpenn@cs.toronto.edu",
                "primary": {
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                }
            },
            {
                "id": "auth4601",
                "givenName": "Amit",
                "familyName": "Nanavati",
                "email": "namit@in.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "New Delhi",
                    "state": "Delhi",
                    "country": "India"
                }
            },
            {
                "id": "auth1374",
                "givenName": "Stephen",
                "familyName": "Brewster",
                "email": "stephen@dcs.gla.ac.uk",
                "primary": {
                    "institution": "University of Glasgow",
                    "city": "Glasgow",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 89,
        "name": "CHI at the Barricades – an Activist Agenda?",
        "type": "panel",
        "abstract": "Technology plays an increasingly important role in enabling activist agendas, supporting activist activities and self-organization, bringing people together on causes they support and developing tools and platforms to scaffold activist activities. This panel explores both the role of HCI in activism and activism in HCI.  ",
        "bookmarks": 139,
        "keywords": [
            "Activism",
            "CHI",
            "Social Sustainability",
            "Bottom of the Pyramid",
            "HCI4All"
        ],
        "communities": [
            "design",
            "ux",
            "sustainability"
        ],
        "video": "pl0114-file3.mp4",
        "session": {
            "id": "s156",
            "name": "CHI at the Barricades – an Activist Agenda?"
        },
        "room": "252b",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth1285",
                "givenName": "Daniela",
                "familyName": "Busse",
                "email": "daniela.busse@gmail.com",
                "primary": {
                    "institution": "Samsung R&D Research Center",
                    "city": "San Jose",
                    "state": "CA",
                    "country": "United States"
                }
            },
            {
                "id": "auth8695",
                "givenName": "Lisa",
                "familyName": "Nathan",
                "email": "lisa.nathan@ubc.ca",
                "primary": {
                    "institution": "University of British Columbia",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            },
            {
                "id": "auth24223",
                "givenName": "Samuel",
                "familyName": "Mann",
                "email": "samuel.mann@op.ac.nz",
                "primary": {
                    "institution": "Otago Polytechnic",
                    "city": "Dunedin",
                    "country": "New Zealand"
                }
            },
            {
                "id": "auth4620",
                "givenName": "Alan",
                "familyName": "Borning",
                "email": "borning@cs.washington.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth3519",
                "givenName": "Ben",
                "familyName": "Shneiderman",
                "email": "ben@cs.umd.edu",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                }
            },
            {
                "id": "auth34756",
                "givenName": "Andrea",
                "familyName": "Parker",
                "email": "a.parker@neu.edu",
                "primary": {
                    "dept": "College of Computer & Information Science",
                    "institution": "Northeastern University",
                    "city": "Boston",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth4305",
                "givenName": "Tad",
                "familyName": "Hirsch",
                "email": "thirsch@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth35014",
                "givenName": "Bryan",
                "familyName": "Nunez",
                "email": "bryan@witness.org",
                "primary": {
                    "institution": "WITNESS",
                    "city": "Brooklyn",
                    "state": "New York",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 90,
        "name": "Is My Doctor Listening to Me? Impact of Health IT Systems on Patient-Provider Interaction",
        "type": "panel",
        "abstract": "With the rapid development of information systems in healthcare practices, the traditional within-clinic, face-to-face mode of patient-provider interactions are increasingly facilitated, enriched, and mediated by new types of health technologies. These technologies are designed to bring better access to patient care information, resources, and a variety of communication channels. Yet, the use of these technologies may introduce unintended impacts on both patients and health providers. In this panel, drawing from our recent studies on patient-provider interaction, the panelists will discuss the emerging issues in this field. Specifically, we discuss the impacts of new technologies on synchronous co-located interaction and asynchronous remote interaction, as well as the shifts in patient-provider interaction that will emerge as ubiquitous health technologies becomes more prevalent.   ",
        "bookmarks": 21,
        "keywords": [
            "Patient-provider Interaction",
            "Health Communication",
            "Health Information Technology",
            "Electronic Medical Records",
            "Ubiquitous Technology. "
        ],
        "communities": [
            "health"
        ],
        "video": "pl0118-file3.mp4",
        "session": {
            "id": "s158",
            "name": "Is My Doctor Listening to Me? Impact of Health IT Systems on Patient-Provider Interaction"
        },
        "room": "252b",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth13111",
                "givenName": "Yunan",
                "familyName": "Chen",
                "email": "yunanc@ics.uci.edu",
                "primary": {
                    "institution": "University of California, Irvine",
                    "city": "Irvine",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth14539",
                "givenName": "Karen",
                "familyName": "Cheng",
                "email": "kgcheng@uci.edu",
                "primary": {
                    "institution": "University of California, Irvine",
                    "city": "Irvine",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth5946",
                "givenName": "Charlotte",
                "familyName": "Tang",
                "email": "char.tang@gmail.com",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "University of Michigan-Flint",
                    "city": "Flint",
                    "state": "Michigan",
                    "country": "United States"
                }
            },
            {
                "id": "auth9129",
                "givenName": "Katie",
                "familyName": "Siek",
                "email": "ksiek@cs.colorado.edu",
                "primary": {
                    "institution": "University of Colorado",
                    "city": "Boulder",
                    "state": "Colorado",
                    "country": "United States"
                }
            },
            {
                "id": "auth1962",
                "givenName": "Jakob",
                "familyName": "Bardram",
                "email": "bardram@itu.dk",
                "primary": {
                    "institution": "IT University of Copenhagen",
                    "city": "Copenhagen",
                    "country": "Denmark"
                }
            }
        ]
    },
    {
        "id": 91,
        "name": "Theory vs. Design-Driven Approaches for Behavior Change Research",
        "type": "panel",
        "abstract": "Designing and evaluating interactive systems for encouraging health behavior change at time leaves human-computer interaction researcher in a quandary: the methods and user-centered design philosophies favored in HCI can be incompatible with theory-driven approaches favored in healthcare research. The goal of this panel is to open a discussion about these tensions and to explore methods to reconcile them. ",
        "bookmarks": 133,
        "keywords": [
            "health",
            "behavior change",
            "theory"
        ],
        "communities": [
            "health",
            "sustainability"
        ],
        "session": {
            "id": "s159",
            "name": "Theory vs. Design-Driven Approaches for Behavior Change Research"
        },
        "room": "252b",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth18125",
                "givenName": "Rosa",
                "familyName": "Arriaga",
                "email": "arriaga@cc.gatech.edu",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            },
            {
                "id": "auth8277",
                "givenName": "Andrew",
                "familyName": "Miller",
                "email": "andrew.miller@gatech.edu",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            },
            {
                "id": "auth1040",
                "givenName": "Elizabeth",
                "familyName": "Mynatt",
                "email": "mynatt@cc.gatech.edu",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            },
            {
                "id": "auth32538",
                "givenName": "Claudia",
                "familyName": "Pagliari",
                "email": "hpagliar@staffmail.ed.ac.uk",
                "primary": {
                    "dept": "College of Medicine and Veterinary Medicine",
                    "institution": "The University of Edinburgh",
                    "city": "Edinburgh",
                    "state": "Scotland",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth5903",
                "givenName": "Erika",
                "familyName": "Poole",
                "email": "epoole@ist.psu.edu",
                "primary": {
                    "institution": "The Pennsylvania State University",
                    "city": "University Park",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 92,
        "name": "The Future of HCI Publishing in Journals and Books",
        "type": "panel",
        "abstract": "With the ongoing growth of digital media, academic presses and journals have had to answer some hard questions about the role of publishing in a world of blogs, social media, on-demand video and social networking. In this panel we bring together some of the top editors and publishers in HCI to explore and address these questions in a public forum.",
        "bookmarks": 176,
        "keywords": [
            "Publishing",
            "books",
            "journals."
        ],
        "communities": [],
        "video": "pl0120-file3.mp4",
        "session": {
            "id": "s157",
            "name": "The Future of HCI Publishing in Journals and Books"
        },
        "room": "252b",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth3442",
                "givenName": "Joseph 'Jofish'",
                "familyName": "Kaye",
                "email": "jofish@jofish.com",
                "primary": {
                    "institution": "Yahoo! Research",
                    "city": "Sunnyvale",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth32973",
                "givenName": "Beverley",
                "familyName": "Ford",
                "email": "beverley.ford@springer.com",
                "primary": {
                    "institution": "Springer",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth2900",
                "givenName": "Dianne",
                "familyName": "Murray",
                "email": "dianne@city.ac.uk",
                "primary": {
                    "institution": "Indep. Consultant",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth32974",
                "givenName": "Doug",
                "familyName": "Sery",
                "email": "dsery@mit.edu",
                "primary": {
                    "institution": "MIT Press",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth32975",
                "givenName": "Peter",
                "familyName": "Thomas",
                "email": "peter.thomas@manifesto-group.com",
                "primary": {
                    "institution": "Manifesto Group",
                    "city": "Melbourne",
                    "country": "Australia"
                }
            },
            {
                "id": "auth13221",
                "givenName": "Steve",
                "familyName": "Whittaker",
                "email": "swhittak@ucsc.edu",
                "primary": {
                    "dept": "HCI Lab",
                    "institution": "University of California at Santa Cruz",
                    "city": "Santa Cruz",
                    "state": "California",
                    "country": "USA"
                }
            },
            {
                "id": "auth1220",
                "givenName": "Shumin",
                "familyName": "Zhai",
                "email": "zhai@acm.org",
                "primary": {
                    "institution": "Research @ Google",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 93,
        "name": "Leveraging the Progress of Women in the HCI Field to Address the Diversity Chasm",
        "type": "panel",
        "abstract": "Worldwide there is a gender gap in technology with only a small part of all computer science related positions being held by women. Among different initiatives to encourage women to join STEM fields, we started a video interview initiative last year at CHI to encourage more women to enter and remain in the field of HCI as well as strengthening existing women’s voices. In addition to strengthening women’s progress, many interviewees also identified a diversity chasm within the HCI field that needs to be addressed. This panel aims at continuing and deepening the conversation that was started at CHI 2011 addressing the experience of women in the HCI field in both industry and academia and extending the conversation to include diversity. It will serve as a platform to discuss important issues such as mentoring, leadership, and career development and for creating networks for including and encouraging diversity in HCI. ",
        "bookmarks": 27,
        "keywords": [
            "Women",
            "equality",
            "mentoring",
            "gender",
            "diversity",
            "minorities"
        ],
        "communities": [],
        "video": "pl0121-file3.mp4",
        "session": {
            "id": "s160",
            "name": "Leveraging the Progress of Women in the HCI Field to Address the Diversity Chasm"
        },
        "room": "252b",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth11429",
                "givenName": "Susan",
                "familyName": "Dray",
                "email": "susan.dray@dray.com",
                "primary": {
                    "institution": "Dray & Associates, Inc.",
                    "city": "Minneapolis",
                    "state": "Minnesota",
                    "country": "United States"
                }
            },
            {
                "id": "auth16276",
                "givenName": "Anicia",
                "familyName": "Peters",
                "email": "anpeters@iastate.edu",
                "primary": {
                    "institution": "Iowa State University",
                    "city": "Ames",
                    "state": "Iowa",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Polytechnic of Namibia",
                    "city": "Windhoek",
                    "country": "Namibia"
                }
            },
            {
                "id": "auth25138",
                "givenName": "Anke",
                "familyName": "Brock",
                "email": "anke.brock@irit.fr",
                "primary": {
                    "dept": "IRIT",
                    "institution": "University Toulouse 3 & CNRS",
                    "city": "Toulouse",
                    "country": "France"
                }
            },
            {
                "id": "auth12859",
                "givenName": "Andrea",
                "familyName": "Peer",
                "email": "ajpeer@iastate.edu",
                "primary": {
                    "institution": "Iowa State University",
                    "city": "Ames",
                    "state": "Iowa",
                    "country": "United States"
                }
            },
            {
                "id": "auth31578",
                "givenName": "Shikoh",
                "familyName": "Gitau",
                "email": "shikoh.gitau@gmail.com",
                "primary": {
                    "institution": "Google Inc.",
                    "city": "Nairobi",
                    "country": "Kenya"
                }
            },
            {
                "id": "auth3803",
                "givenName": "Pamela",
                "familyName": "Jennings",
                "email": "pljenn@gmail.com",
                "primary": {
                    "dept": "Shapiro Center for Research and Collaboration",
                    "institution": "School of the Art Institute of Chicago",
                    "city": "Chicago",
                    "state": "Illinois",
                    "country": "United States"
                }
            },
            {
                "id": "auth14090",
                "givenName": "Janaki",
                "familyName": "Kumar",
                "email": "janaki.kumar@sap.com",
                "primary": {
                    "institution": "SAP Labs",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth2900",
                "givenName": "Dianne",
                "familyName": "Murray",
                "email": "diannes@blueyonder.co.uk",
                "primary": {
                    "institution": "Indep. Consultant",
                    "city": "London",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 94,
        "name": "Exploring the Representation of Women Perspectives in Technologies",
        "type": "panel",
        "abstract": "Technology has a profound mediating effect on the way we relate, obtain knowledge, and contribute to society. Given the impact and potential ramifications of technology on our society, it is imperative that both masculine and feminine perspectives are included in shaping our modern day technologies. This panel focuses on the representation of women perspectives in technologies we design, analyze, and use. There are many barriers when it comes to getting women perspectives into system designs such as: the small amount of HCI gender research currently in the literature, the lack of analysis of gender-agnostic software tools which fit female problem-solving approaches, and low grant support for research which looks at the representation of the feminists’ perspective in our current discourse. This panel will address these barriers with respect to the tools and technologies we experience and design.",
        "bookmarks": 81,
        "keywords": [
            "Women",
            "equality",
            "feminism",
            "gender",
            "technology",
            "HCI",
            "system design"
        ],
        "communities": [
            "design",
            "engineering",
            "management",
            "ux"
        ],
        "video": "pl0122-file3.mp4",
        "session": {
            "id": "s161",
            "name": "Exploring the Representation of Women Perspectives in Technologies"
        },
        "room": "252b",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth11429",
                "givenName": "Susan",
                "familyName": "Dray",
                "email": "susan.dray@dray.com",
                "primary": {
                    "institution": "Dray & Associates, Inc.",
                    "city": "Minneapolis",
                    "state": "Minnesota",
                    "country": "United States"
                }
            },
            {
                "id": "auth12859",
                "givenName": "Andrea",
                "familyName": "Peer",
                "email": "ajpeer@iastate.edu",
                "primary": {
                    "institution": "Iowa State University",
                    "city": "Ames",
                    "state": "Iowa",
                    "country": "United States"
                }
            },
            {
                "id": "auth25138",
                "givenName": "Anke",
                "familyName": "Brock",
                "email": "anke.brock@irit.fr",
                "primary": {
                    "institution": "IRIT",
                    "city": "Toulouse",
                    "country": "France"
                }
            },
            {
                "id": "auth16276",
                "givenName": "Anicia",
                "familyName": "Peters",
                "email": "anpeters@iastate.edu",
                "primary": {
                    "institution": "Iowa State University",
                    "city": "Ames",
                    "state": "Iowa",
                    "country": "United States"
                }
            },
            {
                "id": "auth7081",
                "givenName": "Shaowen",
                "familyName": "Bardzell",
                "email": "selu@indiana.edu",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                }
            },
            {
                "id": "auth1299",
                "givenName": "Margaret",
                "familyName": "Burnett",
                "email": "burnett@eecs.oregonstate.edu",
                "primary": {
                    "institution": "Oregon State University",
                    "city": "Corvallis",
                    "state": "Oregon",
                    "country": "United States"
                }
            },
            {
                "id": "auth1149",
                "givenName": "Elizabeth",
                "familyName": "Churchill",
                "email": "churchill@acm.org",
                "primary": {
                    "institution": "Yahoo! Research",
                    "city": "Santa Clara",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth5903",
                "givenName": "Erika",
                "familyName": "Poole",
                "email": "epoole@ist.psu.edu",
                "primary": {
                    "institution": "The Pennsylvania State University",
                    "city": "University Park",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 95,
        "name": "Making Design Probes Work",
        "type": "paper",
        "abstract": "Probes have been adopted with great enthusiasm in both Design and HCI. The heterogeneity with which they have been used in practice reflects how the method has proved elusive for many. Originators and commentators of probes have discussed misinterpretations of the method, highlighting the lack of accounts that describe in detail the design of probes and their use with participants. This paper discusses our particular use of Design Probes as directed craft objects that are both tools for design and tools for exploration across a number of projects, spanning a decade, centered on self-identity and personal significance. In offering an example of what a framework for probe design and use might look like, we attempt to address the identified lacuna, providing a synthetic account of probe design and use over an extended period and conceptualizing the relationship between the properties of probes and their use in design projects.",
        "cbStatement": "We present a synthetic account of Probe design and use over a decade conceptualizing the relationship between the properties of probes and their use in design projects.",
        "bookmarks": 194,
        "keywords": [
            "Design",
            "Probes",
            "Craft",
            "Interaction Design",
            "Materiality",
            "Empathy",
            "Reciprocity",
            "Trust",
            "Investment"
        ],
        "communities": [
            "design"
        ],
        "video": "chi1012-file5.mp4",
        "session": {
            "id": "s212",
            "name": "Designs on Design 2: Exploring Design Approaches and Constructs"
        },
        "room": "bordeaux",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth22495",
                "givenName": "Jayne",
                "familyName": "Wallace",
                "email": "jayne.wallace@northumbria.ac.uk",
                "primary": {
                    "dept": "Design",
                    "institution": "Northumbria University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth6215",
                "givenName": "John",
                "familyName": "McCarthy",
                "email": "john.mccarthy@ucc.ie",
                "primary": {
                    "institution": "University College Cork",
                    "city": "Cork",
                    "country": "Ireland"
                }
            },
            {
                "id": "auth9063",
                "givenName": "Peter",
                "middleInitial": "C",
                "familyName": "Wright",
                "email": "p.c.wright@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth5105",
                "givenName": "Patrick",
                "familyName": "Olivier",
                "email": "p.l.olivier@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 96,
        "name": "4 Design Themes for Skateboarding",
        "type": "paper",
        "abstract": "Interactive technology can support exertion activities, with many examples focusing on improving athletic performance. We see an opportunity for technology to also support extreme sports such as skateboarding, which often focus primarily on the experience of doing tricks rather than on athletic performance. However, there is little knowledge on how to design for such experiences. In response, we designed 12 basic skateboarding prototypes inspired by skateboarding theory. Using an autoethnographical approach, we skated with each of these and reflected on our experiences in order to derive four design themes : location of feedback in relation to the skater’s body, timing of feedback in relation to peaks in emotions after attempts, aspects of the trick emphasized by feedback, and aesthetic fittingness of feedback. We hope our work will guide designers of interactive systems for skateboarding, and extreme sports in general, and will therefore further our understanding of how to design for the active human body.",
        "cbStatement": "We explore how to design interactive technologies to enhance the experience of skateboarding, providing thought provoking insights into how technology can have value beyond the context of performance focused sports.",
        "bookmarks": 181,
        "keywords": [
            "Skateboarding",
            "experience of attempting tricks",
            "autoethnography",
            "extreme sports",
            "exertion"
        ],
        "communities": [
            "design",
            "ux",
            "games"
        ],
        "video": "chi1017-file5.mp4",
        "session": {
            "id": "s239",
            "name": "Phyisical Excersion"
        },
        "room": "242b",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth29369",
                "givenName": "Sebastiaan",
                "familyName": "Pijnappel",
                "email": "spijnappel@gmail.com",
                "primary": {
                    "dept": "Exertion Games Lab",
                    "institution": "RMIT University",
                    "city": "Melbourne",
                    "state": "Victoria",
                    "country": "Australia"
                },
                "role": "presenter"
            },
            {
                "id": "auth2060",
                "givenName": "Florian",
                "familyName": "Mueller",
                "email": "floyd@floydmueller.com",
                "primary": {
                    "dept": "Exertion Games Lab",
                    "institution": "RMIT University",
                    "city": "Melbourne",
                    "country": "Australia"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 97,
        "name": "Gesture Output: Eyes-Free Output: Using a Force Feedback Touch Surface",
        "type": "paper",
        "abstract": "We propose using spatial gestures not only for input but also for output. Analogous to gesture input, the proposed gesture output moves the user’s finger in a gesture, which the user then recognizes. We use our concept in a mobile scenario where a motion path forming a “5” informs users about new emails, or a heart-shaped path serves as a mes- sage from a friend. We built two prototypes: (1) The long- RangeOuija is a stationary prototype that offers a motion range of up to 4cm; (2) The pocketOuija is self-contained mobile device based on an iPhone with up to 1cm motion range. Both devices actuate the user’s fingers by means of an actuated transparent foil overlaid onto a touchscreen. \\  \\ We conducted three studies with the longRangeOuija in which participants recognized 2cm marks with 97% accu- racy, Graffiti digits with 98.8%, pairs of Graffiti digits with 90.5%, and Graffiti letters with 93.4%. Participants previ- ously unfamiliar with Graffiti identified 96.2% of digits and 76.4% of letters, suggesting that properly designed gesture output is guessable. After the experiment, the same participants were able to enter 100% of Graffiti digits by heart and 92.2% of letters. This suggests that participants learned gesture input as a side effect of using gesture output on our prototypes.",
        "cbStatement": "We propose using spatial gestures not only for input but also for output.  Analogous to gesture input, gesture output moves the user’s finger in a gesture, which the user then recognizes.",
        "bookmarks": 36,
        "keywords": [
            "Gestures",
            "Eyes Free",
            "Force feedback",
            "Touch"
        ],
        "communities": [],
        "video": "chi0102-file5.mp4",
        "session": {
            "id": "s226",
            "name": "Haptics"
        },
        "room": "352ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth9441",
                "givenName": "Anne",
                "familyName": "Roudaut",
                "email": "roudauta@gmail.com",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                },
                "secondary": {
                    "institution": "University of Bristol",
                    "city": "Bristol",
                    "country": "UK"
                },
                "role": "presenter"
            },
            {
                "id": "auth29061",
                "givenName": "Andreas",
                "familyName": "Rau",
                "email": "Andreas.Rau@student.hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                }
            },
            {
                "id": "auth30284",
                "givenName": "Christoph",
                "familyName": "Sterz",
                "email": "Christoph.Sterz@student.hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                }
            },
            {
                "id": "auth27195",
                "givenName": "Max",
                "familyName": "Plauth",
                "email": "max.plauth@student.hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                }
            },
            {
                "id": "auth21192",
                "givenName": "Pedro",
                "familyName": "Lopes",
                "email": "Pedro.Lopes@hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                }
            },
            {
                "id": "auth1437",
                "givenName": "Patrick",
                "familyName": "Baudisch",
                "email": "patrick.baudisch@hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 98,
        "name": "Digital Artifacts as Legacy: Exploring the Lifespan and Value of Digital Data",
        "type": "paper",
        "abstract": "Legacy is the meaningful and complex way in which information, values, and possessions are passed on to others. As digital systems and information become meaningfully parts of people’s everyday and social relationships, it is essential to develop new insights about how technology intersects with legacy and inheritance practices. We designed three interactive systems to investigate how digital materials might be passed down in the future. We conducted in-home interviews with ten parents using the systems to provoke discussion about how technology might support or complicate their existing practices. Sessions revealed parents desired to treat their digital information in ways not fully supported by technology. Findings are interpreted to describe design considerations for future work in this emerging space.  ",
        "cbStatement": "We designed interactive systems to investigate how digital materials might be passed down. Sessions revealed parents desired to treat their digital information in ways not fully supported by technology. ",
        "bookmarks": 77,
        "keywords": [
            "Inheritance",
            "legacy",
            "digital artifacts",
            "design",
            "interviews",
            "technology probes",
            "reflective design",
            "speculative design"
        ],
        "communities": [
            "design"
        ],
        "video": "chi1025-file5.mp4",
        "session": {
            "id": "s244",
            "name": "Studies of the Use of Digital Artifacts"
        },
        "room": "342a",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth16763",
                "givenName": "Rebecca",
                "familyName": "Gulotta",
                "email": "rgulotta@andrew.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth8702",
                "givenName": "William",
                "middleInitial": "T",
                "familyName": "Odom",
                "email": "wodom@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth17461",
                "givenName": "Haakon",
                "familyName": "Faste",
                "email": "hfaste@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth1028",
                "givenName": "Jodi",
                "middleInitial": "L",
                "familyName": "Forlizzi",
                "email": "forlizzi@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 99,
        "name": "Muscle-Propelled Force Feedback: Bringing Force Feedback to Mobile Devices",
        "type": "paper",
        "abstract": "Force feedback devices resist miniaturization, because they require physical motors and mechanics. We propose mobile force feedback by eliminating motors and instead actuating the user’s muscles using electrical stimulation. Without the motors, we obtain substantially smaller and more energy-efficient devices. We present a prototype that fits on the back of a mobile phone. It actuates users’ forearm muscles via four electrodes, which causes users’ muscles to contract involuntarily, so that they tilt the device sideways. As users resist this motion using their other arm, they perceive force feedback. We demonstrate the interaction at the example of an interactive videogame in which users steer an airplane through winds rendered using force feedback. In a first user study, we found our device to cause users to produce up to 18.7N of force, when used to actuate their palm flexors. In a second study, participants played the video game de-scribed above; all ten participants reported to prefer the experience of muscle-propelled force feedback to vibrotactile feedback.",
        "cbStatement": "We propose mobile force feedback devices by eliminating motors and instead actuating the user’s muscles using electrical stimulation. Without the motors, we obtain substantially smaller and more energy-efficient devices. ",
        "bookmarks": 20,
        "keywords": [
            "mobile",
            "force feedback",
            "EMS"
        ],
        "communities": [
            "engineering"
        ],
        "video": "chi0103-file5.mp4",
        "session": {
            "id": "s226",
            "name": "Haptics"
        },
        "room": "352ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth21192",
                "givenName": "Pedro",
                "middleInitial": "A. ",
                "familyName": "Lopes",
                "email": "Pedro.Lopes@hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth1437",
                "givenName": "Patrick",
                "middleInitial": "M.",
                "familyName": "Baudisch",
                "email": "patrick.baudisch@hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 100,
        "name": "Extracting Usability and User Experience Information from Online User Reviews",
        "type": "paper",
        "abstract": "Internet review sites allow consumers to write detailed reviews \\ of products potentially containing information related \\ to user experience (UX) and usability. Using 5198 sentences \\ from 3492 online reviews of software and video games, we \\ investigate the content of online reviews with the aims of (i) \\ charting the distribution of information in reviews among different \\ dimensions of usability and UX, and (ii) extracting an \\ associated vocabulary for each dimension using techniques \\ from natural language processing and machine learning.  \\  \\ We (a) find that 13%–49% of sentences in our online reviews pool \\ contain usability or UX information; (b) chart the distribution \\ of four sets of dimensions of usability and UX across \\ reviews from two product categories; (c) extract a catalogue \\ of important word stems for a number of dimensions.  \\  \\ Our results suggest that a greater understanding of users’ preoccupation \\ with different dimensions of usability and UX may be \\ inferred from the large volume of self-reported experiences \\ online, and that research focused on identifying pertinent dimensions \\ of usability and UX may benefit further from empirical \\ studies of user-generated experience reports.",
        "cbStatement": "We chart the occurrences of usability and user experience dimensions and their associated vocabulary found in online reviews of software and video games. \\  \\ ",
        "bookmarks": 118,
        "keywords": [
            "User experience",
            "usability",
            "natural language processing",
            "end user reviews",
            "machine learning"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi1031-file5.mp4",
        "session": {
            "id": "s281",
            "name": "Automated Usability / Evaluation Methods"
        },
        "room": "351",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth30302",
                "givenName": "Steffen",
                "familyName": "Hedegaard",
                "email": "steffenh@diku.dk",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Copenhagen",
                    "city": "Copenhagen",
                    "country": "Denmark"
                },
                "role": "presenter"
            },
            {
                "id": "auth26067",
                "givenName": "Jakob Grue",
                "familyName": "Simonsen",
                "email": "simonsen@diku.dk",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Copenhagen",
                    "city": "Copenhagen",
                    "country": "Denmark"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 101,
        "name": "VideoKheti: Making Video Content Accessible to Low-Literate and Novice Users",
        "type": "paper",
        "abstract": "Designing ICT systems for rural users in the developing world is difficult for a variety of reasons ranging from problems with infrastructure to wide differences in user contexts and capabilities. Developing regions may include huge variability in spoken languages, and users are often low- or non-literate, with very little experience interacting with digital technologies. Researchers have explored the use of text-free graphical interfaces as well as speech-based applications to overcome some of the issues related to language and literacy. While there are benefits and drawbacks to each of these approaches, they can be complementary when used together. In this work, we present VideoKheti, a mobile system using speech, graphics, and touch interaction for low-literate farmers in rural India. VideoKheti helps farmers to find and watch agricultural extension videos in their own language and dialect. In this paper, we detail the design and development of VideoKheti and report on a field study with 20 farmers in rural India who were asked to find videos based on a scenario. The results show that farmers could use VideoKheti, but their success still greatly depended on their education level. While participants were enthusiastic about using the system, the multimodal interface did not overcome many obstacles for low-literate users.",
        "cbStatement": "Reports on the design of a speech and graphics smartphone application for low-literate Indian farmers to help them browse video content. Discusses results found from a user study.",
        "bookmarks": 58,
        "keywords": [
            "Speech interface",
            "Novice users",
            "Low-literate users",
            "Mobile design",
            "Multimodal interfaces",
            "ICTD",
            "HCI4D"
        ],
        "communities": [
            "hci4d"
        ],
        "video": "chi1042-file5.mp4",
        "session": {
            "id": "s258",
            "name": "ICT4D"
        },
        "room": "242ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth17625",
                "givenName": "Sebastien",
                "familyName": "Cuendet",
                "email": "sebastien.cuendet@epfl.ch",
                "primary": {
                    "institution": "EPFL",
                    "city": "Lausanne",
                    "country": "Switzerland"
                },
                "role": "presenter"
            },
            {
                "id": "auth7864",
                "givenName": "Indrani",
                "familyName": "Medhi",
                "email": "indranim@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research India",
                    "city": "Bangalore",
                    "state": "Karnataka",
                    "country": "India"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth24052",
                "givenName": "Kalika",
                "familyName": "Bali",
                "email": "kalikab@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research India",
                    "city": "Bangalore",
                    "state": "Karnataka",
                    "country": "India"
                }
            },
            {
                "id": "auth1287",
                "givenName": "Edward",
                "familyName": "Cutrell",
                "email": "cutrell@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research India",
                    "city": "Bangalore",
                    "state": "Karnataka",
                    "country": "India"
                }
            }
        ]
    },
    {
        "id": 102,
        "name": "Learning and Performance with Gesture Guides",
        "type": "paper",
        "abstract": "Gesture-based interfaces are becoming more prevalent and complex, requiring non-trivial learning of gesture sets. Many methods for learning gestures have been proposed, but they are often evaluated with short-term recall tests that measure user performance, rather than learning. We evaluated four types of gesture guides using a retention and transfer paradigm common in motor learning experiments and found results different from those typically reported with recall tests. The results indicate that many guide systems with higher levels of guidance exhibit high performance benefits while the guide is being used, but are ultimately detrimental to user learning. We propose an adaptive guide that does not suffer from these drawbacks, and that enables a smooth transition from novice to expert. The results contrasting learning and performance can be ex-plained by the guidance hypothesis. They have important implications for the design and evaluation of future gesture learning systems.",
        "cbStatement": "Existing gesture guides show a tradeoff between performance and learning. A novel guide mitigates this tradeoff. New evaluation methods, and implications for gesture design are proposed.",
        "bookmarks": 185,
        "keywords": [
            "Gestures",
            "guides",
            "evaluation",
            "learning"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi1046-file5.mp4",
        "session": {
            "id": "s253",
            "name": "Gestures studies / empirical"
        },
        "room": "241",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth25365",
                "givenName": "Fraser",
                "familyName": "Anderson",
                "email": "frasera@ualberta.ca",
                "primary": {
                    "institution": "University of Alberta",
                    "city": "Edmonton",
                    "state": "Alberta",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth25366",
                "givenName": "Walter",
                "middleInitial": "F",
                "familyName": "Bischof",
                "email": "wfb@ualberta.ca",
                "primary": {
                    "institution": "University of Alberta",
                    "city": "Edmonton",
                    "state": "Alberta",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 103,
        "name": "A Matter of Life and Death: Practical and Ethical Constraints in the Development of a Mobile Verbal Autopsy Tool",
        "type": "paper",
        "abstract": "Verbal autopsy (VA) involves interviewing relatives of the deceased to identify the probable cause of death and is typically used in settings where there is no official system for recording deaths or their causes. Following the interview, physician assessment to determine probable cause can take several years to complete.  The World Health Organization (WHO) recognizes that there is a pressing need for a mobile device that combines direct data capture and analysis if this technique is to become part of routine health surveillance. We conducted a field test in rural South Africa to evaluate a mobile system that we designed to meet WHO requirements (namely, simplicity, feasibility, adaptability to local contexts, cost-effectiveness and program relevance). If desired, this system can provide immediate feedback to respondents about the probable cause of death at the end of a VA interview. We assessed the ethical implications of this technological development by interviewing all the stakeholders in the VA process (respondents, fieldworkers, physicians, population scientists, data managers and community engagement managers) and highlight the issues that this community needs to debate and resolve.",
        "cbStatement": "We describe the ethical issues raised by the field study of a mobile verbal autopsy device that identifies the probable cause of death from interviewing relatives of the deceased. ",
        "bookmarks": 79,
        "keywords": [
            "Verbal autopsy",
            "mobile devices",
            "ethics",
            "HCI4D."
        ],
        "communities": [
            "hci4d"
        ],
        "video": "chi1057-file5.mp4",
        "session": {
            "id": "s294",
            "name": "The Clinical Setting"
        },
        "room": "242ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth23632",
                "givenName": "Jon",
                "familyName": "Bird",
                "email": "jon.bird@ucl.ac.uk",
                "primary": {
                    "dept": "UCL Interaction Centre",
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth29416",
                "givenName": "Peter",
                "familyName": "Byass",
                "email": "peter.byass@epiph.umu.se",
                "primary": {
                    "dept": "Umeå Centre for Global Health Research",
                    "institution": "Umeå University",
                    "city": "Umeå",
                    "country": "Sweden"
                }
            },
            {
                "id": "auth29417",
                "givenName": "Kathy",
                "familyName": "Kahn",
                "email": "kathleen.kahn@wits.ac.za",
                "primary": {
                    "dept": "MRC/Wits Rural Public Health and Health Transitions Research Unit (Agincourt), School of Public Health, Faculty of Health Sciences",
                    "institution": "University of the Witwatersrand",
                    "city": "Johannesburg",
                    "country": "South Africa"
                }
            },
            {
                "id": "auth34749",
                "givenName": "Paul",
                "familyName": "Mee",
                "email": "paul.mee@agincourt.co.za",
                "primary": {
                    "dept": "MRC/Wits Rural Public Health and Health Transitions Research Unit (Agincourt), School of Public Health, Faculty of Health Sciences",
                    "institution": "University of the Witwatersrand",
                    "city": "Joh",
                    "country": "South Africa"
                }
            },
            {
                "id": "auth29418",
                "givenName": "Edward",
                "familyName": "Fottrell",
                "email": "e.fottrell@ucl.ac.uk",
                "primary": {
                    "dept": "UCL Institute for Global Health",
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 104,
        "name": "Morphees: Toward High “Shape Resolution” in Self-Actuated Flexible Mobile Devices",
        "type": "paper",
        "abstract": "We introduce the term shape resolution, which adds to the existing definitions of screen and touch resolution. We propose a framework, based on a geometric model (Non-Uniform Rational B-splines), which defines a metric for shape resolution in ten features. We illustrate it by comparing the current related work of shape changing devices. We then propose the concept of Morphees that are self-actuated flexible mobile devices adapting their shapes on their own to the context of use in order to offer better affordances. For instance, when a game is launched, the mobile device morphs into a console-like shape by curling two opposite edges to be better grasped with two hands. We then create preliminary prototypes of Morphees in order to explore six different building strategies using advanced shape changing materials (dielectric electro active polymers and shape memory alloys). By comparing the shape resolution of our prototypes, we generate insights to help designers toward creating high shape resolution Morphees.",
        "cbStatement": "We introduce the term shape resolution in 10 features, which adds to the existing definitions of screen and touch resolution and helps the design of shape-shifting mobile devices.",
        "bookmarks": 94,
        "keywords": [
            "Shape resolution, organic user interface, shape changing, flexible touchscreen, haptic feedback."
        ],
        "communities": [],
        "video": "chi0106-file5.mp4",
        "session": {
            "id": "s229",
            "name": "Bendable, Flexible"
        },
        "room": "352ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth9441",
                "givenName": "Anne",
                "familyName": "Roudaut",
                "email": "roudauta@gmail.com",
                "primary": {
                    "institution": "University of Bristol",
                    "city": "Bristol",
                    "country": "UK"
                },
                "role": "presenter"
            },
            {
                "id": "auth15656",
                "givenName": "Abhijit",
                "familyName": "Karnik",
                "email": "abe.karnik@gmail.com",
                "primary": {
                    "institution": "University of Bristol",
                    "city": "Bristol",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth16012",
                "givenName": "Markus",
                "familyName": "Löchtefeld",
                "email": "markus.loechtefeld@dfki.de",
                "primary": {
                    "institution": "German Research Center for Artificial Intelligence (DFKI)",
                    "city": "Saarbrucken",
                    "country": "Germany"
                }
            },
            {
                "id": "auth2491",
                "givenName": "Sriram",
                "familyName": "Subramanian",
                "email": "sriramable@gmail.com",
                "primary": {
                    "institution": "University of Bristol",
                    "city": "Bristol",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 105,
        "name": "Collaborative Sensemaking on a Digital Tabletop and Personal Tablets: Prioritization, Comparisons, and Tableaux",
        "type": "paper",
        "abstract": "We describe an investigation of the support that three different display configurations provided for a collaborative sensemaking task: a digital table; personal tablets; and both the tabletop and personal tablets. Mixed-methods analyses revealed that the presence of a digital tabletop display led to improved sensemaking performance, and identified activities that were supported by the shared workspace. The digital tabletop supported a group's ability to prioritize information, to make comparisons between task data, and to form and critique the group's working hypothesis. Analyses of group performance revealed a positive correlation with equity of member participation using the shared digital table, and a negative correlation of equity of member participation using personal tablets. Implications for the support of sensemaking groups, and the use of equity of member participation as a predictive measure of their performance are discussed.",
        "cbStatement": "We describe an investigation of the support that three different display configurations provided for a collaborative sensemaking task: a digital table; personal tablets; and both the tabletop and personal tablets.",
        "bookmarks": 158,
        "keywords": [
            "CSCW",
            "Sensemaking",
            "Process",
            "Equity of Participation;"
        ],
        "communities": [],
        "video": "chi1062-file5.mp4",
        "session": {
            "id": "s218",
            "name": "Multi-device Interaction"
        },
        "room": "352ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth5945",
                "givenName": "James",
                "middleInitial": "R",
                "familyName": "Wallace",
                "email": "james.wallace@gmail.com",
                "primary": {
                    "dept": "create",
                    "institution": "Systems Design Engineering, University of Waterloo",
                    "city": "Waterloo",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth1394",
                "givenName": "Stacey",
                "middleInitial": "D.",
                "familyName": "Scott",
                "email": "stacey.scott@uwaterloo.ca",
                "primary": {
                    "dept": "Systems Design Engineering",
                    "institution": "University of Waterloo",
                    "city": "Waterloo",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30316",
                "givenName": "Carolyn",
                "middleInitial": "G.",
                "familyName": "MacGregor",
                "email": "carolyn.macgregor@uwaterloo.ca",
                "primary": {
                    "dept": "create",
                    "institution": "Systems Design Engineering, University of Waterloo",
                    "city": "Waterloo",
                    "state": "Ontario",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 106,
        "name": "At Home with Agents: Exploring Attitudes Towards Future Smart Energy Infrastructures",
        "type": "paper",
        "abstract": "Energy systems researchers are proposing a broad range of future “smart” energy infrastructures to promote more efficient management of energy resources. This paper considers how consumers might relate to these future smart grids within the UK. To address this challenge we exploited a combination of demonstration and animated sketches to convey the nature of a future smart energy infrastructure based on software agents. Users’ reactions suggested that although they felt an obligation to engage with energy issues, they were principally disinterested. Users showed a considerable lack of trust in energy companies raising a dilemma of design. While users might welcome agents to help in engaging with complex energy infrastructures, they had little faith in those that might provide them. This suggests the need to consider how to design software agents to enhance trust in these socio-economic settings. ",
        "cbStatement": "This paper considers critical socio-economical issues regarding how consumers might relate to future smart energy infrastructures and suggests a number of key design principles to address those.",
        "bookmarks": 161,
        "keywords": [
            "Agent-based systems",
            "smart grid",
            "whiteboard animations",
            "sketching",
            "participatory design",
            "envisioning",
            "focus groups"
        ],
        "communities": [
            "sustainability"
        ],
        "video": "chi1063-file5.mp4",
        "session": {
            "id": "s259",
            "name": "Energy / Sustainability"
        },
        "room": "blue",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth1132",
                "givenName": "Tom",
                "middleInitial": "A",
                "familyName": "Rodden",
                "email": "tar@Cs.Nott.AC.UK",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth11772",
                "givenName": "Joel",
                "middleInitial": "E",
                "familyName": "Fischer",
                "email": "jef@cs.nott.ac.uk",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth13683",
                "givenName": "Nadia",
                "familyName": "Pantidi",
                "email": "Konstantia.Pantidi@nottingham.ac.uk",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth24743",
                "givenName": "Khaled",
                "familyName": "Bachour",
                "email": "khaled.bachour@gmail.com",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth28023",
                "givenName": "Stuart",
                "familyName": "Moran",
                "email": "stuart.moran@nottingham.ac.uk",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 107,
        "name": "A Design-led Inquiry into Personhood in Dementia",
        "type": "paper",
        "abstract": "Writers and practitioners in dementia care have invoked personhood to offer potential for preserving the agency of people living with dementia. In this context we use personhood to explore how relationships bring agentive potential to experience-centered design through a co-creative, design-led inquiry with Gillian, a woman living with dementia, and John her husband. We designed bespoke probes to empathically engage the couple in the design of both jewellery and digital jewellery to support Gillian’s personhood. Our design activity addressed the relationships involved in the context of Gillian’s family life and the progression of her illness and how they could be mediated technologically. Reminiscence became, through Gillian and John’s own hands, acts of sense making and legacy. The process of design became the way of conducting the inquiry and the designed artifacts became ways of posing questions to make sense of our experiences together.",
        "cbStatement": "A design-led, co-creative inquiry into personhood with Gillian, who has dementia, and John her husband - mediated by Design Probes and resulting in Digital Jewellery to support personhood and relationships.",
        "bookmarks": 178,
        "keywords": [
            "Personhood",
            "Self",
            "Experience-centered design",
            "Dementia",
            "Empathy",
            "Reminiscence",
            "Reflection",
            "Memory",
            "Probes"
        ],
        "communities": [
            "design"
        ],
        "video": "chi1067-file5.mp4",
        "session": {
            "id": "s297",
            "name": "Desing in a Psychiatric Setting"
        },
        "room": "242ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth22495",
                "givenName": "Jayne",
                "familyName": "Wallace",
                "email": "jayne.wallace@northumbria.ac.uk",
                "primary": {
                    "dept": "Design",
                    "institution": "Northumbria University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth9063",
                "givenName": "Peter",
                "middleInitial": "C",
                "familyName": "Wright",
                "email": "p.c.wright@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth6215",
                "givenName": "John",
                "familyName": "McCarthy",
                "email": "john.mccarthy@ucc.ie",
                "primary": {
                    "institution": "University College Cork",
                    "city": "Cork",
                    "country": "Ireland"
                }
            },
            {
                "id": "auth17320",
                "givenName": "David",
                "middleInitial": "Philip",
                "familyName": "Green",
                "email": "d.p.green@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth29442",
                "givenName": "James",
                "familyName": "Thomas",
                "email": "james.e.thomas@northumbria.ac.uk",
                "primary": {
                    "dept": "Design",
                    "institution": "Northumbria University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth5105",
                "givenName": "Patrick",
                "familyName": "Olivier",
                "email": "p.l.olivier@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 108,
        "name": "EyeContext: Recognition of High-level Contextual Cues from Human Visual Behaviour",
        "type": "paper",
        "abstract": "In this work we present EyeContext, a system to infer high-level contextual cues from human visual behaviour. We conducted a user study to record eye movements of four participants over a full day of their daily life, totalling 42.5 hours of eye movement data. Participants were asked to self-annotate four non-mutually exclusive cues: social (interacting with somebody vs. no interaction), cognitive (concentrated work vs. leisure), physical (physically active vs. not active), and spatial (inside vs. outside a building). We evaluate a proof-of-concept EyeContext system that combines encoding of eye movements into strings and a spectrum string kernel support vector machine (SVM) classifier. Our results demonstrate the large information content available in long-term human visual behaviour and opens up new venues for research on eye-based behavioural monitoring and life logging.",
        "cbStatement": "We present EyeContext, a system to automatically infer high-level contextual cues from visual behaviour. We demonstrate the large information content available in long-term visual behaviour that's potentially useful for eye-based behavioural monitoring or life logging.",
        "bookmarks": 26,
        "keywords": [
            "Context Recognition",
            "Eye Movement Analysis",
            "Visual Behaviour",
            "Electrooculography (EOG)"
        ],
        "communities": [],
        "video": "chi0107-file5.mp4",
        "session": {
            "id": "s235",
            "name": "Gaze"
        },
        "room": "bordeaux",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth11540",
                "givenName": "Andreas",
                "familyName": "Bulling",
                "email": "andreas.bulling@acm.org",
                "primary": {
                    "institution": "Max Planck Institute for Informatics",
                    "city": "Saarbrücken",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth28777",
                "givenName": "Christian",
                "familyName": "Weichel",
                "email": "c.weichel@lancaster.ac.uk",
                "primary": {
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth5955",
                "givenName": "Hans",
                "familyName": "Gellersen",
                "email": "hwg@comp.lancs.ac.uk",
                "primary": {
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 109,
        "name": "Food Practices as Situated Action: Exploring and designing for everyday food practices with households",
        "type": "paper",
        "abstract": "Household food practices are complex. Many people are unable to effectively respond to challenges in their food environment to maintain diets considered to be in line with national and international standards for healthy eating. We argue that recognizing food practices as situated action affords opportunities to identify and design for practiced, local and achievable solutions to such food problems. Interviews and shop-a-longs were carried as part of a contextual inquiry with ten households. From this, we identify food practices, such as fitting food, stocking up, food value transitions, and having fun with others and how these practices are enacted in different ways with varied outcomes. We explore how HCI might respond to these practices through issues of social fooding, the presence of others, conceptions about food practices and food routines. ",
        "cbStatement": "This paper describes everyday practices of food shopping, preparation and consumption. The paper contributes design recommendations and rich descriptions of the configuration of food practices.",
        "bookmarks": 69,
        "keywords": [
            "Food",
            "situated action",
            "everyday practice",
            "health."
        ],
        "communities": [
            "design",
            "health"
        ],
        "video": "chi0108-file5.mp4",
        "session": {
            "id": "s263",
            "name": "Food"
        },
        "room": "351",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth22329",
                "givenName": "Rob",
                "familyName": "Comber",
                "email": "robert.comber@newcastle.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth9366",
                "givenName": "Jettie",
                "familyName": "Hoonhout",
                "email": "jettie.hoonhout@philips.com",
                "primary": {
                    "institution": "Philips Research",
                    "city": "Eindhoven",
                    "country": "The Netherlands"
                }
            },
            {
                "id": "auth11614",
                "givenName": "Aart",
                "middleInitial": "T",
                "familyName": "van Halteren",
                "email": "aart.van.halteren@philips.com",
                "primary": {
                    "institution": "Philips Research",
                    "city": "Eindhoven",
                    "country": "The Netherlands"
                }
            },
            {
                "id": "auth34732",
                "givenName": "Paula",
                "familyName": "Moynihan",
                "email": "paula.moynihan@newcastle.ac.uk",
                "primary": {
                    "dept": "Institute for Ageing and Health",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth5105",
                "givenName": "Patrick",
                "familyName": "Olivier",
                "email": "p.l.olivier@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 110,
        "name": "Play it by Ear: A Case for Serendipitous Discovery of Places with Musicons",
        "type": "paper",
        "abstract": "Current location-based services (LBS) typically allow users to locate points of interest (POI) in their vicinity but can detract from the user's emotional experience of exploring a new location. In this paper, we examine how cues in the form of popular music (musicons) can emotionally engage users and enhance their experience of discovering nearby POIs serendipitously in unfamiliar places. The primary contribution of this paper is a field study, in which we evaluate the performance and emotional engagement of different types of audio-based cues for directing users' attention to specific POIs. Musicons and mixed-modality cues performed close to visual and speech cues, and significantly better than auditory icons, for POI identification while creating a much more pleasant and engaging user experience. We conclude that cues for POI discovery need not always be as explicit as the baseline visual cues. Indeed, the most challenging cues, auditory icons, led to a heightened sense of autonomy.",
        "cbStatement": "Field study investigating user performance and emotional engagement of various audio-based cues, especially musicons, during POI discovery. Helps location-based service designers design more enjoyable cues for serendipitous journeys.",
        "bookmarks": 121,
        "keywords": [
            "Audio interfaces",
            "mobility",
            "affective computing",
            "emotion"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi1085-file5.mp4",
        "session": {
            "id": "s232",
            "name": "Visual perception"
        },
        "room": "blue",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth2798",
                "givenName": "Anupriya",
                "familyName": "Ankolekar",
                "email": "anupriya.ankolekar@hp.com",
                "primary": {
                    "institution": "Hewlett Packard",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth23744",
                "givenName": "Thomas",
                "familyName": "Sandholm",
                "email": "thomas.e.sandholm@hp.com",
                "primary": {
                    "institution": "Hewlett Packard",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30333",
                "givenName": "Louis",
                "familyName": "Yu",
                "email": "louis.yu@pomona.edu",
                "primary": {
                    "institution": "Pomona College",
                    "city": "Claremont",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 111,
        "name": "How Tools in IDEs Shape Developers' Navigation Behavior",
        "type": "paper",
        "abstract": "Understanding source code is crucial for successful software maintenance, and navigating the call graph is especially helpful to understand source code. We compared maintenance performance across four different development environments: an IDE without any call graph exploration tool, a Call Hierarchy tool as found in Eclipse, and the tools Stacksplorer and Blaze. Using any of the call graph exploration tools more developers could solve certain maintenance tasks correctly. Only Stacksplorer and Blaze, however, were also able to decrease task completion times, although the Call Hierarchy offers access to a larger part of the call graph. To investigate if this result was caused by a change in navigation behavior between the tools, we used a set of predictive models to create formally comparable descriptions of programmer navigation. The results suggest that the decrease in task completion times has been caused by Stacksplorer and Blaze promoting call graph navigation more than the Call Hierarchy tool.",
        "cbStatement": "Introduces a model to describe the code navigation behavior of programmers; this model can be used to analyze the influence of different call graph navigation tools on navigation strategies.",
        "bookmarks": 169,
        "keywords": [
            "Development Tools / Toolkits / Programming Environments",
            "Analysis Methods"
        ],
        "communities": [],
        "video": "chi1090-file5.m4v",
        "session": {
            "id": "s230",
            "name": "Uis for Software Development"
        },
        "room": "blue",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth15362",
                "givenName": "Jan-Peter",
                "familyName": "Krämer",
                "email": "jpk@cs.rwth-aachen.de",
                "primary": {
                    "institution": "RWTH Aachen University",
                    "city": "Aachen",
                    "state": "NRW",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth9819",
                "givenName": "Thorsten",
                "familyName": "Karrer",
                "email": "karrer@cs.rwth-aachen.de",
                "primary": {
                    "institution": "RWTH Aachen University",
                    "city": "Aachen",
                    "state": "NRW",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth22592",
                "givenName": "Joachim",
                "familyName": "Kurz",
                "email": "joachim.kurz@rwth-aachen.de",
                "primary": {
                    "institution": "RWTH Aachen University",
                    "city": "Aachen",
                    "state": "NRW",
                    "country": "Germany"
                }
            },
            {
                "id": "auth12947",
                "givenName": "Moritz",
                "familyName": "Wittenhagen",
                "email": "wittenhagen@cs.rwth-aachen.de",
                "primary": {
                    "institution": "RWTH Aachen University",
                    "city": "Aachen",
                    "state": "NRW",
                    "country": "Germany"
                }
            },
            {
                "id": "auth1497",
                "givenName": "Jan",
                "familyName": "Borchers",
                "email": "borchers@cs.rwth-aachen.de",
                "primary": {
                    "institution": "RWTH Aachen University",
                    "city": "Aachen",
                    "state": "NRW",
                    "country": "Germany"
                }
            }
        ]
    },
    {
        "id": 112,
        "name": "Using Crowdsourcing to Support Pro-Environmental Community Activism",
        "type": "paper",
        "abstract": "Community activist groups typically rely on core groups of highly motivated members. In this paper we consider how crowdsourcing strategies can be used to supplement the activities of pro-environmental community activists, thus increasing the scalability of their campaigns. We focus on mobile data collection applications and strategies that can be used to engage casual participants in pro-environmental data collection. We report the results of a study that used both quantitative and qualitative methods to investigate the impact of different motivational factors and strategies, including both intrinsic and extrinsic motivators. The study compared and provides empirical evidence for the effectiveness of two extrinsic motivation strategies, pointification – a subset of gamification – and financial incentives. Prior environmental interest is also assessed as an intrinsic motivation factor. In contrast to previous HCI research on pro-environmental technology, much of which has focused on individual behavior change, this paper offers new insights and recommendations on the design of systems that target groups and communities.",
        "cbStatement": "We developed mobile applications and investigated motivational techniques to support crowdsourcing and pro-environmental community activism. The paper offers new insights and recommendations for environmental technologies targeting communities, rather than individuals.",
        "bookmarks": 91,
        "keywords": [
            "Community activism",
            "sustainability",
            "participatory urbanism, crowdsourcing",
            "gamification",
            "motivation"
        ],
        "communities": [
            "sustainability"
        ],
        "video": "chi1091-file5.mp4",
        "session": {
            "id": "s260",
            "name": "Crowdsource Activism Volunteering Citizen Science"
        },
        "room": "bordeaux",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth29446",
                "givenName": "Elaine",
                "familyName": "Massung",
                "email": "Elaine.Massung@bristol.ac.uk",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Bristol",
                    "city": "Bristol",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth11860",
                "givenName": "David",
                "familyName": "Coyle",
                "email": "david.coyle@bristol.ac.uk",
                "primary": {
                    "institution": "University of Bristol",
                    "city": "Bristol",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth8725",
                "givenName": "Kirsten",
                "middleInitial": "F",
                "familyName": "Cater",
                "email": "cater@cs.bris.ac.uk",
                "primary": {
                    "institution": "University of Bristol",
                    "city": "Bristol",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth30043",
                "givenName": "Marc",
                "familyName": "Jay",
                "email": "marc@marcjay.co.uk",
                "primary": {
                    "institution": "University of Bristol",
                    "city": "Bristol",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth29438",
                "givenName": "Chris",
                "familyName": "Preist",
                "email": "chris.preist@bris.ac.uk",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "University of Bristol",
                    "city": "Bristol",
                    "country": "UK"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 113,
        "name": "Supporting Orientation during Search Result Examination",
        "type": "paper",
        "abstract": "Search engines help their users decide which results to visit using captions comprising titles, URLs, and snippets containing the query keywords and proximal text from landing pages (the search results linked from the result page). Although caption content can be a key factor in these decisions, snippets provide only basic support for orienting users with landing page content from the search-engine result page (SERP), and no support during the transition to landing pages or once users reach the page following a selection decision. As a result, many searchers must employ inefficient strategies such as skimming and scanning the content of the landing page. In this paper we propose a novel method, called clickable snippets, to address this shortcoming. Clickable snippets provide searchers with a direct and actionable link between SERP captions and landing-page content. We describe a user study comparing clickable snippets with extant methods of orientation support such as query-term highlighting on the landing page and thumbnail previews on the SERP. We show that clickable snippets are preferred by participants, and lead to more effective and efficient searching. Our findings have implications for the design of the user experience in search systems.",
        "cbStatement": "Describes and evaluates Clickable Snippets, a new method to help searchers transition from results to landing pages. Can help searchers orient themselves in landing-page content and find relevant information faster.",
        "bookmarks": 49,
        "keywords": [
            "Clickable snippets",
            "Orientation",
            "Search-result examination"
        ],
        "communities": [],
        "video": "chi1094-file5.mp4",
        "session": {
            "id": "s265",
            "name": "Search and Find"
        },
        "room": "havane",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth29453",
                "givenName": "Henry",
                "familyName": "Feild",
                "email": "hfeild@cs.umass.edu",
                "primary": {
                    "institution": "University of Massachusetts",
                    "city": "Amherst",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth5929",
                "givenName": "Ryen",
                "middleInitial": "W",
                "familyName": "White",
                "email": "ryenw@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth34607",
                "givenName": "Xin",
                "familyName": "Fu",
                "email": "xfu@linkedin.com",
                "primary": {
                    "institution": "LinkedIn",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 114,
        "name": "The Presentation of Health-Related Search Results and Its Impact on Negative Emotional Outcomes",
        "type": "paper",
        "abstract": "Searching for health information online has become increasingly common, yet few studies have examined potential negative emotional effects of online health information search. We present results from an experiment manipulating the presentation of search results for common symptoms, which shows that the frequency and placement of serious illness mentions within results can influence perceptions of symptom severity and susceptibility of having the serious illness, respectively. The increase in severity and susceptibility can then lead to higher levels of negative emotional outcomes experienced–including feeling overwhelmed and frightened. Interestingly, health literacy can help reduce perceived symptom severity, and high online health experience actually increases the likelihood that individuals use a frequency-based heuristic. Technological implications and directions for future research are discussed. ",
        "cbStatement": "This experiment demonstrates features of health symptom search results that can influence negative emotional outcomes, with results suggesting strategies for web developers and users to help avoid such effects.",
        "bookmarks": 93,
        "keywords": [
            "Online health information",
            "negative effects",
            "health literacy"
        ],
        "communities": [
            "health"
        ],
        "video": "chi1104-file5.mp4",
        "session": {
            "id": "s289",
            "name": "Technologies for Life"
        },
        "room": "242ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth27802",
                "givenName": "Carolyn",
                "familyName": "Lauckner",
                "email": "carolyn.lauckner@gmail.com",
                "primary": {
                    "institution": "Michigan State Univeristy",
                    "city": "East Lansing",
                    "state": "Michigan",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth3228",
                "givenName": "Gary",
                "familyName": "Hsieh",
                "email": "garyh@msu.edu",
                "primary": {
                    "institution": "Michigan State Univeristy",
                    "city": "East Lansing",
                    "state": "Michigan",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 115,
        "name": "Playing with Leadership and Expertise: Military Tropes and Teamwork in an ARG",
        "type": "paper",
        "abstract": "Ad-hoc virtual teams often lack tools to formalize leadership and structure collaboration, yet they are often successful. How does this happen? We argue that the emergence of leadership and the development of expertise occurs in the process of taking action and in direct response to a lack of structure. Using a twinned set of eight modality sliders, we examine the interactions of fourteen players in an alternate reality game. We find that players adopted military language and culture to structure and arrange their play. We determine that it is critical to account for the context of play across these modalities in order to design appropriately for effective in-game virtual organizing.",
        "cbStatement": "Explores how ARG teams arrange and militarize play within unstructured ludic systems. Illustrates that the development of expertise and emergence of leadership occurs in response to this lack of structure.",
        "bookmarks": 195,
        "keywords": [
            "Alternate reality games",
            "computer-supported cooperative work",
            "expertise",
            "leadership",
            "team work",
            "qualitative research"
        ],
        "communities": [
            "games"
        ],
        "video": "chi1108-file5.mp4",
        "session": {
            "id": "s284",
            "name": "Nonkid Games"
        },
        "room": "251",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth30200",
                "givenName": "Tamara",
                "familyName": "Peyton",
                "email": "typ5121@psu.edu",
                "primary": {
                    "dept": "Information Sciences & Technology",
                    "institution": "The Pennsylvania State University",
                    "city": "University Park",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth25602",
                "givenName": "Alyson",
                "middleInitial": "Leigh",
                "familyName": "Young",
                "email": "alyson1@umbc.edu",
                "primary": {
                    "dept": "Information Systems",
                    "institution": "University of Maryland, Baltimore County",
                    "city": "Baltimore",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1462",
                "givenName": "Wayne",
                "familyName": "Lutters",
                "email": "lutters@umbc.edu",
                "primary": {
                    "dept": "Information Systems",
                    "institution": "University of Maryland, Baltimore County",
                    "city": "Baltimore",
                    "state": "Maryland",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 116,
        "name": "Personal Clipboards for Individual Copy-and-Paste on Shared Multi-User Surfaces",
        "type": "paper",
        "abstract": "Clipboards are omnipresent on today’s personal computing platforms. They provide copy-and-paste functionalities that let users easily reorganize information and quickly transfer data across applications. In this work, we introduce personal clipboards to multi-user surfaces. Personal clipboards enable individual and independent copy-and-paste operations, in the presence of multiple users concurrently sharing the same direct-touch interface. As common surface computing platforms do not distinguish touch input of different users, we have developed clipboards that leverage complementary personalization strategies. Specifically, we have built a context menu clipboard based on implicit user identification of every touch, a clipboard based on personal subareas dynamically placed on the surface, and a handheld clipboard based on integration of personal devices for surface interaction. In a user study, we demonstrate the effectiveness of personal clipboards for shared surfaces, and show that different personalization strategies enable clipboards, albeit with different impacts on interaction characteristics.",
        "cbStatement": "Introduces personal clipboards for individual copy-and-paste to multi-user surfaces by implementing three clipboard systems. Provides better understanding of user-identification strategies and can guide the design of personalized surface applications.",
        "bookmarks": 2,
        "keywords": [
            "multi-touch surfaces",
            "clipboards",
            "copy-and-paste"
        ],
        "communities": [
            "design",
            "engineering"
        ],
        "video": "chi0111-file5.mp4",
        "session": {
            "id": "s218",
            "name": "Multi-device Interaction"
        },
        "room": "352ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth28799",
                "givenName": "Dominik",
                "familyName": "Schmidt",
                "email": "dominik.schmidt@hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth5881",
                "givenName": "Corina",
                "familyName": "Sas",
                "email": "c.sas@lancaster.ac.uk",
                "primary": {
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth5955",
                "givenName": "Hans",
                "middleInitial": "W",
                "familyName": "Gellersen",
                "email": "hwg@comp.lancs.ac.uk",
                "primary": {
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 117,
        "name": "Putting Things in Focus: Establishing Co-Orientation Through Video in Context",
        "type": "paper",
        "abstract": "In collaborative video communication systems, establishing co-orientation around physical objects, virtual objects and people is a critical requirement. This is problematic as the technical limitations of video fractures the display of conduct in the connected environments. We present the results of a study of one collaborative system, CamBlend, which aims to alleviate some of these problems by using screen based pointing tools to both physical spaces and virtual resources. We report on how participants achieved co-orientation when using this system. We relate these findings to previous research into the fractured ecologies of collaborative spaces, describing how the form and nature of fractures in CamBlend differ from earlier reported work.",
        "cbStatement": "The CamBlend video collaboration system is used to assess how participants co-orientate around objects, both local or remote, virtual or physical, as well as around people, showing new interactional fractures.",
        "bookmarks": 157,
        "keywords": [
            "CSCW",
            "collaboration",
            "interaction analysis",
            "focus+context"
        ],
        "communities": [],
        "video": "chi1111-file5.mp4",
        "authors": [
            {
                "id": "auth15559",
                "givenName": "James",
                "familyName": "Norris",
                "email": "jzn@cs.nott.ac.uk",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth2912",
                "givenName": "Holger",
                "middleInitial": "M",
                "familyName": "Schnädelbach",
                "email": "holger.schnadelbach@nottingham.ac.uk",
                "primary": {
                    "dept": "Mixed Reality Lab, Computer Science",
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1157",
                "givenName": "Paul",
                "middleInitial": "K",
                "familyName": "Luff",
                "email": "Paul.Luff@kcl.ac.uk",
                "primary": {
                    "dept": "Department of Management",
                    "institution": "King's College, London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 118,
        "name": "Designing Action-based Exergames for Children with Cerebral Palsy",
        "type": "paper",
        "abstract": "Children with cerebral palsy (CP) want to play fast-paced action-oriented videogames similar to those played by their peers without motor disabilities. This is particularly true of exergames, whose physically-active gameplay matches the fast pace of action games. But disabilities resulting from CP can make it difficult to play action games. Guidelines for developing games for people with motor disabilities steer away from high-paced action, including recommendations to avoid the need for time-sensitive actions and to keep game pace slow. Through a year-long participatory design process with children with CP, we have discovered that it is in fact possible to develop action-oriented exergames for children with CP at level III on the Gross Motor Function Classification Scale. We followed up the design process with an eight-week home trial, in which we found the games to be playable and enjoyable. In this paper, we discuss the design of these games, and present a set of design recommendations for how to achieve both action-orientation and playability.",
        "cbStatement": "We present guidelines for the design of action-oriented exergames for people with motor disabilities. These preserve the core message of traditional guidelines, while mitigating their push to slow-paced gameplay.",
        "bookmarks": 47,
        "keywords": [
            "Exergame",
            "video game design",
            "children with cerebral palsy."
        ],
        "communities": [
            "games",
            "cci"
        ],
        "video": "chi1118-file5.mp4",
        "session": {
            "id": "s283",
            "name": "Exergames, Inclusion"
        },
        "room": "251",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth23048",
                "givenName": "Hamilton A",
                "familyName": "Hernandez",
                "email": "hamilton@cs.queensu.ca",
                "primary": {
                    "institution": "Queen's University",
                    "city": "Kingston",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth23694",
                "givenName": "Zi",
                "familyName": "Ye",
                "email": "zi@acm.org",
                "primary": {
                    "institution": "Queen's University",
                    "city": "Kingston",
                    "state": "Ontario",
                    "country": "Canada"
                }
            },
            {
                "id": "auth6619",
                "givenName": "T.C. Nicholas",
                "familyName": "Graham",
                "email": "graham@cs.queensu.ca",
                "primary": {
                    "institution": "Queen's University",
                    "city": "Kingston",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29506",
                "givenName": "Darcy",
                "familyName": "Fehlings",
                "email": "dfehlings@hollandbloorview.ca",
                "primary": {
                    "dept": "Bloorview Research Institute",
                    "institution": "Holland Bloorview Kids Rehabilitation Hospital",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "secondary": {
                    "dept": "Department of Paediatrics",
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                }
            },
            {
                "id": "auth29507",
                "givenName": "Lauren",
                "familyName": "Switzer",
                "email": "lswitzer@hollandbloorview.ca",
                "primary": {
                    "dept": "Bloorview Research Institute",
                    "institution": "Holland Bloorview Kids Rehabilitation Hospital",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 119,
        "name": "Configuring Participation: On How We Involve People In Design",
        "type": "paper",
        "abstract": "The term ‘participation’ is traditionally used in HCI to describe the involvement of users and stakeholders in design processes, with a pretext of distributing control to participants to shape their technological future. In this paper we ask whether these values can hold up in practice, particularly as participation takes on new meanings and incorporates new perspectives. We argue that much HCI research leans towards configuring participation. In discussing this claim we explore three questions that we consider important for understanding how HCI configures participation; Who initiates, directs and benefits from user participation in design? In what forms does user participation occur? How is control shared with users in design? In answering these questions we consider the conceptual, ethical and pragmatic problems this raises for current participatory HCI research. Finally, we offer directions for future work explicitly dealing with the configuration of participation.",
        "cbStatement": "Critically examines the goals of user participation in design processes in contemporary HCI. Highlights limitations in how participatory processes are documented by the community, and outlines strategies for future research.",
        "bookmarks": 103,
        "keywords": [
            "Participation",
            "participatory design",
            "performance art",
            "participatory media"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0112-file5.mp4",
        "session": {
            "id": "s245",
            "name": "Co-Design: involving propspective users in design"
        },
        "room": "351",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth21260",
                "givenName": "John",
                "familyName": "Vines",
                "email": "john.vines@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth20164",
                "givenName": "Rachel",
                "familyName": "Clarke",
                "email": "rachel@twisteddigits.co.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth9063",
                "givenName": "Peter",
                "familyName": "Wright",
                "email": "p.c.wright@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth6215",
                "givenName": "John",
                "familyName": "McCarthy",
                "email": "john.mccarthy@ucc.ie",
                "primary": {
                    "institution": "University College Cork",
                    "city": "Cork",
                    "country": "Ireland"
                }
            },
            {
                "id": "auth5105",
                "givenName": "Patrick",
                "familyName": "Olivier",
                "email": "p.l.olivier@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 120,
        "name": "Cultivating Energy Literacy— Results from a Longitudinal Living Lab Study  of a Home Energy Management System",
        "type": "paper",
        "abstract": "This paper presents results of a three-year research project focused on the emplacement of Home Energy Management Systems (HEMS) in a living lab setting with seven households. The HEMS used in this study allowed householders to monitor energy consumption both in real-time and in retrospective on the TV and on mobile devices. Contrasting with existing research focused on how technology persuades people to consume less energy, our study uses a grounded approach to analyze HEMS emplacement. As an important result, we present here the issue of ‘energy literacy’. Our study reveals that, by using HEMS, participants became increasingly literate in understanding domestic electricity consumption. We discuss the role HEMS played in that process and how the acquired literacy changed energy consumption patterns. We conclude that literacy in energy consumption has value on its own and explain how eco feedback system designs can benefit from this understanding.",
        "cbStatement": "The paper presents a 13-month living lab study around the use of Home Energy Management Systems and introduces and discusses the concept of energy literacy as a key observed category.",
        "bookmarks": 158,
        "keywords": [
            "Energy Monitoring",
            "HEMS",
            "Energy Literacy"
        ],
        "communities": [
            "sustainability"
        ],
        "video": "chi1121-file5.mp4",
        "session": {
            "id": "s259",
            "name": "Energy / Sustainability"
        },
        "room": "blue",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth17057",
                "givenName": "Tobias",
                "familyName": "Schwartz",
                "email": "tobias.schwartz@fit.fraunhofer.de",
                "primary": {
                    "institution": "Fraunhofer Institute for Applied Information Technology (FIT)",
                    "city": "Sankt Augustin",
                    "country": "Germany"
                }
            },
            {
                "id": "auth10643",
                "givenName": "Sebastian",
                "familyName": "Denef",
                "email": "sebastian.denef@fit.fraunhofer.de",
                "primary": {
                    "institution": "Fraunhofer Institute for Applied Information Technology (FIT)",
                    "city": "Sankt Augustin",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth4329",
                "givenName": "Gunnar",
                "familyName": "Stevens",
                "email": "stevens@fb5.uni-siegen.de",
                "primary": {
                    "institution": "Institut of Information Systems / University of Siegen ",
                    "city": "Siegen",
                    "state": "NRW",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth10376",
                "givenName": "Leonardo",
                "familyName": "Ramirez",
                "email": "leonardo.ramirez@fit.fraunhofer.de",
                "primary": {
                    "institution": "Fraunhofer Institute for Applied Information Technology (FIT)",
                    "city": "Sankt Augustin",
                    "country": "Germany"
                }
            },
            {
                "id": "auth1678",
                "givenName": "Volker",
                "familyName": "Wulf",
                "email": "volker.wulf@uni-siegen.de",
                "primary": {
                    "institution": "University of Siegen",
                    "city": "Siegen",
                    "state": "NRW",
                    "country": "Germany"
                },
                "secondary": {
                    "institution": "Fraunhofer Institute for Applied Information Technology (FIT)",
                    "city": "Sankt Augustin",
                    "state": "NRW",
                    "country": "Germany"
                }
            }
        ]
    },
    {
        "id": 121,
        "name": "PointAssist: Assisting Individuals with Motor Impairments",
        "type": "paper",
        "abstract": "We tested PointAssist, software that assists in pointing tasks by detecting difficulty through a sub-movement analysis and triggering help, with adjustments proposed to personalize the assistance provided to individuals with motor impairments. A within-subjects study with sixteen individuals with fine motor skills impairments resulted in statistically significant effects on accuracy using Friedman's test with chi-square(1)=6.4, p=.011 in favor of personalized PointAssist compared to no assistance.",
        "cbStatement": "This paper presents results from evaluating PointAssist with participants with motor impairments in a \\ remote test. It contributes to HCI by showing how PointAssist can be adapted to individual differences.",
        "bookmarks": 58,
        "keywords": [
            "Human-computer interaction",
            "older adults",
            "motor impairments",
            "sub-movements",
            "pointing tasks"
        ],
        "communities": [],
        "video": "chi1122-file5.mp4",
        "session": {
            "id": "s291",
            "name": "Impairment and Rehabilitation"
        },
        "room": "242ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth19028",
                "givenName": "Guarionex",
                "middleInitial": "J",
                "familyName": "Salivia",
                "email": "guarionex.salivia@mnsu.edu",
                "primary": {
                    "dept": "Computer Information Science",
                    "institution": "Minnesota State University",
                    "city": "Mankato",
                    "state": "Minnesota",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1924",
                "givenName": "Juan Pablo",
                "familyName": "Hourcade",
                "email": "hourcade@cs.uiowa.edu",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Iowa",
                    "city": "Iowa City",
                    "state": "Iowa",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 122,
        "name": "Don't Hide in the Crowd! Increasing Social Transparency Between Peer Workers Improves Crowdsourcing Outcomes",
        "type": "paper",
        "abstract": "This paper studied how social transparency and different peer-dependent reward schemes (i.e., individual, teamwork, and competition) affect the outcomes of crowdsourcing. The results showed that when social transparency was increased by asking otherwise anonymous workers to share their demographic information (e.g., name, nationality) to the paired worker, they performed significantly better. A more detailed analysis showed that in a teamwork reward scheme, in which the reward of the paired workers depended only on the collective outcomes, increasing social transparency could offset effects of social loafing by making them more accountable to their teammates. In a competition reward scheme, in which workers competed against each other and the reward depended on how much they outperformed their opponent, increasing social transparency could augment effects of social facilitation by providing more incentives for them to outperform their opponent. The results suggested that a careful combination of methods that increase social transparency and different reward schemes can significantly improve crowdsourcing outcomes.",
        "cbStatement": "Our study suggests that a careful combination of methods that increase social transparency and different peer-dependent reward schemes can significantly improve crowdsourcing outcomes.",
        "bookmarks": 183,
        "keywords": [
            "Crowdsourcing",
            "human computation",
            "social transparency",
            "social facilitation",
            "social loafing"
        ],
        "communities": [],
        "video": "chi1124-file5.mp4",
        "session": {
            "id": "s204",
            "name": "Smart Tools for Smart Work Environments: working with the crowds"
        },
        "room": "havane",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth27745",
                "givenName": "Shih-Wen",
                "familyName": "Huang",
                "email": "shuang51@illinois.edu",
                "primary": {
                    "institution": "University of Illinois at Urbana-Champaign",
                    "city": "Urbana",
                    "state": "Illinois",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth8362",
                "givenName": "Wai-Tat",
                "familyName": "Fu",
                "email": "wfu@illinois.edu",
                "primary": {
                    "institution": "University of Illinois at Urbana-Champaign",
                    "city": "Urbana",
                    "state": "Illinois",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 123,
        "name": "Understanding Palm-Based Imaginary Interfaces: The Role of Visual and Tactile Cues when Browsing",
        "type": "paper",
        "abstract": "Imaginary Interfaces are screen-less ultra-mobile interfaces. Previously we showed that even though they offer no visual feedback they allow users to interact spatially, e.g., by pointing at a location on their non-dominant hand. \\  \\ The primary goal of this paper is to provide a deeper understanding of palm-based imaginary interfaces, i.e., why they work. We perform our exploration using an interaction style inspired by interfaces for visually impaired users. We implemented a system that audibly announces target names as users scrub across their palm. Based on this interface, we conducted three studies. We found that (1) even though imaginary interfaces cannot display visual contents, users’ visual sense remains the main mechanism that allows users to control the interface, as they watch their hands interact. (2) When we remove the visual sense by blindfolding, the tactile cues of both hands feeling each other in part replace the lacking visual cues, keeping imaginary interfaces usable. (3) While we initially expected the cues sensed by the pointing finger to be most important, we found instead that it is the tactile cues sensed by the palm that allow users to orient themselves most effectively.  \\  \\ While these findings are primarily intended to deepen our understanding of Imaginary Interfaces, they also show that eyes-free interfaces located on skin outperform interfaces on physical devices. In particular, this suggests that palm-based imaginary interfaces may have benefits for visually impaired users, potentially outperforming the touchscreen-based devices they use today. \\ ",
        "cbStatement": "The main contribution of this paper is an exploration into the inherent properties of palm-based imaginary interfaces and how the available visual and tactile cues are responsible for user performance.",
        "bookmarks": 31,
        "keywords": [
            "Imaginary interfaces",
            "mobile",
            "wearable",
            "visual feedback, tactile feedback",
            "non-visual"
        ],
        "communities": [],
        "video": "chi0113-file5.mp4",
        "session": {
            "id": "s220",
            "name": "Interaction around Devices"
        },
        "room": "352ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth10512",
                "givenName": "Sean",
                "middleInitial": "G.",
                "familyName": "Gustafson",
                "email": "sean.gustafson@hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth28778",
                "givenName": "Bernhard",
                "familyName": "Rabe",
                "email": "bernhard.rabe2@student.hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                }
            },
            {
                "id": "auth1437",
                "givenName": "Patrick",
                "middleInitial": "M.",
                "familyName": "Baudisch",
                "email": "patrick.baudisch@hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 124,
        "name": "On the Relation of Ordinary Gestures to TV Screens: General Lessons for the Design of Collaborative Interactive Techniques",
        "type": "paper",
        "abstract": "We present an interaction analysis based on ethnographic fieldwork of how physical movements, including gestures, are produced by viewers in front of television screens in a sports bar. Understanding ordinary life and specifically television watching in social situations will benefit the dis-cussion of the potential of gesture techniques for controlling interactive televisions in various locations. Challenges for system design include body movement recognition, since movements can have many different purposes and are di¬rected simultaneously at the screen and co-viewers. More¬over, gestures as elements of conversation are sometimes negotiated and overlapping. Since these ordinary move¬ments are hard to automatically track and analyse, sug¬gested systems might lead to demands on viewers to re¬strain their accustomed movements and adapt them in ways that might be considered awkward. We also reveal new design opportunities that draw upon the ways viewers’ gestures are influenced by ongoing broadcast. ",
        "cbStatement": "If natural and social gesturing in front of TV screens are on-goingly and collaboratively shaped, then viewers might need to adapt such behaviour to emerging gesture tracking technology.",
        "bookmarks": 137,
        "keywords": [
            "TV viewing",
            "interaction analysis",
            "ethnomethodology",
            "ges- tures",
            "interactive television",
            "everyday practice",
            "group watching",
            "overlaps",
            "gesture tracking adaptation"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi1131-file5.m4v",
        "session": {
            "id": "s215",
            "name": "Design for the Home"
        },
        "room": "242ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth2594",
                "givenName": "Oskar",
                "familyName": "Juhlin",
                "email": "oskarj@dsv.su.se",
                "primary": {
                    "institution": "Mobile Life @ Stockholm University",
                    "city": "Kista",
                    "country": "Sweden"
                },
                "role": "presenter"
            },
            {
                "id": "auth20728",
                "givenName": "Elin",
                "familyName": "Onnevall",
                "email": "elino@tii.se",
                "primary": {
                    "institution": "Mobile Life @ Stockholm University",
                    "city": "Kista",
                    "country": "Sweden"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 125,
        "name": "Swipe Vs. Scroll: Web Page Switching on Mobile Browsers",
        "type": "paper",
        "abstract": "Tabbed web browsing interfaces enable users to multi-task and easily switch between open web pages. However, tabbed browsing is difficult for mobile web browsers due to the limited screen space and the reduced precision of touch. We present an experiment comparing Safari’s pages-based switching interface using horizontal swiping gestures with the stacked cards-based switching interface using vertical scrolling gestures, introduced by Chrome. The results of our experiment show that cards-based switching interface allows for faster switching and is less frustrating, with no significant effect on error rates. We generalize these findings, and provide design implications for mobile information spaces.",
        "cbStatement": "We present an experiment comparing Safari’s pages-based switching interface using horizontal swiping gestures with the stacked cards-based switching interface using vertical scrolling gestures, introduced by Chrome.",
        "bookmarks": 43,
        "keywords": [
            "Web browser",
            "Web browser interfaces",
            "Information spaces",
            "Task spaces",
            "Mobile"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi1134-file5.mp4",
        "session": {
            "id": "s248",
            "name": "Mobiles and more"
        },
        "room": "havane",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth17154",
                "givenName": "Andrew",
                "familyName": "Warr",
                "email": "andywarr@google.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1100",
                "givenName": "Ed",
                "middleInitial": "H",
                "familyName": "Chi",
                "email": "edchi@google.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 126,
        "name": "Envisioning Across Generations: A Multi-lifespan Information System for International Justice in Rwanda",
        "type": "paper",
        "abstract": "With this research we investigate how to account for multi-generational perspectives in the design of multi-lifespan information systems, particularly in support of long-term peace-building and international justice. We do our work in the context of the publicly available Voices from the Rwanda Tribunal testbed, a historically significant collection of video interviews with personnel from the International Criminal Tribunal for Rwanda. In the research reported here, we worked with 109 Rwandan adults and youth from perpetrator and survivor communities in three provincial cities in Rwanda (Byumba, Kibuye, and Gisenyi) to understand the potentials and challenges they envision for the interview collection. Participants envisioned five categories of long-term positive outcomes for individuals and society from a multi-lifespan information system for the interview collection; and eight categories of challenges to realize those potential outcomes. In terms of multi-generational perspectives, while adults and youth tended to share an overall vision for the long-term potential of such a system, adults emphasized actionable tasks while youth educational benefits. Based on the findings, we highlight issues for appropriation of multi-lifespan information systems and reflect on our methods for eliciting multi-generational perspectives on information system design in a post-conflict society.",
        "cbStatement": "With this research we investigate how to account for multi-generational perspectives in the design of multi-lifespan information systems, particularly in support of long-term peace-building and international justice. ",
        "bookmarks": 142,
        "keywords": [
            "Multi-lifespan information system design",
            "value sensitive design",
            "peace-building",
            "justice, cyclical violence",
            "cultural sensitivity",
            "generational perspectives"
        ],
        "communities": [
            "design",
            "hci4d"
        ],
        "session": {
            "id": "s262",
            "name": "Crime, Conflicts, and Resolution"
        },
        "room": "blue",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth14093",
                "givenName": "Daisy",
                "familyName": "Yoo",
                "email": "dyoo@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30481",
                "givenName": "Milli",
                "familyName": "Lake",
                "email": "milli@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth30482",
                "givenName": "Trond",
                "familyName": "Nilsen",
                "email": "xorgnz@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth30483",
                "givenName": "Molly",
                "middleInitial": "E",
                "familyName": "Utter",
                "email": "meutter@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth30602",
                "givenName": "Robert",
                "familyName": "Alsdorf",
                "email": "ralsdorf@alsdorfadr.com",
                "primary": {
                    "institution": "unaffiliated",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth30603",
                "givenName": "Theoneste",
                "familyName": "Bizimana",
                "email": "bizitheorda@gmail.com",
                "primary": {
                    "institution": "Healing and Rebuilding our Communities",
                    "city": "Gisenyi",
                    "country": "Rwanda"
                }
            },
            {
                "id": "auth8695",
                "givenName": "Lisa",
                "middleInitial": "P",
                "familyName": "Nathan",
                "email": "lisa.nathan@ubc.ca",
                "primary": {
                    "institution": "University of British Columbia",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            },
            {
                "id": "auth30604",
                "givenName": "Mark",
                "familyName": "Ring",
                "email": "ringm@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth15334",
                "givenName": "Elizabeth",
                "middleInitial": "J",
                "familyName": "Utter",
                "email": "rutter4804@aol.com",
                "primary": {
                    "institution": "unaffiliated",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth15334",
                "givenName": "Robert",
                "middleInitial": "F",
                "familyName": "Utter",
                "email": "rutter4804@aol.com",
                "primary": {
                    "institution": "unaffiliated",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth1585",
                "givenName": "Batya",
                "familyName": "Friedman",
                "email": "batya@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 127,
        "name": "HCI in the Press: Online Public Reactions to Mass Media Portrayals of HCI Research",
        "type": "paper",
        "abstract": "HCI researchers working in publically funded institutions are increasingly encouraged to engage the public in their research. Mass media is often seen as an effective medium with which to communicate research to large parts of the population. We present an account of three HCI projects that have used engagements with mass media in order to communicate research to the public. We describe the motivations for working with mass media and the mechanics of writing press releases. A grounded theory analysis of online public responses to the projects in the mass media leads us to identify a number of concerns about how research is portrayed by news outlets and thus interpreted by the public. Tensions about technologies and wider societal issues were revealed that might normally be hidden when using traditional user-centred methods. We critically reflect on the efficacy of using the mass media in research and provide guidance for HCI researchers wishing to engage in dialogues with the public in the future.",
        "cbStatement": "Describes the use of mass-media to provoke online public commentaries of HCI projects. Will benefit those wanting to engage the public in their research and understand associated strengths and weaknesses.",
        "bookmarks": 178,
        "keywords": [
            "Mass media",
            "public engagement",
            "sustainability",
            "digital banking",
            "older people",
            "navigation systems"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0114-file5.mp4",
        "session": {
            "id": "s278",
            "name": "HCI Ethics"
        },
        "room": "351",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth21260",
                "givenName": "John",
                "familyName": "Vines",
                "email": "john.vines@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth14057",
                "givenName": "Anja",
                "familyName": "Thieme",
                "email": "anja-thieme@gmx.de",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth22329",
                "givenName": "Rob",
                "familyName": "Comber",
                "email": "robert.comber@newcastle.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth1332",
                "givenName": "Mark",
                "familyName": "Blythe",
                "email": "mark.blythe@northumbria.ac.uk",
                "primary": {
                    "institution": "Northumbria University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth9063",
                "givenName": "Peter",
                "middleInitial": "C",
                "familyName": "Wright",
                "email": "p.c.wright@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth5105",
                "givenName": "Patrick",
                "familyName": "Olivier",
                "email": "p.l.olivier@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 128,
        "name": "Building Open Bridges: Collaborative Remixing and Reuse of Open Educational Resources across Organisations",
        "type": "paper",
        "abstract": "In this paper we analyse the remixing and reuse of online learning materials offered as Open Educational Resources (OER). We explore the practices that developed as a set of course materials were released as OER from the UK, remixed for a US context by a cross-organisational, cross-cultural team, and then reused in a broad range of educational settings. We analyse the approaches taken during these remixing and reuse activities as novel forms of creative collaboration. As a basis for comparison, we explore similarities and differences with openness in other domains. We identify how openness provoked novel inter-organisational collaboration and forms of ownership; define forms of open practice that need support, and present issues that should be considered in devising and supporting open projects in education and beyond.",
        "cbStatement": "We broaden understanding of open collaborations through analysing a cross-organisational initiative to remix and reuse Open Educational Resources. We define emerging practices and issues as openness evolves in different domains.",
        "bookmarks": 15,
        "keywords": [
            "Open",
            "Education",
            "OER",
            "Collaboration"
        ],
        "communities": [],
        "video": "chi1141-file5.mp4",
        "session": {
            "id": "s285",
            "name": "Classrooms"
        },
        "room": "blue",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth6108",
                "givenName": "Tim",
                "familyName": "Coughlan",
                "email": "tim.coughlan@nottingham.ac.uk",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "state": "Nottinghamshire",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth34954",
                "givenName": "Rebecca",
                "familyName": "Pitt",
                "email": "r.e.pitt@open.ac.uk",
                "primary": {
                    "dept": "Institute of Educational Technology",
                    "institution": "The Open University",
                    "city": "Milton Keynes",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30187",
                "givenName": "Patrick",
                "familyName": "McAndrew",
                "email": "patrick.mcandrew@open.ac.uk",
                "primary": {
                    "dept": "Institute of Educational Technology",
                    "institution": "The Open University",
                    "city": "Milton Keynes",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 129,
        "name": "Evaluating the Efficiency of Physical Visualizations",
        "type": "paper",
        "abstract": "Data sculptures are an increasingly popular form of physical visualization whose purposes are essentially artistic, communicative or educational. But can physical visualizations help carry out actual information visualization tasks? We present the first infovis study comparing physical to on-screen visualizations. We focus on 3D visualizations, as these are common among physical visualizations but known to be problematic on computers. Taking 3D bar charts as an example, we show that moving visualizations to the physical world can improve users' efficiency at information retrieval tasks. In contrast, augmenting on-screen visualizations with stereoscopic rendering alone or with prop-based manipulation was of limited help. The efficiency of physical visualizations seems to stem from features that are unique to physical objects, such as their ability to be touched and their perfect visual realism. These findings provide empirical motivation for current research on fast digital fabrication and self-reconfiguring interfaces.",
        "cbStatement": "Presents an infovis study comparing physical to on-screen visualizations. Identifies and evaluates inherent properties of physical interfaces.",
        "bookmarks": 76,
        "keywords": [
            "Physical visualization",
            "evaluation",
            "3D visualization"
        ],
        "communities": [],
        "video": "chi0115-file5.mp4",
        "session": {
            "id": "s227",
            "name": "Fabrication"
        },
        "room": "352ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth15329",
                "givenName": "Yvonne",
                "familyName": "Jansen",
                "email": "jansen@lri.fr",
                "primary": {
                    "institution": "Université Paris-Sud",
                    "city": "Orsay",
                    "country": "France"
                },
                "secondary": {
                    "institution": "INRIA",
                    "city": "Saclay",
                    "country": "France"
                },
                "role": "presenter"
            },
            {
                "id": "auth4560",
                "givenName": "Pierre",
                "familyName": "Dragicevic",
                "email": "pierre.dragice@gmail.com",
                "primary": {
                    "institution": "INRIA",
                    "city": "Saclay",
                    "country": "France"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1567",
                "givenName": "Jean-Daniel",
                "familyName": "Fekete",
                "email": "Jean-Daniel.Fekete@inria.fr",
                "primary": {
                    "institution": "INRIA",
                    "city": "Saclay",
                    "country": "France"
                }
            }
        ]
    },
    {
        "id": 130,
        "name": "MorePhone: A Study of Actuated Shape Deformations for Flexible Thin-Film Smartphone Notifications",
        "type": "paper",
        "abstract": "We present MorePhone, an actuated flexible smartphone with a thin-film E Ink display. MorePhone uses shape memory alloys to actuate the entire surface of the display as well as individual corners. We conducted a participatory study to determine how users associate urgency and notification type with full screen, 1 corner, 2 corner and 3 corner actuations of the smartphone. Results suggest that with the current prototype, actuated shape notifications are useful for visual feedback. Urgent notifications such as alarms and voice calls were best matched with actuation of the entire display surface, while less urgent notifications, such as software notifications were best matched to individual corner bends. While different corner actuations resulted in significantly different matches between notification types, medium urgency notification types were treated as similar, and best matched to a single corner bend. A follow-up study suggested that users prefer to dedicate each corner to a specific type of notification. Users would like to personalize the assignment of corners to notification type. Animation of shape actuation significantly increased the perceived urgency of any of the presented shapes.",
        "cbStatement": "Presents a shape changing flexible smartphone that actuates its body for the purpose of providing notifications. Empirically evaluates mapping between shape actuations, urgency and notification type.",
        "bookmarks": 102,
        "keywords": [
            "Flexible Displays",
            "Shape Changing Interfaces",
            "Actuation",
            "Notification",
            "Organic User Interfaces"
        ],
        "communities": [
            "design"
        ],
        "video": "chi1153-file5.mp4",
        "session": {
            "id": "s229",
            "name": "Bendable, Flexible"
        },
        "room": "352ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth30698",
                "givenName": "Antonio",
                "familyName": "Gomes",
                "email": "gomes@cs.queensu.ca",
                "primary": {
                    "dept": "Human Media Lab",
                    "institution": "Queen's University",
                    "city": "Kingston",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth30699",
                "givenName": "Andrea",
                "familyName": "Nesbitt",
                "email": "andrea.m.nesbitt@gmail.com",
                "primary": {
                    "dept": "Human Media Lab",
                    "institution": "Queen's University",
                    "city": "Kingston",
                    "state": "Ontario",
                    "country": "Canada"
                }
            },
            {
                "id": "auth1095",
                "givenName": "Roel",
                "familyName": "Vertegaal",
                "email": "roel@cs.queensu.ca",
                "primary": {
                    "dept": "Human Media Lab",
                    "institution": "Queen's University",
                    "city": "Kingston",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 131,
        "name": "Why Interactive Learning Environments Can Have It All: Resolving Design Conflicts Between Competing Goals",
        "type": "paper",
        "abstract": "Designing interactive learning environments (ILEs; e.g., intelligent tutoring systems, educational games, etc.) is a challenging interdisciplinary process that needs to satisfy multiple stakeholders. ILEs need to function in real educa-tional settings (e.g., schools) in which a number of goals interact. Several instructional design methodologies exist to help developers address these goals. However, they often lead to conflicting recommendations. Due to the lack of an established methodology to resolve such conflicts, develop-ers of ILEs have to rely on ad-hoc solutions. We present a principled methodology to resolve such conflicts. We build on a well-established design process for creating Cognitive Tutors, a highly effective type of ILE. We extend this pro-cess by integrating methods from multiple disciplines to resolve design conflicts. We illustrate our methodology’s effectiveness by describing the iterative development of the Fractions Tutor, which has proven to be effective in class-room studies with 3,000 4th-6th graders.",
        "cbStatement": "We present a principled, approach to resolving conflicts between competing goals in educational settings. We provide evidence that our approach lead to the development of a successful interactive learning environment.",
        "bookmarks": 75,
        "keywords": [
            "Design conflicts",
            "instructional design",
            "interactive learning environments",
            "Cognitive Tutors"
        ],
        "communities": [
            "design",
            "cci"
        ],
        "video": "chi1154-file5.mp4",
        "session": {
            "id": "s288",
            "name": "Learning"
        },
        "room": "251",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth20694",
                "givenName": "Martina",
                "middleInitial": "A",
                "familyName": "Rau",
                "email": "marau@cs.cmu.edu",
                "primary": {
                    "dept": "Human-Computer Interaction Institute",
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30548",
                "givenName": "Vincent",
                "familyName": "Aleven",
                "email": "aleven@cs.cmu.edu",
                "primary": {
                    "dept": "Human-Computer Interaction Institute",
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth30549",
                "givenName": "Nikol",
                "familyName": "Rummel",
                "email": "nikol.rummel@rub.de",
                "primary": {
                    "dept": "Institute of Educational Research",
                    "institution": "Ruhr-Universität Bochum",
                    "city": "Bochum",
                    "country": "Germany"
                }
            },
            {
                "id": "auth30550",
                "givenName": "Stacie",
                "familyName": "Rohrbach",
                "email": "stacie@cmu.edu",
                "primary": {
                    "dept": "School of Design",
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 132,
        "name": "Body-centric Design Space for Multi-surface Interaction",
        "type": "paper",
        "abstract": "We introduce BodyScape, a body-centric design space that allows us to describe, classify and systematically compare multi-surface interaction techniques, both individually and in combination. \\ BodyScape reflects the relationship between users and their environment, specifically how different body parts enhance or restrict movement within particular interaction techniques and can be used to analyze existing techniques or suggest new ones. \\ We illustrate the use of BodyScape by comparing two free-hand techniques, on-body touch and mid-air pointing, first separately, then combined.  \\ We found that touching the torso is faster than touching the lower legs, since it affects the user's balance; \\ and touching targets on the dominant arm is slower than targets on the torso \\ because the user must compensate for the applied force. ",
        "cbStatement": "BodyScape, a body-centric design space, allows researchers and practitioners to describe, classify and systematically compare existing multi-surface interaction techniques, individually or in combination, as well as generate new interaction techniques. \\ ",
        "bookmarks": 163,
        "keywords": [
            "Multi-surface interaction",
            "Body-centric design space"
        ],
        "communities": [],
        "video": "chi0116-file5.m4v",
        "session": {
            "id": "s238",
            "name": "Playing with Body"
        },
        "room": "242b",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth13288",
                "givenName": "Julie",
                "familyName": "Wagner",
                "email": "julie.wagner@telecom-paristech.fr",
                "primary": {
                    "institution": "INRIA",
                    "city": "Orsay",
                    "country": "France"
                },
                "secondary": {
                    "institution": "Univ Paris-Sud",
                    "city": "Orsay",
                    "country": "France"
                },
                "role": "presenter"
            },
            {
                "id": "auth12363",
                "givenName": "Mathieu",
                "familyName": "Nancel",
                "email": "nancel@lri.fr",
                "primary": {
                    "institution": "Université Paris Sud",
                    "city": "Orsay",
                    "country": "France"
                }
            },
            {
                "id": "auth10512",
                "givenName": "Sean",
                "middleInitial": "G.",
                "familyName": "Gustafson",
                "email": "sean.gustafson@hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                }
            },
            {
                "id": "auth4580",
                "givenName": "Stephane",
                "familyName": "Huot",
                "email": "Stephane.Huot@lri.fr",
                "primary": {
                    "institution": "INRIA",
                    "city": "Orsay",
                    "country": "France"
                },
                "secondary": {
                    "institution": "Univ Paris-Sud",
                    "city": "Orsay",
                    "country": "France"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1688",
                "givenName": "Wendy",
                "middleInitial": "E.",
                "familyName": "Mackay",
                "email": "mackay@lri.fr",
                "primary": {
                    "institution": "INRIA",
                    "city": "Paris",
                    "country": "France"
                }
            }
        ]
    },
    {
        "id": 133,
        "name": "Q-Methodology as a Research and Design Tool for HCI",
        "type": "paper",
        "abstract": "A “discount” version of Q-methodology for HCI, called “HCI-Q,” can be used in iterative design cycles to explore, from the point of view of users and other stakeholders, what makes technologies personally significant. Initially, designers critically reflect on their own assumptions about how a design may affect social and individual behavior. Then, designers use these assumptions as stimuli to elicit other people’s points of view. This process of critical self-reflection and evaluation helps the designer to assess the fit between a design and its intended social context of use. To demonstrate the utility of HCI-Q for research and design, we use HCI-Q to explore stakeholders’ responses to a prototype Alternative and Augmentative Communication (AAC) application called Vid2Speech. We show that our adaptation of Q-methodology is useful for revealing the structure of consensus and conflict among stakeholder perspectives, helping to situate design within the context of relevant value tensions and norms.",
        "cbStatement": "HCI-Q provides statistically valid and qualitatively rich perspectives of the personal significance of designs. HCI-Q provides design constraints by leveraging statistical methods to reveal consensus and conflict among those perspectives. ",
        "bookmarks": 178,
        "keywords": [
            "Qualitative methods",
            "quantitative methods",
            "user studies",
            "design methodology",
            "psychology",
            "personal significance"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi1160-file5.mp4",
        "session": {
            "id": "s214",
            "name": "Design Research, Paradigm and Theory"
        },
        "room": "havane",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth22824",
                "givenName": "Kathleen",
                "familyName": "O'Leary",
                "email": "katieole@gmail.com",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "WA",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1537",
                "givenName": "Jacob",
                "middleInitial": "O.",
                "familyName": "Wobbrock",
                "email": "wobbrock@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth13013",
                "givenName": "Eve",
                "middleInitial": "A.",
                "familyName": "Riskin",
                "email": "riskin@ee.washington.edu",
                "primary": {
                    "dept": "Electrical Engineering",
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 134,
        "name": "Front-Camera Video Recordings as Emotion Responses to Mobile Photos Shared Within Close-Knit Groups",
        "type": "paper",
        "abstract": "People use social-photography services to tell stories about themselves and to solicit responses from viewers. State of the-art services concentrate on textual comments, “Like” buttons, or similar means for viewers to give explicit feedback, but they overlook other, non-textual means. This paper investigates how emotion responses—as video clips captured by the front camera of a cell phone and used as tags for the individual photo viewed—can enhance photo-sharing experiences for close-knit groups. Our exploration was carried out with a mobile social-photography service called Social Camera. Four user groups (N=19) used the application for two to four weeks. The study’s results support the value of using front-camera video recordings to glean emotion response. It supports lightweight phatic social interactions not possible with comments and “Like” buttons. Most users kept sharing emotion responses throughout the study. They typically shared the responses right after they saw a just taken photo received from a remote partner. They used the responses to share their current contexts with others just as much as to convey nuanced feelings about a photo. We discuss the implications for future design and research. ",
        "cbStatement": "Using the front camera of a cell phone in social photography services: capturing video clips and sharing them as emotion responses to the individual photo viewed",
        "bookmarks": 182,
        "keywords": [
            "Social Camera",
            "Mobile",
            "Feedback",
            "Co-presence",
            "Close-knit Group",
            "Social Photography",
            "Emotion Response"
        ],
        "communities": [
            "design",
            "ux",
            "games"
        ],
        "video": "chi1166-file5.mp4",
        "session": {
            "id": "s207",
            "name": "Social Face: creativity unleashed online"
        },
        "room": "bordeaux",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth11598",
                "givenName": "Yanqing",
                "familyName": "Cui",
                "email": "yanqing.cui@gmail.com",
                "primary": {
                    "institution": "Nokia Research Center",
                    "city": "Espoo",
                    "country": "Finland"
                },
                "role": "presenter"
            },
            {
                "id": "auth29501",
                "givenName": "Jari",
                "familyName": "Kangas",
                "email": "jari.a.kangas@gmail.com",
                "primary": {
                    "institution": "Nokia Research Center",
                    "city": "Espoo",
                    "country": "Finland"
                }
            },
            {
                "id": "auth15843",
                "givenName": "Jukka",
                "familyName": "Holm",
                "email": "jukka.holm@tut.fi",
                "primary": {
                    "institution": "Nokia Research Center",
                    "city": "Espoo",
                    "country": "Finland"
                }
            },
            {
                "id": "auth29502",
                "givenName": "Guido",
                "familyName": "Grassel",
                "email": "guido.grassel@nokia.com",
                "primary": {
                    "institution": "Nokia Research Center",
                    "city": "Espoo",
                    "country": "Finland"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 135,
        "name": "The Challenges of Specifying Intervals and Absences in Temporal Queries: A Graphical Language Approach",
        "type": "paper",
        "abstract": "In our burgeoning world of ubiquitous sensors and affordable data storage, records of timestamped events are being produced across nearly every domain of personal and professional computing.  The resulting data surge has created an overarching need to search these records for meaningful patterns of events.  This paper reports on a two-part user study, as well as a series of early tests and interviews with clinical researchers, that informed the development of two temporal query interfaces: a basic, menu-based interface and an advanced, graphic-based interface. While the scope of temporal query is very broad, this work focuses on two particularly complex and critical facets of temporal event sequences: intervals (events with both a start time and an end time), and the absence of an event. We describe how users encounter a common set of difficulties when specifying such queries, and propose solutions to help overcome them.  Finally, we report on two case studies with epidemiologists at the US Army Pharmacovigilance Center, illustrating how both query interfaces were used to study patterns of drug use. ",
        "cbStatement": "Our contributions incude an assessment of the primary user difficulties in specifying queries involving intervals and absences, and two novel temporal query interfaces, designed to offer intuitive access to a wide range of temporal relationships.",
        "bookmarks": 126,
        "keywords": [
            "Query languages",
            "temporal query",
            " event sequences",
            "query interfaces",
            "electronic health records."
        ],
        "communities": [
            "health"
        ],
        "video": "chi1168-file5.m4v",
        "session": {
            "id": "s268",
            "name": "Navigating Data"
        },
        "room": "blue",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth29505",
                "givenName": "Megan",
                "familyName": "Monroe",
                "email": "madeyjay@umd.edu",
                "primary": {
                    "dept": "Department of Computer Science and HCIL",
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth29613",
                "givenName": "Rongjian",
                "familyName": "Lan",
                "email": "rjlan@cs.umd.edu",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                }
            },
            {
                "id": "auth29515",
                "givenName": "Juan",
                "familyName": "Morales del Olmo",
                "email": "juanmoralesdelolmo@gmail.com",
                "primary": {
                    "dept": "CeSViMa",
                    "institution": "Universidad Politécnica de Madrid",
                    "city": "Pozuelo de Alarcón",
                    "state": "Madrid",
                    "country": "Spain"
                }
            },
            {
                "id": "auth3519",
                "givenName": "Ben",
                "familyName": "Shneiderman",
                "email": "ben@cs.umd.edu",
                "primary": {
                    "dept": "Department of Computer Science and Human-Computer Interaction Lab",
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1222",
                "givenName": "Catherine",
                "familyName": "Plaisant",
                "email": "plaisant@cs.umd.edu",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                }
            },
            {
                "id": "auth29511",
                "givenName": "Jeff",
                "middleInitial": "A",
                "familyName": "Millstein",
                "email": "jeff.millstein@oracle.com",
                "primary": {
                    "dept": "Health Sciences",
                    "institution": "Oracle Corporation",
                    "city": "Broomfield",
                    "state": "MA",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 136,
        "name": "‘See Me, Feel Me, Touch Me, Hear Me’: Trajectories and Interpretation in a Sculpture Garden",
        "type": "paper",
        "abstract": "We apply the HCI concept of trajectories to the design of a sculpture trail. We crafted a trajectory through each sculpture, combining textual and audio instructions to drive directed viewing, movement and touching while listening to accompanying music. We designed key transitions along the way to oscillate between moments of social interaction and isolated personal engagement, and to deliver official interpretation only after visitors had been given the opportunity to make their own. We describe how visitors generally followed our trajectory, engaging with sculptures and making interpretations that sometimes challenged the received interpretation. We relate our findings to discussions of sense-making and design for multiple interpretations, concluding that curators and designers may benefit from considering ‘trajectories of interpretation’.",
        "cbStatement": "Describes the application of the trajectories framework to the design of a user experience in a sculpture garden. Can assist in designing experiences for engagement and interpretation.",
        "bookmarks": 109,
        "keywords": [
            "Galleries",
            "museums",
            "trajectories",
            "interpretation",
            "art",
            "sculpture",
            "collaboration",
            "audio",
            "instructions."
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi1169-file5.mp4",
        "session": {
            "id": "s246",
            "name": "Touching Experiences: tangible computing & trajectories"
        },
        "room": "351",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth29504",
                "givenName": "Lesley",
                "familyName": "Fosh",
                "email": "psxlf@nottingham.ac.uk",
                "primary": {
                    "dept": "Horizon Doctoral Training Centre",
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth1508",
                "givenName": "Steve",
                "familyName": "Benford",
                "email": "sdb@cs.nott.ac.uk",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth4484",
                "givenName": "Stuart",
                "familyName": "Reeves",
                "email": "stuart@tropic.org.uk",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth2250",
                "givenName": "Boriana",
                "familyName": "Koleva",
                "email": "bnk@cs.nott.ac.uk",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth13297",
                "givenName": "Patrick",
                "familyName": "Brundell",
                "email": "prb@cs.nott.ac.uk",
                "primary": {
                    "dept": "Mixed Reality Lab, Computer Science",
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 137,
        "name": "High-Precision Pointing on Large Wall Displays using Small Handheld Devices",
        "type": "paper",
        "abstract": "Rich interaction with high-resolution wall displays is not limited to remotely pointing at targets. Other relevant types of interaction include virtual navigation, text entry, and direct manipulation of control widgets. However, most techniques for remotely acquiring targets with high precision have studied remote pointing in isolation, focusing on pointing efficiency and ignoring the need to support these other types of interaction. \\ We investigate high-precision pointing techniques capable of acquiring targets as small as 4 millimeters on a 5.5 meters wide display while leaving up to 93 % of a typical tablet device's screen space available for task-specific widgets. We compare these techniques to state-of-the-art distant pointing techniques and show that two of our techniques, a purely relative one and one that uses head orientation, perform as well or better than the best pointing-only input techniques while using a fraction of the interaction resources.",
        "cbStatement": "Reports on the design and evaluation of pointing techniques, some of which use head orientation, so the handheld device can also be used for other interactions.",
        "bookmarks": 123,
        "keywords": [
            "Wall Displays",
            "Handheld Devices",
            "Pointing"
        ],
        "communities": [],
        "video": "chi0117-file5.mp4",
        "session": {
            "id": "s249",
            "name": "Large and public Displays"
        },
        "room": "241",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth12363",
                "givenName": "Mathieu",
                "familyName": "Nancel",
                "email": "nancel@lri.fr",
                "primary": {
                    "institution": "Univ Paris-Sud",
                    "city": "Orsay",
                    "country": "France"
                },
                "secondary": {
                    "institution": "INRIA",
                    "city": "Orsay",
                    "country": "France"
                },
                "role": "presenter"
            },
            {
                "id": "auth7237",
                "givenName": "Olivier",
                "familyName": "Chapuis",
                "email": "chapuis@lri.fr",
                "primary": {
                    "institution": "Univ Paris-Sud",
                    "city": "Orsay",
                    "country": "France"
                },
                "secondary": {
                    "institution": "INRIA",
                    "city": "Orsay",
                    "country": "France"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth5828",
                "givenName": "Emmanuel",
                "familyName": "Pietriga",
                "email": "emmanuel.pietriga@inria.fr",
                "primary": {
                    "institution": "INRIA, Orsay, France & INRIA Chile",
                    "city": "Orsay",
                    "country": "France"
                }
            },
            {
                "id": "auth10966",
                "givenName": "Xing-Dong",
                "familyName": "Yang",
                "email": "xingdong@cs.ualberta.ca",
                "primary": {
                    "institution": "University of Alberta",
                    "city": "Edmonton",
                    "state": "Alberta",
                    "country": "Canada"
                }
            },
            {
                "id": "auth2567",
                "givenName": "Pourang",
                "middleInitial": "P",
                "familyName": "Irani",
                "email": "irani@cs.umanitoba.ca",
                "primary": {
                    "institution": "University of Manitoba",
                    "city": "Winnipeg",
                    "state": "Manitoba",
                    "country": "Canada"
                }
            },
            {
                "id": "auth1137",
                "givenName": "Michel",
                "familyName": "Beaudouin-Lafon",
                "email": "mbl@lri.fr",
                "primary": {
                    "institution": "Univ Paris-Sud",
                    "city": "Orsay",
                    "country": "France"
                },
                "secondary": {
                    "institution": "INRIA",
                    "city": "Orsay",
                    "country": "France"
                }
            }
        ]
    },
    {
        "id": 138,
        "name": "Beyond the Filter Bubble: Interactive Effects of Perceived Threat and Topic Involvement on Selective Exposure to Information",
        "type": "paper",
        "abstract": "We investigated participants’ preferential selection of information and their attitude moderation in an online environment. Results showed that even when opposing views were presented side-to-side, people would still preferentially select information that reinforced their existing attitudes. Preferential selection of information was, however, influenced by both situational (e.g., perceived threat) and personal (e.g., topic involvement) factors. Specifically, perceived threat induced selective exposure to attitude consistent information for topics that participants had low involvement. Participants had a higher tendency to select peer user opinions in topics that they had low than high involvement, but only when there was no perception of threat. Overall, participants’ attitudes were moderated after being exposed to diverse views, although high topic involvement led to higher resistance to such moderation. Perceived threat also weakened attitude moderation, especially for low involvement topics. Results have important implication to the potential effects of “information bubble” – selective exposure can be induced by situational and personal factors even when competing views are presented side-by-side.",
        "cbStatement": "Investigated whether information bubble can emerge from people's preferential selection between attitude reinforcing versus attitude challenging information in an online environment, and the roles situational factors and personal factors play.",
        "bookmarks": 99,
        "keywords": [
            "Information Seeking",
            "Filter bubble",
            "Attitude Change",
            "Perceived Threat",
            "Topic Involvement",
            "Peer Opinions."
        ],
        "communities": [],
        "session": {
            "id": "s268",
            "name": "Navigating Data"
        },
        "room": "blue",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth13677",
                "givenName": "Q. Vera",
                "familyName": "Liao",
                "email": "liaoqz08@gmail.com",
                "primary": {
                    "dept": "Computer Science Department",
                    "institution": "University of Illinois at Urbana-Champaign",
                    "city": "Champaign",
                    "state": "Illinois",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth8362",
                "givenName": "Wai-Tat",
                "familyName": "Fu",
                "email": "wfu@illinois.edu",
                "primary": {
                    "institution": "University of Illinois at Urbana-Champaign",
                    "city": "Urbana",
                    "state": "Illinois",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 139,
        "name": "Why Do People Seek Anonymity on the Internet?  Informing Policy and Design",
        "type": "paper",
        "abstract": "In this research we set out to discover why and how people seek anonymity in their online interactions. Our goal is to inform policy and the design of future Internet architecture and applications. We interviewed 44 people from America, Asia, Europe, and Africa who had sought anonymity and asked them about their experiences. A key finding of our research is the very large variation in interviewees’ past experiences and life situations leading them to seek anonymity, and how they tried to achieve it. Our results suggest implications for the design of online communities, challenges for policy, and ways to improve anonymity tools and educate users about the different routes and threats to anonymity on the Internet.",
        "cbStatement": "We conducted 44 interviews with people from America, Asia, Europe and Africa, and found a large variation in their motivation and strategies for achieving anonymity on the Internet.",
        "bookmarks": 111,
        "keywords": [
            "Anonymity",
            "online community",
            "information disclosure",
            "privacy"
        ],
        "communities": [],
        "video": "chi1172-file5.mp4",
        "session": {
            "id": "s275",
            "name": "Consent and Integrity"
        },
        "room": "251",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth12637",
                "givenName": "Ruogu",
                "familyName": "Kang",
                "email": "ruoguk@cs.cmu.edu",
                "primary": {
                    "dept": "Human Computer Interaction Institute",
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth29534",
                "givenName": "Stephanie",
                "familyName": "Brown",
                "email": "smb1@andrew.cmu.edu",
                "primary": {
                    "dept": "Department of Psychology",
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth1474",
                "givenName": "Sara",
                "familyName": "Kiesler",
                "email": "kiesler@cs.cmu.edu",
                "primary": {
                    "dept": "Human Computer Interaction Institute",
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 140,
        "name": "“I want to imagine how that place looks”: Designing Technologies to Support Connectivity Between Africans Living Abroad and Home",
        "type": "paper",
        "abstract": "Uneven access to Information and Communication Technologies (ICTs) in parts of the African continent make it challenging for some Africans who migrate to the U.S. to communicate with family members in their countries of origin. However, Internet access is becoming more widespread throughout the continent and this development presents an opportunity to explore how future interactive systems can support exchanges between families with members living in developed and less developed countries. To investigate these design possibilities we interviewed 27 African-born students, currently living in Virginia, U.S., and asked them how they used ICTs to connect with family members in their home countries. Our findings informed the development of a low-fidelity prototype that eight students lived with for four to five months. Findings from this deployment study motivate a discussion regarding features to include in interfaces designed to support transnational family communication. Features include personally meaningful imagery, country specific content, and the ability to monitor the weather and changing currency rates in migrants’ countries of origin.",
        "cbStatement": "We asked African-born students how they used ICTs to connect with family  in their home countries. Findings informed a  prototype we evaluated. We discuss novel features to include in interfaces designed to support transnational communication.",
        "bookmarks": 187,
        "keywords": [
            "HCI4D/ICTD",
            "Family communication",
            "research through design",
            "interaction design",
            "diaspora communities",
            "transnational"
        ],
        "communities": [
            "design",
            "hci4d"
        ],
        "video": "chi1174-file5.mp4",
        "session": {
            "id": "s261",
            "name": "Sustainability / MISC"
        },
        "room": "bordeaux",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth28618",
                "givenName": "Susan",
                "middleInitial": "P.",
                "familyName": "Wyche",
                "email": "spwyche@msu.edu",
                "primary": {
                    "dept": "Michigan State Univeristy, East Lansing, Michigan, United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth5937",
                "givenName": "Marshini",
                "familyName": "Chetty",
                "email": "marshini@cc.gatech.edu",
                "primary": {
                    "dept": "College of Information Studies ",
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 141,
        "name": "Using Behavioral Data to Identify Interviewer Fabrication in Surveys",
        "type": "paper",
        "abstract": "Surveys conducted by human interviewers are one of the principal means of gathering data from all over the world, but the quality of this data can be threatened by interviewer fabrication. In this paper, we investigate a new approach to detecting interviewer fabrication automatically. We instrument electronic data collection software to record logs of low-level behavioral data and show that supervised classification, when applied to features extracted from these logs, can identify interviewer fabrication with an accuracy of up to 96%.  We show that even when interviewers know that our approach is being used, have some knowledge of how it works, and are incentivized to avoid detection, it can still achieve an accuracy of 86%. We also demonstrate the robustness of our approach to a moderate amount of label noise and provide practical recommendations, based on empirical evidence, on how much data is needed for our approach to be effective.",
        "cbStatement": "We show that by instrumenting electronic data-collection software to record logs of behavioral data, and by using supervised classification on this data, we can accurately detect interviewer fabrication in surveys.",
        "bookmarks": 58,
        "keywords": [
            "user logging",
            "data collection",
            "data quality",
            "behavioral data",
            "supervised classification",
            "surveys",
            "curbstoning",
            "HCI4D"
        ],
        "communities": [
            "hci4d"
        ],
        "video": "chi1176-file5.mp4",
        "session": {
            "id": "s280",
            "name": "Evaluation Methods 2"
        },
        "room": "351",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth29490",
                "givenName": "Benjamin",
                "familyName": "Birnbaum",
                "email": "birnbaum@cs.washington.edu",
                "primary": {
                    "dept": "Computer Science and Engineering",
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "WA",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1590",
                "givenName": "Gaetano",
                "familyName": "Borriello",
                "email": "gaetano@cs.washington.edu",
                "primary": {
                    "dept": "Computer Science and Engineering",
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth30174",
                "givenName": "Abraham",
                "middleInitial": "D",
                "familyName": "Flaxman",
                "email": "abie@uw.edu",
                "primary": {
                    "dept": "Institue for Health Metrics and Evaluation",
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth9528",
                "givenName": "Brian",
                "familyName": "DeRenzi",
                "email": "bderenzi@cs.washington.edu",
                "primary": {
                    "dept": "Computer Science and Engineering",
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30175",
                "givenName": "Anna",
                "middleInitial": "R",
                "familyName": "Karlin",
                "email": "karlin@cs.washington.edu",
                "primary": {
                    "dept": "Computer Science and Engineering",
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 142,
        "name": "Effects of Peer Feedback on Contribution: A Field Experiment in Wikipedia",
        "type": "paper",
        "abstract": "One of the most significant challenges for many online communities is increasing members’ contributions over time. Prior studies on peer feedback in online communities have suggested its impact on contribution, but have been limited by their correlational nature. In this paper, we conducted a field experiment on Wikipedia to test the effects of different feedback types (positive feedback, negative feedback, directive feedback, and social feedback) on members’ contribution. Our results characterize the effects of different feedback types, and suggest trade-offs in the effects of feedback between the focal task and general motivation, as well as differences in how newcomers and experienced editors respond to peer feedback. This research provides insights into the mechanisms underlying peer feedback in online communities and practical guidance to design more effective peer feedback systems.",
        "cbStatement": "The paper furthers our understanding of the effects of peer feedback in online communities and provides practical guidance to design more effective peer feedback systems.",
        "bookmarks": 43,
        "keywords": [
            "Peer Feedback",
            "Field Experiment",
            "Online Communities",
            "Wikipedia."
        ],
        "communities": [
            "management"
        ],
        "video": "chi1177-file5.mp4",
        "session": {
            "id": "s208",
            "name": "Managment of Knowledge and Collaoration: brining the best out of teams"
        },
        "room": "blue",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth16569",
                "givenName": "Haiyi",
                "familyName": "Zhu",
                "email": "haiyiz@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth29619",
                "givenName": "Amy",
                "middleInitial": "X",
                "familyName": "Zhang",
                "email": "amyz@andrew.cmu.edu",
                "primary": {
                    "dept": "Human Computer Interaction Institure, Carnegie Mellon University, Pittsburgh, Pennsylvania, United States"
                }
            },
            {
                "id": "auth29624",
                "givenName": "Jiping",
                "familyName": "He",
                "email": "jipingh@andrew.cmu.edu",
                "primary": {
                    "dept": "Human-Computer Interaction Institute",
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "PA",
                    "country": "United States"
                }
            },
            {
                "id": "auth3627",
                "givenName": "Robert",
                "middleInitial": "E",
                "familyName": "Kraut",
                "email": "robert.kraut@cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth7954",
                "givenName": "Aniket",
                "familyName": "Kittur",
                "email": "nkittur@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 143,
        "name": "Hustling Online: Understanding Consolidated Facebook Use in an Informal Settlement in Nairobi",
        "type": "paper",
        "abstract": "Facebook is a global phenomenon, yet little is known about use of the site in urban parts of the developing world where the social network’s users are increasingly located. We qualitatively studied Facebook use among 28 young adults living in Viwandani, an informal settlement, or slum, in Nairobi, Kenya. We find that to overcome the costs associated with Internet use, participants consolidated diverse online activities onto Facebook; here we focus on the most common practice—using Facebook to support income generation. Viwandani residents used the site to look for employment opportunities, market themselves, and seek remittances from friends and family abroad. We use our findings to motivate a design agenda for the urban poor built on an understanding that Facebook is used, with mixed-success, to support income generation. A key part of this agenda calls for developing ICT interventions grounded in users’ existing practices rather than introducing new and unfamiliar ones. ",
        "cbStatement": "This is the first study of Facebook use in a Nairobi slum. We find that to overcome the costs associated with Internet use, residents consolidated diverse online activities onto Facebook.",
        "bookmarks": 146,
        "keywords": [
            "ICTD",
            "Facebook",
            "social media",
            "social computing",
            "Kenya",
            "Nairobi",
            "informal settlements",
            "youth"
        ],
        "communities": [
            "ux",
            "hci4d"
        ],
        "video": "chi1180-file5.mp4",
        "session": {
            "id": "s258",
            "name": "ICT4D"
        },
        "room": "242ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth28618",
                "givenName": "Susan",
                "middleInitial": "P.",
                "familyName": "Wyche",
                "email": "spwyche@msu.edu",
                "primary": {
                    "dept": "Michigan State Univeristy, East Lansing, Michigan, United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth29562",
                "givenName": "Forte",
                "familyName": "Andrea",
                "email": "andrea.forte.drexel@gmail.com",
                "primary": {
                    "institution": "Drexel University",
                    "city": "Philadelphia",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth6155",
                "givenName": "Sarita",
                "familyName": "Yardi Schoenebeck",
                "email": "sarita.yardi@gmail.com",
                "primary": {
                    "dept": "School of Information",
                    "institution": "University of Michigan",
                    "city": "Ann Arbor",
                    "state": "Michigan",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 144,
        "name": "The Efficacy of Human Post-Editing for Language Translation",
        "type": "paper",
        "abstract": "Language translation is slow and expensive, so various forms of machine assistance have been devised. Automatic machine translation systems process text quickly and cheaply, but with quality far below that of skilled human translators. To bridge this quality gap, the translation industry has investigated post-editing, or the manual correction of machine output. We present the first rigorous, controlled analysis of post-editing and find that post-editing leads to reduced time and, surprisingly, improved quality for three diverse language pairs (English to Arabic, French, and German). Our statistical models and visualizations of experimental data indicate that some simple predictors (like source text part of speech counts) predict translation time, and that post-editing results in very different interaction patterns. From these results we distill implications for the design of new language translation interfaces.",
        "cbStatement": "We analyzed human post-editing of machine translation output, a common feature in translator interfaces. We found that machine suggestions reduce human translation time and improved final quality.",
        "bookmarks": 183,
        "keywords": [
            "Language translation, post-editing, experiment, modeling"
        ],
        "communities": [],
        "video": "chi1183-file5.mp4",
        "session": {
            "id": "s266",
            "name": "Language"
        },
        "room": "blue",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth29510",
                "givenName": "Spence",
                "familyName": "Green",
                "email": "spenceg@stanford.edu",
                "primary": {
                    "dept": "Computer Science Department",
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "CA",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth2167",
                "givenName": "Jeffrey",
                "familyName": "Heer",
                "email": "jheer@cs.stanford.edu",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth17166",
                "givenName": "Christopher",
                "middleInitial": "D",
                "familyName": "Manning",
                "email": "manning@cs.stanford.edu",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 145,
        "name": "IllumiRoom: Peripheral Projected Illusions for Interactive Experiences",
        "type": "paper",
        "abstract": "IllumiRoom is a proof-of-concept system that augments the area surrounding a television with projected visualizations to enhance traditional gaming experiences. We investigate how projected visualizations in the periphery can negate, include, or augment the existing physical environment and complement the content displayed on the television screen. Peripheral projected illusions can change the appearance of the room, induce apparent motion, extend the field of view, and enable entirely new physical gaming experiences. Our system is entirely self-calibrating and is designed to work in any room. We present a detailed exploration of the design space of peripheral projected illusions and we demonstrate ways to trigger and drive such illusions from gaming content. We also contribute specific feedback from two groups of target users (10 gamers and 15 game designers); providing insights for enhancing game experiences through peripheral projected illusions.",
        "cbStatement": "IllumiRoom is a proof-of-concept system that augments the area surrounding a television with projected visualizations to enhance traditional gaming experiences. ",
        "bookmarks": 126,
        "keywords": [
            "Spatial augmented reality",
            "projection mapping",
            "gaming",
            "immersion",
            "apparent motion",
            "augmented reality"
        ],
        "communities": [
            "design",
            "engineering",
            "games"
        ],
        "video": "chi1187-file5.mp4",
        "session": {
            "id": "s220",
            "name": "Interaction around Devices"
        },
        "room": "352ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth15916",
                "givenName": "Brett",
                "middleInitial": "R",
                "familyName": "Jones",
                "email": "brjones2@illinois.edu",
                "primary": {
                    "institution": "University of Illinois at Urbana-Champaign",
                    "city": "Urbana",
                    "state": "Illinois",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth4513",
                "givenName": "Hrvoje",
                "familyName": "Benko",
                "email": "benko@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth27276",
                "givenName": "Eyal",
                "familyName": "Ofek",
                "email": "eyalofek@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth2175",
                "givenName": "Andrew",
                "middleInitial": "D",
                "familyName": "Wilson",
                "email": "awilson@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 146,
        "name": "Three Perspectives on Behavior Change for Serious Games",
        "type": "paper",
        "abstract": "Research into the effects of serious games often engages with interdisciplinary models of how human behaviors are shaped and changed over time. To better understand these different perspectives we articulate three cognitive models of behavior change and consider the potential of these models to support a deeper understanding of behavior change in serious games. Two of these models – Information Deficit and Procedural Rhetoric – have already been employed in the design of serious games, while the third – Emergent Dialogue – is introduced from the field of Environmental Studies.  We situate this discussion within a context of designing games for public engagement with issues of environmental sustainability.",
        "cbStatement": "We introduce a model of behavior change and persuasion from Environmental Studies and consider its application for serious games for sustainability alongside two other commonly used models.",
        "bookmarks": 19,
        "keywords": [
            "Serious Games",
            "Sustainability",
            "Behavior Change",
            "Procedural Rhetoric",
            "Emergent Dialogue"
        ],
        "communities": [
            "games",
            "sustainability"
        ],
        "session": {
            "id": "s283",
            "name": "Exergames, Inclusion"
        },
        "room": "251",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth17138",
                "givenName": "Joshua",
                "middleInitial": "G",
                "familyName": "Tanenbaum",
                "email": "joshuat@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth5238",
                "givenName": "Alissa",
                "middleInitial": "N",
                "familyName": "Antle",
                "email": "aantle@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29516",
                "givenName": "John",
                "familyName": "Robinson",
                "email": "johnr@ires.ubc.ca",
                "primary": {
                    "dept": "Institute for Resources, Environment, and Sustainability",
                    "institution": "University of British Columbia",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 147,
        "name": "Flights in my Hands: Coherence Concerns in Designing Strip’TIC, a Tangible Space for Air Traffic Controllers",
        "type": "paper",
        "abstract": "We reflect upon the design of a paper-based tangible interactive space to support air traffic control. We have observed, studied, prototyped and discussed with controllers a new mixed interaction system based on Anoto, video projection, and tracking. Starting from the understanding of the benefits of tangible paper strips, our goal is to study how mixed physical and virtual augmented data can support the controllers’ mental work. The context of the activity led us to depart from models that are proposed in tangible interfaces research where coherence is based on how physical objects are representative of virtual objects. We propose a new account of coherence in a mixed interaction system that integrates externalization mechanisms. We found that physical objects play two roles: they act both as representation of mental objects and as tangible artifacts for interacting with augmented features. We observed that virtual objects represent physical ones, and not the reverse, and, being virtual representations of physical objects, should seamlessly converge with the cognitive role of the physical object. Finally, we show how coherence is achieved by providing a seamless interactive space.",
        "cbStatement": "We reflect upon the design of a paper-based tangible space to support air traffic control. We propose a new account of coherence for mixed interaction that integrates cognitive externalization mechanisms.",
        "bookmarks": 59,
        "keywords": [
            "Tangible interaction",
            "Augmented paper",
            "Pen-based UIs",
            "Distributed cognition",
            "Participatory design",
            "Ethnography",
            "Air Traffic Control",
            "Transport",
            "Security."
        ],
        "communities": [
            "design"
        ],
        "video": "chi0120-file5.mp4",
        "authors": [
            {
                "id": "auth3686",
                "givenName": "Catherine",
                "familyName": "Letondal",
                "email": "catherine.letondal@enac.fr",
                "primary": {
                    "dept": "University of Toulouse ",
                    "institution": "ENAC",
                    "city": "Toulouse",
                    "country": "France"
                },
                "role": "presenter"
            },
            {
                "id": "auth10709",
                "givenName": "Christophe",
                "familyName": "Hurter",
                "email": "christophe.hurter@enac.fr",
                "primary": {
                    "dept": "University of Toulouse",
                    "institution": "ENAC",
                    "city": "Toulouse",
                    "country": "France"
                },
                "secondary": {
                    "institution": "IRIT",
                    "city": "Toulouse",
                    "country": "France"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth28929",
                "givenName": "Rémi",
                "familyName": "Lesbordes",
                "email": "remi.lesbordes@aviation-civile.gouv.fr",
                "primary": {
                    "dept": "DTI R&D",
                    "institution": "DGAC DSNA",
                    "city": "Toulouse",
                    "country": "France"
                }
            },
            {
                "id": "auth32501",
                "givenName": "Jean-Luc",
                "familyName": "Vinot",
                "email": "jean-luc.vinot@enac.fr",
                "primary": {
                    "dept": "University of Toulouse",
                    "institution": "ENAC",
                    "city": "Toulouse",
                    "country": "France"
                },
                "secondary": {
                    "institution": "IRIT",
                    "city": "Toulouse",
                    "country": "France"
                }
            },
            {
                "id": "auth3858",
                "givenName": "Stéphane",
                "familyName": "Conversy",
                "email": "conversy@gmail.com",
                "primary": {
                    "dept": "University of Toulouse",
                    "institution": "ENAC",
                    "city": "Toulouse",
                    "country": "France"
                },
                "secondary": {
                    "institution": "IRIT",
                    "city": "Toulouse",
                    "country": "France"
                }
            }
        ]
    },
    {
        "id": 148,
        "name": "From Codes to Patterns:  Designing Interactive Decoration for Tableware",
        "type": "paper",
        "abstract": "We explore the idea of making aesthetic decorative patterns that contain multiple visual codes. We chart an iterative collaboration with ceramic designers and a restaurant to refine a recognition technology to work reliably on ceramics, produce a pattern book of designs, and prototype sets of tableware and a mobile app to enhance a dining experience. We document how the designers learned to work with and creatively exploit the technology, enriching their patterns with embellishments and backgrounds and developing strategies for embedding codes into complex designs. We discuss the potential and challenges of interacting with such patterns. We argue for a transition from designing ‘codes to patterns’ that reflects the skills of designers alongside the development of new technologies.",
        "cbStatement": "A collaboration between ceramic designers, technologists and a restaurant reveals strategies for creating aesthetic decorative pattern for plates and other tableware that contain multiple embedded visual codes hidden within them.",
        "bookmarks": 7,
        "keywords": [
            "Barcodes",
            "QR codes",
            "patterns",
            "vision",
            "recognition",
            "mobile applications",
            "ceramics",
            "food"
        ],
        "communities": [
            "design"
        ],
        "video": "chi1214-file5.mp4",
        "session": {
            "id": "s215",
            "name": "Design for the Home"
        },
        "room": "242ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth26737",
                "givenName": "Rupert",
                "familyName": "Meese",
                "email": "rupert.meese@nottingham.ac.uk",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth30146",
                "givenName": "Shakir",
                "familyName": "Ali",
                "email": "shakir.ali@nottingham.ac.uk",
                "primary": {
                    "dept": "Horizon Digital Economy Research",
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth30309",
                "givenName": "Emily-Clare",
                "familyName": "Thorne",
                "email": "emilyclare_thorn@me.com",
                "primary": {
                    "dept": "School of Design",
                    "institution": "Central Saint Martins College of Art and Design",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth1508",
                "givenName": "Steve",
                "middleInitial": "D",
                "familyName": "Benford",
                "email": "sdb@cs.nott.ac.uk",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth30310",
                "givenName": "Anthony",
                "familyName": "Quinn",
                "email": "mail@anthonyquinndesign.com",
                "primary": {
                    "dept": "School of Design",
                    "institution": "Central Saint Martins College of Art and Design",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth24719",
                "givenName": "Richard",
                "familyName": "Mortier",
                "email": "richard.mortier@nottingham.ac.uk",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth2250",
                "givenName": "Boriana",
                "middleInitial": "N",
                "familyName": "Koleva",
                "email": "bnk@cs.nott.ac.uk",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30311",
                "givenName": "Tony",
                "familyName": "Pridmore",
                "email": "tpp@cs.nott.ac.uk",
                "primary": {
                    "dept": "chool of Computer Science",
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth8333",
                "givenName": "Sharon",
                "middleInitial": "L",
                "familyName": "Baurley",
                "email": "Sharon.Baurley@brunel.ac.uk",
                "primary": {
                    "institution": "Brunel University",
                    "city": "London",
                    "state": "London",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 149,
        "name": "Digital Apartheid: An Ethnographic Account  of Racialised HCI in Cape Town Hip-Hop",
        "type": "paper",
        "abstract": "We describe findings from a 15-month ethnography of hip-hop performers in Cape Town, South Africa. Mobile communications and social media are hugely important to the development of these performers’ careers, opening access to collaborators, production tools, audiences and distribution channels. This group go to extraordinary lengths to gain and maintain access to these technologies, often by exploiting their social capital through musical and ethnic networks. We document that even after nearly twenty years of democracy, a ridged separation along racial lines persists, which can be seen in all areas of life including access to and proficiency in digital technologies. We illustrate how hip-hop performers harness these divisions both on and offline in order to distinguish themselves from other artists. Our research raises a number of implications for post-colonial computing, highlighting difficulties related to discontinuous access, and how international preconceptions of identity and authenticity emerge as a consequence of the increased use of communication technology.",
        "cbStatement": "Ethnography of Cape Town hip-hop performers exploring how technology such as social media supports yet inhibits the development and sustainment of their careers. Raises implications for HCI4D and post-colonial computing.",
        "bookmarks": 146,
        "keywords": [
            "Hip-Hop",
            "South Africa",
            "Identity",
            "HCI4D",
            "Racial Inequality",
            "Music-Making"
        ],
        "communities": [
            "hci4d"
        ],
        "video": "chi0122-file5.mp4",
        "session": {
            "id": "s262",
            "name": "Crime, Conflicts, and Resolution"
        },
        "room": "blue",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth28780",
                "givenName": "Gary",
                "middleInitial": "W",
                "familyName": "Pritchard",
                "email": "gary.pritchard@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth21260",
                "givenName": "John",
                "familyName": "Vines",
                "email": "john.vines@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 150,
        "name": "Improving Teamwork Using Real-Time Language Feedback",
        "type": "paper",
        "abstract": "We develop and evaluate a real-time language feedback system that monitors the communication patterns among students in a discussion group and provides real-time instructions to shape the way the group works together. As an initial step, we determine which group processes are related to better outcomes. We then experimentally test the efficacy of providing real-time instructions which target two of these group processes. The feedback system was successfully able to shape the way groups worked together. However, only appropriate feedback given to groups that were not working well together from the start was able to improve group performance.",
        "cbStatement": "We develop a real-time language feedback system that monitors the communication patterns among students in a discussion group and provides real-time instructions to shape the way the group works together.",
        "bookmarks": 17,
        "keywords": [
            "Feedback",
            "linguistic analysis",
            "CSCW",
            "teamwork",
            "CMC"
        ],
        "communities": [],
        "video": "chi1221-file5.mp4",
        "session": {
            "id": "s266",
            "name": "Language"
        },
        "room": "blue",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth13121",
                "givenName": "Yla",
                "middleInitial": "R.",
                "familyName": "Tausczik",
                "email": "ylataus@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth18083",
                "givenName": "James",
                "middleInitial": "W.",
                "familyName": "Pennebaker",
                "email": "pennebaker@mail.utexas.edu",
                "primary": {
                    "institution": "The University of Texas at Austin",
                    "city": "Austin",
                    "state": "Texas",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 151,
        "name": "Direct Space-Time Trajectory Control  for Visual Media Editing",
        "type": "paper",
        "abstract": "We explore the design space for using object motion trajectories to create and edit visual elements in various media across space and time. We introduce a suite of pen-based techniques that facilitate fluid stylization, annotation and editing of space-time content such as video, slide presentations and 2D animation, utilizing pressure and multi-touch input. We implemented and evaluated these techniques in DirectPaint, a system for creating free-hand painting and annotation over video. ",
        "cbStatement": "An exploration of the design space for using motion trajectories to edit visual elements across space and time. Pen-based techniques are introduced in DirectPaint: a video painting and annotation system.",
        "bookmarks": 134,
        "keywords": [
            "Sketching",
            "Pen-based interface",
            "Pressure",
            "Optical flow",
            "Video navigation",
            "Bimodal"
        ],
        "communities": [
            "design"
        ],
        "video": "chi1226-file5.mp4",
        "session": {
            "id": "s234",
            "name": "Video"
        },
        "room": "bordeaux",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth27387",
                "givenName": "Stephanie",
                "familyName": "Santosa",
                "email": "ssantosa@gmail.com",
                "primary": {
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth13877",
                "givenName": "Fanny",
                "familyName": "Chevalier",
                "email": "fanny@dgp.toronto.edu",
                "primary": {
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1019",
                "givenName": "Ravin",
                "familyName": "Balakrishnan",
                "email": "ravin@dgp.toronto.edu",
                "primary": {
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                }
            },
            {
                "id": "auth4937",
                "givenName": "Karan",
                "familyName": "Singh",
                "email": "karan@dgp.toronto.edu",
                "primary": {
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 152,
        "name": "Using fNIRS Brain Sensing to Evaluate Information Visualization Interfaces",
        "type": "paper",
        "abstract": "We show how brain sensing can lend insight to the evaluation of visual interfaces and establish a role for fNIRS in visualization. Research suggests that the evaluation of visual design benefits by going beyond performance measures or questionnaires to measurements of the user's cognitive state. Unfortunately, objectively and unobtrusively monitoring the brain is difficult. While functional near-infrared spectroscopy (fNIRS) has emerged as a practical brain sensing technology in HCI, visual tasks often rely on the brain's quick, massively parallel visual system, which may be inaccessible to this measurement. It is unknown whether fNIRS can distinguish differences in cognitive state that derive from visual design alone. In this paper, we use the classic comparison of bar graphs and pie charts to test the viability of fNIRS for measuring the impact of a visual design on the brain. Our results demonstrate that we can indeed measure this impact, and furthermore measurements indicate that there are not universal differences in bar graphs and pie charts.",
        "cbStatement": "We explore the use of fNIRS brain sensing to evaluate information visualization interfaces.",
        "bookmarks": 185,
        "keywords": [
            "fNIRS",
            "BCI",
            "Visualization",
            "Brain Sensing",
            "Evaluation."
        ],
        "communities": [],
        "video": "chi1228-file5.mp4",
        "session": {
            "id": "s271",
            "name": "Brain Interfaces"
        },
        "room": "342a",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth14727",
                "givenName": "Evan M",
                "middleInitial": "M",
                "familyName": "Peck",
                "email": "evan.peck@tufts.edu",
                "primary": {
                    "institution": "Tufts University",
                    "city": "Medford",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth29574",
                "givenName": "Beste F",
                "middleInitial": "F",
                "familyName": "Yuksel",
                "email": "beste.yuksel@tufts.edu",
                "primary": {
                    "institution": "Tufts University",
                    "city": "Medford",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth22772",
                "givenName": "Alvitta",
                "familyName": "Ottley",
                "email": "alvittao@cs.tufts.edu",
                "primary": {
                    "institution": "Tufts University",
                    "city": "Medford",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth1151",
                "givenName": "Robert",
                "middleInitial": "J.K.",
                "familyName": "Jacob",
                "email": "jacob@cs.tufts.edu",
                "primary": {
                    "institution": "Tufts University",
                    "city": "Medford",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth19370",
                "givenName": "Remco",
                "familyName": "Chang",
                "email": "remco@cs.tufts.edu",
                "primary": {
                    "institution": "Tufts University",
                    "city": "Medford",
                    "state": "MA",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 153,
        "name": "How Fast is Fast Enough? A Study of the Effects of Latency in Direct-Touch Pointing Tasks",
        "type": "paper",
        "abstract": "Although advances in touchscreen technology have provided us with more precise devices, touchscreens are still laden with latency issues. Common commercial devices present with latency up to 125ms. Although these levels have been shown to impact users’ perception of the responsiveness of the system [16], relatively little is known about the impact of latency on the performance of tasks common to direct-touch interfaces, such as direct physical manipulation. \\  \\ In this paper, we study the effect of latency of a directtouch pointing device on dragging tasks. Our tests show that user performance decreases as latency increases. We also find that user performance is more severely affected by latency when targets are smaller or farther away. We present a detailed analysis of users’ coping mechanisms for latency, and present the results of a follow-up study demonstrating user perception of latency in the land-on phase of the dragging task.",
        "cbStatement": "Further explores the issue of the effects of latency on input performance. We find that, for pointing on direct-touch, even extremely low latencies reduce performance.",
        "bookmarks": 41,
        "keywords": [
            "Latency",
            "direct input",
            "direct manipulations",
            "touch input"
        ],
        "communities": [],
        "video": "chi1229-file5.mp4",
        "session": {
            "id": "s222",
            "name": "Touch"
        },
        "room": "352ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth14062",
                "givenName": "Ricardo",
                "familyName": "Jota",
                "email": "jotacosta@dgp.toronto.edu",
                "primary": {
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth27349",
                "givenName": "Albert",
                "familyName": "Ng",
                "email": "albertng@outlook.com",
                "primary": {
                    "institution": "Microsoft Applied Sciences Group",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth3588",
                "givenName": "Paul",
                "middleInitial": "H",
                "familyName": "Dietz",
                "email": "pdietz@microsoft.com",
                "primary": {
                    "institution": "Microsoft Applied Sciences Group",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth3440",
                "givenName": "Daniel",
                "middleInitial": "J",
                "familyName": "Wigdor",
                "email": "dwigdor@dgp.toronto.edu",
                "primary": {
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 154,
        "name": "Waves: Exploring Idiographic Design for Live Performance",
        "type": "paper",
        "abstract": "We explore whether idiographic design, a category of interaction design that focuses upon responding to detailed personal accounts of individuals’ practices, can be used to support interaction designers in responding to the complex and multifaceted design space posed by live performance. We describe and reflect upon the application of an idiographic approach during the design of Waves, an interface for live VJ performance. This approach involved a close and dialogical engagement with the practices and experiences of an individual live performer, during a series of semi-structured interviews and then the discussion and iteration of an evolving prototypical design. Reflection on the experience of applying this approach highlights idiographic design as a practical means to support interaction designers in proposing innovative designs that respond sensitively to the kinds of subtle and complex issues that underpin people’s lived and felt experiences of live performance and, potentially, many other domains.",
        "cbStatement": "We explore whether idiographic design, an approach that focuses on personal accounts of individuals’ experiences, can support designers in responding to the subtle and complex issues that affect live performance.",
        "bookmarks": 85,
        "keywords": [
            "Experience-centered design",
            "idiographic design",
            "interaction design",
            "liveness",
            "live performance",
            "multi-touch",
            "VJing"
        ],
        "communities": [
            "design",
            "arts"
        ],
        "video": "chi0123-file5.mp4",
        "session": {
            "id": "s232",
            "name": "Visual perception"
        },
        "room": "blue",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth11918",
                "givenName": "Jonathan",
                "familyName": "Hook",
                "email": "jonathan.hook@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth6215",
                "givenName": "John",
                "familyName": "McCarthy",
                "email": "john.mccarthy@ucc.ie",
                "primary": {
                    "institution": "University College Cork",
                    "city": "Cork",
                    "country": "Ireland"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth9063",
                "givenName": "Peter",
                "familyName": "Wright",
                "email": "p.c.wright@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth5105",
                "givenName": "Patrick",
                "familyName": "Olivier",
                "email": "p.l.olivier@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 155,
        "name": "CrashAlert: Enhancing Peripheral Alertness for Eyes-Busy Mobile Interaction while Walking",
        "type": "paper",
        "abstract": "Mobile device use while walking, or eyes-busy mobile in-teraction, is a leading cause of life-threatening pedestrian collisions. We introduce CrashAlert, a system that aug-ments mobile devices with a depth camera, to provide dis-tance and location visual cues of obstacles on the user’s path. In a realistic environment outside the lab, CrashAlert users improve their handling of potential collisions, dodg-ing and slowing down for simple ones while lifting their head in more complex situations. Qualitative results outline the value of extending users’ peripheral alertness in eyes-busy mobile interaction through non-intrusive depth cues, as used in CrashAlert. We present the design features of our system and lessons learned from our evaluation.",
        "cbStatement": "CrashAlert improves safety when walking and texting with smartphones. CrashAlert uses a depth camera to create ambient visualizations of the obstacles ahead of the user. Results show safer walking behaviors without compromising performance.",
        "bookmarks": 48,
        "keywords": [
            "Eyes-busy interaction",
            "obstacle avoidance",
            "texting and walking",
            "walking user interfaces"
        ],
        "communities": [],
        "video": "chi1231-file5.mp4",
        "session": {
            "id": "s270",
            "name": "Untitled (Automotive and Awareness)"
        },
        "room": "241",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth13982",
                "givenName": "Juan David",
                "familyName": "Hincapié-Ramos",
                "email": "jdhr@cs.umanitoba.ca",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Manitoba",
                    "city": "Winnipeg",
                    "state": "Manitoba",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth2567",
                "givenName": "Pourang",
                "familyName": "Irani",
                "email": "irani@cs.umanitoba.ca",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Manitoba",
                    "city": "Winnipeg",
                    "state": "Manitoba",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 156,
        "name": "Flexpad: Highly Flexible Bending Interactions for Projected Handheld Displays",
        "type": "paper",
        "abstract": "Flexpad is an interactive system that combines a depth camera and a projector to transform sheets of plain paper or foam into flexible, highly deformable, and spatially aware handheld displays. We present a novel approach for tracking deformed surfaces from depth images in real time. It captures deformations in high detail, is very robust to occlusions created by the user’s hands and fingers, and does not require any kind of markers or visible texture. As a result, the display is considerably more deformable than in previous work on flexible handheld displays, enabling novel applications that leverage the high expressiveness of detailed deformation. We illustrate these unique capabilities through three application examples: curved cross-cuts in volumetric images, deforming virtual paper characters, and slicing through time in videos. Results from two user studies show that our system is capable of detecting complex deformations and that users are able to perform them quickly and precisely.",
        "cbStatement": "Introduces highly flexible handheld displays as user interfaces. Contributes a novel real-time method for capturing complex deformations of flexible surfaces and novel interactions that leverage highly flexible deformations of displays.",
        "bookmarks": 177,
        "keywords": [
            "Flexible display",
            "handheld display",
            "tracking",
            "projection",
            "depth camera",
            "deformation",
            "bending",
            "volumetric data"
        ],
        "communities": [
            "design",
            "engineering",
            "ux"
        ],
        "video": "chi1234-file5.mp4",
        "session": {
            "id": "s229",
            "name": "Bendable, Flexible"
        },
        "room": "352ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth9521",
                "givenName": "Jürgen",
                "familyName": "Steimle",
                "email": "steimle@media.mit.edu",
                "primary": {
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth28969",
                "givenName": "Andreas",
                "familyName": "Jordt",
                "email": "jordt@mip.informatik.uni-kiel.de",
                "primary": {
                    "dept": "Christian-Albrechts-Universitaet ",
                    "institution": "Kiel University of Applied Sciences",
                    "city": "Kiel",
                    "country": "Germany"
                }
            },
            {
                "id": "auth3707",
                "givenName": "Pattie",
                "familyName": "Maes",
                "email": "pattie@media.mit.edu",
                "primary": {
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 157,
        "name": "TouchViz: A Case Study Comparing Two Interfaces for Data Analytics on Tablets",
        "type": "paper",
        "abstract": "As more applications move from the desktop to touch devices like tablets, designers must wrestle with the costs of porting a design with as little revision of the UI as possible from one device to the other, or of optimizing the interaction per device. We consider the tradeoffs between two versions of a UI for working with data on a touch tablet. One interface is based on using the conventional desktop metaphor (WIMP) with a control panel, push buttons, and checkboxes – where the mouse click is effectively replaced by a finger tap. The other interface (which we call FLUID) eliminates the control panel and focuses touch actions on the data visualization itself. We describe our design process and evaluation of each interface. We discuss the significantly better task performance and preference for the FLUID interface, in particular how touch design may challenge certain assumptions about the performance benefits of WIMP interfaces that do not hold on touch devices, such as the superiority of gestural vs. control panel based interaction. ",
        "cbStatement": "Two different design approaches to touch based data analytics and an evaluation of relative advantages and benefits thereof.",
        "bookmarks": 159,
        "keywords": [
            "Gesture interfaces",
            "touch displays",
            "user studies",
            "data visualization."
        ],
        "communities": [
            "design"
        ],
        "video": "chi1241-file5.mp4",
        "session": {
            "id": "s222",
            "name": "Touch"
        },
        "room": "352ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth2660",
                "givenName": "Steven",
                "middleInitial": "M.",
                "familyName": "Drucker",
                "email": "sdrucker@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "secondary": {
                    "dept": "CSE",
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1087",
                "givenName": "Danyel",
                "familyName": "Fisher",
                "email": "danyelf@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30117",
                "givenName": "Ramik",
                "familyName": "Sadana",
                "email": "rsadana3@gatech.edu",
                "primary": {
                    "dept": "School of Interactive Computing",
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                },
                "secondary": {
                    "dept": "Microsoft Research",
                    "institution": "Microsoft",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth30118",
                "givenName": "Jessica",
                "familyName": "Herron",
                "email": "v-jeher@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth3353",
                "givenName": "m.c.",
                "familyName": "schraefel",
                "email": "mc@ecs.soton.ac.uk",
                "primary": {
                    "institution": "University of Southampton",
                    "city": "Southampton ",
                    "country": "United Kingdom"
                },
                "secondary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 158,
        "name": "Slow Design for Meaningful Interactions",
        "type": "paper",
        "abstract": "In this paper we report on an exploration of how to apply the theory of Slow Design to mass produced products to establish more mindful usage of products; the intention behind this is to promote product attachment and the associated sustainable benefits of long term use. Slow Design is a design philosophy that focuses on promoting well-being for individuals, society, and the natural environment. It encourages people to do things at the right time and at the right speed which helps them to understand and reflect on their actions. Several authors have proposed Slow Design principles and cases have been reported in which these principles were applied in cultural design projects. These applications indicated that Slow Design can indeed have a positive impact on wellbeing. Although promising, this philosophy has not yet been used in the design of mass consumer products. In this paper we present a design case study in which we explored how the Slow Design principles can be applied in the design of an electric fruit juicer. Two studies are reported on where the conditions for implementing Slow Design are explored.  The results led to a revision of the principles for use by product designers. The main finding from the case study is that the Slow Design principles can be used to create more ‘mindful’ interactions that stimulate positive user involvement.  This is not from designing interactions that require more time per se, but by stimulating the user to use more time for those parts of the interaction that are meaningful and less for those that are not meaningful.",
        "cbStatement": "In this paper we report on an exploration of how to apply the theory of Slow Design to mass produced products to establish more mindful usage of products.",
        "bookmarks": 53,
        "keywords": [
            "Slow design",
            "Product Attachment",
            "Sustainability"
        ],
        "communities": [
            "design",
            "ux",
            "sustainability"
        ],
        "video": "chi1247-file5.mp4",
        "session": {
            "id": "s212",
            "name": "Designs on Design 2: Exploring Design Approaches and Constructs"
        },
        "room": "bordeaux",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth29564",
                "givenName": "Barbara",
                "familyName": "Grosse-Hering",
                "email": "grosse.hering@gmail.com",
                "primary": {
                    "institution": "Designit",
                    "city": "Munich",
                    "state": "n/a",
                    "country": "Germany"
                },
                "secondary": {
                    "dept": "Industrial Design Engineering",
                    "institution": "Delft University of Technology",
                    "city": "Delft",
                    "country": "The Netherlands"
                },
                "role": "presenter"
            },
            {
                "id": "auth26277",
                "givenName": "Jon",
                "familyName": "Mason",
                "email": "jon.mason@philips.com",
                "primary": {
                    "institution": "Philips Research",
                    "city": "Eindhoven",
                    "country": "The Netherlands"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth2493",
                "givenName": "Dzmitry",
                "familyName": "Aliakseyeu",
                "email": "d.aliakseyeu@gmail.com",
                "primary": {
                    "institution": "Philips Research",
                    "city": "Eindhoven",
                    "country": "The Netherlands"
                }
            },
            {
                "id": "auth28940",
                "givenName": "Conny",
                "middleInitial": "A.",
                "familyName": "Bakker",
                "email": "c.a.bakker@tudelft.nl",
                "primary": {
                    "dept": "Industrial Design Engineering",
                    "institution": "Delft University of Technology",
                    "city": "Delft",
                    "state": "-",
                    "country": "The Netherlands"
                }
            },
            {
                "id": "auth8310",
                "givenName": "Pieter",
                "middleInitial": "M.A.",
                "familyName": "Desmet",
                "email": "p.m.a.desmet@tudelft.nl",
                "primary": {
                    "institution": "Delft University of Technology",
                    "city": "Delft",
                    "country": "The Netherlands"
                }
            }
        ]
    },
    {
        "id": 159,
        "name": "The Whats and Hows of Programmers’ Foraging Diets",
        "type": "paper",
        "abstract": "One of the least studied areas of Information Foraging Theory is diet: the information foragers choose to seek.  For example, do foragers choose solely based on cost, or do they stubbornly pursue certain diets regardless of cost? Do their debugging strategies vary with their diets? To investigate \"what\" and \"how\" questions like these for the domain of software debugging, we qualitatively analyzed 9 professional developers' foraging goals, goal patterns, and strategies. Participants spent 50% of their time foraging. Of their foraging, 58% fell into distinct dietary patterns--mostly in patterns not previously discussed in the literature. In general, programmers' foraging strategies leaned more heavily toward enrichment than we expected, but different strategies aligned with different goal types. These and our other findings help fill the gap as to what programmers' dietary goals are and how their strategies relate to those goals.  \\ ",
        "cbStatement": "Information Foraging Theory investigation into information diets of professional programmers during debugging, and how these diets interact with their foraging strategies. Helps unify Information Foraging Theory with debugging research.",
        "bookmarks": 143,
        "keywords": [
            "Information foraging theory",
            "information diet",
            "debugging strategies"
        ],
        "communities": [],
        "video": "chi1254-file5.mp4",
        "session": {
            "id": "s230",
            "name": "Uis for Software Development"
        },
        "room": "blue",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth22509",
                "givenName": "David",
                "middleInitial": "J",
                "familyName": "Piorkowski",
                "email": "piorkoda@eecs.oregonstate.edu",
                "primary": {
                    "institution": "Oregon State University",
                    "city": "Corvallis",
                    "state": "Oregon",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth22029",
                "givenName": "Scott",
                "middleInitial": "D.",
                "familyName": "Fleming",
                "email": "Scott.Fleming@memphis.edu",
                "primary": {
                    "institution": "University of Memphis",
                    "city": "Memphis",
                    "state": "Tennessee",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth22934",
                "givenName": "Irwin",
                "familyName": "Kwan",
                "email": "kwan@eecs.oregonstate.edu",
                "primary": {
                    "institution": "Oregon State University",
                    "city": "Corvallis",
                    "state": "Oregon",
                    "country": "United States"
                }
            },
            {
                "id": "auth1299",
                "givenName": "Margaret",
                "middleInitial": "M",
                "familyName": "Burnett",
                "email": "burnett@eecs.oregonstate.edu",
                "primary": {
                    "institution": "Oregon State University",
                    "city": "Corvallis",
                    "state": "Oregon",
                    "country": "United States"
                }
            },
            {
                "id": "auth7024",
                "givenName": "Christopher",
                "familyName": "Scaffidi",
                "email": "cscaffid@eecs.oregonstate.edu",
                "primary": {
                    "institution": "Oregon State University",
                    "city": "Corvallis",
                    "state": "Oregon",
                    "country": "United States"
                }
            },
            {
                "id": "auth1377",
                "givenName": "Rachel",
                "middleInitial": "K. E.",
                "familyName": "Bellamy",
                "email": "rachel@us.ibm.com",
                "primary": {
                    "institution": "IBM T.J. Watson Research Center",
                    "city": "Yorktown Heights",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth30476",
                "givenName": "Joshua",
                "familyName": "Jordahl",
                "email": "jordahlj@eecs.oregonstate.edu",
                "primary": {
                    "institution": "Oregon State University",
                    "city": "Corvallis",
                    "state": "Oregon",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 160,
        "name": "Patina: Dynamic Heatmaps for Visualizing Application Usage",
        "type": "paper",
        "abstract": "We present Patina, an application independent system for collecting and visualizing software application usage data.  Patina requires no instrumentation of the target application, all data is collected through standard window metrics and accessibility APIs. The primary visualization is a dynamic heatmap overlay which adapts to match the content, location, and shape of the user interface controls visible in the active application. We discuss a set of design guidelines for the Patina system, describe our implementation of the system, and report on an initial evaluation based on a short-term deployment of the system. ",
        "cbStatement": "Patina is an application independent system which uses accessibility APIs to collect and visualize software application usage data. The primary visualization is a dynamic heatmap overlaid on the application.",
        "bookmarks": 82,
        "keywords": [
            "Visualization",
            "Social Learning"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi1263-file5.mp4",
        "session": {
            "id": "s231",
            "name": "Visualization 1"
        },
        "room": "bordeaux",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth11856",
                "givenName": "Justin",
                "familyName": "Matejka",
                "email": "Justin.Matejka@autodesk.com",
                "primary": {
                    "institution": "Autodesk Research",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth1476",
                "givenName": "Tovi",
                "familyName": "Grossman",
                "email": "tovi.grossman@autodesk.com",
                "primary": {
                    "institution": "Autodesk Research",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1229",
                "givenName": "George",
                "familyName": "Fitzmaurice",
                "email": "George.Fitzmaurice@autodesk.com",
                "primary": {
                    "institution": "Autodesk Research",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 161,
        "name": "Modeling How People Extract Color Themes from Images",
        "type": "paper",
        "abstract": "Color choice plays an important role in works of graphic art and design. However, it can be difficult to choose a compelling set of colors, or \\\\emph{color theme}, from scratch. In this work, we present a method for extracting color themes from images using a regression model trained on themes created by people. We collect 1600 themes from Mechanical Turk as well as from artists. We find that themes extracted by Turk participants were similar to ones extracted by artists. In addition, people tended to select diverse colors and focus on colors in salient image regions. We show that our model can match human-extracted themes more closely compared to previous work. Themes extracted by our model were also rated higher as representing the image than previous approaches in a Mechanical Turk study.",
        "cbStatement": "We present a method for extracting color themes from images, using a regression model trained on themes people extract. Model-extracted themes match the source image more closely than previous approaches.",
        "bookmarks": 97,
        "keywords": [
            "color theme extraction",
            "color themes",
            "color names",
            "algorithms",
            "crowdsourcing"
        ],
        "communities": [
            "design",
            "engineering",
            "arts"
        ],
        "video": "chi1264-file5.mp4",
        "session": {
            "id": "s250",
            "name": "Beyond Desktop Interaction"
        },
        "room": "242a",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth29569",
                "givenName": "Sharon",
                "middleInitial": "Derie",
                "familyName": "Lin",
                "email": "sharonl@cs.stanford.edu",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth29718",
                "givenName": "Pat",
                "familyName": "Hanrahan",
                "email": "hanrahan@cs.stanford.edu",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 162,
        "name": "Carpe ́ Data: Supporting Serendipitous Data Integration in Personal Information Management",
        "type": "paper",
        "abstract": "The information processing capabilities of humans enable them to opportunistically draw and integrate knowledge from nearly any information source.  However, the integration of digital, structured data from diverse sources remains difficult, due to problems of heterogeneity that arise when data modelled separately are brought together.  In this paper, we present an investigation of the feasibility of extending Personal Information Management (PIM) tools to support lightweight, user-driven mixing of previously un-integrated data, with the objective of allowing  users to take advantage of the emerging ecosystems of structured data currently becoming available.  In this study, we conducted an exploratory, sequential, mixed-method investigation, starting with two pre-studies of the data integration needs and challenges, respectively, of Web-based data sources. Observations from these pre-studies led to DataPalette, an interface that introduced simple co-reference and group multi-path-selection mechanisms for working with terminologically and structurally heterogeneous data.  Our lab study showed that participants readily understood the new interaction mechanisms which were introduced.  Participants made more carefully justified decisions, even while weighing a greater number of factors, moreover expending less effort, during subjective-choice tasks when using DataPalette, than with a control set-up.  \\ ",
        "cbStatement": "This paper focuses on the problem of user-driven data integration on the Web, with the objective of enabling end-users to use the emerging ecosystems of structured data APIs and feeds.",
        "bookmarks": 34,
        "keywords": [
            "Personal information management",
            "end-user data integration",
            "mash-ups",
            "sensemaking  with data"
        ],
        "communities": [],
        "video": "chi0127-file5.mp4",
        "session": {
            "id": "s268",
            "name": "Navigating Data"
        },
        "room": "blue",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth4132",
                "givenName": "Max",
                "familyName": "Van Kleek",
                "email": "emax@alum.mit.edu",
                "primary": {
                    "institution": "University of Southampton",
                    "city": "Southampton",
                    "state": "Hampshire",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth8149",
                "givenName": "Daniel",
                "middleInitial": "A",
                "familyName": "Smith",
                "email": "ds@ecs.soton.ac.uk",
                "primary": {
                    "dept": "Web and Internet Science",
                    "institution": "University of Southampton",
                    "city": "Southampton",
                    "state": "Hampshire",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29372",
                "givenName": "Heather",
                "middleInitial": "S",
                "familyName": "Packer",
                "email": "hp3@ecs.soton.ac.uk",
                "primary": {
                    "institution": "University of Southampton",
                    "city": "Southampton",
                    "state": "Hampshire",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth29312",
                "givenName": "Jim",
                "familyName": "Skinner",
                "email": "jskinner.mail@gmail.com",
                "primary": {
                    "institution": "University of Southampton",
                    "city": "Southampton",
                    "state": "Hampshire",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth27796",
                "givenName": "Nigel",
                "middleInitial": "R",
                "familyName": "Shadbolt",
                "email": "nrs@ecs.soton.ac.uk",
                "primary": {
                    "institution": "University of Southampton",
                    "city": "Southampton",
                    "state": "Hampshire",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 163,
        "name": "A Multi-touch Interface for Fast Architectural Sketching and Massing",
        "type": "paper",
        "abstract": "Architectural sketching and massing are used by designers to analyze and explore the design space of buildings.  This paper describes a novel multi-touch interface for fast architectural sketching and massing of tall buildings.  It incorporates a family of multi-touch gestures, enabling one to quickly sketch the 2D contour of a base floor plan and extrude it to model a building with multi-floor structures.  Further, it provides a set of gestures to users: select and edit a range of floors; scale contours of a building; copy, paste, and rotate a building, i.e., create a twisted structure; edit profile curves of a building's profile; and collapse and remove a selected range of floors.  The multi-touch system also allows users to apply textures or geometric facades to the building, and to compare different designs side-by-side.  To guide the design process, we describe interactions with a domain expert, a practicing architect.  The final interface is evaluated by architects and students in an architecture department, which demonstrates that the system allows rapid conceptual design and massing of novel multi-story building structures.",
        "cbStatement": "This paper proposes a novel multi-touch interface for architectural Sketching and Massing; it offers a rich set of direct finger gestures for rapid prototyping of contemporary building designs. \\ ",
        "bookmarks": 173,
        "keywords": [
            "Building design",
            "multi-touch",
            "sketching",
            "massing"
        ],
        "communities": [
            "design"
        ],
        "video": "chi1271-file5.mp4",
        "session": {
            "id": "s221",
            "name": "Multitouch and Gestures"
        },
        "room": "352ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth16937",
                "givenName": "Qian",
                "familyName": "Sun",
                "email": "SUNQ0004@e.ntu.edu.sg",
                "primary": {
                    "institution": "Nanyang Technological University",
                    "city": "Singapore",
                    "country": "Singapore"
                },
                "role": "presenter"
            },
            {
                "id": "auth29601",
                "givenName": "Juncong",
                "familyName": "Lin",
                "email": "jclin@xmu.edu.cn",
                "primary": {
                    "institution": "Xiamen University",
                    "city": "Xiamen",
                    "state": "Fujian",
                    "country": "China"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth13849",
                "givenName": "Chi-Wing",
                "familyName": "Fu",
                "email": "cwfu@ntu.edu.sg",
                "primary": {
                    "institution": "Nanyang Technological University",
                    "city": "Singapore",
                    "country": "Singapore"
                }
            },
            {
                "id": "auth29582",
                "givenName": "Sawako",
                "familyName": "Kaijima",
                "email": "sawakokaijima@sutd.edu.sg",
                "primary": {
                    "institution": "Singapore University of Technology and Design",
                    "city": "Singapore",
                    "state": "Singapore",
                    "country": "Singapore"
                }
            },
            {
                "id": "auth16908",
                "givenName": "Ying",
                "familyName": "He",
                "email": "yhe@ntu.edu.sg",
                "primary": {
                    "institution": "Nanyang Technological University",
                    "city": "Singapore",
                    "country": "Singapore"
                }
            }
        ]
    },
    {
        "id": 164,
        "name": "Age-Related Differences in Performance with Touchscreens Compared to Traditional Mouse Input",
        "type": "paper",
        "abstract": "Despite the apparent popularity of touchscreens for older adults, little is known about the psychomotor performance of these devices. We compared performance between older adults and younger adults on four desktop and touchscreen tasks: pointing, dragging, crossing and steering. On the touchscreen, we also examined pinch-to-zoom. Our results show that while older adults were significantly slower than younger adults in general, the touchscreen reduced this performance gap relative to the desktop and mouse. Indeed, the touchscreen resulted in a significant movement time reduction of 35% over the mouse for older adults, compared to only 16% for younger adults. Error rates also decreased.",
        "cbStatement": "We compared performance of older and younger adults on a range of desktop and touchscreen tasks. The touchscreen reduced the performance gap between the two groups relative to the desktop. ",
        "bookmarks": 72,
        "keywords": [
            "older adults",
            "input",
            "touchscreens",
            "accessibility"
        ],
        "communities": [],
        "video": "chi1274-file5.mp4",
        "session": {
            "id": "s289",
            "name": "Technologies for Life"
        },
        "room": "242ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth3198",
                "givenName": "Leah",
                "familyName": "Findlater",
                "email": "leahkf@umd.edu",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth6165",
                "givenName": "Jon",
                "middleInitial": "E.",
                "familyName": "Froehlich",
                "email": "jonf@cs.umd.edu",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30444",
                "givenName": "Kays",
                "familyName": "Fattal",
                "email": "kays.fattal@gmail.com",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                }
            },
            {
                "id": "auth1537",
                "givenName": "Jacob",
                "middleInitial": "O.",
                "familyName": "Wobbrock",
                "email": "wobbrock@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth30390",
                "givenName": "Tanya",
                "familyName": "Dastyar",
                "email": "tdastyar@gmail.com",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 165,
        "name": "Does My Password Go up to Eleven? The Impact of Password Meters on Password Selection",
        "type": "paper",
        "abstract": "Password meters tell users whether their passwords are \"weak\" or \"strong.\"  We performed a laboratory experiment to examine whether these meters influenced users' password selections when they were forced to change their real passwords, and when they were not told that their passwords were the subject of a study.  We observed that the presence of meters yielded significantly stronger passwords.  We performed a followup field experiment to test a different scenario: creating a password for an unimportant account.  In this scenario, we found that the meters made no observable difference: participants simply reused weak passwords that they used to protect similar low-risk accounts.  We conclude that meters result in stronger passwords when users are forced to change existing passwords on \"important\" accounts and that individual meter design decisions likely have a marginal impact.",
        "cbStatement": "We show that password meters result in stronger passwords during changes to \"important\" accounts, whereas they do not have an observable effect when users create new passwords for \"unimportant\" accounts.",
        "bookmarks": 62,
        "keywords": [
            "Security",
            "Passwords",
            "User Study"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi0128-file5.mp4",
        "session": {
            "id": "s276",
            "name": "Authentication"
        },
        "room": "251",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth8172",
                "givenName": "Serge",
                "familyName": "Egelman",
                "email": "egelman@cs.berkeley.edu",
                "primary": {
                    "institution": "University of California, Berkeley",
                    "city": "Berkeley",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth28785",
                "givenName": "Andreas",
                "familyName": "Sotirakopoulos",
                "email": "andreass@ece.ubc.ca",
                "primary": {
                    "institution": "University of British Columbia",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            },
            {
                "id": "auth19815",
                "givenName": "Ildar",
                "middleInitial": "Irekovich",
                "familyName": "Muslukhov",
                "email": "ildarm@ece.ubc.ca",
                "primary": {
                    "dept": "University of British Columbia, Vancouver, British Columbia, Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth28786",
                "givenName": "Konstantin",
                "familyName": "Beznosov",
                "email": "beznosov@ece.ubc.ca",
                "primary": {
                    "institution": "University of British Columbia",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            },
            {
                "id": "auth11993",
                "givenName": "Cormac",
                "familyName": "Herley",
                "email": "cormac@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 166,
        "name": "Quantifying the Invisible Audience in Social Networks",
        "type": "paper",
        "abstract": "When you share content in an online social network, who is listening? Users have scarce information about who actually sees their content, making their audience seem invisible and difficult to estimate. However, understanding this invisible audience can impact both science and design, since perceived audiences influence content production and self-presentation online. In this paper, we combine survey and large-scale log data to examine how well users' perceptions of their audience match their actual audience on Facebook. We find that social media users consistently underestimate their audience size for their posts, guessing that their audience is just 27% of its true size. Qualitative coding of survey responses reveals folk theories that attempt to reverse-engineer audience size using feedback and friend count, though none of these approaches are particularly accurate. We analyze audience logs for 222,000 Facebook users' posts over the course of one month and find that publicly visible signals --- friend count, likes, and comments --- vary widely and do not strongly indicate the audience of a single post. Despite the variation, users typically reach 61% of their friends each month. Together, our results begin to reveal the invisible undercurrents of audience attention and behavior in online social networks.",
        "cbStatement": "When you share content in a social network, who is listening? We combine survey and log data to examine how well users' audience perceptions match their true audience on Facebook.",
        "bookmarks": 42,
        "keywords": [
            "Social networks",
            "audience",
            "information distribution"
        ],
        "communities": [],
        "video": "chi1281-file5.mp4",
        "session": {
            "id": "s205",
            "name": "Look how popular I am: managing social media platforms"
        },
        "room": "blue",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth7809",
                "givenName": "Michael",
                "middleInitial": "S",
                "familyName": "Bernstein",
                "email": "msb@cs.stanford.edu",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Facebook, Inc.",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30405",
                "givenName": "Eytan",
                "familyName": "Bakshy",
                "email": "ebakshy@fb.com",
                "primary": {
                    "institution": "Facebook, Inc.",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth7882",
                "givenName": "Moira",
                "familyName": "Burke",
                "email": "mburke@fb.com",
                "primary": {
                    "institution": "Facebook, Inc.",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth29588",
                "givenName": "Brian",
                "familyName": "Karrer",
                "email": "briankarrer@fb.com",
                "primary": {
                    "institution": "Facebook, Inc.",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 167,
        "name": "Wikipedia Classroom Experiment: Bidirectional Benefits of Students' Engagement in Online Production Communities",
        "type": "paper",
        "abstract": "Over the last decade, a citizen science movement has tried to engage students, laymen and other non-scientists in the production of science. However, there has been less attention in citizen science projects to use the public to disseminate scientific knowledge. Wikipedia provides a platform to study engagement of citizen scientists in knowledge dissemination. College and university students are especially appropriate members of the public to write science articles, because of the course-work and mentorship they receive from faculty. This paper describes a project to support students' writing of scientific articles in Wikipedia. In collaboration with a scientific association, we involved 640 students from 36 courses in editing scientific articles on Wikipedia.  This paper provides details in the design of the program and our quantitative and qualitative approaches to evaluating it. Our results show that the Wikipedia classroom experiment benefits both the Wikipedia community and students.  Undergraduate and graduate students substantially improved the scientific content of over 800 articles, at a level of quality indistinguishable from content written by PhD experts.  Both students and faculty endorsed the motivational benefits of an authentic writing experience that would be read by thousands of people.",
        "cbStatement": "This paper provides details in the design of a program to encourage students’ contribution to Wikipedia and our quantitative and qualitative approaches to evaluating it. ",
        "bookmarks": 196,
        "keywords": [
            "online volunteer community",
            "socialization",
            "experiment"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi1297-file5.mp4",
        "session": {
            "id": "s287",
            "name": "Online Classrooms"
        },
        "room": "251",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth29605",
                "givenName": "Rosta",
                "familyName": "Farzan",
                "email": "rfarzan@pitt.edu",
                "primary": {
                    "dept": "School of Information Sciences",
                    "institution": "University of Pittsburgh",
                    "city": "Pittsburgh",
                    "state": "PA",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth3627",
                "givenName": "Robert",
                "middleInitial": "E",
                "familyName": "Kraut",
                "email": "robert.kraut@cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 168,
        "name": "PanoInserts: Mobile Spatial Teleconferencing",
        "type": "paper",
        "abstract": "We present PanoInserts: a novel teleconferencing system that uses smartphone cameras to create a surround representation of meeting places. We take a static panoramic image of a location into which we insert live videos from smartphones. We use a combination of marker- and image-based tracking to position the video inserts within the panorama, and transmit this representation to a remote viewer. We conduct a user study comparing our system with fully-panoramic video and conventional webcam video conferencing for two spatial reasoning tasks. \\ Results indicate that our system performs comparably with fully-panoramic video, and better than webcam video conferencing in tasks that require an accurate surrounding representation of the remote space. We discuss the representational properties and usability of varying video presentations, exploring how they are perceived and how they influence users when performing spatial reasoning tasks.",
        "cbStatement": "PanoInserts is a novel teleconferencing system that uses smartphone cameras to create a surround representation of meeting places. ",
        "bookmarks": 160,
        "keywords": [
            "Mixed reality",
            "teleconferencing",
            "telepresence",
            "remote collaboration",
            "mobile phones",
            "panoramas",
            "camera tracking"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi0130-file5.mp4",
        "authors": [
            {
                "id": "auth28688",
                "givenName": "Fabrizio",
                "familyName": "Pece",
                "email": "f.pece@cs.ucl.ac.uk",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth10921",
                "givenName": "William",
                "familyName": "Steptoe",
                "email": "w.steptoe@cs.ucl.ac.uk",
                "primary": {
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29199",
                "givenName": "Fabian",
                "familyName": "Wanner",
                "email": "f.wanner@cs.ucl.ac.uk",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth12384",
                "givenName": "Simon",
                "familyName": "Julier",
                "email": "S.Julier@cs.ucl.ac.uk",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth29201",
                "givenName": "Tim",
                "familyName": "Weyrich",
                "email": "t.weyrich@cs.ucl.ac.uk",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth29200",
                "givenName": "Jan",
                "familyName": "Kautz",
                "email": "j.kautz@cs.ucl.ac.uk",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth3018",
                "givenName": "Anthony",
                "familyName": "Steed",
                "email": "A.Steed@cs.ucl.ac.uk",
                "primary": {
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 169,
        "name": "Gender, Topic, and Audience Response: An Analysis of User-Generated Content on Facebook",
        "type": "paper",
        "abstract": "Although both men and women communicate frequently on Facebook, we know little about what they talk about, whether their topics differ and how their network responds. Using Latent Dirichlet Allocation (LDA), we identify topics from more than half a million Facebook status updates and determine which topics are more likely to receive feedback, such as likes and comments. Women tend to share more personal topics (e.g., family matters), while men discuss more public ones (e.g., politics and sports). Generally, women receive more feedback than men, but \"male\" topics (those more often posted by men) receive more feedback, especially when posted by women.",
        "cbStatement": "This paper identifies topics that men and women talk about in Facebook status updates and determines which topics are more likely to receive feedback.",
        "bookmarks": 113,
        "keywords": [
            "Social networking sites",
            "Facebook",
            "computer-mediated communication",
            "gender",
            "topics",
            "natural language analysis"
        ],
        "communities": [],
        "video": "chi1301-file5.mp4",
        "session": {
            "id": "s205",
            "name": "Look how popular I am: managing social media platforms"
        },
        "room": "blue",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth17478",
                "givenName": "Yi-Chia",
                "familyName": "Wang",
                "email": "yichiaw@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth7882",
                "givenName": "Moira",
                "familyName": "Burke",
                "email": "mburke@fb.com",
                "primary": {
                    "institution": "Facebook, Inc.",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth3627",
                "givenName": "Robert",
                "middleInitial": "E",
                "familyName": "Kraut",
                "email": "robert.kraut@cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 170,
        "name": "\"I Need to Try This!\": A Statistical Overview of Pinterest",
        "type": "paper",
        "abstract": "Over the past decade, social network sites have become ubiquitous places for people to maintain relationships, as well as loci of intense research interest. Recently, a new site has exploded into prominence: Pinterest became the fastest social network to reach 10M users, growing 4000% in 2011 alone. While many Pinterest articles have appeared in the popular press, there has been little scholarly work so far. In this paper, we use a quantitative approach to study three research questions about the site. What drives activity on Pinterest? What role does gender play in the site’s social connections? And finally, what distinguishes Pinterest from existing networks, in particular Twitter? In short, we find that being female means more repins, but fewer followers, and that four verbs set Pinterest apart from Twitter: use, look, want and need. This work serves as an early snapshot of Pinterest that later work can leverage.",
        "cbStatement": "We use a quantitative approach to study activity, gender and distinctiveness on Pinterest. This work serves as an early snapshot of Pinterest that later work can leverage.",
        "bookmarks": 192,
        "keywords": [
            "social network sites",
            "cmc",
            "pinterest",
            "twitter"
        ],
        "communities": [],
        "session": {
            "id": "s267",
            "name": "Shopping and Tagging"
        },
        "room": "241",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth7571",
                "givenName": "Eric",
                "familyName": "Gilbert",
                "email": "gilbert@cc.gatech.edu",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth29617",
                "givenName": "Saeideh",
                "familyName": "Bakhshi",
                "email": "saeideh@gatech.edu",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            },
            {
                "id": "auth29540",
                "givenName": "Shuo",
                "familyName": "Chang",
                "email": "schang@cs.umn.edu",
                "primary": {
                    "institution": "University of Minnesota",
                    "city": "Minneapolis",
                    "state": "Minnesota",
                    "country": "United States"
                }
            },
            {
                "id": "auth1048",
                "givenName": "Loren",
                "familyName": "Terveen",
                "email": "terveen@cs.umn.edu",
                "primary": {
                    "institution": "University of Minnesota",
                    "city": "Minneapolis",
                    "state": "Minnesota",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 171,
        "name": "I Feel For My Avatar: Embodied Perception in VEs",
        "type": "paper",
        "abstract": "Visual perception is dependent upon one’s physical state. The apparent inclination of a hill is overestimated when the observer is carrying a heavy backpack. But, what if the hill is a virtual one and the user is about to navigate the virtual environment through an avatar? In a 2 (user with a backpack vs. user without the backpack) × 2 (avatar with a virtual backpack vs. avatar without a virtual backpack) × 2 (customized avatar vs. assigned avatar) between-subjects experiment (N = 121), participants estimated the hill as being steeper when using a customized avatar rather than an assigned one. When the avatar is encumbered by a heavy virtual backpack, those with a customized avatar perceived the virtual hill as being more difficult to climb. Avatar customization and the physical resources of the avatar (operationalized here in the form of a ‘virtual’ backpack) were found to be key predictors of embodied perception in virtual environments (VE). This has implications for the design of games and interventions that make use of VEs.",
        "cbStatement": "Experimental evidence of the embodied perception in the virtual environments (VEs). Users felt burdened, when their customized avatars were burdened in the virtual environments.",
        "bookmarks": 60,
        "keywords": [
            "avatars",
            "customization",
            "embodied perception",
            "virtual worlds"
        ],
        "communities": [
            "ux",
            "games"
        ],
        "video": "chi1307-file5.mp4",
        "session": {
            "id": "s238",
            "name": "Playing with Body"
        },
        "room": "242b",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth29620",
                "givenName": "Sangseok",
                "familyName": "You",
                "email": "sangyou@umich.edu",
                "primary": {
                    "institution": "University of Michigan",
                    "city": "Ann Arbor",
                    "state": "Michigan",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth3339",
                "givenName": "S. Shyam",
                "familyName": "Sundar",
                "email": "sss12@psu.edu",
                "primary": {
                    "institution": "The Pennsylvania State University",
                    "city": "University Park",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Sungkyunkwan University",
                    "city": "Seoul",
                    "country": "Republic of Korea"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 172,
        "name": "Scenario-Based Interactive UI Design",
        "type": "paper",
        "abstract": "Clearly picturing user behavior is one of the key requirements when designing successful interactive software. However, covering all possible user behaviors with one UI is a complex challenge. The Scenario-based Interactive UI Design tool is designed to support the characterization of user behavior based on scenarios and then using the information in UI design. Scenarios make it easy to understand and share user behavior even if we have little design knowledge. However, they have two big weaknesses; 1) integrating several scenarios in one UI is difficult, even if we can create appropriate scenarios, 2) maintaining the links between scenarios and the UI is a heavy task in iterative design. Our tool solves the above problems through its hierarchical scenario structure and visualized overview of scenarios. It enhances the designer’s skill in writing scenarios and designing UIs smoothly and easily.",
        "cbStatement": "Our proposal is a novel tool that enhances the designer’s skill in writing scenarios and designing UIs smoothly and easily.",
        "bookmarks": 12,
        "keywords": [
            "User interface design",
            "Scenario",
            "Design tool",
            "Traceability"
        ],
        "communities": [
            "design"
        ],
        "video": "chi1308-file5.mp4",
        "session": {
            "id": "s279",
            "name": "Evaluation Methods 1"
        },
        "room": "351",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth28184",
                "givenName": "Koki",
                "familyName": "Kusano",
                "email": "kusano.kouki@lab.ntt.co.jp",
                "primary": {
                    "dept": "Human Analysis Project",
                    "institution": "NTT Service Evolution Laboratories",
                    "city": "Hikari-on-oka, Yokosuka-Shi, Kanagawa",
                    "country": "Japan"
                },
                "role": "presenter"
            },
            {
                "id": "auth13826",
                "givenName": "Momoko",
                "familyName": "Nakatani",
                "email": "nakatani.momoko@lab.ntt.co.jp",
                "primary": {
                    "dept": "Human Analysis Project",
                    "institution": "NTT Service Evolution Laboratories",
                    "city": "Hikari-on-oka, Yokosuka-Shi, Kanagawa",
                    "country": "Japan"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth2553",
                "givenName": "Takehiko",
                "familyName": "Ohno",
                "email": "ohno.takehiko@lab.ntt.co.jp",
                "primary": {
                    "dept": "Human Analysis Project",
                    "institution": "NTT Service Evolution Laboratories",
                    "city": "Hikari-on-oka, Yokosuka-Shi, Kanagawa",
                    "country": "Japan"
                }
            }
        ]
    },
    {
        "id": 173,
        "name": "Pointing at 3D Target Projections with One-Eyed and Stereo Cursors",
        "type": "paper",
        "abstract": "We present a study of cursors for selecting 2D-projected 3D targets. We compared a stereo- and mono-rendered (one-eyed) cursor using two mouse-based and two remote pointing techniques in a 3D Fitts’ law pointing experiment. The first experiment used targets at fixed depths. Results indicate that one-eyed cursors only improve screen-plane pointing techniques, and that constant target depth does not influence pointing throughput. A second experiment included pointing between targets at varying depths and used only “screen-plane” pointing techniques. Our results suggest that in the absence of stereo cue conflicts, screen-space projections of Fitts’ law parameters (target size and distance) yield constant throughput despite target depth differences and produce better models of performance. ",
        "cbStatement": "We investigate 2D-projected 3D pointing tasks. In particular, we look at the modeling of perspective-scaled 3D targets in screen-plane pointing, while comparing mouse and remote pointing techniques.",
        "bookmarks": 176,
        "keywords": [
            "3D pointing",
            "cursors",
            "selection",
            "Fitts’ law"
        ],
        "communities": [
            "engineering",
            "games"
        ],
        "video": "chi1312-file5.mp4",
        "session": {
            "id": "s251",
            "name": "3D Uis"
        },
        "room": "241",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth13633",
                "givenName": "Robert",
                "middleInitial": "J.",
                "familyName": "Teather",
                "email": "rteather@cse.yorku.ca",
                "primary": {
                    "institution": "York University",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth1316",
                "givenName": "Wolfgang",
                "familyName": "Stuerzlinger",
                "email": "wolfgang@cse.yorku.ca",
                "primary": {
                    "institution": "York University",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 174,
        "name": "Shifting Dynamics or Breaking Sacred Traditions? The Role of Technology in Twelve-Step Fellowships",
        "type": "paper",
        "abstract": "Twelve-step fellowships are the most common long-term maintenance program for recovery from alcoholism and addiction. Informed by six months of participatory observation of twelve-step fellowship meetings and service structure, I conducted in-depth interviews with twelve members of Alcoholics Anonymous (AA) and Narcotics Anonymous (NA) about the role of technology in recovery. I found that there are a number of tensions in how technology is perceived and adopted. As technology and twelve-step fellowships interact, issues of anonymity, identity, consensus, access, unity, autonomy, and physical presence are foregrounded. I relate these findings to the broader research landscape and provide implications for future design in this space. ",
        "cbStatement": "Presents in-depth interviews with member of twelve-step recovery groups to understand the role of technology in these communities. Relates these findings to wider questions of design in social computing.",
        "bookmarks": 120,
        "keywords": [
            "Recovery",
            "addiction",
            "twelve-step fellowships",
            "spirituality"
        ],
        "communities": [],
        "video": "chi1317-file5.mp4",
        "session": {
            "id": "s274",
            "name": "Privacy"
        },
        "room": "251",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth9072",
                "givenName": "Svetlana",
                "familyName": "Yarosh",
                "email": "lana@research.att.com",
                "primary": {
                    "institution": "AT&T Research Labs",
                    "city": "Jersey City",
                    "state": "New Jersey",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 175,
        "name": "Mastering the Art of War: How Patterns of Gameplay Influence Skill in Halo",
        "type": "paper",
        "abstract": "How do video game skills develop, and what sets the top players apart? We study this question of skill through a rating generated from repeated multiplayer matches called TrueSkill. Using these ratings from 7 months of games from over 3 million players, we look at how play intensity, breaks in play, skill change over time, and other games affect skill. These analyzed factors are then combined to model future skill and games played; the results show that skill change in early matches is a useful metric for modeling future skill, while play intensity explains eventual games played. The best players in the 7-month period, who we call \"Master Blasters\", have varied skill patterns that often run counter to the trends we see for typical players. The data analysis is supplemented with a 70 person survey to explore how players' self-perceptions compare to the gameplay data; most survey responses align well with the data and provide insight into player beliefs and motivation. Finally, we wrap up with a discussion about hiding skill information from players, and implications for game designers.",
        "cbStatement": "We look at patterns of skill through large-scale gameplay analysis and player surveys to identify how different factors (play intensity, skill change over time, demographics, breaks, and prior games played) affect players' skill in Halo.",
        "bookmarks": 92,
        "keywords": [
            "video games",
            "learning",
            "gaming skill",
            "online multiplayer"
        ],
        "communities": [
            "games"
        ],
        "video": "chi1318-file5.mp4",
        "session": {
            "id": "s284",
            "name": "Nonkid Games"
        },
        "room": "251",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth14008",
                "givenName": "Jeff",
                "familyName": "Huang",
                "email": "chi2010@jeffhuang.com",
                "primary": {
                    "dept": "Information School",
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth13027",
                "givenName": "Thomas",
                "familyName": "Zimmermann",
                "email": "tzimmer@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30789",
                "givenName": "Nachiappan",
                "familyName": "Nagapan",
                "email": "nachin@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth30790",
                "givenName": "Charles",
                "familyName": "Harrison",
                "email": "charlesh@microsoft.com",
                "primary": {
                    "institution": "Microsoft",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth5916",
                "givenName": "Bruce",
                "middleInitial": "C",
                "familyName": "Phillips",
                "email": "bphil@microsoft.com",
                "primary": {
                    "institution": "Microsoft",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 176,
        "name": "SeeSay and HearSay CAPTCHAs for Mobile Interaction",
        "type": "paper",
        "abstract": "Speech certainly has advantages as an input modality for smartphone applications, especially in scenarios where using touch or keyboard entry is difficult, on increasingly miniaturized devices where useable keyboards are difficult to accommodate, or in scenarios where only small amounts of text need to be input, such as when entering SMS texts or responding to a CAPTCHA challenge. In this paper, we propose two new alternative ways to design CAPTCHAs in which the user says the answer instead of typing it with (a) output stimuli provided visually (SeeSay) or (b) auditorily (HearSay). Our user study results show that SeeSay CAPTCHA requires less time to be solved and users prefer it over current text-based CAPTCHA methods.",
        "cbStatement": "We propose two alternative designs for CAPTCHAs in which the user says the answer instead of typing it. Output stimuli are provided visually (SeeSay) or auditorily (HearSay).",
        "bookmarks": 94,
        "keywords": [
            "CAPTCHA",
            "Mobile Phone",
            "Speech Recognition"
        ],
        "communities": [],
        "authors": [
            {
                "id": "auth11586",
                "givenName": "Sajad",
                "familyName": "Shirali-Shahreza",
                "email": "shirali@cs.toronto.edu",
                "primary": {
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth8487",
                "givenName": "Gerald",
                "familyName": "Penn",
                "email": "gpenn@cs.toronto.edu",
                "primary": {
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                }
            },
            {
                "id": "auth1019",
                "givenName": "Ravin",
                "familyName": "Balakrishnan",
                "email": "ravin@dgp.toronto.edu",
                "primary": {
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth18179",
                "givenName": "Yashar",
                "familyName": "Ganjali",
                "email": "yganjali@cs.toronto.edu",
                "primary": {
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 177,
        "name": "Effects of Visualization and Note-Taking  on Sensemaking and Analysis",
        "type": "paper",
        "abstract": "Many sophisticated tools have been developed to help analysts detect patterns in large datasets, but the value of these tools’ individual features is rarely tested. In an experiment in which participants played detectives solving homicides, we tested the utility of a visualization of data links and a notepad for collecting and organizing annotations. The visualization significantly improved participants’ ability to solve the crime whereas the notepad did not. Having both features available provided no benefit over having just the visualization. The results raise questions about the potential constraints on the usefulness of intelligence analysis tools.",
        "cbStatement": "The utility of intelligence analysis tools’ individual features is rarely tested. Through experiment, we tested the utility of visualization and notetaking. Our Results question potential constraints on their individual utility.",
        "bookmarks": 180,
        "keywords": [
            "Analysis",
            "sensemaking",
            "visualization",
            "interface design"
        ],
        "communities": [],
        "video": "chi1327-file5.mp4",
        "session": {
            "id": "s233",
            "name": "Text Visualization"
        },
        "room": "bordeaux",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth34639",
                "givenName": "Nitesh",
                "familyName": "Goyal",
                "email": "ng323@cornell.edu",
                "primary": {
                    "dept": "Information Science",
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth5502",
                "givenName": "Gilly",
                "familyName": "Leshed",
                "email": "gl87@cornell.edu",
                "primary": {
                    "dept": "Information Science",
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1053",
                "givenName": "Susan",
                "middleInitial": "R.",
                "familyName": "Fussell",
                "email": "sfussell@cornell.edu",
                "primary": {
                    "dept": "Information Science",
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 178,
        "name": "LightCloth: Senseable Illuminating Optical Fiber Cloth for Creating Interactive Surfaces",
        "type": "paper",
        "abstract": "This paper introduces an input and output device that enables illumination, bi-directional data communication, and position sensing on a soft cloth. This “LightCloth” is woven from diffusive optical fibers. Since the fibers are arranged in parallel, the cloth has one-dimensional position information. Sensor-emitter pairs attached to bundles of contiguous fibers enable bundle-specific light input and output. We developed a prototype system that allows full-color illumination and 8-bit data input by infrared signals. We present as an application a chair with a LightCloth cover whose illumination pattern is specified using an infrared light pen. Here we describe the implementation details of the device and discuss possible interactions using the device.",
        "cbStatement": "LightCloth is a fabric interface that enables illumination, light communication, and position sensing. We added a sensory function to diffusive optical fibers, and widened the possibilities for new fabric interactions.",
        "bookmarks": 96,
        "keywords": [
            "Soft deformable user interface",
            "diffusive optical fiber",
            "illumination",
            "light communication",
            "position sensing"
        ],
        "communities": [
            "design",
            "engineering",
            "games",
            "arts"
        ],
        "video": "chi1328-file5.mp4",
        "session": {
            "id": "s229",
            "name": "Bendable, Flexible"
        },
        "room": "352ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth18058",
                "givenName": "Sunao",
                "familyName": "Hashimoto",
                "email": "hashimoto@kougaku-navi.net",
                "primary": {
                    "institution": "JST ERATO Igarashi Design Interface Project",
                    "city": "Bunkyo",
                    "country": "Japan"
                },
                "role": "presenter"
            },
            {
                "id": "auth29651",
                "givenName": "Ryohei",
                "familyName": "Suzuki",
                "email": "suzuki@designinterface.jp",
                "primary": {
                    "institution": "The University of Tokyo",
                    "city": "Tokyo",
                    "country": "Japan"
                },
                "secondary": {
                    "institution": "JST ERATO Igarashi Design Interface Project",
                    "city": "Bunkyo",
                    "country": "Japan"
                }
            },
            {
                "id": "auth29652",
                "givenName": "Youichi",
                "familyName": "Kamiyama",
                "email": "kamiyama@designinterface.jp",
                "primary": {
                    "institution": "JST ERATO Igarashi Design Interface Project",
                    "city": "Bunkyo",
                    "state": "Tokyo",
                    "country": "Japan"
                }
            },
            {
                "id": "auth10126",
                "givenName": "Masahiko",
                "familyName": "Inami",
                "email": "inami@inami.info",
                "primary": {
                    "institution": "Keio University",
                    "city": "Yokohama City",
                    "state": "Kanagawa",
                    "country": "Japan"
                },
                "secondary": {
                    "institution": "JST ERATO Igarashi Design Interface Project",
                    "city": "Bunkyo",
                    "state": "Tokyo",
                    "country": "Japan"
                }
            },
            {
                "id": "auth1051",
                "givenName": "Takeo",
                "familyName": "Igarashi",
                "email": "takeo@acm.org",
                "primary": {
                    "institution": "The University of Tokyo",
                    "city": "Tokyo",
                    "country": "Japan"
                },
                "secondary": {
                    "institution": "JST ERATO IGARASHI Design Interface Project",
                    "city": "Bunkyo",
                    "state": "Tokyo",
                    "country": "Japan"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 179,
        "name": "Reality Jockey: Lifting the Barrier between Alternate Realities through Audio and Haptic Feedback",
        "type": "paper",
        "abstract": "We present Reality Jockey, a system that confuses the participant’s perception of the reality by mixing in a recorded past-reality. The participant will be immersed in a spatialized 3D sound environment that is a mix of sounds from the reality and from the past. The sound environment from the past is augmented with haptic feedback in cross-modality. The haptic feedback is associated with certain sounds such as the vibration in the table when stuff is placed on the table to make the illusion of it happening in live. The seamless transition between live and past creates immersive experience of past events. The blending of live and past allows interactivity. To validate our system, we conducted user studies on 1) does blending live sensations improve such experiences, and 2) how beneficial is it to provide haptic feedbacks in recorded pasts. Potential applications are suggested to illustrate the significance of Reality Jockey.",
        "cbStatement": "This research works on the concept of how alternate realities from the past can be re-experienced with immersion through the cross-modality of audio and haptics.",
        "bookmarks": 3,
        "keywords": [
            "Substitutional Reality",
            "Haptic",
            "Spatial Sound",
            "Cross-Modality",
            "Illusion"
        ],
        "communities": [],
        "video": "chi1330-file5.mp4",
        "session": {
            "id": "s226",
            "name": "Haptics"
        },
        "room": "352ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth28731",
                "givenName": "Kevin",
                "familyName": "Fan",
                "email": "kevin0228ca@gmail.com",
                "primary": {
                    "institution": "Keio University",
                    "city": "Yokohama City",
                    "state": "Kanagawa",
                    "country": "Japan"
                },
                "role": "presenter"
            },
            {
                "id": "auth30306",
                "givenName": "Hideyuki",
                "familyName": "Izumi",
                "email": "hid1979@kmd.keio.ac.jp",
                "primary": {
                    "institution": "Keio University",
                    "city": "Yokohama City",
                    "state": "Kanagawa",
                    "country": "Japan"
                }
            },
            {
                "id": "auth13921",
                "givenName": "Yuta",
                "familyName": "Sugiura",
                "email": "yuta.sugiura@gmail.com",
                "primary": {
                    "institution": "Keio University",
                    "city": "Yokohama City",
                    "state": "Kanagawa",
                    "country": "Japan"
                }
            },
            {
                "id": "auth28345",
                "givenName": "Kouta",
                "familyName": "Minamizawa",
                "email": "kouta@tachilab.org",
                "primary": {
                    "institution": "Keio University",
                    "city": "Yokohama City",
                    "state": "Kanagawa",
                    "country": "Japan"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth34617",
                "givenName": "Sohei",
                "familyName": "Wakisaka",
                "email": "wakisaka@brain.riken.jp",
                "primary": {
                    "institution": "RIKEN",
                    "city": "Wako",
                    "state": "Saitama",
                    "country": "Japan"
                }
            },
            {
                "id": "auth10126",
                "givenName": "Masahiko",
                "familyName": "Inami",
                "email": "inami@inami.info",
                "primary": {
                    "institution": "Keio University",
                    "city": "Yokohama City",
                    "state": "Kanagawa",
                    "country": "Japan"
                }
            },
            {
                "id": "auth34618",
                "givenName": "Naotaka",
                "familyName": "Fujii",
                "email": "na@brain.riken.jp",
                "primary": {
                    "institution": "RIKEN",
                    "city": "Wako",
                    "state": "Saitama",
                    "country": "Japan"
                }
            },
            {
                "id": "auth30307",
                "givenName": "Susumu",
                "familyName": "Tachi",
                "email": "tachi@tachilab.org",
                "primary": {
                    "institution": "Keio University",
                    "city": "Yokohama City",
                    "state": "Kanagawa",
                    "country": "Japan"
                }
            }
        ]
    },
    {
        "id": 180,
        "name": "FACIT PD: A Framework for Analysis and Creation of Intergenerational Techniques for Participatory Design",
        "type": "paper",
        "abstract": "In this paper, we present a framework that describes commonly used design techniques for Participatory Design with children. Although there are many currently used techniques for designing with children, researchers working in differing contexts and in a changing technological landscape find themselves facing difficult design situations. The FACIT PD framework presented in this paper can aid in choosing existing design techniques or in developing new techniques regardless of the stage in the design cycle, the technology being developed, or philosophical approach to design method. The framework consists of eight dimensions, concerning the design partners, the design goal, and the design technique. The partner dimensions are partner experience and need for accommodation. The design goal dimensions are design space and maturity of design. The technique dimensions include: cost, portability, technology and physical interaction. Three cases will be presented which describe new techniques developed using the framework and two cases will describe existing techniques. ",
        "cbStatement": "This paper describes a framework that can aid design teams in choosing or designing new techniques to design with children regardless of the subject area or method being used.",
        "bookmarks": 181,
        "keywords": [
            "Children",
            "design",
            "design techniques",
            "design methods"
        ],
        "communities": [
            "cci"
        ],
        "video": "chi1337-file5.mp4",
        "session": {
            "id": "s327",
            "name": "Children"
        },
        "room": "bordeaux",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth12709",
                "givenName": "Greg",
                "familyName": "Walsh",
                "email": "gwalsh@umd.edu",
                "primary": {
                    "dept": "User Interface Lab",
                    "institution": "University of Baltimore",
                    "city": "Baltimore",
                    "state": "Maryland",
                    "country": "United States"
                },
                "secondary": {
                    "dept": "HCIL",
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth15705",
                "givenName": "Elizabeth",
                "familyName": "Foss",
                "email": "efoss@umd.edu",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                }
            },
            {
                "id": "auth23842",
                "givenName": "Jason",
                "familyName": "Yip",
                "email": "jasonyip@umd.edu",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                }
            },
            {
                "id": "auth1070",
                "givenName": "Allison",
                "familyName": "Druin",
                "email": "allisond@umiacs.umd.edu",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 181,
        "name": "Facilitating Parallel Web Browsing through Multiple-Page View",
        "type": "paper",
        "abstract": "Parallel web browsing describes the behavior where users visit web pages in multiple concurrent threads. Qualitative studies have observed this activity being performed with multiple browser windows or tabs. However, these solutions are not satisfying since a large amount of time is wasted on switch among windows and tabs. In this paper, we propose the multiple-page view to facilitate parallel web browsing. Specifically, we provide users with the experience of visiting multiple web pages in one browser window and tab with extensions of prevalent desktop web browsers. Through user study and survey, we found that 2-4 pages within the window size were preferred for multiple-page view in spite of the diverse screen sizes and resolutions. Analytical results of logs from the user study also showed an improvement of 26.3% in users’ efficiency of performing parallel web browsing tasks, compared to traditional browsing with multiple windows or tabs.",
        "cbStatement": "We propose the multiple-page view to provide users with the experience of visiting multiple web pages in one browser window and tab with extensions of prevalent desktop web browsers.",
        "bookmarks": 107,
        "keywords": [
            "Parallel web browsing",
            "multiple-page view",
            "user study."
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi1339-file5.mp4",
        "session": {
            "id": "s248",
            "name": "Mobiles and more"
        },
        "room": "havane",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth13884",
                "givenName": "Wenchang",
                "familyName": "Xu",
                "email": "wencxu@gmail.com",
                "primary": {
                    "institution": "Tsinghua University",
                    "city": "Beijing",
                    "country": "China"
                },
                "role": "presenter"
            },
            {
                "id": "auth14029",
                "givenName": "Chun",
                "familyName": "Yu",
                "email": "yc2pcg@gmail.com",
                "primary": {
                    "institution": "Tsinghua University",
                    "city": "Beijing",
                    "country": "China"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth34640",
                "givenName": "Songmin",
                "familyName": "Zhao",
                "email": "zhaosongmin@gmail.com",
                "primary": {
                    "institution": "Tsinghua University",
                    "city": "Beijing",
                    "country": "China"
                }
            },
            {
                "id": "auth19760",
                "givenName": "Jie",
                "familyName": "Liu",
                "email": "liujiejesse@gmail.com",
                "primary": {
                    "institution": "Tsinghua University",
                    "city": "Beijing",
                    "country": "China"
                }
            },
            {
                "id": "auth17817",
                "givenName": "Yuanchun",
                "familyName": "Shi",
                "email": "shiyc@tsinghua.edu.cn",
                "primary": {
                    "institution": "Tsinghua University",
                    "city": "Beijing",
                    "country": "China"
                }
            }
        ]
    },
    {
        "id": 182,
        "name": "Some Evidence for the Impact of Limited Education on Hierarchical User Interface Navigation",
        "type": "paper",
        "abstract": "One of the greatest challenges in designing applications for economically poor communities is that potential users may have little or no education. We investigated how limited education appears to impact the ability to navigate a hierarchical UI, even when it has no text. We scored 60 participants from low-income communities in India using tests of textual literacy and Raven’s Progressive Matrices. These were used as proxies for educational level and a subset of cognitive abilities. We then evaluated participants’ performance on a UI task involving hierarchical navigation. First, our results confirm that textual literacy is correlated with scores on the Raven’s test. In addition, we found that performance on both instruments are predictive of performance in navigating UI hierarchies, even when the UI is text-free. This provides statistically significant confirmation of previous anecdotal hypotheses. We conclude with design recommendations for UI hierarchies for people with limited education.",
        "cbStatement": "Experimental study shows limited education impacting the ability to navigate a hierarchical UI, even when text-free. Can benefit designers interested in recommendations for UI hierarchies for people with limited education.",
        "bookmarks": 26,
        "keywords": [
            "Limited education",
            "abstract reasoning",
            "hierarchy navigation"
        ],
        "communities": [
            "design",
            "ux",
            "hci4d"
        ],
        "video": "chi1346-file5.mp4",
        "session": {
            "id": "s258",
            "name": "ICT4D"
        },
        "room": "242ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth7864",
                "givenName": "Indrani",
                "familyName": "Medhi",
                "email": "indranim@microsoft.com",
                "primary": {
                    "dept": "Industrial Design Centre",
                    "institution": "Indian Institute of Technology",
                    "city": "Bombay",
                    "country": "India"
                },
                "secondary": {
                    "institution": "Microsoft Research India",
                    "city": "Bangalore",
                    "state": "Karnataka",
                    "country": "India"
                },
                "role": "presenter"
            },
            {
                "id": "auth23729",
                "givenName": "Meera",
                "familyName": "Lakshmanan",
                "email": "meeragargi@gmail.com",
                "primary": {
                    "institution": "temp",
                    "city": "temp",
                    "state": "Bangalore",
                    "country": "India"
                }
            },
            {
                "id": "auth16406",
                "givenName": "Kentaro",
                "familyName": "Toyama",
                "email": "kentaro_toyama@hotmail.com",
                "primary": {
                    "dept": "School of Information",
                    "institution": "University of California, Berkeley",
                    "city": "Berkeley",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth1287",
                "givenName": "Edward",
                "familyName": "Cutrell",
                "email": "cutrell@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research India",
                    "city": "Bangalore",
                    "state": "Karnataka",
                    "country": "India"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 183,
        "name": "TrailMap: Facilitating Information Seeking in a Multi-Scale Digital Map via Implicit Bookmarking",
        "type": "paper",
        "abstract": "Web applications designed for map exploration in local neighborhoods have become increasingly popular and important in everyday life. During the information-seeking process, users often revisit previously viewed locations, repeat earlier searches, or need to memorize or manually mark areas of interest. To facilitate rapid returns to earlier views during map exploration, we propose a novel algorithm to automatically generate map bookmarks based on a user’s interaction. TrailMap, a web application based on this algorithm, is developed, providing a fluid and effective neighborhood exploration experience. A one-week study is conducted to evaluate TrailMap in users’ everyday web browsing activities. Results showed that TrailMap’s implicit bookmarking mechanism is efficient for map exploration and the interactive and visual nature of the tool is intuitive to users.",
        "cbStatement": "Designed an auto-bookmark generation algorithm according to a user’s interactions in multi-scale digital map exploration and developed a web-application based on the proposed algorithm.",
        "bookmarks": 159,
        "keywords": [
            "Digital map browsing",
            "revisitation",
            "implicit bookmarking."
        ],
        "communities": [],
        "video": "chi1350-file5.mp4",
        "session": {
            "id": "s265",
            "name": "Search and Find"
        },
        "room": "havane",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth15005",
                "givenName": "Jian",
                "familyName": "Zhao",
                "email": "jianzhao@dgp.toronto.edu",
                "primary": {
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth3440",
                "givenName": "Daniel",
                "middleInitial": "J",
                "familyName": "Wigdor",
                "email": "dwigdor@dgp.toronto.edu",
                "primary": {
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1019",
                "givenName": "Ravin",
                "familyName": "Balakrishnan",
                "email": "ravin@dgp.toronto.edu",
                "primary": {
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 184,
        "name": "Designing Engagement-aware Agents for Multiparty Conversations",
        "type": "paper",
        "abstract": "Recognizing users’ engagement state and intentions is a pressing task for computational agents to facilitate fluid conversations in situated interactions. We investigate how to quantitatively evaluate high-level user engagement and intentions based on low-level visual cues, and how to design engagement-aware behaviors for the conversational agents to behave in a sociable manner. Drawing on machine learning techniques, we propose two computational models to quantify users’ attention saliency and engagement intentions. Their performances are validated by a close match between the predicted values and the ground truth annotation data. Next, we design a novel engagement-aware behavior model for the agent to adjust its direction of attention and manage the conversational floor based on the estimated users’ engagement. In a user study, we evaluated the agent’s behaviors in a multiparty dialog scenario. The results show that the agent’s engagement-aware behaviors significantly improved the effectiveness of communication and positively affected users’ experience.",
        "cbStatement": "Presents quantitative methods to evaluate users’ engagement state and intentions from visual cues. Can assist the design of conversational agents for multiparty dialog in the public space.",
        "bookmarks": 163,
        "keywords": [
            "Human-robot interaction",
            "Engagement",
            "Intention",
            "Gaze",
            "Multiparty conversation",
            "Visual perception. "
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi1351-file5.mp4",
        "session": {
            "id": "s243",
            "name": "Place meets Engagement"
        },
        "room": "342a",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth17193",
                "givenName": "Qianli",
                "familyName": "Xu",
                "email": "qxu@i2r.a-star.edu.sg",
                "primary": {
                    "institution": "Institute for Infocomm Research, A*STAR",
                    "city": "Singapore",
                    "country": "Singapore"
                },
                "role": "presenter"
            },
            {
                "id": "auth29867",
                "givenName": "Liyuan",
                "familyName": "Li",
                "email": "lyli@i2r.a-star.edu.sg",
                "primary": {
                    "institution": "Institute for Infocomm Research, ASTAR",
                    "city": "Singapore",
                    "country": "Singapore"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29947",
                "givenName": "Gang ",
                "familyName": "Wang",
                "email": "gswang@i2r.a-star.edu.sg",
                "primary": {
                    "institution": "Institute for Infocomm Research, ASTAR",
                    "city": "Singapore",
                    "country": "Singapore"
                }
            }
        ]
    },
    {
        "id": 185,
        "name": "Mobile Advertising: Evaluating the Effects of Animation, User and Content Relevance",
        "type": "paper",
        "abstract": "The potential for user-relevant, context-appropriate, \\ targeted advertising on mobile devices is enormous given \\ device improvements and advances in personal and \\ location-based data collection. However, little is known \\ about how users experience display advertisements (‘ads’) \\ on mobile devices, or what factors drive mobile ad \\ effectiveness. In this paper, we investigate users’ \\ experiences of display advertising on mobile devices. We \\ consider three factors that are often studied in desktop \\ settings –the ad’s level of personal relevance to the user, its \\ relevance to the page content, and within-ad properties, \\ with a particular focus on the level of animation in the ad. \\ Our findings reveal a few surprises. First, personal \\ relevance to the user has little or no impact on ad efficacy \\ measured by recall. Instead, content relevance boosts ad \\ recall. Second, user relevance leads to a more pleasant and \\ interesting experience, but content relevance has no effect. \\ Third, contrary to the popular notion that animation often \\ leads to more effective ads by garnering more user \\ attention, we find that a simple type of animation, such as \\ blinking animation, negatively affects user experience and \\ reduces ad recall. Our findings, while focused on \\ advertising, offer insights for design of mobile content \\ presentation in general.",
        "cbStatement": "Study on animation, user and content relevance on mobile ads. Results indicate personal relevance leads to better experiences, content relevance to better ad recall and blinking animation affects user experience.",
        "bookmarks": 152,
        "keywords": [
            "Mobile devices",
            "evaluation",
            "animation",
            "relevance",
            "user experience",
            "advertising"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi1352-file5.mp4",
        "session": {
            "id": "s248",
            "name": "Mobiles and more"
        },
        "room": "havane",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth28525",
                "givenName": "Marco",
                "familyName": "de Sa",
                "email": "marcodesa@acm.org",
                "primary": {
                    "institution": "Facebook, Inc.",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth34572",
                "givenName": "Vidhya",
                "familyName": "Navalpakkam",
                "email": "vidhyan@google.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth1149",
                "givenName": "Elizabeth",
                "middleInitial": "F",
                "familyName": "Churchill",
                "email": "churchill@acm.org",
                "primary": {
                    "institution": "eBay Research Lab",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 186,
        "name": "Making Touchscreen Keyboards Adaptive to Keys, Hand Postures,  and Individuals - A Hierarchical Spatial Backoff Model Approach",
        "type": "paper",
        "abstract": "We propose a new approach for improving text entry accuracy on touchscreen \\ keyboards by adapting the underlying spatial model to factors such as input hand postures, individuals, and target key positions. To combine these factors together, we introduce a hierarchical spatial backoff model (SBM) that consists of submodels with different levels of complexity. The most general model includes no adaptive factors, whereas the most specific model includes all three. Considering that in practice people may switch hand postures (e.g., from two-thumb to one-finger) to better suit a situation, and that the specific submodels may take time to train for each user,  a specific submodel should be applied only if its corresponding input posture can be identified with confidence, and if the submodel has enough training data from the user.  We  \\ introduce the \\\\textit{backoff} mechanism to fall back to a simpler model if  \\ either of these conditions are not met.  We implemented a prototype system  \\ capable of reducing the language-model-independent error rate by 13.2\\\\% using an \\ online posture classifier with  86.4\\\\% accuracy.  Further improvements in error \\ rate may be possible with even better posture classification. ",
        "cbStatement": "We propose a hierarchical spatial backoff model for improving text entry accuracy on touchscreen keyboards. This approach adapts the underlying spatial model to input hand postures, individuals, and key positions, reducing error rate by 13.2%.",
        "bookmarks": 127,
        "keywords": [
            " Touchscreen text input",
            "posture adaptation",
            "personalization",
            "adaptive model."
        ],
        "communities": [
            "engineering",
            "ux"
        ],
        "video": "chi1360-file5.mp4",
        "session": {
            "id": "s254",
            "name": "Mobile keyboard / text entry"
        },
        "room": "241",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth21061",
                "givenName": "Ying",
                "familyName": "Yin",
                "email": "yingyin@mit.edu",
                "primary": {
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth22882",
                "givenName": "Tom",
                "middleInitial": "Yu",
                "familyName": "Ouyang",
                "email": "ouyang@google.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth34701",
                "givenName": "Kurt",
                "familyName": "Partridge",
                "email": "kep@google.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth1220",
                "givenName": "Shumin",
                "familyName": "Zhai",
                "email": "zhai@acm.org",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 187,
        "name": "The Mobile Media Actor-Network in Urban India",
        "type": "paper",
        "abstract": "Building on a growing body of human-computer interaction (HCI) literature on information and communication technology (ICT) use in the developing world, this paper describes the vast, growing mobile media consumption culture in India, which relies on the ubiquity of informal socioeconomic practices for reproducing, sharing, and distributing pirated digital media. Using an Actor-Network Theory (ANT) based approach, we show how piracy not only fuels media consumption, but also drives further technology adoption and promotes digital literacy. To do this, we first uncover the role of piracy as a legitimate actor that brings ICT capability to underserved communities and reveal the heterogeneous character of the pirated mobile media distribution and consumption infrastructure in India. We then emphasize the benefits of an ANT-based theory-driven analysis to HCI’s efforts in this arena. In particular, ANT enables us to one, draw attention to the ties in the pirate media network that facilitate the increased decentralization of piracy in India; two, highlight the progressive transition from the outsourcing to the self-sourcing of users’ media needs as this network evolves; and three, recognize the agency of human and non-human entities in this inherently sociotechnical ecosystem.  ",
        "cbStatement": "This paper describes the vast, growing mobile media consumption culture in urban India, which relies on the ubiquity of informal socioeconomic practices for reproducing, sharing, and distributing pirated digital media. ",
        "bookmarks": 38,
        "keywords": [
            "Actor-Network Theory",
            "Mobile",
            "Media",
            "Piracy",
            "Entertainment",
            "ICTD",
            "HCI4D"
        ],
        "communities": [
            "hci4d"
        ],
        "video": "chi1363-file5.mp4",
        "session": {
            "id": "s257",
            "name": "Crowds and activism"
        },
        "room": "blue",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth15363",
                "givenName": "Neha",
                "familyName": "Kumar",
                "email": "neha.kumar@gmail.com",
                "primary": {
                    "dept": "School of Information",
                    "institution": "University of California, Berkeley",
                    "city": "Berkeley",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth8849",
                "givenName": "Nimmi",
                "familyName": "Rangaswamy",
                "email": "nimmir@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research India",
                    "city": "Bangalore",
                    "state": "Karnataka",
                    "country": "India"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 188,
        "name": "Design to Promote Mindfulness Practice and Sense of Self for Vulnerable Women in Secure Hospital Services",
        "type": "paper",
        "abstract": "In the field of mental health care technologies, very limited attention has been given to the design of interventions for individuals who undergo treatment for severe mental health problems in intense care contexts. Exploring novel designs to engage vulnerable psychiatric patients in therapeutic skills practice and expanding on the potential of technology to promote mental health, the paper introduces the design concept of the Spheres of Wellbeing. A set of interactive artifacts is developed specifically for women with a dual diagnosis of a Learning Disability and Borderline Personality Disorder, living in the medium secure services of a forensic hospital in the UK. The women present a difficult to treat group due to extremely challenging behaviors and a fundamental lack of motivation to engage in therapy. The Spheres are designed to assist the women in practices of mindfulness, to help them tolerate emotional distress and to strengthen their sense of self, all of which are vital components of their specialist treatment Dialectical Behavioral Therapy (DBT). The Spheres are intended to supplement the therapy of the women and to contribute to our understanding of designing technology to enhance mental wellbeing and quality of life more generally.",
        "cbStatement": "Introduces the design concept of interactive artifacts to engage women with severe mental health problems in therapeutic skills practice. Provides insights from our collaboration with hospital staff for the design.",
        "bookmarks": 107,
        "keywords": [
            "Mental Health Technology",
            "Hospital",
            "Mindfulness",
            "Sense of Self",
            "Mental Wellbeing",
            "Interaction Design",
            "Materiality"
        ],
        "communities": [
            "design",
            "health"
        ],
        "video": "chi0137-file5.mp4",
        "session": {
            "id": "s297",
            "name": "Desing in a Psychiatric Setting"
        },
        "room": "242ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth14057",
                "givenName": "Anja",
                "familyName": "Thieme",
                "email": "anja-thieme@gmx.de",
                "primary": {
                    "institution": "Newcastle University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth22495",
                "givenName": "Jayne",
                "familyName": "Wallace",
                "email": "jayne.wallace@northumbria.ac.uk",
                "primary": {
                    "dept": "School of Design",
                    "institution": "Northumbria University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth34724",
                "givenName": "Paula",
                "familyName": "Johnson",
                "email": "paula.johnson@calderstones.nhs.uk",
                "primary": {
                    "dept": "Research & Development",
                    "institution": "Calderstones Partnership NHS Foundation Trust",
                    "city": "Whalley",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth6215",
                "givenName": "John",
                "familyName": "McCarthy",
                "email": "john.mccarthy@ucc.ie",
                "primary": {
                    "institution": "University College Cork",
                    "city": "Cork",
                    "state": "Cork",
                    "country": "Ireland"
                }
            },
            {
                "id": "auth2278",
                "givenName": "Siân",
                "middleInitial": "E",
                "familyName": "Lindley",
                "email": "sianl@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "state": "Cambridgeshire",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth9063",
                "givenName": "Peter",
                "middleInitial": "C",
                "familyName": "Wright",
                "email": "p.c.wright@newcastle.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth5105",
                "givenName": "Patrick",
                "familyName": "Olivier",
                "email": "p.l.olivier@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth30103",
                "givenName": "Thomas",
                "middleInitial": "D",
                "familyName": "Meyer",
                "email": "thomas.meyer@ncl.ac.uk",
                "primary": {
                    "dept": "Institute of Neuroscience",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 189,
        "name": "A Preliminary Investigation of Human Adaptations for Various Virtual Eyes in Video See-Through HMDs",
        "type": "paper",
        "abstract": "A video see-through head mounted display (HMD) has a different viewing point than does the real eye, resulting in visual displacement (VD). VD deteriorates visuomotor performance due to sensory conflict. Previous work has investigated this deterioration and human adaptation by comparing fixed VD and real eye conditions. In this study we go a step further to investigate whether any differences in visuomotor and adaptation trends exist across 16 distinct VD conditions. The performance tasks studied were of two types: foot placement and finger touch. In contrast to our initial prediction, the results showed equal task performance levels and adaptation within about 5 minutes regardless of VD conditions. We found that human adaptation covered a variety of VDs — up to 55 mm in the X, Y direction; up to 125mm in the Z direction; and up to 140mm of interocular distance (IOD). In addition, we found that partial adaptation gave participants the interesting experience of a sense of body structure distortion for a few minutes.",
        "cbStatement": "We investigated whether any differences in visuomotor and adaptation trends exist across 16 distinct VD conditions. The performance tasks studied were of two types: foot placement and finger touch.",
        "bookmarks": 115,
        "keywords": [
            "video see-through",
            "HMD",
            "immersive reality",
            "adaptation",
            "visual displacement",
            "visuomotor",
            "task performance."
        ],
        "communities": [],
        "video": "chi1374-file5.mp4",
        "session": {
            "id": "s235",
            "name": "Gaze"
        },
        "room": "bordeaux",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth27223",
                "givenName": "Joong Ho",
                "familyName": "Lee",
                "email": "022756@kist.re.kr",
                "primary": {
                    "institution": "Korea Institute of Science and Technology (KIST)",
                    "city": "Seoul",
                    "state": "Seoul",
                    "country": "Republic of Korea"
                },
                "role": "presenter"
            },
            {
                "id": "auth29671",
                "givenName": "Sei-young",
                "familyName": "Kim",
                "email": "swsy52@yahoo.com",
                "primary": {
                    "dept": "Interaction and Robotics Research Center",
                    "institution": "Korea Institute of Science and Technology (KIST)",
                    "city": "Seoul",
                    "country": "Republic of Korea"
                }
            },
            {
                "id": "auth29672",
                "givenName": "Hae cheol",
                "familyName": "Yoon",
                "email": "yhchahaha@nate.com",
                "primary": {
                    "dept": "Interaction and Robotics Research Center",
                    "institution": "Korea Institute of Science and Technology (KIST)",
                    "city": "Seoul",
                    "country": "Republic of Korea"
                }
            },
            {
                "id": "auth29587",
                "givenName": "Bo Kyung",
                "familyName": "Huh",
                "email": "t12456@kist.re.kr",
                "primary": {
                    "dept": "Interaction and Robotics Research Center",
                    "institution": "KIST(Korea Institute of Science and Technology)",
                    "city": "Seoul ",
                    "country": "Republic of Korea"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth16828",
                "givenName": "Ji-Hyung",
                "familyName": "Park",
                "email": "jhpark@kist.re.kr",
                "primary": {
                    "institution": "Korea Institute of Science and Technology (KIST)",
                    "city": "Seoul",
                    "state": "Seoul",
                    "country": "Republic of Korea"
                }
            }
        ]
    },
    {
        "id": 190,
        "name": "Improving Two-Thumb Text Entry  on Touchscreen Devices",
        "type": "paper",
        "abstract": "We study the design of split keyboards for fast text entry with two thumbs on mobile touchscreen devices. The layout of KALQ was determined through first studying how users should grip a device with two hands. We then assigned letters to keys computationally, using a model of two-thumb tapping. KALQ minimizes thumb travel distance and maximizes alternation between thumbs. An error correction algorithm was added to help address linguistic and motor errors. Users reached a rate of 37 words per minute (with a 5% error rate) after a training program. ",
        "cbStatement": "We designed a split keyboard to improve two-thumb text entry on tablet devices.  \\ KALQ's design considers grip, coordinated performance of the two thumbs, and linguistic and motor errors.",
        "bookmarks": 46,
        "keywords": [
            "Soft keyboards",
            "keyboard optimization",
            "two-thumb text entry",
            "touchscreen devices",
            "bimanual performance"
        ],
        "communities": [],
        "video": "chi1376-file5.mp4",
        "session": {
            "id": "s254",
            "name": "Mobile keyboard / text entry"
        },
        "room": "241",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth2881",
                "givenName": "Antti",
                "familyName": "Oulasvirta",
                "email": "antti.oulasvirta@mpii.de",
                "primary": {
                    "institution": "Max Planck Institute for Informatics",
                    "city": "Saarbruecken",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth29678",
                "givenName": "Anna",
                "familyName": "Reichel",
                "email": "areichel@mpi-inf.mpg.de",
                "primary": {
                    "dept": "create",
                    "institution": "Max Planck Institute for Informatics",
                    "city": "Saarbrücken",
                    "country": "Germany"
                }
            },
            {
                "id": "auth29679",
                "givenName": "Wenbin",
                "familyName": "Li",
                "email": "wenbinli@mpi-inf.mpg.de",
                "primary": {
                    "dept": "create",
                    "institution": "Max Planck Institute for Informatics",
                    "city": "Saarbrücken",
                    "country": "Germany"
                }
            },
            {
                "id": "auth29680",
                "givenName": "Yan",
                "familyName": "Zhang",
                "email": "rzhang@mpi-inf.mpg.de",
                "primary": {
                    "dept": "create",
                    "institution": "Max Planck Institute for Informatics",
                    "city": "Saarbrücken",
                    "country": "Germany"
                }
            },
            {
                "id": "auth29681",
                "givenName": "Myroslav",
                "familyName": "Bachynskyi",
                "email": "mbachyns@mpi-inf.mpg.de",
                "primary": {
                    "dept": "create",
                    "institution": "Max Planck Institute for Informatics",
                    "city": "Saarbrücken",
                    "country": "Germany"
                }
            },
            {
                "id": "auth9760",
                "givenName": "Keith",
                "familyName": "Vertanen",
                "email": "kvertanen@mtech.edu",
                "primary": {
                    "institution": "Montana Tech of The University of Montana",
                    "city": "Butte",
                    "state": "Montana",
                    "country": "United States"
                }
            },
            {
                "id": "auth3496",
                "givenName": "Per Ola",
                "familyName": "Kristensson",
                "email": "kristensson@gmail.com",
                "primary": {
                    "dept": "School of Computer Science",
                    "institution": "University of St Andrews",
                    "city": "St Andrews",
                    "state": "Fife",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 191,
        "name": "Whoo.ly: Facilitating Information Seeking For Hyperlocal Communities Using Social Media",
        "type": "paper",
        "abstract": "Social media systems promise powerful opportunities for people to connect to timely, relevant information at the hyper local level. Yet, finding the meaningful signal in noisy social media streams can be quite daunting to users. In this paper, we present and evaluate Whoo.ly, a web service that provides neighborhood-specific information based on Twitter posts that were automatically inferred to be hyperlocal. Whoo.ly automatically extracts and summarizes hyperlocal information about events, topics, people, and places from these Twitter posts. We provide an overview of our design goals with Whoo.ly and describe the system including the user interface and our unique event detection and summarization algorithms. We tested the usefulness of the system as a tool for finding neighborhood information through a comprehensive user study. The outcome demonstrated that most participants found Whoo.ly easier to use than Twitter and they would prefer it as a tool for exploring their neighborhoods.",
        "cbStatement": "We present Whoo.ly, an extraction service for hyperlocal information: events, topics, people and places; from neighborhood-specific tweets. We demonstrate that users prefer its use for neighborhood exploration over competing approaches. \\ ",
        "bookmarks": 65,
        "keywords": [
            "Hyperlocal community",
            "Twitter",
            "Social media",
            "Location-based social networks",
            "Civic engagement",
            "Event detection"
        ],
        "communities": [
            "engineering",
            "ux"
        ],
        "video": "chi1380-file5.mp4",
        "session": {
            "id": "s203",
            "name": "Smart City: use social media for and in the public domain"
        },
        "room": "havane",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth30697",
                "givenName": "Yuheng",
                "familyName": "Hu",
                "email": "yuhenghu@asu.edu",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "Arizona State University",
                    "city": "Tempe",
                    "state": "Arizona",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1985",
                "givenName": "Shelly",
                "middleInitial": "D.",
                "familyName": "Farnham",
                "email": "shellyfa@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "FUSE Labs",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth14276",
                "givenName": "Andrés",
                "familyName": "Monroy-Hernández",
                "email": "amh@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 192,
        "name": "Predicting Postpartum Changes in Emotion and Behavior via Social Media",
        "type": "paper",
        "abstract": "We consider social media as a promising tool for public health, focusing on the use of Twitter posts to build predictive models about the forthcoming influence of childbirth on the behavior and mood of new mothers. Using Twitter posts, we quantify postpartum changes in 376 mothers along dimensions of social engagement, emotion, social network, and linguistic style. We then construct statistical models from a training set of observations of these measures before and after the reported childbirth, to forecast significant postpartum changes in mothers. The predictive models can classify mothers who will change significantly following childbirth with an accuracy of 71%, using observations about their prenatal behavior, and as accurately as 80-83% when additionally leveraging the initial 2-3 weeks of postnatal data. The study is motivated by the opportunity to use social media to identify mothers at risk of postpartum depression, an underreported health concern among large populations, and to inform the design of low-cost, privacy-sensitive early-warning systems and intervention programs aimed at promoting wellness postpartum.",
        "cbStatement": "We consider social media as a tool for behavioral health. We focus on how Twitter posts maybe used to build predictive models about the behavior of new mothers following childbirth.",
        "bookmarks": 199,
        "keywords": [
            "behavioral health",
            "childbirth",
            "depression",
            "emotion",
            "health",
            "language",
            "postpartum",
            "PPD",
            "social media",
            "Twitter",
            "wellness"
        ],
        "communities": [
            "health"
        ],
        "video": "chi1404-file5.mp4",
        "session": {
            "id": "s200",
            "name": "Online Sorrows Shared: Online dealing with problems"
        },
        "room": "havane",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth17433",
                "givenName": "Munmun",
                "familyName": "De Choudhury",
                "email": "munmund@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth3178",
                "givenName": "Scott",
                "familyName": "Counts",
                "email": "counts@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth2121",
                "givenName": "Eric",
                "familyName": "Horvitz",
                "email": "horvitz@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 193,
        "name": "\"Shared Joy is Double Joy\": The Social Practices of User Networks Within Group Shopping Sites",
        "type": "paper",
        "abstract": "Group shopping sites are beginning to rise in popularity amongst eCommerce users. Yet we do not know how or why people are using such sites, and whether or not the design of group shopping sites map to the real shopping needs of end users.  To address this, we describe an interview study that investigates the friendship networks of people who participate in group shopping sites  (e.g., Groupon) with the goal of understanding how to best design for these experiences. Our results show that group shopping sites are predominently used to support social activities; that is, users do not use them first and foremost to find ‘deals.’  Instead, group shopping sites are used for planning group activities, extending and building friendships, and constructing one’s social identity. Based on these findings, we suggest improved social network integration and impression management tools to improve user experience within group shopping sites.",
        "cbStatement": "eCommerce has transformed with the emergence of social, apps and mobile. One emerging area is group shopping sites. We investigate these users' routines, sharing networks, purpose and chosen mediums.",
        "bookmarks": 176,
        "keywords": [
            "ecommerce",
            "shopping",
            "group shopping",
            "group buying",
            "impression management",
            "social shopping",
            "social commerce",
            "user interfaces",
            "user-centered design"
        ],
        "communities": [],
        "video": "chi1408-file5.mp4",
        "session": {
            "id": "s267",
            "name": "Shopping and Tagging"
        },
        "room": "241",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth23759",
                "givenName": "Serena",
                "familyName": "Hillman",
                "email": "shillman@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth29726",
                "givenName": "Carman",
                "familyName": "Neustaedter",
                "email": "carman_neustaedter@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth27684",
                "givenName": "Carolyn",
                "familyName": "Pang",
                "email": "carolyn_pang@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            },
            {
                "id": "auth27685",
                "givenName": "Erick",
                "familyName": "Oduor",
                "email": "eoduor@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 194,
        "name": "Design-Driven Narrative: Using Stories to Prototype and Build Immersive Design Worlds",
        "type": "paper",
        "abstract": "This paper examines the role of narrative in the process of interactive experience design, focusing on the potential uses of narrative in prototyping and iteration efforts to uncover deeper and more meaningful responses from users by engaging them in the co-creation of narratives of use around the design. We created a series of narrative fictions with embedded design concepts, and built low-fi prototype artifacts for directed storytelling sessions with twelve participants. We conclude with a discussion of findings regarding the opportunities to more effectively use narrative techniques and immersive storytelling to create valuable experiences between designers and users.",
        "cbStatement": "This paper examines the role of narrative in the process of interactive experience design, focusing on its potential uses in prototyping to uncover deeper and more meaningful user responses.",
        "bookmarks": 54,
        "keywords": [
            "Narrative-driven design",
            "design evaluation",
            "reader-response theory",
            "prototyping",
            "scenario building;"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi1420-file5.mp4",
        "session": {
            "id": "s240",
            "name": "Hedonism, narrative, materiality & Media (This that and the other)"
        },
        "room": "342a",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth29740",
                "givenName": "Eric",
                "familyName": "Spaulding",
                "email": "ixd@att.com",
                "primary": {
                    "institution": "AT&T Foundry",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth17461",
                "givenName": "Haakon",
                "familyName": "Faste",
                "email": "hfaste@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 195,
        "name": "Sublimate: State-Changing Virtual and Physical Rendering to Augment Interaction with Shape Displays",
        "type": "paper",
        "abstract": "Recent research in 3D user interfaces pushes towards immersive graphics and actuated shape displays. Our work explores the hybrid of these directions, and we introduce sublimation and vaporization, as metaphors for the transitions between physical and virtual states. We discuss how digital models, handles and controls can be interacted with as virtual 3D graphics or dynamic physical shapes, and how user interfaces can rapidly and fluidly switch between those representations. To explore this space, we developed systems that integrate actuated shape displays and augmented reality (AR) for co-located physical shapes and 3D graphics. Our spatial optical see-through display provides a single user with head-tracked stereoscopic augmentation, whereas our handheld devices enable multi-user interaction through video see-through AR. We describe interaction techniques and applications that explore 3D interaction for these new modalities. We conclude by discussing the results from a user study that show how free- hand interaction with physical shape displays and co-located graphics can outperform wand-based interaction with virtual 3D graphics.",
        "cbStatement": "Sublimate co-locates spatial 3D visuals with actuated shape displays. We introduce interfaces and applications that combine virtual graphics and physical form, and explores the transitions between those states.",
        "bookmarks": 91,
        "keywords": [
            "Shape Display",
            "Actuated Tangibles",
            "Spatial AR",
            "3D Interaction"
        ],
        "communities": [],
        "video": "chi1424-file5.mp4",
        "session": {
            "id": "s224",
            "name": "Displays and Wearable"
        },
        "room": "352ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth16013",
                "givenName": "Daniel",
                "familyName": "Leithinger",
                "email": "daniell@media.mit.edu",
                "primary": {
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth15323",
                "givenName": "Sean",
                "familyName": "Follmer",
                "email": "sfollmer@media.mit.edu",
                "primary": {
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth4018",
                "givenName": "Alex",
                "familyName": "Olwal",
                "email": "olwal@mit.edu",
                "primary": {
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth29753",
                "givenName": "Samuel",
                "familyName": "Luescher",
                "email": "luescher@media.mit.edu",
                "primary": {
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth29754",
                "givenName": "Akimitsu",
                "familyName": "Hogge",
                "email": "akimitsu@mit.edu",
                "primary": {
                    "dept": "create",
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth15276",
                "givenName": "Jinha",
                "familyName": "Lee",
                "email": "jinhalee@media.mit.edu",
                "primary": {
                    "dept": "MIT",
                    "institution": "Media Lab",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth2008",
                "givenName": "Hiroshi",
                "familyName": "Ishii",
                "email": "ishii@media.mit.edu",
                "primary": {
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 196,
        "name": "Virtual Birding: Extending an Environmental Pastime into the Virtual World for Citizen Science",
        "type": "paper",
        "abstract": "This paper investigates engaging experienced birders, as volunteer citizen scientists, to analyze large recorded audio datasets gathered through environmental acoustic monitoring. Although audio data is straightforward to gather, automated analysis remains a challenging task; the existing expertise, local knowledge and motivation of the birder community can complement computational approaches and provide distinct benefits. We explored both the culture and practice of birders, and paradigms for interacting with recorded audio data. A variety of candidate design elements were tested with birders. \\  \\ This study contributes an understanding of how virtual interactions and practices can be developed to complement existing practices of experienced birders in the physical world. In so doing this study contributes a new approach to engagement in e-science. Whereas most citizen science projects task lay participants with discrete real world or artificial activities, sometimes using extrinsic motivators, this approach builds on existing intrinsically satisfying practices.",
        "cbStatement": "This paper investigates how to engage the experienced birder with local knowledge to extend their hobby online. We explore interaction designs for identifying bird vocalisations in large recorded audio datasets gathered through environmental acoustic monitoring.",
        "bookmarks": 94,
        "keywords": [
            "Citizen science",
            "birder",
            "bird watching",
            "bioacoustics",
            "domain-specific expertise",
            "biodiversity monitoring"
        ],
        "communities": [
            "design",
            "sustainability"
        ],
        "video": "chi1426-file5.mp4",
        "session": {
            "id": "s260",
            "name": "Crowdsource Activism Volunteering Citizen Science"
        },
        "room": "bordeaux",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth28883",
                "givenName": "Mark",
                "familyName": "Cottman-Fields",
                "email": "m.cottman-fields@student.qut.edu.au",
                "primary": {
                    "institution": "Queensland University of Technology",
                    "city": "Brisbane",
                    "state": "Queensland",
                    "country": "Australia"
                },
                "role": "presenter"
            },
            {
                "id": "auth17738",
                "givenName": "Margot",
                "familyName": "Brereton",
                "email": "m.brereton@qut.edu.au",
                "primary": {
                    "institution": "Queensland University of Technology",
                    "city": "Brisbane",
                    "state": "Queensland",
                    "country": "Australia"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30421",
                "givenName": "Paul",
                "familyName": "Roe",
                "email": "p.roe@qut.edu.au",
                "primary": {
                    "institution": "Queensland University of Technology",
                    "city": "Brisbane",
                    "state": "Queensland",
                    "country": "Australia"
                }
            }
        ]
    },
    {
        "id": 197,
        "name": "Interview Approaches to Researching Embodiment",
        "type": "paper",
        "abstract": "The methods of data collection that we choose determine the kinds of data that we have access to, and thus shape analyses. In the context of novel interfaces where different modes, available through the environment and context, mediate the interaction, understanding methodological approaches is critical. This paper examines alternative methods of data collection for exploring student’s embodied interaction with novel technology in a learning context. Specifically it analyses non-facilitated interaction in a tangible learning environment, in conjunction with three different post activity interview approaches: semi-structured interviews; semi-structured interview with video prompted recall; and interviews using the technology itself. Findings suggest that the different interview approaches change the nature of information elicited, and that non-facilitated interaction offers clearer insight into interpretation, both in terms of the meaning that emerges through, and is, therefore, embodied in the interaction, and in terms of representation, directly informing design.",
        "cbStatement": "This paper makes a methodological contribution to child computer interaction. It examines three interview approaches, providing guidance on interview choices to explore communicational modes of interaction in tangible learning environments.",
        "bookmarks": 46,
        "keywords": [
            "Research methods",
            "Interview approaches",
            "Tangible interfaces",
            "Multimodality",
            "Learning "
        ],
        "communities": [
            "cci"
        ],
        "video": "chi1431-file5.mp4",
        "session": {
            "id": "s327",
            "name": "Children"
        },
        "room": "bordeaux",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth10095",
                "givenName": "Sara",
                "familyName": "Price",
                "email": "s.price@ioe.ac.uk",
                "primary": {
                    "dept": "London Knowledge Lab",
                    "institution": "Institute of Education",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth29751",
                "givenName": "Carey",
                "familyName": "Jewitt",
                "email": "c.jewitt@ioe.ac.uk",
                "primary": {
                    "dept": "London Knowledge Lab",
                    "institution": "Institute of Education",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 198,
        "name": "MultiNet: Reducing Interaction Overhead in Domestic Wireless Networks",
        "type": "paper",
        "abstract": "We present MultiNet, a novel method for securely associating devices with a domestic wireless network. We show that MultiNet has usability benefits over currently deployed commercial solutions while being backwards compatible with existing devices. MultiNet reduces the interaction overhead of secure association by focusing on users' interactions rather than the network's requirements. This leads to a novel architectural arrangement of the home network infrastructure: the network is dynamically re-configured to accept each pre-configured device, rather than the current norm where each device is configured to be acceptable to the pre-configured network. Assuming devices are pre-configured for a unique, device-specific network name and passphrase, MultiNet constructs an out-of-band visual channel via an intermediary network controller device to convey the device's configuration to the network. This makes the interaction to join a device to the wireless network lightweight and identical across all devices, considerably reducing the interaction overheads for users.",
        "cbStatement": "A novel method for securely associating devices with domestic wireless networks. Where the interaction is lightweight and consistent across all devices; improving usability, decreasing interaction overhead and enabling access revocation.",
        "bookmarks": 176,
        "keywords": [
            "Usable security",
            "domestic environments",
            "802.11"
        ],
        "communities": [
            "engineering"
        ],
        "video": "chi1435-file5.mp4",
        "authors": [
            {
                "id": "auth29483",
                "givenName": "Anthony",
                "familyName": "Brown",
                "email": "psxab@nottingham.ac.uk",
                "primary": {
                    "dept": "School of Computer Science ",
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "state": "Nottinghamshire",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth24719",
                "givenName": "Richard",
                "familyName": "Mortier",
                "email": "Richard.Mortier@nottingham.ac.uk",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1132",
                "givenName": "Tom",
                "middleInitial": "A",
                "familyName": "Rodden",
                "email": "tar@Cs.Nott.AC.UK",
                "primary": {
                    "dept": "School of Computer Science",
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "state": "Nottinghamshire",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 199,
        "name": "Small, Medium, or Large? Estimating the User-Perceived Scale of Stroke Gestures",
        "type": "paper",
        "abstract": "We show that large consensus exists among users in the way they articulate stroke gestures at various scales (i.e., small, medium, and large), and formulate a simple rule that estimates the user-intended scale of input gestures with 87% accuracy. Our estimator can enhance current gestural interfaces by leveraging scale as a natural parameter for gesture input, reflective of user perception (i.e., no training required). Gesture scale can simplify gesture set design, improve gesture-to-function mappings, and reduce the need for users to learn and for recognizers to discriminate unnecessary symbols.",
        "cbStatement": "We explore scale as parameter for gesture commands. We deliver a training-free, user- and device-independent scale estimator that can be integrated into existing gestural interfaces with three lines of code.",
        "bookmarks": 16,
        "keywords": [
            "Gesture recognition",
            "gesture scale",
            "gesture size",
            "Bayes' rule",
            "gesture articulation",
            "pen gestures",
            "human factors"
        ],
        "communities": [
            "design"
        ],
        "video": "chi1437-file5.mp4",
        "session": {
            "id": "s221",
            "name": "Multitouch and Gestures"
        },
        "room": "352ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth8944",
                "givenName": "Radu-Daniel",
                "familyName": "Vatavu",
                "email": "raduvro@yahoo.com",
                "primary": {
                    "institution": "University Stefan cel Mare of Suceava",
                    "city": "Suceava",
                    "country": "Romania"
                },
                "role": "presenter"
            },
            {
                "id": "auth3033",
                "givenName": "Géry",
                "familyName": "Casiez",
                "email": "gery.casiez@lifl.fr",
                "primary": {
                    "institution": "LIFL & INRIA Lille, University of Lille",
                    "city": "Villeneuve d'Ascq",
                    "country": "France"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth17310",
                "givenName": "Laurent",
                "familyName": "Grisoni",
                "email": "laurent.grisoni@lifl.fr",
                "primary": {
                    "institution": "University Lille",
                    "city": "Lille",
                    "country": "France"
                }
            }
        ]
    },
    {
        "id": 200,
        "name": "LEMtool - Measuring Emotions in Visual Interfaces",
        "type": "paper",
        "abstract": "In this paper the development process and validation of the LEMtool (Layered Emotion Measurement tool) are described. The LEMtool consists of eight images that display a cartoon figure expressing four positive and four negative emotions using facial expressions and body postures. The instrument can be used during interaction with a visual interface, such as a website, and allows participants to select elements of the interface that elicit a certain emotion. The images  of the cartoon figure were submitted to a validation study, in which participants rated the recognizability of the images as specific emotions. All images were found to be recognizable above chance level. In another study, the LEMtool was used to assess visual appeal judgements of a number of web pages. The LEMtool ratings were supported by visual appeal ratings of web pages both for very brief (50 milliseconds) and for long (free-viewing) stimulus exposures. Furthermore, the instrument provided insight into the elements of the web pages that elicited the emotional responses.",
        "cbStatement": "The paper describes the development and validation of the LEMtool: a non-verbal self-report method for indicating emotions during interaction with a visual interface.",
        "bookmarks": 37,
        "keywords": [
            "LEMtool",
            "emotion",
            "user experience",
            "visual appeal",
            "web pages."
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi1438-file5.mp4",
        "session": {
            "id": "s279",
            "name": "Evaluation Methods 1"
        },
        "room": "351",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth26338",
                "givenName": "Gijs",
                "familyName": "Huisman",
                "email": "gijs.huisman@utwente.nl",
                "primary": {
                    "institution": "University of Twente",
                    "city": "Enschede",
                    "country": "The Netherlands"
                },
                "role": "presenter"
            },
            {
                "id": "auth30515",
                "givenName": "Marco",
                "familyName": "Van Hout",
                "email": "marco.vanhout@susagroup.com",
                "primary": {
                    "institution": "SusaGroup",
                    "city": "Enschede",
                    "country": "The Netherlands"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth34736",
                "givenName": "Elisabeth",
                "middleInitial": "M.A.G.",
                "familyName": "van Dijk",
                "email": "e.m.a.g.dijk@utwente.nl",
                "primary": {
                    "institution": "University of Twente",
                    "city": "Enschede",
                    "country": "The Netherlands"
                }
            },
            {
                "id": "auth19068",
                "givenName": "Thea",
                "middleInitial": "M.",
                "familyName": "Van der Geest",
                "email": "t.m.vandergeest@utwente.nl",
                "primary": {
                    "institution": "University of Twente",
                    "city": "Enschede",
                    "country": "The Netherlands"
                }
            },
            {
                "id": "auth34737",
                "givenName": "Dirk",
                "middleInitial": "K.J.",
                "familyName": "Heylen",
                "email": "d.k.j.heylen@utwente.nl",
                "primary": {
                    "institution": "University of Twente",
                    "city": "Enschede",
                    "country": "The Netherlands"
                }
            }
        ]
    },
    {
        "id": 201,
        "name": "My Profile Is My Password, Verify Me! The Privacy/Convenience Tradeoff of Facebook Connect",
        "type": "paper",
        "abstract": "We performed a laboratory experiment to study the privacy tradeoff offered by Facebook Connect: disclosing Facebook profile data to third-party websites for the convenience of logging in without creating separate accounts.  We controlled for trustworthiness and amount of information each website requested, as well as the consent dialog layout.  We discovered that these factors had no observable effects, likely because participants did not read the dialogs.  Yet, 15% still refused to use Facebook Connect, citing privacy concerns.  A likely explanation for subjects ignoring the dialogs while also understanding the privacy tradeoff---our exit survey indicated that 88% broadly understood what data would be collected---is that subjects were already familiar with the dialogs prior to the experiment.  We discuss how our results demonstrate informed consent, but also how habituation prevented subjects from understanding the nuances between individual websites' data collection policies.",
        "cbStatement": "We experimentally measure informed consent across users of Facebook Connect, the most widely-used single sign-on (SSO) implementation, to examine whether users understand they are trading privacy for convenience.",
        "bookmarks": 39,
        "keywords": [
            "Privacy",
            "Facebook Connect",
            "User Study"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi0144-file5.mp4",
        "session": {
            "id": "s276",
            "name": "Authentication"
        },
        "room": "251",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth8172",
                "givenName": "Serge",
                "familyName": "Egelman",
                "email": "egelman@cs.berkeley.edu",
                "primary": {
                    "institution": "University of California, Berkeley",
                    "city": "Berkeley",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 202,
        "name": "StrikeAPose: Revealing Mid-Air Gestures on Public Displays",
        "type": "paper",
        "abstract": "We investigate how to reveal an initial mid-air gesture on interactive public displays. This initial gesture can serve as gesture registration for advanced operations. We propose three strategies to reveal the initial gesture: spatial division, temporal division and integration. Spatial division permanently shows the gesture on a dedicated screen area. Temporal division interrupts the application to reveal the gesture. Integration embeds gesture hints directly in the application. We also propose a novel initial gesture called Teapot to illustrate our strategies. We report on a laboratory and field study. Our main findings are: A large percentage of all users execute the gesture, especially with spatial division (56%). Users intuitively discover a gesture vocabulary by exploring variations of the Teapot gesture by themselves, as well as by imitating and extending other users' variations.",
        "cbStatement": "Proposes three strategies to reveal mid-air gestures on interactive public displays and introduces the Teapot gesture as a novel initial mid-air gesture. Shows that users naturally explore gesture variations.",
        "bookmarks": 1,
        "keywords": [
            "Public Displays",
            "Initial Gesture",
            "Revelation",
            "Field Study"
        ],
        "communities": [],
        "video": "chi1440-file5.mp4",
        "session": {
            "id": "s249",
            "name": "Large and public Displays"
        },
        "room": "241",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth29378",
                "givenName": "Robert",
                "familyName": "Walter",
                "email": "rwalter83@gmail.com",
                "primary": {
                    "dept": "Quality and Usability Lab",
                    "institution": "Telekom Innovation Laboratories, TU Berlin",
                    "city": "Berlin",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth9471",
                "givenName": "Gilles",
                "familyName": "Bailly",
                "email": "gillesbailly1@gmail.com",
                "primary": {
                    "dept": "Quality and Usability Lab",
                    "institution": "Telekom Innovation Laboratories, TU Berlin",
                    "city": "Berlin",
                    "country": "Germany"
                }
            },
            {
                "id": "auth13650",
                "givenName": "Jörg",
                "familyName": "Müller",
                "email": "joerg.mueller@tu-berlin.de",
                "primary": {
                    "institution": "University of the Arts",
                    "city": "Berlin",
                    "country": "Germany"
                },
                "secondary": {
                    "dept": "Quality and Usability Lab",
                    "institution": "Telekom Innovation Laboratories, TU Berlin",
                    "city": "Berlin",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 203,
        "name": "NailDisplay: Bringing an Always Available Visual Display to Fingertips",
        "type": "paper",
        "abstract": "This work presents a novel and always-available nail mounted display known as NailDisplay. The proposed display augments the use of a finger  by allowing for always-available visual feedback owing to its fast accessibility and  binding user controls with the display, i.e. what you control is what you see (through the display). Potential benefits of NailDisplay are demonstrated in three applications: from displaying to combining it with user controls. In the first application, NailDisplay can reveal what is occluded under a finger touch, making it a solution to operate small UI elements. In the second application, NailDisplay is complementary to an imaginary interface,  helping users to learn an imaginary interface (e.g., on the users' arms) and allowing them to reassure the interface when their memory of it becomes unclear. In the third application, NailDisplay is integrated with rich finger interactions, such as swiping in the air. We also report users' feedbacks gathered from an explorative user study. ",
        "cbStatement": "Explores the possibility of turing fingernails into places for system input and visual output by adding a nail-mounted display.",
        "bookmarks": 1,
        "keywords": [
            "Always-available display",
            "Nail-mounted device",
            "Transparent finger"
        ],
        "communities": [
            "design",
            "engineering",
            "ux"
        ],
        "video": "chi1451-file5.mp4",
        "session": {
            "id": "s224",
            "name": "Displays and Wearable"
        },
        "room": "352ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth22269",
                "givenName": "Chao-Huai",
                "familyName": "Su",
                "email": "domossu@gmail.com",
                "primary": {
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                },
                "role": "presenter"
            },
            {
                "id": "auth19308",
                "givenName": "Liwei",
                "familyName": "Chan",
                "email": "liwei.name@gmail.com",
                "primary": {
                    "dept": "Research Center for Information Technology Innovation (CITI)",
                    "institution": "Academia Sinica",
                    "city": "Taipei",
                    "state": "Taiwan",
                    "country": "Taiwan"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth27450",
                "givenName": "Chien-Ting",
                "familyName": "Weng",
                "email": "ctweng@cmlab.csie.ntu.edu.tw",
                "primary": {
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                }
            },
            {
                "id": "auth16958",
                "givenName": "Rong-Hao",
                "familyName": "Liang",
                "email": "howieliang@cmlab.csie.ntu.edu.tw",
                "primary": {
                    "institution": "Academia Sinica",
                    "city": "Taipei",
                    "country": "Taiwan"
                }
            },
            {
                "id": "auth11521",
                "givenName": "Kai-Yin",
                "familyName": "Cheng",
                "email": "keynes@cmlab.csie.ntu.edu.tw",
                "primary": {
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                }
            },
            {
                "id": "auth11664",
                "givenName": "Bing-Yu",
                "familyName": "Chen",
                "email": "robin@ntu.edu.tw",
                "primary": {
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                }
            }
        ]
    },
    {
        "id": 204,
        "name": "Form Digitization in BPO: From Outsourcing to Crowdsourcing?",
        "type": "paper",
        "abstract": "This paper describes an ethnographic study of an outsourced business process – the digitization of healthcare forms. The aim of the study was to understand how the work is currently organized, with an eye to uncovering the research challenges which need to be addressed if that work is to be crowdsourced. The findings are organised under four emergent themes: Workplace Ecology, Data Entry Skills and Knowledge, Achieving Targets and Collaborative Working. For each theme a description of how the work is undertaken in the outsourcer’s Indian office locations is given, followed by the implications for crowdsourcing that work. This research is a first step in understanding how crowdsourcing might be applied to BPO activities. The paper examines features specific to form digitization – extreme distribution and form decomposition – and lightly touches on the crowdsourcing of BPO work more generally.",
        "cbStatement": "This work describes findings from an ethnographic study of an outsourced business process for “form digitization”. It is a first step to how crowdsourcing might be applied to business processes.",
        "bookmarks": 93,
        "keywords": [
            "Crowdsourcing",
            "Ethnography",
            "Business Process",
            "Outsourcing"
        ],
        "communities": [
            "hci4d"
        ],
        "video": "chi1454-file5.mp4",
        "session": {
            "id": "s209",
            "name": "Power to the People: utalizing crowdsourcing"
        },
        "room": "241",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth4330",
                "givenName": "Jacki",
                "familyName": "O'Neill",
                "email": "jacki.oneill@xrce.xerox.com",
                "primary": {
                    "dept": "Xerox Innovation Group",
                    "institution": "Xerox Research Centre Europe",
                    "city": "Grenoble",
                    "country": "France"
                },
                "role": "presenter"
            },
            {
                "id": "auth29764",
                "givenName": "Shourya",
                "familyName": "Roy",
                "email": "shourya.roy@xerox.com",
                "primary": {
                    "dept": "Xerox Innovation Group",
                    "institution": "Xerox Research Centre India",
                    "city": "Bangalore",
                    "state": "Karnataka",
                    "country": "India"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1517",
                "givenName": "Antonietta",
                "familyName": "Grasso",
                "email": "grasso@xrce.xerox.com",
                "primary": {
                    "dept": "Xerox Research Centre Europe",
                    "institution": "Xerox Innovation Group",
                    "city": "Grenoble",
                    "country": "France"
                }
            },
            {
                "id": "auth11252",
                "givenName": "David",
                "middleInitial": "B",
                "familyName": "Martin",
                "email": "david.martin@xrce.xerox.com",
                "primary": {
                    "institution": "Xerox Research Center Europe",
                    "city": "Meylan",
                    "state": "Isere",
                    "country": "France"
                }
            }
        ]
    },
    {
        "id": 205,
        "name": "Warping Time for More Effective Real-Time Crowdsourcing",
        "type": "paper",
        "abstract": "  In this paper, we introduce the idea of ''warping time'' to improve \\   crowd performance on the difficult task of captioning speech in \\   real-time.  Prior work has shown that the crowd can collectively \\   caption speech in real-time by merging the partial results of \\   multiple workers.  Because non-expert workers cannot keep up with \\   natural speaking rates, the task is frustrating and prone to errors \\   as workers buffer what they hear to type later.  The TimeWarp \\   approach automatically increases and decreases the speed of speech \\   playback systematically across individual workers who caption only \\   the periods played at reduced speed. Studies with 139 remote crowd \\   workers and 24 local participants show that this approach improves \\   median coverage (14.8%), precision (11.2%), and per-word latency \\   (19.1%). Warping time may also help crowds outperform individuals on \\   other difficult real-time performance tasks.",
        "cbStatement": "We present TimeWarp, a crowdsourcing approach that allows workers to individually complete continuous tasks that involve streaming media at reduced speeds, while the crowd can collectively keep up with real-time.",
        "bookmarks": 105,
        "keywords": [
            "Real-Time Crowdsourcing",
            "Human Computation",
            "Captioning"
        ],
        "communities": [
            "design",
            "engineering",
            "management"
        ],
        "video": "chi1460-file5.mp4",
        "session": {
            "id": "s210",
            "name": "Creative Source Unitied: Crowdsourcing used in colaborative creation"
        },
        "room": "bordeaux",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth21848",
                "givenName": "Walter",
                "middleInitial": "S.",
                "familyName": "Lasecki",
                "email": "wlasecki@cs.rochester.edu",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "University of Rochester",
                    "city": "Rochester",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth27451",
                "givenName": "Christopher",
                "middleInitial": "D.",
                "familyName": "Miller",
                "email": "c.miller@rochester.edu",
                "primary": {
                    "institution": "University of Rochester",
                    "city": "Rochester",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth8964",
                "givenName": "Jeffrey",
                "middleInitial": "P.",
                "familyName": "Bigham",
                "email": "jbigham@cs.rochester.edu",
                "primary": {
                    "institution": "University of Rochester",
                    "city": "Rochester",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 206,
        "name": "Can We Beat the Mouse with MAGIC?",
        "type": "paper",
        "abstract": "MAGIC pointing techniques combine eye tracking with manual input. Since the mouse performs exceptionally well in a desktop setting, previous research on MAGIC pointing either resulted in minor improvements, or the techniques were applied to alternative devices or environments. We design Animated MAGIC, a novel, target-agnostic MAGIC pointing technique, for the specific goal of beating the mouse in a desktop setting. To improve the eye-tracking accuracy, we develop a dynamic local calibration method that uses each selection as a local calibration point. We compare Animated MAGIC to mouse-only and Conservative MAGIC, one of the two original MAGIC pointing methods, in a Fitts' Law experiment. We conduct a user questionnaire to evaluate the usability of the interaction methods. Results suggest that Dynamic Local Calibration improves eye-tracking accuracy and, consequently, MAGIC pointing performance. Powered with Dynamic Local Calibration, Animated MAGIC outperformed mouse-only by 8% in terms of throughput. Both MAGIC pointing methods reduced the amount of hand movement by more than half.",
        "cbStatement": "Animated MAGIC is a novel interaction method that improves the throughput of the mouse by incorporating eye-tracking as a complementary input.",
        "bookmarks": 170,
        "keywords": [
            "Input",
            "mouse",
            "MAGIC",
            "animated",
            "eye",
            "tracking",
            "multimodal",
            "Fitts",
            "Law",
            "gaze",
            "interaction",
            "dynamic",
            "local",
            "calibration"
        ],
        "communities": [
            "design",
            "ux",
            "games"
        ],
        "video": "chi1465-file5.mp4",
        "session": {
            "id": "s252",
            "name": "Pointing and Fitts Law"
        },
        "room": "241",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth25886",
                "givenName": "Ribel",
                "familyName": "Fares",
                "email": "rf1190@txstate.edu",
                "primary": {
                    "institution": "Texas State University",
                    "city": "San Marcos",
                    "state": "Texas",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth29784",
                "givenName": "Shaomin",
                "familyName": "Fang",
                "email": "s_f5@txstate.edu",
                "primary": {
                    "institution": "Texas State University",
                    "city": "San Marcos",
                    "state": "Texas",
                    "country": "United States"
                }
            },
            {
                "id": "auth9468",
                "givenName": "Oleg",
                "middleInitial": "V",
                "familyName": "Komogortsev",
                "email": "ok11@txstate.edu",
                "primary": {
                    "institution": "Texas State University",
                    "city": "San Marcos",
                    "state": "Texas",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 207,
        "name": "Talking about Tactile Experiences",
        "type": "paper",
        "abstract": "A common problem with designing and developing applications with tactile interfaces is the lack of a vocabulary that allows one to describe or communicate about haptics. Here we present the findings from a study exploring participants’ verbalizations of their tactile experiences across two modulated tactile stimuli (16Hz and 250Hz) related to two important mechanoreceptors in the human hand. The study, with 14 participants, applied the explicitation interview technique to capture detailed descriptions of the diachronic and synchronic structure of tactile experiences. We propose 14 categories for a human-experiential vocabulary based on the categorization of the findings and tie them back to neurophysiological and psychophysical data on the human hand. We finally discuss design opportunities created through this experiential understanding in relation to the two mechanoreceptors.",
        "cbStatement": "A common problem with designing applications with tactile interfaces is the lack of a vocabulary that allows one to communicate about haptics. We present a human-experiential vocabulary for tactile experiences.",
        "bookmarks": 16,
        "keywords": [
            "Tactile experiences",
            "human-experiential vocabulary",
            "user study",
            "mechanoreceptors",
            "human hand",
            "non-contact haptic system",
            "ultrasound",
            "explicitation interview technique."
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi0147-file5.mp4",
        "session": {
            "id": "s228",
            "name": "Tactile Presentation Theory"
        },
        "room": "blue",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth7742",
                "givenName": "Marianna",
                "familyName": "Obrist",
                "email": "marianna.obrist@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth29769",
                "givenName": "Sue Ann",
                "familyName": "Seah",
                "email": "S.A.Seah@bristol.ac.uk",
                "primary": {
                    "institution": "University of Bristol",
                    "city": "Bristol",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth2491",
                "givenName": "Sriram",
                "familyName": "Subramanian",
                "email": "sriram@cs.bris.ac.uk",
                "primary": {
                    "institution": "University of Bristol",
                    "city": "Bristol",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 208,
        "name": "Design Metaphors for Procedural Content Generation in Games",
        "type": "paper",
        "abstract": "Procedural content generation (PCG), the algorithmic creation of game content with limited or indirect user input, has much to offer to game design. In recent years, it has become a mainstay of game AI, with significant research being put towards the investigation of new PCG systems, algorithms, and techniques. But for PCG to be absorbed into the practice of game design, it must be contextualised within design-centric as opposed to AI or engineering perspectives. We therefore provide a set of design metaphors for understanding potential relationships between a designer and PCG. These metaphors are:  tool, material, designer, and domain expert. By examining PCG through these metaphors, we gain the ability to articulate qualities, consequences, affordances, and limitations of existing PCG approaches in relation to design. These metaphors are intended both to aid designers in understanding and appropriating PCG for their own contexts, and to advance PCG research by highlighting the assumptions implicit in existing systems and discourse.",
        "cbStatement": "We present procedural content generation (PCG) design metaphors that help designers understand and appropriate PCG, and advance research by highlighting assumptions implicit in existing systems and discourse.",
        "bookmarks": 177,
        "keywords": [
            "Game Design",
            "Metaphor",
            "Game AI",
            "Procedural Content Generation",
            "Adaptive Games"
        ],
        "communities": [
            "design",
            "games"
        ],
        "video": "chi1477-file5.mp4",
        "session": {
            "id": "s282",
            "name": "Game Design"
        },
        "room": "251",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth29789",
                "givenName": "Rilla",
                "familyName": "Khaled",
                "email": "rilla.khaled@um.edu.mt",
                "primary": {
                    "dept": "Department of Digital Games",
                    "institution": "University of Malta",
                    "city": "Msida",
                    "country": "Malta"
                },
                "role": "presenter"
            },
            {
                "id": "auth29786",
                "givenName": "Mark",
                "middleInitial": "J.",
                "familyName": "Nelson",
                "email": "mjas@itu.dk",
                "primary": {
                    "dept": "Center for Computer Games Research",
                    "institution": "IT University of Copenhagen",
                    "city": "Copenhagen",
                    "country": "Denmark"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth12045",
                "givenName": "Pippin",
                "familyName": "Barr",
                "email": "pippin.barr@gmail.com",
                "primary": {
                    "dept": "Department of Digital Games",
                    "institution": "University of Malta",
                    "city": "Msida",
                    "country": "Malta"
                }
            }
        ]
    },
    {
        "id": 209,
        "name": "GaussBits: Magnetic Tangible Bits for Portable and Occlusion-Free Near-Surface Interactions",
        "type": "paper",
        "abstract": "We present GaussBits, which is a system of the passive magnetic tangible designs that enables 3D tangible interactions in the near-surface space of portable displays. When a thin magnetic sensor grid is attached to the back of the display, the 3D position and partial 3D orientation of the GaussBits can be resolved by the proposed bi-polar magnetic field tracking technique. This portable platform can therefore enrich tangible interactions by extending the design space to the near-surface space. Since non-ferrous materials, such as the user's hand, do not occlude the magnetic field, interaction designers can freely incorporate a magnetic unit into an appropriately shaped non-ferrous object to exploit the metaphors of the real-world tasks, and users can freely manipulate the GaussBits by hands or using other non-ferrous tools without causing interference. The presented example applications and the collected feedback from an explorative workshop revealed that this new approach is widely applicable.",
        "cbStatement": "This work presents a system of the passive magnetic tangible designs that enables occlusion-free tangible interactions in the near-surface space of portable displays.",
        "bookmarks": 188,
        "keywords": [
            "Near-Surface Tracking",
            "Portable",
            "Occlusion-Free",
            "Magnetism",
            "Tangible Interactions"
        ],
        "communities": [
            "design",
            "engineering"
        ],
        "video": "chi1479-file5.mp4",
        "session": {
            "id": "s225",
            "name": "Touch, Tangibles, Touch Sensor"
        },
        "room": "352ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth16958",
                "givenName": "Rong-Hao",
                "familyName": "Liang",
                "email": "howieliang@cmlab.csie.ntu.edu.tw",
                "primary": {
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                },
                "secondary": {
                    "institution": "Academia Sinica",
                    "city": "Taipei",
                    "country": "Taiwan"
                },
                "role": "presenter"
            },
            {
                "id": "auth28194",
                "givenName": "Kai-Yin",
                "familyName": "Cheng",
                "email": "keynes.z@gmail.com",
                "primary": {
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                }
            },
            {
                "id": "auth19308",
                "givenName": "Liwei",
                "familyName": "Chan",
                "email": "liwei.name@gmail.com",
                "primary": {
                    "institution": "Academia Sinica",
                    "city": "Taipei",
                    "country": "Taiwan"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth33279",
                "givenName": "Chuan-Xhyuan",
                "familyName": "Peng",
                "email": "M10010206@mail.ntust.edu.tw",
                "primary": {
                    "institution": "National Taiwan University of Science and Technology",
                    "city": "Taipei",
                    "country": "Taiwan"
                }
            },
            {
                "id": "auth6300",
                "givenName": "Mike",
                "middleInitial": "Y.",
                "familyName": "Chen",
                "email": "mikechen@csie.ntu.edu.tw",
                "primary": {
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                }
            },
            {
                "id": "auth16790",
                "givenName": "Rung-Huei",
                "familyName": "Liang",
                "email": "liang@mail.ntust.edu.tw",
                "primary": {
                    "institution": "National Taiwan University of Science and Technology",
                    "city": "Taipei",
                    "country": "Taiwan"
                }
            },
            {
                "id": "auth17016",
                "givenName": "De-Nian",
                "familyName": "Yang",
                "email": "dnyang@iis.sinica.edu.tw",
                "primary": {
                    "institution": "Academia Sinica",
                    "city": "Taipei",
                    "country": "Taiwan"
                }
            },
            {
                "id": "auth11664",
                "givenName": "Bing-Yu",
                "familyName": "Chen",
                "email": "robin@ntu.edu.tw",
                "primary": {
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                }
            }
        ]
    },
    {
        "id": 210,
        "name": "HomeProxy: Exploring a Physical Proxy for Video Communication in the Home",
        "type": "paper",
        "abstract": "HomeProxy is a research prototype that explores supporting video communication in the home among distributed family members through a physical proxy. It leverages a physical artifact dedicated to representing remote family members to make it easier to share activities with them. HomeProxy combines a form factor designed for the home environment with a “no-touch” user experience and an interface that responsively transitions between recorded and live video messages. We designed and implemented a prototype and conducted a pilot study with eight pairs of users. Our study demonstrated the challenges of a no-touch interface and the promise of offering quick video messaging in the home. ",
        "cbStatement": "HomeProxy is a prototype system that supports video messaging in the home. It explores a “no-touch” user experience that allows transitioning from recorded to live video messages. ",
        "bookmarks": 152,
        "keywords": [
            "Video chat",
            "home",
            "physical proxies",
            "asynchronous video"
        ],
        "communities": [
            "design",
            "ux",
            "cci"
        ],
        "video": "chi0148-file5.mp4",
        "session": {
            "id": "s215",
            "name": "Design for the Home"
        },
        "room": "242ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth1108",
                "givenName": "John",
                "middleInitial": "C.",
                "familyName": "Tang",
                "email": "johntang@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth27250",
                "givenName": "Robert",
                "familyName": "Xiao",
                "email": "brx@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth17148",
                "givenName": "Aaron",
                "familyName": "Hoff",
                "email": "aaronho@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth2115",
                "givenName": "Gina",
                "familyName": "Venolia",
                "email": "ginav@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth28791",
                "givenName": "Patrick",
                "familyName": "Therien",
                "email": "patherie@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth16421",
                "givenName": "Asta",
                "familyName": "Roseway",
                "email": "astar@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 211,
        "name": "TypeRighting: Combining the Benefits of Handwriting and Typeface in Online Educational Videos",
        "type": "paper",
        "abstract": "Recent years have seen enormous growth of online educational videos, spanning K-12 tutorials to university lectures. As this content has grown, so too has grown the number of presentation styles.  Some educators have strong allegiance to handwritten recordings (using pen and tablet), while others use only typed (PowerPoint) presentations. In this paper, we present the first systematic comparison of these two presentation styles and how they are perceived by viewers. Surveys on edX and Mechanical Turk suggest that users enjoy handwriting because it is personal and engaging, yet they also enjoy typeface because it is clear and legible. Based on these observations, we propose a new presentation style, TypeRighting, that combines the benefits of handwriting and typeface. Each phrase is written by hand, but fades into typeface soon after it appears. Our surveys suggest that about 80% of respondents prefer TypeRighting over handwriting. The same fraction of respondents prefer TypeRighting over typeface, for videos in which the handwriting is sufficiently legible.",
        "cbStatement": "Examines viewers’ preferences of presentation styles for online educational videos and presents a novel way to combine the benefits of handwriting and typeface called TypeRighting.",
        "bookmarks": 150,
        "keywords": [
            "Online education",
            "massive open online course",
            "handwriting"
        ],
        "communities": [
            "hci4d"
        ],
        "video": "chi1483-file5.mp4",
        "session": {
            "id": "s250",
            "name": "Beyond Desktop Interaction"
        },
        "room": "242a",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth28407",
                "givenName": "Andrew",
                "familyName": "Cross",
                "email": "t-across@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research India",
                    "city": "Bangalore",
                    "state": "Karnataka",
                    "country": "India"
                },
                "role": "presenter"
            },
            {
                "id": "auth27694",
                "givenName": "Mydhili",
                "familyName": "Bayyapunedi",
                "email": "mydhilib@gmail.com",
                "primary": {
                    "institution": "Microsoft Research India",
                    "city": "Bangalore",
                    "state": "Karnataka",
                    "country": "India"
                }
            },
            {
                "id": "auth1287",
                "givenName": "Edward",
                "familyName": "Cutrell",
                "email": "cutrell@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research India",
                    "city": "Bangalore",
                    "state": "Karnataka",
                    "country": "India"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth34808",
                "givenName": "Anant",
                "familyName": "Agarwal",
                "email": "agarwal@edx.org",
                "primary": {
                    "institution": "edX",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth14161",
                "givenName": "William",
                "familyName": "Thies",
                "email": "thies@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research India",
                    "city": "Bangalore",
                    "state": "Karnataka",
                    "country": "India"
                }
            }
        ]
    },
    {
        "id": 212,
        "name": "LaserOrigami: Laser-Cutting 3D Objects",
        "type": "paper",
        "abstract": "We present LaserOrigami, a rapid prototyping system that produces 3D objects using a laser cutter. Laser¬Origami is substantially faster than traditional 3D fabrication techniques such as 3D printing and unlike traditional laser cutting the resulting 3D objects require no manual assembly. The key idea behind LaserOrigami is that it achieves three-dimensionality by folding and stretching the workpiece, rather than by placing joints, thereby eliminating the need for manual assembly. Laser¬Origami achieves this by heating up selected regions of the workpiece until they become compliant and bend down under the force of gravity. LaserOrigami administers the heat by defocusing the laser, which distributes the laser’s power across a larger surface. LaserOrigami implements cutting and bending in a single integrated process by automatically moving the cutting table up and down—when users take out the workpiece, it is already fully assembled. We present the three main design elements of Laser¬Origami: the bend, the suspender, and the stretch, and demonstrate how to use them to fabricate a range of physical objects. Finally, we demonstrate an interactive fabrication version of Laser¬Origami, a process in which user interaction and fabrication alternate step-by-step.",
        "cbStatement": "LaserOrigami is a rapid prototyping system that produces 3D objects using a laser cutter. LaserOrigami is substantially faster than 3D-printing and unlike traditional laser cutting it requires no manual assembly.",
        "bookmarks": 1,
        "keywords": [
            "rapid prototyping",
            "laser cutting",
            "interactive fabrication",
            "3D",
            "physical prototyping"
        ],
        "communities": [
            "engineering"
        ],
        "video": "chi0149-file5.mp4",
        "session": {
            "id": "s227",
            "name": "Fabrication"
        },
        "room": "352ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth21882",
                "givenName": "Stefanie",
                "familyName": "Mueller",
                "email": "stefanie.mueller@student.hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth29791",
                "givenName": "Bastian",
                "familyName": "Kruck",
                "email": "bastian.kruck@student.hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                }
            },
            {
                "id": "auth1437",
                "givenName": "Patrick",
                "familyName": "Baudisch",
                "email": "patrick.baudisch@hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 213,
        "name": "How Categories Come to Matter",
        "type": "paper",
        "abstract": "In a study of users' interactions with Siri, the iPhone personal assistant application, we noticed the emergence of overlaps and blurrings between explanatory categories such as “human” and “machine.” We found that users work to purify these categories, thus resolving the tensions related to the overlaps. This \"purification work\" demonstrates how such categories are always in flux and are redrawn even as they are kept separate. Drawing on STS analytic techniques, we demonstrate the mechanisms of such \"purification work.\" We also describe how such category work remained invisible to us during initial data analysis, due to our own forms of latent purification, and outline the particular analytic techniques that helped lead to this discovery. We thus provide an illustrative case of how categories come to matter in HCI research and design.",
        "cbStatement": "We present and discuss interviews with Siri users as a means to understand the role categories play in the design of user studies and of technologies. ",
        "bookmarks": 118,
        "keywords": [
            "Diffractive analysis",
            "category flux",
            "materiality for design."
        ],
        "communities": [
            "design"
        ],
        "session": {
            "id": "s272",
            "name": "Different Perspectives"
        },
        "room": "241",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth9106",
                "givenName": "Lucian",
                "familyName": "Leahu",
                "email": "lleahu@cs.cornell.edu",
                "primary": {
                    "institution": "Mobile Life @ SICS",
                    "city": "Stockholm",
                    "country": "Sweden"
                },
                "role": "presenter"
            },
            {
                "id": "auth15576",
                "givenName": "Marisa",
                "middleInitial": "Leavitt",
                "familyName": "Cohn",
                "email": "mlcohn@ics.uci.edu",
                "primary": {
                    "institution": "University of California, Irvine",
                    "city": "Irvine",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth3834",
                "givenName": "Wendy",
                "familyName": "March",
                "email": "wendy.march@intel.com",
                "primary": {
                    "institution": "Intel Labs",
                    "city": "Portland",
                    "state": "Oregon",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 214,
        "name": "Social Media and the Police—Tweeting Practices of British Police Forces during the August 2011 Riots",
        "type": "paper",
        "abstract": "With this paper we take a first step to understand the appropriation of social media by the police. For this purpose we analyzed the Twitter communication by the London Metropolitan Police (MET) and the Greater Manchester Police (GMP) during the riots in August 2011. The systematic comparison of tweets demonstrates that the two forces developed very different practices for using Twitter. While MET followed an instrumental approach in their communication, in which the police aimed to remain in a controlled position and keep a distance to the general public, GMP developed an expressive approach, in which the police actively decreased the distance to the citizens. In workshops and interviews, we asked the police officers about their perspectives, which confirmed the identified practices. Our study discusses benefits and risks of the two approaches and the potential impact of social media on the evolution of the role of police in society.",
        "cbStatement": "Analyzes the Twitter use by the London Metropolitan and the Greater Manchester Police during the riots in August 2011. Shows that the forces developed very different practices to appropriate Twitter.",
        "bookmarks": 109,
        "keywords": [
            "Police",
            "Twitter",
            "UK Riots",
            "Crisis Communication",
            "Microblogging"
        ],
        "communities": [],
        "video": "chi1498-file5.mp4",
        "session": {
            "id": "s203",
            "name": "Smart City: use social media for and in the public domain"
        },
        "room": "havane",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth10643",
                "givenName": "Sebastian",
                "familyName": "Denef",
                "email": "sebastian.denef@fit.fraunhofer.de",
                "primary": {
                    "institution": "Fraunhofer Institute for Applied Information Technology (FIT)",
                    "city": "Sankt Augustin",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth22323",
                "givenName": "Petra",
                "middleInitial": "S.",
                "familyName": "Bayerl",
                "email": "pbayerl@rsm.nl",
                "primary": {
                    "dept": "School of Management",
                    "institution": "Erasmus University Rotterdam",
                    "city": "Rotterdam",
                    "country": "Netherlands"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth34621",
                "givenName": "Nico",
                "middleInitial": "A.",
                "familyName": "Kaptein",
                "email": "n.kaptein@cot.nl",
                "primary": {
                    "institution": "COT Institute for Safety, Security and Crisis Management",
                    "city": "Den Haag",
                    "country": "Netherlands"
                }
            }
        ]
    },
    {
        "id": 215,
        "name": "The Effect of Virtual Achievements on Student Engagement",
        "type": "paper",
        "abstract": "Badge-based achievement systems are being used increasingly to drive user participation and engagement across a variety of platforms and contexts.  Despite positive anecdotal reports, there is currently little empirical evidence to support their efficacy in particular domains.  With the recent rapid growth of tools for online learning, an interesting open question for educators is the extent to which badges can positively impact student participation. \\  \\ In this paper, we report on a large-scale (n > 1000) randomized, controlled experiment measuring the impact of incorporating a badge-based achievement system within an online learning tool.  We discover a highly significant positive effect on the quantity of students' contributions, without a corresponding reduction in their quality, as well as on the period of time over which students engaged with the tool. Students enjoyed being able to earn badges, and indicated a strong preference for having them available in the user interface.",
        "cbStatement": "Do badge-based achievement systems actually engage users?  We present the first large-scale study providing empirical evidence of their impact within an online learning tool. \\ ",
        "bookmarks": 9,
        "keywords": [
            "Badges",
            "achievements",
            "gamification",
            "PeerWise",
            "education",
            "online learning"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi1499-file5.mp4",
        "session": {
            "id": "s286",
            "name": "Design for the Classroom"
        },
        "room": "251",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth29544",
                "givenName": "Paul",
                "familyName": "Denny",
                "email": "paul@cs.auckland.ac.nz",
                "primary": {
                    "institution": "The University of Auckland",
                    "state": "Auckland",
                    "country": "New Zealand"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 216,
        "name": "Emotions, Experiences and Usability in Real-Life Mobile Phone Use",
        "type": "paper",
        "abstract": "Positive emotional experiences with an interactive product are assumed to lead to good user experience and, ultimately, to product success. However, the path from emotional experiences to product evaluation may not be direct, as emotions fluctuate over time, and some experiences are easier to recall than others. In this study, we examined emotions and experience episodes during real-life mobile phone use over a five-month period. The goal is to understand how emotions and memories are related to overall evaluation of a product: usability, user experience and behavioral intentions. The results show that both emotions and how people remember them had strong unique roles in the overall evaluation of the product. Positive emotions were mostly related to good user experience and negative emotions to low usability. In the early stages of use, users overestimated their positive emotions and seemed to focus on user experience, the importance of usability increased over time.",
        "cbStatement": "Longitudinal study investigating emotions over a five-month period of product use. Clarifies the role of emotions in usability, user experience and product success and helps in designing for user experience.",
        "bookmarks": 89,
        "keywords": [
            "User experience",
            "usability",
            "emotions",
            "memories",
            "word of mouth",
            "user satisfaction",
            "day reconstruction method",
            "mobile phone"
        ],
        "communities": [
            "design",
            "management",
            "ux"
        ],
        "video": "chi1506-file5.mp4",
        "session": {
            "id": "s241",
            "name": "Mobile 1: Mobile Phones: pricing, Emotions, looks, and positioning"
        },
        "room": "241",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth9099",
                "givenName": "Sari",
                "familyName": "Kujala",
                "email": "sari.kujala@aalto.fi",
                "primary": {
                    "institution": "Aalto University",
                    "city": "Helsinki",
                    "country": "Finland"
                },
                "secondary": {
                    "institution": "Tampere University of Technology",
                    "city": "Tampere",
                    "country": "Finland"
                },
                "role": "presenter"
            },
            {
                "id": "auth29823",
                "givenName": "Talya",
                "familyName": "Miron-Shatz",
                "email": "talyam@wharton.upenn.edu",
                "primary": {
                    "dept": "Business School",
                    "institution": "Ono Academic College",
                    "city": "Kiryat Ono",
                    "country": "Israel"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 217,
        "name": "An Evaluation of State Switching Methods for Indirect Touch Systems",
        "type": "paper",
        "abstract": "Indirect touch systems combine a horizontal touch input surface with a vertical display for output. While this division is ergonomically superior to simple direct-touch displays for many tasks, users are no longer looking at their hands when touching. This requires the system to support an intermediate “tracking” state that lets users aim at objects without trigger- ing a selection, similar to the hover state in mouse-based UIs. We present an empirical analysis of several interaction techniques for indirect touch systems to switch to this intermediate state, and derive design recommendations for incorporat- ing it into such systems.",
        "cbStatement": "Comparing four different state switching techniques for indirect touch systems that allow the users to rest their arms on the surfaces while they are in the Tracking state.",
        "bookmarks": 123,
        "keywords": [
            "indirect-touch",
            "three-state model"
        ],
        "communities": [],
        "video": "chi0153-file5.m4v",
        "session": {
            "id": "s223",
            "name": "Table and Floors"
        },
        "room": "352ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth21405",
                "givenName": "Simon",
                "familyName": "Voelker",
                "email": "voelker@cs.rwth-aachen.de",
                "primary": {
                    "institution": "RWTH Aachen University",
                    "city": "Aachen",
                    "state": "NRW",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth16712",
                "givenName": "Chat",
                "familyName": "Wacharamanotham",
                "email": "chat@cs.rwth-aachen.de",
                "primary": {
                    "institution": "RWTH Aachen University",
                    "city": "Aachen",
                    "state": "NRW",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1497",
                "givenName": "Jan",
                "familyName": "Borchers",
                "email": "borchers@cs.rwth-aachen.de",
                "primary": {
                    "institution": "RWTH Aachen University",
                    "city": "Aachen",
                    "state": "NRW",
                    "country": "Germany"
                }
            }
        ]
    },
    {
        "id": 218,
        "name": "Designing and Theorizing Co-Located Interactions",
        "type": "paper",
        "abstract": "This paper gives an interwoven account of the theoretical and practical work we undertook in pursuit of designing co-located interactions. We show how we sensitized ourselves to theory from diverse intellectual disciplines, to develop an analytical lens to better think about co-located interactions. By critiquing current systems and their conceptual foundations, and further interrelating theories particularly in regard to performative aspects of identity and communication, we develop a more nuanced way of thinking about co-located interactions. Drawing on our sensitivities, we show how we generated and are exploring, through the process of design, a set of co-located interactions that are situated within our social ecologies, and contend that our upfront theoretical work enabled us to identify and explore this space in the first place. This highlights the importance of problem framing, especially for projects adopting design methodologies. ",
        "cbStatement": "This paper gives an interwoven account of the theoretical and practical work we undertook in pursuit of designing co-located interactions on mobile devices.",
        "bookmarks": 142,
        "keywords": [
            "co-located interaction",
            "co-presence",
            "design research",
            "theory"
        ],
        "communities": [
            "design"
        ],
        "video": "chi1532-file5.mp4",
        "session": {
            "id": "s206",
            "name": "Colaborative Technology: I share, you share, we share"
        },
        "room": "havane",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth13854",
                "givenName": "Thomas",
                "familyName": "Reitmaier",
                "email": "treitmaier@googlemail.com",
                "primary": {
                    "institution": "University of Cape Town",
                    "city": "Cape Town",
                    "country": "South Africa"
                },
                "role": "presenter"
            },
            {
                "id": "auth29866",
                "givenName": "Pierre",
                "familyName": "Benz",
                "email": "benz.pierre@gmail.com",
                "primary": {
                    "institution": "University of Cape Town",
                    "city": "Cape Town",
                    "country": "South Africa"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth3025",
                "givenName": "Gary",
                "familyName": "Marsden",
                "email": "gaz@cs.uct.ac.za",
                "primary": {
                    "institution": "University of Cape Town",
                    "city": "Cape Town",
                    "country": "South Africa"
                }
            }
        ]
    },
    {
        "id": 219,
        "name": "Effects of the Display Angle in Museums on User's Cognition, Behavior, and Subjective Responses",
        "type": "paper",
        "abstract": "In order to achieve the intended level of communication with visitors in museums where large displays are installed, it is essential to understand how various display factors affect visitors. We explore the effects of the display angle on individual users. In our experiment, we set up three types of flat displays—vertical, horizontal, and tilted—and comprehensively tested users' cognitive, behavioral, and subjective aspects. The results showed that a significant difference could be discerned in regards to cognitive and subjective aspects. Test results for the cognitive aspect showed that the display angle on which the displayed content was easy to understand and remember differed depending on age. Test results for the subjective aspect showed that irrespective of age, users rated tilted displays as being quicker to attract attention and easier to peruse, to understand and remember the content, and to interact with, and such displays were the most preferred.",
        "cbStatement": "This paper described a user study in effects of using horizontal, vertical and tilted flat displays on people visiting in a museum.",
        "bookmarks": 44,
        "keywords": [
            "Large Interactive Display",
            "Display Angle",
            "Museum"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi1537-file5.mp4",
        "session": {
            "id": "s232",
            "name": "Visual perception"
        },
        "room": "blue",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth9536",
                "givenName": "Junko",
                "familyName": "Ichino",
                "email": "ichino@is.uec.ac.jp",
                "primary": {
                    "institution": "University of Electro-Communications",
                    "city": "Tokyo",
                    "state": "Tokyo",
                    "country": "Japan"
                },
                "role": "presenter"
            },
            {
                "id": "auth29859",
                "givenName": "Kazuo",
                "familyName": "Isoda",
                "email": "isoda-k@mail.dnp.co.jp",
                "primary": {
                    "institution": "Dai Nippon Printing Co., Ltd.",
                    "city": "Tokyo",
                    "country": "Japan"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29860",
                "givenName": "Ayako",
                "familyName": "Hanai",
                "email": "hanai-a@mail.dnp.co.jp",
                "primary": {
                    "institution": "Dai Nippon Printing Co., Ltd.",
                    "city": "Tokyo",
                    "country": "Japan"
                }
            },
            {
                "id": "auth29861",
                "givenName": "Tetsuya",
                "familyName": "Ueda",
                "email": "ueda-t5@mail.dnp.co.jp",
                "primary": {
                    "institution": "Dai Nippon Printing Co., Ltd.",
                    "city": "Tokyo",
                    "country": "Japan"
                }
            }
        ]
    },
    {
        "id": 220,
        "name": "SPRWeb: Preserving Subjective Responses to Website Colour Schemes through Automatic Recolouring",
        "type": "paper",
        "abstract": "Colours are an important part of user experiences on the Web. Colour schemes influence the aesthetics, first impressions and long-term engagement with websites. However, five percent of people perceive a subset of all colours because they have colour vision deficiency (CVD), resulting in an unequal and less-rich user experience on the Web. Traditionally, people with CVD have been supported by recolouring tools that improve colour differentiability, but do not consider the subjective properties of colour schemes while recolouring. To address this, we developed SPRWeb, a tool that recolours websites to preserve subjective responses and improve colour differentiability - thus enabling users with CVD to have similar online experiences. To develop SPRWeb, we extended existing models of non-CVD subjective responses to CVD, then used this extended model to steer the recolouring process. In a lab study, we found that SPRWeb did significantly better than a standard recolouring tool at preserving the temperature and naturalness of websites, while achieving similar weight and differentiability preservation. We also found that recolouring did not preserve activity, and hypothesize that visual complexity influences activity more than colour. SPRWeb is the first tool to automatically preserve the subjective and perceptual properties of website colour schemes thereby equalizing the colour-based web experience for people with CVD.",
        "cbStatement": "SPRWeb equalizes website experience for people with colour vision deficiency by improving colour differentiation (like previous recolouring tools), but also maintains the original colour scheme's subjective properties ('warmth', 'weight', 'activity').",
        "bookmarks": 72,
        "keywords": [
            "colour",
            "colour vision deficiency",
            "automatic recolouring"
        ],
        "communities": [],
        "video": "chi0154-file5.mp4",
        "session": {
            "id": "s273",
            "name": "How We Feel About Websites"
        },
        "room": "bordeaux",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth12764",
                "givenName": "David",
                "middleInitial": "R",
                "familyName": "Flatla",
                "email": "david.flatla@usask.ca",
                "primary": {
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth10757",
                "givenName": "Katharina",
                "familyName": "Reinecke",
                "email": "reinecke@seas.harvard.edu",
                "primary": {
                    "institution": "Harvard University",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth1181",
                "givenName": "Carl",
                "familyName": "Gutwin",
                "email": "gutwin@cs.usask.ca",
                "primary": {
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth4508",
                "givenName": "Krzysztof",
                "middleInitial": "Z",
                "familyName": "Gajos",
                "email": "kgajos@seas.harvard.edu",
                "primary": {
                    "institution": "Harvard University",
                    "city": "Cambridge",
                    "state": "MA",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 221,
        "name": "Older Adults as Digital Content Producers",
        "type": "paper",
        "abstract": "Older adults are normally characterized as consumers, rather than producers, of digital content. Current research concerning the design of technologies for older adults typically focuses on providing access to digital resources. Access is important, but is often insufficient, especially when establishing new social relationships. This paper investigates the nature and role of digital content that has been created by older adults, for the purpose of forging new relationships. We present a unique field study in which seven older adults (aged 71-92 years), who did not know each other, used a prototype iPad application (Enmesh) to create and share photographs and messages. The findings demonstrate that older adults, even those in the “oldest old” age group, embraced opportunities to express themselves creatively through digital content production. We show that self-expression and social engagement with peers can be realized when socio-technical systems are suitably designed to allow older adults to create and share their own digital content.",
        "cbStatement": "This paper examines the self-expression and social engagement that occurred when older adults used an iPad application to create and share photographs and messages within a small peer community. ",
        "bookmarks": 123,
        "keywords": [
            "Older Adults",
            "User-Generated Content",
            "Social Connection"
        ],
        "communities": [
            "hci4d"
        ],
        "video": "chi1541-file5.mp4",
        "session": {
            "id": "s296",
            "name": "Content, Creation, and Health"
        },
        "room": "242ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth29844",
                "givenName": "Jenny",
                "familyName": "Waycott",
                "email": "jwaycott@unimelb.edu.au",
                "primary": {
                    "institution": "The University of Melbourne",
                    "city": "Melbourne",
                    "country": "Australia"
                },
                "role": "presenter"
            },
            {
                "id": "auth1470",
                "givenName": "Frank",
                "familyName": "Vetere",
                "email": "f.vetere@unimelb.edu.au",
                "primary": {
                    "institution": "The University of Melbourne",
                    "city": "Melbourne",
                    "country": "Australia"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29890",
                "givenName": "Sonja",
                "familyName": "Pedell",
                "email": "s.pedell@swin.edu.au",
                "primary": {
                    "dept": "Swinburne University of Technology, Melbourne, Australia"
                }
            },
            {
                "id": "auth29891",
                "givenName": "Lars",
                "familyName": "Kulik",
                "email": "lkulik@unimelb.edu.au",
                "primary": {
                    "institution": "The University of Melbourne",
                    "city": "Melbourne",
                    "country": "Australia"
                }
            },
            {
                "id": "auth29892",
                "givenName": "Elizabeth",
                "familyName": "Ozanne",
                "email": "eao@unimelb.edu.au",
                "primary": {
                    "institution": "The University of Melbourne",
                    "city": "Melbourne",
                    "country": "Australia"
                }
            },
            {
                "id": "auth29893",
                "givenName": "Alan",
                "familyName": "Gruner",
                "email": "agruner@benetas.com.au",
                "primary": {
                    "institution": "Benetas Aged Care Services",
                    "city": "Melbourne",
                    "country": "Australia"
                }
            },
            {
                "id": "auth22083",
                "givenName": "John",
                "familyName": "Downs",
                "email": "jdowns@student.unimelb.edu.au",
                "primary": {
                    "institution": "The University of Melbourne",
                    "city": "Melbourne",
                    "country": "Australia"
                }
            }
        ]
    },
    {
        "id": 222,
        "name": "Multi-Touch Rotation Gestures: Performance and Ergonomics",
        "type": "paper",
        "abstract": "Rotations performed with the index finger and thumb involve some of the most complex motor action among common multi-touch gestures, yet little is known about the factors affecting performance and ergonomics. This note presents results from a study where the angle, direction, diameter, and position of rotations were systematically manipulated. Subjects were asked to perform the rotations as quickly as possible without losing contact with the display, and were allowed to skip rotations that were too uncomfortable. The data show surprising interaction effects among the variables, and help us identify whole categories of rotations that are slow and cumbersome for users.",
        "cbStatement": "Studies performance and ergonomics characteristics of multi-touch rotations. Presents findings concerning the effects of angle, diameter, diameter, and position.  ",
        "bookmarks": 90,
        "keywords": [
            "Rotation",
            "multi-touch interaction",
            "gestures",
            "empirical study",
            "ergonomics"
        ],
        "communities": [],
        "video": "chi1545-file5.mp4",
        "session": {
            "id": "s219",
            "name": "Mobile Gestures and Grasp"
        },
        "room": "352ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth6946",
                "givenName": "Eve",
                "middleInitial": "E",
                "familyName": "Hoggan",
                "email": "eve.hoggan@hiit.fi",
                "primary": {
                    "institution": "Helsinki Institute for Information Technology",
                    "city": "Helsinki",
                    "country": "Finland"
                },
                "role": "presenter"
            },
            {
                "id": "auth4134",
                "givenName": "John",
                "middleInitial": "H",
                "familyName": "Williamson",
                "email": "jhw@dcs.gla.ac.uk",
                "primary": {
                    "institution": "University of Glasgow",
                    "city": "Glasgow",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth2881",
                "givenName": "Antti",
                "familyName": "Oulasvirta",
                "email": "antti.oulasvirta@mpii.de",
                "primary": {
                    "institution": "Max Planck Institute for Informatics",
                    "city": "Saarbruecken",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth6171",
                "givenName": "Miguel",
                "middleInitial": "A.",
                "familyName": "Nacenta",
                "email": "mans@st-andrews.ac.uk",
                "primary": {
                    "institution": "University of St Andrews",
                    "city": "St Andrews",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth3496",
                "givenName": "Per Ola",
                "familyName": "Kristensson",
                "email": "kristensson@gmail.com",
                "primary": {
                    "dept": "School of Computer Science",
                    "institution": "University of St Andrews",
                    "city": "St Andrews",
                    "state": "Fife",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth30500",
                "givenName": "Anu",
                "familyName": "Lehtiö",
                "email": "anu.lehtio@helsinki.fi",
                "primary": {
                    "dept": "create",
                    "institution": "Helsinki Institute for Information Technology",
                    "city": "Helsinki",
                    "country": "Finland"
                }
            }
        ]
    },
    {
        "id": 223,
        "name": "Predicting Users' First Impressions of Website Aesthetics With a Quantification of Perceived Visual Complexity and Colorfulness",
        "type": "paper",
        "abstract": "Users make lasting judgments about a website's appeal within a split second of seeing it for the first time. This first impression is influential enough to later affect their opinions of a site's usability and trustworthiness. In this paper, we demonstrate a means to predict the initial impression of aesthetics based on perceptual models of a website's colorfulness and visual complexity. In an online study, we collected ratings of colorfulness, visual complexity, and visual appeal of a set of 450 websites from 548 volunteers. Based on these data, we developed computational models that accurately measure the perceived visual complexity and colorfulness of website screenshots. In combination with demographic variables such as a user's education level and age, these models explain approximately half of the variance in the ratings of aesthetic appeal given after viewing a website for 500ms only.",
        "cbStatement": "We collected colorfulness, complexity, and overall visual appeal ratings from 548 volunteers. Utilizing these data, we developed models that accurately predict perceived visual complexity and perceived colorfulness in websites based on computational image statistics.",
        "bookmarks": 40,
        "keywords": [
            "Website Aesthetics",
            "First Impression",
            "Colorfulness",
            "Complexity",
            "Modeling",
            "Prediction",
            "Perception"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi1554-file5.mp4",
        "session": {
            "id": "s273",
            "name": "How We Feel About Websites"
        },
        "room": "bordeaux",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth10757",
                "givenName": "Katharina",
                "familyName": "Reinecke",
                "email": "reinecke@seas.harvard.edu",
                "primary": {
                    "institution": "Harvard University",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth4904",
                "givenName": "Tom",
                "familyName": "Yeh",
                "email": "tom.yeh@Colorado.EDU",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Colorado",
                    "city": "Boulder",
                    "state": "Colorado",
                    "country": "United States"
                }
            },
            {
                "id": "auth30680",
                "givenName": "Luke",
                "familyName": "Miratrix",
                "email": "lmiratrix@fas.harvard.edu",
                "primary": {
                    "institution": "Harvard University",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth30681",
                "givenName": "Yuechen",
                "familyName": "Zhao",
                "email": "yuechenzhao@college.harvard.edu",
                "primary": {
                    "institution": "Harvard University",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth30682",
                "givenName": "Rahmatri",
                "familyName": "Mardiko",
                "email": "mardiko@cs.umd.edu",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                }
            },
            {
                "id": "auth30683",
                "givenName": "Jenny",
                "familyName": "Liu",
                "email": "jennyliu@college.harvard.edu",
                "primary": {
                    "institution": "Harvard University",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth4508",
                "givenName": "Krzysztof Z.",
                "middleInitial": "Z.",
                "familyName": "Gajos",
                "email": "kgajos@seas.harvard.edu",
                "primary": {
                    "institution": "Harvard University",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 224,
        "name": "iPhone In Vivo: Video Analysis of Mobile Device Use",
        "type": "paper",
        "abstract": "Despite the widespread use of mobile devices, details of mobile technology use ‘in the wild’ have proven difficult to collect. This paper uses video data to gain new insight into the use of mobile computing devices. Our new method combines screen-capture of iPhone use with video recordings from wearable cameras. We use this data to analyse how mobile device use is threaded into other co-present activities, focusing on the use of maps and internet searches. Close analysis reveals novel aspects of gestures on touch screens, how they serve ‘double duty” - both as interface gestures but as as resources for ongoing joint action. We go on to describe how users ‘walk the blue dot’ to orientate themselves, and how searches are occasioned by the local environment. In conclusion, we argue that mobile devices - rather than pushing us away from the world around us - are instead just another thread in the complex tapestry of everyday interaction. \\ ",
        "cbStatement": "This paper uses video data to gain new insight into the use of mobile computing devices. Our new method combines screen-capture of iPhone use with video recordings from wearable cameras. ",
        "bookmarks": 16,
        "keywords": [
            "Video methods",
            "smartphone use",
            "mobility",
            "ethnography"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi1557-file5.mp4",
        "session": {
            "id": "s242",
            "name": "Mobile 2: Very Moving: reflection in mobile technologies"
        },
        "room": "351",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth1785",
                "givenName": "Barry",
                "familyName": "Brown",
                "email": "barry@mobilelifecentre.org",
                "primary": {
                    "institution": "Mobile Life @ Stockholm University",
                    "city": "Kista",
                    "country": "Sweden"
                },
                "role": "presenter"
            },
            {
                "id": "auth29864",
                "givenName": "Moira",
                "familyName": "McGregor",
                "email": "mcgregor.moira@gmail.com",
                "primary": {
                    "dept": "School of Informatics",
                    "institution": "City University, London",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth6406",
                "givenName": "Eric",
                "familyName": "Laurier",
                "email": "eric.laurier@ed.ac.uk",
                "primary": {
                    "institution": "University of Edinburgh",
                    "city": "Edinburgh",
                    "country": "UK.University of Edinburgh"
                }
            }
        ]
    },
    {
        "id": 225,
        "name": "Leaving the Wild: Lessons from Community Technology Handovers",
        "type": "paper",
        "abstract": "As research increasingly turns to work ‘in the wild’ to design and evaluate technologies under real-world conditions, little consideration has been given to what happens when research ends. In many cases, users are heavily involved in the design process and encouraged to integrate the resulting technologies into their lives before they are withdrawn, while in some cases technologies are being left in place after research concludes. Often, little is done to assess the impact and legacy of these deployments. In this paper, we return to two examples in which we designed technologies with the involvement of communities and examine what steps were taken to ensure their long-term viability and what happened following the departure of researchers. From these examples, we provide guidelines for planning and executing technology handovers when conducting research with communities. ",
        "cbStatement": "We examine two cases where research prototypes were handed over to participants at the end of projects and suggest best practices for leaving technologies in the wild.",
        "bookmarks": 194,
        "keywords": [
            "Community",
            "research in the wild",
            "action research",
            "longitudinal"
        ],
        "communities": [],
        "video": "chi0156-file5.mp4",
        "session": {
            "id": "s287",
            "name": "Online Classrooms"
        },
        "room": "251",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth13500",
                "givenName": "Nick",
                "familyName": "Taylor",
                "email": "nick.taylor@newcastle.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth1405",
                "givenName": "Keith",
                "familyName": "Cheverst",
                "email": "kc@comp.lancs.ac.uk",
                "primary": {
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth9063",
                "givenName": "Peter",
                "familyName": "Wright",
                "email": "p.c.wright@newcastle.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth5105",
                "givenName": "Patrick",
                "familyName": "Olivier",
                "email": "p.l.olivier@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 226,
        "name": "The Secret Life of a Persona: When the Personal Becomes Private",
        "type": "paper",
        "abstract": "Some organizations fail to involve users in systems development due to a widespread organization, high workload or secrecy issues. A remedy against this situation could be the persona method in which users and main stakeholders as represented as fictitious characters. Personas help eliciting user needs and requirements, facilitate design choices and are an overall communication aid where users cannot be present. An important part of the persona method, as portrayed in literature, is the personal details that make the personas trustworthy and alive. In this paper we present two cases in which personas have been developed and used, but where the personal is scarce or even non-existent because of a dispersed organisation, the organisational culture and secrecy issues. The paper describes how the personas were developed, used and received and how the method was altered in order to work in these special circumstances.",
        "cbStatement": "Two persona cases for a secretive organization are uncovered! Secrecy makes personas problematic. This paper examines how to turn the unspoken into a resource: “Not to tell is to tell”.",
        "bookmarks": 57,
        "keywords": [
            "Persona",
            "user centred design",
            "stakeholder",
            "secrecy issues",
            "systems development."
        ],
        "communities": [
            "design"
        ],
        "video": "chi1563-file5.mp4",
        "authors": [
            {
                "id": "auth29858",
                "givenName": "Elina",
                "familyName": "Eriksson",
                "email": "elina@kth.se",
                "primary": {
                    "institution": "KTH - Royal Institute of Technology",
                    "city": "Stockholm",
                    "country": "Sweden"
                },
                "role": "presenter"
            },
            {
                "id": "auth29959",
                "givenName": "Henrik",
                "familyName": "Artman",
                "email": "artman@kth.se",
                "primary": {
                    "institution": "Swedish Defence Research Agency (FOI)",
                    "city": "Stockholm",
                    "country": "Sweden"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29897",
                "givenName": "Anna",
                "familyName": "Swartling",
                "email": "anna.swartling@scania.com",
                "primary": {
                    "institution": "Scania CV AB",
                    "city": "Södertälje",
                    "country": "Sweden"
                }
            }
        ]
    },
    {
        "id": 227,
        "name": "Gestures and Widgets: Performance in Text Editing on Multi-Touch Capable Mobile Devices",
        "type": "paper",
        "abstract": "We describe the design and evaluation of a gestural text editing technique for touchscreen devices. The gestures are drawn on top of the soft keyboard and interpreted as commands for moving the caret, performing selections, and controlling the clipboard. Our implementation is an Android service that can be used in any text editing task on Android-based devices. We conducted an experiment to compare the gestural editing technique against the widget-based technique available on a smartphone (Samsung Galaxy II with Android 2.3.5). The results show a performance benefit of 13-24% for the gestural technique depending on the font size. Subjective feedback from the participants was also positive. Because the two editing techniques use different input areas, they can co-exist on a device. This means that the gestural editing can be added on any soft keyboard without interfering with user experience for those users that choose not to use it.",
        "cbStatement": "We present the design and evaluation of a gestural text editing technique for touchscreens.  \\ Gestures drawn on the soft keyboard are often faster than conventional editing techniques.",
        "bookmarks": 167,
        "keywords": [
            "Gestures",
            "Text editing",
            "Caret movement",
            "Clipboard",
            "Android"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi1566-file5.mp4",
        "session": {
            "id": "s254",
            "name": "Mobile keyboard / text entry"
        },
        "room": "241",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth15970",
                "givenName": "Vittorio",
                "familyName": "Fuccella",
                "email": "vfuccella@unisa.it",
                "primary": {
                    "dept": "Dipartimento di Informatica",
                    "institution": "Università di Salerno",
                    "city": "Fisciano",
                    "country": "Italy"
                }
            },
            {
                "id": "auth1262",
                "givenName": "Poika",
                "middleInitial": "M",
                "familyName": "Isokoski",
                "email": "poika.isokoski@uta.fi",
                "primary": {
                    "institution": "University of Tampere",
                    "city": "Tampere",
                    "country": "Finland"
                },
                "role": "presenter"
            },
            {
                "id": "auth11631",
                "givenName": "Benoit",
                "familyName": "Martin",
                "email": "benoit.martin@univ-metz.fr",
                "primary": {
                    "dept": "UFR MIM - LITA",
                    "institution": "Université de Lorraine",
                    "city": "Metz",
                    "country": "France"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 228,
        "name": "The Effects of Tactile Feedback and Movement Alteration on Interaction and Awareness with Digital Embodiments",
        "type": "paper",
        "abstract": "Collaborative tabletop systems can employ direct touch, where people’s real arms and hands manipulate objects, or indirect input, where people are represented on the table with digital embodiments. The input type and the resulting embodiment dramatically influence tabletop interaction: in particular, the touch avoidance that naturally governs people’s touching and crossing behavior with physical arms is lost with digital embodiments. One result of this loss is that people are less aware of each others’ arms, and less able to coordinate actions and protect personal territories. To determine whether there are strategies that can influence group interaction on shared digital tabletops, we studied augmented digital arm embodiments that provide tactile feedback or movement alterations when people touched or crossed arms. The study showed that both augmentation types changed people’s behavior (people crossed less than half as often) and also changed their perception (people felt more aware of the other person’s arm, and felt more awkward when touching). This work shows how groupware designers can influence people’s interaction, awareness, and coordination abilities when physical constraints are absent.",
        "cbStatement": "Presents and evaluates methods for affecting group behaviour in tabletop groupware by providing cues of physical boundaries in digital space.",
        "bookmarks": 159,
        "keywords": [
            "Embodiments",
            "tabletop groupware",
            "awareness",
            "coordination"
        ],
        "communities": [],
        "video": "chi0158-file5.mp4",
        "session": {
            "id": "s237",
            "name": "Bodies Matter"
        },
        "room": "bordeaux",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth13739",
                "givenName": "Andre",
                "familyName": "Doucette",
                "email": "andre.doucette@usask.ca",
                "primary": {
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth3590",
                "givenName": "Regan",
                "middleInitial": "L",
                "familyName": "Mandryk",
                "email": "regan@cs.usask.ca",
                "primary": {
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1181",
                "givenName": "Carl",
                "familyName": "Gutwin",
                "email": "gutwin@cs.usask.ca",
                "primary": {
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                }
            },
            {
                "id": "auth6171",
                "givenName": "Miguel",
                "middleInitial": "A",
                "familyName": "Nacenta",
                "email": "mans@st-andrews.ac.uk",
                "primary": {
                    "institution": "University of St Andrews",
                    "city": "St Andrews",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth1892",
                "givenName": "Andriy",
                "familyName": "Pavlovych",
                "email": "andriyp@gmail.com",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 229,
        "name": "Cascade: Crowdsourcing Taxonomy Creation",
        "type": "paper",
        "abstract": "Taxonomies are a useful and ubiquitous way of organizing information. However, creating organizational hierarchies is difficult because the process requires a global understanding of the objects to be categorized. Usually one is created by an individual or a small group of people working together for hours or even days. Unfortunately, this centralized approach does not work well for the large, quickly changing datasets found on the web. Cascade is an automated workflow that allows crowd workers to spend as little at 20 seconds each while collectively making a taxonomy. We evaluate Cascade and show that on three datasets its quality is 80-90% of that of experts. Cascade has a competitive cost to expert information architects, despite taking six times more human labor. Fortunately, this labor can be parallelized such that Cascade will run in as fast as four minutes instead of hours or days.",
        "cbStatement": "Cascade is a novel crowd algorithm that produces a global understanding of large datasets.  Cascade is an online algorithm.  The tasks given to workers are quick and parallelizable. \\  \\ ",
        "bookmarks": 141,
        "keywords": [
            "Crowdsourcing, human computation",
            "algorithm",
            "information architecture"
        ],
        "communities": [],
        "video": "chi1584-file5.mp4",
        "session": {
            "id": "s210",
            "name": "Creative Source Unitied: Crowdsourcing used in colaborative creation"
        },
        "room": "bordeaux",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth14239",
                "givenName": "Lydia",
                "middleInitial": "B",
                "familyName": "Chilton",
                "email": "hmslydia@gmail.com",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth7275",
                "givenName": "Greg",
                "familyName": "Little",
                "email": "glittle@gmail.com",
                "primary": {
                    "institution": "oDesk",
                    "city": "Redwood City",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth9574",
                "givenName": "Darren",
                "familyName": "Edge",
                "email": "darren.edge@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research Asia",
                    "city": "Beijing",
                    "state": "Beijing",
                    "country": "China"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth5696",
                "givenName": "Daniel",
                "middleInitial": "S",
                "familyName": "Weld",
                "email": "weld@cs.washington.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth1472",
                "givenName": "James",
                "middleInitial": "A",
                "familyName": "Landay",
                "email": "landay@cs.washington.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 230,
        "name": "Interaction Techniques for Creating and Exchanging Content with Public Displays",
        "type": "paper",
        "abstract": "Falling hardware prices and ever more displays being connected to the Internet will lead to large public display networks, potentially forming a novel communication medium. We envision that such networks are not restricted to display owners and advertisers anymore, but allow also passersby (e.g., customers) to exchange content, similar to traditional public notice areas, such as bulletin boards. In this context it is crucial to understand emerging practices and provide easy and straight forward interaction techniques to be used for creating and exchanging content. In this paper, we present Digifieds, a digital public notice area we built to investigate and compare possible interaction techniques. Based on a lab study we show that using direct touch at the display as well as using the mobile phone as a complementing interaction technology are most suitable. Direct touch at the display closely resembles the interaction known from classic bulletin boards and provides the highest usability. Mobile phones preserve the users' privacy as they exchange (sensitive) data with the display and at the same time allow content to be created on-the-go or to be retrieved. ",
        "cbStatement": "This paper presents Digifieds, a digital public notice area. We compare interaction techniques for exchanging content with public displays and show that user preferences are based on situation and privacy awareness.",
        "bookmarks": 112,
        "keywords": [
            "Public displays",
            "interaction",
            "classified ads",
            "Digifieds"
        ],
        "communities": [],
        "video": "chi1585-file5.m4v",
        "session": {
            "id": "s247",
            "name": "Displays in public space"
        },
        "room": "241",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth13952",
                "givenName": "Florian",
                "familyName": "Alt",
                "email": "florian.alt@vis.uni-stuttgart.de",
                "primary": {
                    "institution": "University of Stuttgart",
                    "city": "Stuttgart",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth13827",
                "givenName": "Alireza",
                "familyName": "Sahami",
                "email": "alireza.sahami@vis.uni-stuttgart.de",
                "primary": {
                    "institution": "University of Stuttgart",
                    "city": "Stuttgart",
                    "state": "BW",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29907",
                "givenName": "Thomas",
                "familyName": "Kubitza",
                "email": "thomas.kubitza@vis.uni-stuttgart.de",
                "primary": {
                    "institution": "University of Stuttgart",
                    "city": "Stuttgart",
                    "country": "Germany"
                }
            },
            {
                "id": "auth2436",
                "givenName": "Albrecht",
                "familyName": "Schmidt",
                "email": "albrecht.schmidt@acm.org",
                "primary": {
                    "institution": "University of Stuttgart",
                    "city": "Stuttgart",
                    "country": "Germany"
                }
            }
        ]
    },
    {
        "id": 231,
        "name": "Contextifier: Automatic Generation of Annotated Stock Visualizations",
        "type": "paper",
        "abstract": "Online news tools—for aggregation, summarization and automatic generation—are an area of fruitful development as reading news online becomes increasingly commonplace. While textual tools have dominated these developments, annotated information visualizations are a promising way to complement articles based on their ability to add context. But the manual effort required for professional designers to create thoughtful annotations for contextualizing news visualizations is difficult to scale. We describe the design of Contextifier, a novel system that automatically produces custom, annotated visualizations of stock behavior given a news article about a company. Contextifier’s algorithms for choosing annotations is informed by a study of professionally created visualizations and takes into account visual salience, contextual relevance, and a detection of key events in the company’s history. In evaluating our system we find that Contextifier better balances graphical salience and relevance than the baseline.",
        "cbStatement": "We present the Contextifier system for automatic annotated stock visualizations from company news. Contextifier’s algorithms, informed by news professional visualizations, account for visual salience, contextual relevance, and notable company events.",
        "bookmarks": 124,
        "keywords": [
            "Information visualization",
            "annotation",
            "time series"
        ],
        "communities": [],
        "video": "chi1594-file5.mp4",
        "session": {
            "id": "s233",
            "name": "Text Visualization"
        },
        "room": "bordeaux",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth14237",
                "givenName": "Jessica",
                "familyName": "Hullman",
                "email": "jhullman@umich.edu",
                "primary": {
                    "institution": "University of Michigan",
                    "city": "Ann Arbor",
                    "state": "Michigan",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth4715",
                "givenName": "Nicholas",
                "familyName": "Diakopoulos",
                "email": "nicholas.diakopoulos@gmail.com",
                "primary": {
                    "institution": "Interaction Foundry",
                    "city": "New York",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth6196",
                "givenName": "Eytan",
                "familyName": "Adar",
                "email": "eadar@umich.edu",
                "primary": {
                    "institution": "University of Michigan",
                    "city": "Ann Arbor",
                    "state": "Michigan",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 232,
        "name": "Canyon: Providing Location Awareness of Multiple Moving Objects in a Detail View on Large Displays",
        "type": "paper",
        "abstract": "Overview+Detail interfaces can be used to examine the details of complex data while retaining the data's overall context. Dynamic data introduce challenges for these interfaces, however, as moving objects may exit the detail view, as well as a person’s field of view if they are working at a large interactive surface. To address this \"off-view\" problem, we propose a new information visualization technique, called Canyon. This technique attaches a small view of an off-view object, including some surrounding context, to the external boundary of the detail view. The area between the detail view and the region containing the off-view object is virtually \"folded\" to conserve space. A comparison study was conducted contrasting the benefits and limitations of Canyon to an established technique, called Wedge. Canyon was more accurate across a number of tasks, especially more complex tasks, and was comparably efficient.",
        "cbStatement": "A novel interaction technique, Canyon, was implemented and evaluated addressing the problem of data exiting a person's field of view on large displays. Results indicate higher accuracy and comparable speed.",
        "bookmarks": 39,
        "keywords": [
            "Information Visualization",
            "Overview+Detail",
            "Dynamic Data",
            "Large Display",
            "Map Data"
        ],
        "communities": [
            "design",
            "engineering"
        ],
        "video": "chi1599-file5.mp4",
        "session": {
            "id": "s211",
            "name": "Designs on Design 1: Exploring Design Approaches and Constructs"
        },
        "room": "bordeaux",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth23099",
                "givenName": "Alexandra",
                "familyName": "Ion",
                "email": "alexandra.ion@fh-hagenberg.at",
                "primary": {
                    "dept": "Media Interaction Lab",
                    "institution": "University of Applied Sciences Upper Austria",
                    "city": "Hagenberg",
                    "state": "Upper Austria",
                    "country": "Austria"
                },
                "role": "presenter"
            },
            {
                "id": "auth21362",
                "givenName": "Y.-L. Betty",
                "familyName": "Chang",
                "email": "betty.chang@uwaterloo.ca",
                "primary": {
                    "institution": "University of Waterloo",
                    "city": "Waterloo",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth3937",
                "givenName": "Michael",
                "familyName": "Haller",
                "email": "haller@fh-hagenberg.at",
                "primary": {
                    "dept": "Media Interaction Lab",
                    "institution": "University of Applied Sciences Upper Austria",
                    "city": "Hagenberg",
                    "country": "Austria"
                },
                "secondary": {
                    "dept": "Media Interaction Lab",
                    "institution": "University of Applied Sciences Upper Austria",
                    "city": "Hagenberg",
                    "country": "Austria"
                }
            },
            {
                "id": "auth5952",
                "givenName": "Mark",
                "familyName": "Hancock",
                "email": "mark.hancock@uwaterloo.ca",
                "primary": {
                    "dept": "Department of Management Sciences",
                    "institution": "University of Waterloo",
                    "city": "Waterloo",
                    "state": "Ontario",
                    "country": "Canada"
                }
            },
            {
                "id": "auth1394",
                "givenName": "Stacey",
                "middleInitial": "D.",
                "familyName": "Scott",
                "email": "stacey.scott@uwaterloo.ca",
                "primary": {
                    "dept": "Systems Design Engineering",
                    "institution": "University of Waterloo",
                    "city": "Waterloo",
                    "state": "Ontario",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 233,
        "name": "Control Your Game-Self: Effects of Controller Type on Enjoyment, Motivation, and Personality in Game",
        "type": "paper",
        "abstract": "Whether they are made to entertain you, or to educate you, good video games engage you. Significant research has tried to understand engagement in games by measuring player experience (PX). Traditionally, PX evaluation has focused on the enjoyment of game, or the motivation of players; these factors no doubt contribute to engagement, but do decisions regarding play environment (e.g., the choice of game controller) affect the player more deeply than that? We apply self-determination theory (specifically satisfaction of needs and self-discrepancy represented using the five factors model of personality) to explain PX in an experiment with controller type as the manipulation. Our study shows that there are a number of effects of controller on PX and in-game player personality. These findings provide both a lens with which to view controller effects in games and a guide for controller choice in the design of new games. Our research demonstrates that including self-characteristics assessment in the PX evaluation toolbox is valuable and useful for understanding player experience.",
        "cbStatement": "We show that controller choice affects a player’s enjoyment and motivation of a game, but also affects a player’s perception of themselves during play as measured by their in-game personality.",
        "bookmarks": 195,
        "keywords": [
            "Personality, motivation, self-discrepancy theory, self-determination theory, games, controller"
        ],
        "communities": [],
        "video": "chi0160-file5.mp4",
        "session": {
            "id": "s284",
            "name": "Nonkid Games"
        },
        "room": "251",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth28546",
                "givenName": "Max",
                "familyName": "Birk",
                "email": "max.birk@usask.ca",
                "primary": {
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth3590",
                "givenName": "Regan",
                "familyName": "Mandryk",
                "email": "regan@cs.usask.ca",
                "primary": {
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 234,
        "name": "Investigating the Use of Circles in Social Networks to Support Independence of Individuals with Autism",
        "type": "paper",
        "abstract": "Building social support networks is crucial both for less-independent individuals with autism and for their primary caregivers. In this paper, we describe a four-week exploratory study of a social network service (SNS) that allows young adults with autism to garner support from their family and friends. We explore the unique benefits and challenges of using SNSs to mediate requests for help or advice. In particular, we examine the extent to which specialized features of an SNS can engage users in communicating with their network members to get advice in varied situations. Our findings indicate that technology-supported communication particularly strengthened the relationship between the individual and extended network members, mitigating concerns about over-reliance on primary caregivers. Our work identifies implications for the design of social networking services tailored to meet the needs of this special needs population. ",
        "cbStatement": "Explores using communication circle on a social network site for young adults with autism. Provides implications for social intervention and technical design to support independence of the special needs population.",
        "bookmarks": 62,
        "keywords": [
            "Social networks, social support, autism, independence"
        ],
        "communities": [
            "design",
            "ux",
            "health"
        ],
        "video": "chi1606-file5.mp4",
        "session": {
            "id": "s293",
            "name": "Autism"
        },
        "room": "blue",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth30714",
                "givenName": "Hwajung",
                "familyName": "Hong",
                "email": "hwajung@gatech.edu",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth9072",
                "givenName": "Svetlana",
                "familyName": "Yarosh",
                "email": "lana@research.att.com",
                "primary": {
                    "institution": "AT&T Research Labs",
                    "city": "Jersey City",
                    "state": "New Jersey",
                    "country": "United States"
                }
            },
            {
                "id": "auth26487",
                "givenName": "Jennifer",
                "middleInitial": "G",
                "familyName": "Kim",
                "email": "jennifer.gahee@gmail.com",
                "primary": {
                    "institution": "University of Illinois at Urbana-Champaign",
                    "city": "Champaign",
                    "state": "Illinois",
                    "country": "United States"
                }
            },
            {
                "id": "auth1232",
                "givenName": "Gregory",
                "middleInitial": "D",
                "familyName": "Abowd",
                "email": "abowd@gatech.edu",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            },
            {
                "id": "auth18125",
                "givenName": "Rosa",
                "middleInitial": "I.",
                "familyName": "Arriaga",
                "email": "arriaga@cc.gatech.edu",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 235,
        "name": "HeartLink: Open Broadcast of Live Biometric Data to Social Networks",
        "type": "paper",
        "abstract": "A number of studies in the literature have looked into the use of real-time biometric data to improve one’s own physiological performance and wellbeing. However, there is limited research that looks into the effects that sharing biometric data with others could have on one’s social network. Following a period of research on existing mobile applications and prototype testing, we developed a system, HeartLink, which collects real-time personal biometric data such as heart rate and broadcasts this data online. Insights gained on designing systems to broadcast real-time biometric data are presented. In this paper we also report emerging results from testing HeartLink in a pilot study and a user study that were conducted during sport events. The results showed that sharing heart rate data does influence the relationship of the persons involved and that the degree of influence seems related to the tie strength prior to visualizing the data.",
        "cbStatement": "The key novelty of HeartLink is the analysis of changes in social connectedness through bio data sharing and the proposed two-way communication between the runner and the viewer. ",
        "bookmarks": 160,
        "keywords": [
            "Biometric Data",
            "Mobile Computing",
            "Digital Economy",
            "Data Broadcast",
            "Social Networks."
        ],
        "communities": [
            "design",
            "engineering",
            "ux",
            "health"
        ],
        "video": "chi1607-file5.mp4",
        "session": {
            "id": "s295",
            "name": "Health, Information, and Communication"
        },
        "room": "242ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth28835",
                "givenName": "Franco",
                "familyName": "Curmi",
                "email": "f.curmi@lancaster.ac.uk",
                "primary": {
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth29952",
                "givenName": "Maria Angela",
                "familyName": "Ferrario",
                "email": "m.a.ferrario@lancaster.ac.uk",
                "primary": {
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29954",
                "givenName": "Jen",
                "familyName": "Southern",
                "email": "j.a.southern@lancaster.ac.uk",
                "primary": {
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth29956",
                "givenName": "Jon",
                "familyName": "Whittle",
                "email": "j.n.whittle@lancaster.ac.uk",
                "primary": {
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 236,
        "name": "Reflexive Loopers for Solo Musical Improvisation",
        "type": "paper",
        "abstract": "Loop pedals are real-time samplers that playback audio \\ played previously by a musician. Such pedals are routinely \\ used for music practice or outdoor “busking”. However, \\ loop pedals always playback the same material, which can \\ make performances monotonous and boring both to the \\ musician and the audience, preventing their widespread \\ uptake in professional concerts. In response, we propose a \\ new approach to loop pedals that addresses this issue, \\ which is based on an analytical multi-modal representation \\ of the audio input. Instead of simply playing back prerecorded \\ audio, our system enables real-time generation of \\ an audio accompaniment reacting to what is currently being \\ performed by the musician. By combining different modes \\ of performance – e.g. bass line, chords, solo - from the musician \\ and system automatically, solo musicians can perform \\ duets or trios with themselves, without engendering \\ the so-called canned (boringly repetitive and unresponsive) \\ music effect of loop pedals. We describe the technology, \\ based on supervised classification and concatenative synthesis, \\ and then illustrate our approach on solo performances \\ of jazz standards by guitar. We claim this approach \\ opens up new avenues for concert performance.",
        "cbStatement": "We describe a system that automatically learns the accompaniement style of a musician from a real-time jazz performance. The system can then be used to perform trios with themselves.",
        "bookmarks": 10,
        "keywords": [
            "Music interaction",
            "loop pedals",
            "classification",
            "synthesis"
        ],
        "communities": [
            "engineering",
            "ux",
            "games",
            "arts"
        ],
        "video": "chi1612-file5.mp4",
        "session": {
            "id": "s236",
            "name": "Performing on Stage"
        },
        "authors": [
            {
                "id": "auth2095",
                "givenName": "Francois",
                "familyName": "Pachet",
                "email": "pachet@csl.sony.fr",
                "primary": {
                    "dept": "Sony CSL Paris",
                    "institution": "Sony CSL Paris",
                    "city": "Paris",
                    "country": "France"
                },
                "role": "presenter"
            },
            {
                "id": "auth30100",
                "givenName": "Pierre",
                "familyName": "Roy",
                "email": "roy@csl.sony.fr",
                "primary": {
                    "dept": "Sony CSL Paris",
                    "institution": "Sony CSL",
                    "city": "Paris",
                    "country": "France"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30101",
                "givenName": "Julian",
                "familyName": "Moreira",
                "email": "moreira@csl.sony.fr",
                "primary": {
                    "dept": "Sony CSL Paris",
                    "institution": "Sony CSL",
                    "city": "Paris",
                    "country": "France"
                }
            },
            {
                "id": "auth33977",
                "givenName": "Mark",
                "familyName": "d'Inverno",
                "email": "dinverno@gold.ac.uk",
                "primary": {
                    "dept": "Sony CSL Paris",
                    "institution": "Sony CSL",
                    "city": "Paris",
                    "country": "France"
                },
                "secondary": {
                    "dept": "Computing Department",
                    "institution": "Goldsmiths, University of London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 237,
        "name": "SimMed: Combining Simulation and Interactive Tabletops for Medical Education",
        "type": "paper",
        "abstract": "A large body of work asserts that interactive tabletops are well suited for group work, and numerous studies have examined these devices in educational contexts. However, few of the described systems support simulations for collaborative learning, and none of them explicitly address immersion. We present SimMed, a system allowing medical students to collaboratively diagnose and treat a virtual patient using an interactive tabletop. The hybrid user interface combines elements of virtual reality with multitouch input. The paper delineates the development process of the system and rationale behind a range of interface design decisions. Thereby, the role of realism in gaining procedural knowledge is discussed - in particular, the interplay between realism, immersion and training goals. We implemented several medical test cases and evaluated our approach with a user study that suggests the great potential of the system. Results show a high level of immersion, cooperation and engagement by the students.",
        "cbStatement": "SimMed supports collaborative medical education using a life-sized virtual patient on a multitouch tabletop. We address the interplay between realism, immersion and training goals in this context.",
        "bookmarks": 101,
        "keywords": [
            "Collaboration",
            "interactive surfaces",
            "tabletop",
            "multitouch",
            "procedural knowledge",
            "education",
            "learning",
            "medicine"
        ],
        "communities": [
            "health"
        ],
        "video": "chi1624-file5.mp4",
        "session": {
            "id": "s294",
            "name": "The Clinical Setting"
        },
        "room": "242ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth27658",
                "givenName": "Ulrich",
                "familyName": "von Zadow",
                "email": "uzadow@libavg.de",
                "primary": {
                    "institution": "Archimedes Exhibitions GmbH",
                    "city": "Berlin",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth29963",
                "givenName": "Sandra",
                "familyName": "Buron",
                "email": "sandra.buron@charite.de",
                "primary": {
                    "dept": "Kompetenzbereich eLearning",
                    "institution": "Charité-Universitätsmedizin",
                    "city": "Berlin",
                    "country": "Germany"
                }
            },
            {
                "id": "auth29964",
                "givenName": "Tina",
                "familyName": "Harms",
                "email": "tina.harms@charite.de",
                "primary": {
                    "dept": "Kompetenzbereich eLearning",
                    "institution": "Charité-Universitätsmedizin",
                    "city": "Berlin",
                    "country": "Germany"
                }
            },
            {
                "id": "auth29965",
                "givenName": "Florian",
                "familyName": "Behringer",
                "email": "florian.behringer@charite.de",
                "primary": {
                    "dept": "Kompetenzbereich eLearning",
                    "institution": "Charité-Universitätsmedizin",
                    "city": "Berlin",
                    "country": "Germany"
                }
            },
            {
                "id": "auth29966",
                "givenName": "Kai",
                "familyName": "Sostmann",
                "email": "kai.sostmann@charite.de",
                "primary": {
                    "dept": "Kompetenzbereich eLearning",
                    "institution": "Charité-Universitätsmedizin",
                    "city": "Berlin",
                    "country": "Germany"
                }
            },
            {
                "id": "auth6857",
                "givenName": "Raimund",
                "familyName": "Dachselt",
                "email": "raimund.dachselt@tu-dresden.de",
                "primary": {
                    "dept": "Interactive Media Lab",
                    "institution": "Technische Universität Dresden",
                    "city": "Dresden",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 238,
        "name": "Real-Time Perception-Level Translation from Audio Signals to Vibrotactile Effects",
        "type": "paper",
        "abstract": "In this paper, we propose a real-time perception-level audio-to-vibrotactile translation algorithm. Unlike previous signal-level conversion methods, our algorithm considers only perceptual characteristics, such as loudness and roughness, of audio and tactile stimuli. This perception-level approach allows for designing intuitive and explicit conversion models with clear understandings of their perceptual consequences. Our current implementation is tailored to accurate detection of special sound effects to provide well-synchronized audio-tactile feedback in immersive applications. We also assessed the performance of our translation algorithm in terms of the detection rate of special sound effects, computational performance, and user preference. All the experimental results supported that our algorithm works well as intended with better performance than the signal-level conversion methods, especially for games. Our algorithm can be easily realized in current products, including mobile devices, gaming devices, and 4D home theater systems, for richer user experience.",
        "cbStatement": "This paper presents an automatic translation framework that creates vibrotactile effects from audio content with explicit understandings of the perceptual consequences, for easy production of tactile effects for multimedia content.",
        "bookmarks": 194,
        "keywords": [
            "Haptics",
            "vibrotactile effect",
            "audio",
            "perceived intensity",
            "perceived roughness",
            "automatic conversion"
        ],
        "communities": [
            "engineering",
            "games"
        ],
        "video": "chi1626-file5.mp4",
        "session": {
            "id": "s226",
            "name": "Haptics"
        },
        "room": "352ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth29946",
                "givenName": "Jaebong",
                "familyName": "Lee",
                "email": "novaever@gmail.com",
                "primary": {
                    "institution": "Pohang University of Science and Technology (POSTECH)",
                    "city": "Pohang",
                    "state": "Gyungbuk",
                    "country": "Republic of Korea"
                },
                "role": "presenter"
            },
            {
                "id": "auth16002",
                "givenName": "Seungmoon",
                "familyName": "Choi",
                "email": "choism@postech.ac.kr",
                "primary": {
                    "institution": "Pohang University of Science and Technology (POSTECH)",
                    "city": "Pohang",
                    "state": "Gyungbuk",
                    "country": "Republic of Korea"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 239,
        "name": "Design Research at CHI and its Applicability to Design Practice",
        "type": "paper",
        "abstract": "This note describes our analysis of 35 papers from CHI 2011 that aim to improve or support interaction design practice. In our analysis, we characterize how these CHI authors conceptualize design practice and the types of contributions they propose. This work is motivated by the recognition that design methods proposed by HCI researchers often do not fit the needs and constraints of professional design practice. As a complement to the analysis of the CHI papers we also interviewed 13 practitioners about their attitudes towards learning new methods and approaches. We conclude the note by offering some critical reflections about how HCI research can better support actual design practice.",
        "cbStatement": "We present an analysis of papers from CHI 2011 and draw on interviews with professional designers to suggest ways that CHI research can better support practice.",
        "bookmarks": 118,
        "keywords": [
            "Design research",
            "interaction design",
            "design practice"
        ],
        "communities": [
            "design"
        ],
        "session": {
            "id": "s214",
            "name": "Design Research, Paradigm and Theory"
        },
        "room": "havane",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth8812",
                "givenName": "David",
                "middleInitial": "J",
                "familyName": "Roedl",
                "email": "droedl@indiana.edu",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth5985",
                "givenName": "Erik",
                "familyName": "Stolterman",
                "email": "estolter@indiana.edu",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 240,
        "name": "Interactive Horizon Graphs: Improving the Compact Visualization of Multiple Time Series",
        "type": "paper",
        "abstract": "Many approaches have been proposed for the visualization of multiple time series. Two prominent approaches are reduced line charts (RLC), which display small multiples for time series, and the more recent horizon graphs (HG). We propose to unify RLC and HG using a new technique---interactive horizon graphs (IHG)---which uses pan and zoom interaction to increase the number of time series that can be analysed in parallel. In a user study we compared RLC, HG, and IHG across several tasks and numbers of time series, focusing on datasets with both large scale and small scale variations. Our results show that IHG outperform the other two techniques in complex comparison and matching tasks where the number of charts is large. In the hardest task PHG have a significantly higher number of good answers (correctness) than HG (+14%) and RLC (+51%) and a lower error magnitude than HG (-64%) and RLC (-86%).",
        "cbStatement": "Interactive Horizon Graphs---Horizon Graphs with pan and zoom interactions--- significantly increase the number of time series that can be analyzed in parallel for common comparison tasks.",
        "bookmarks": 46,
        "keywords": [
            "Visualization",
            "Horizon Graphs",
            "Time Series",
            "Evaluation."
        ],
        "communities": [],
        "video": "chi0164-file5.mp4",
        "session": {
            "id": "s231",
            "name": "Visualization 1"
        },
        "room": "bordeaux",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth28533",
                "givenName": "Charles",
                "familyName": "Perin",
                "email": "charles.perin@inria.fr",
                "primary": {
                    "institution": "INRIA",
                    "city": "Saclay",
                    "state": "Ile-de-france",
                    "country": "France"
                },
                "secondary": {
                    "institution": "Univ Paris-Sud",
                    "city": "Orsay",
                    "state": "Ile-de-france",
                    "country": "France"
                },
                "role": "presenter"
            },
            {
                "id": "auth3648",
                "givenName": "Frédéric",
                "familyName": "Vernier",
                "email": "frederic.vernier@limsi.fr",
                "primary": {
                    "institution": "Univ Paris-Sud",
                    "city": "Orsay",
                    "state": "Ile-de-france",
                    "country": "France"
                }
            },
            {
                "id": "auth1567",
                "givenName": "Jean-Daniel",
                "familyName": "Fekete",
                "email": "Jean-Daniel.Fekete@inria.fr",
                "primary": {
                    "institution": "INRIA",
                    "city": "Saclay",
                    "state": "Ile-de-france",
                    "country": "France"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 241,
        "name": "Non-parametric Decision Trees and Online HCI",
        "type": "paper",
        "abstract": "This paper proposes that online HCI studies (such as web-surveys and remotely monitored usability tests) can benefit from statistical data analysis using modern statistical learning methods such as classification and regression trees (CARTs). Applying CARTs to the often large amount of data yielded by online studies can easily provide clarity concerning the most important effects underlying experimental data in situations where myriad possible factors are under consideration. The feedback provided by such an analysis can also provide valuable reflection on the experimental methodology. We discuss these matters with reference to a study of 1300 participants in a structured experiment concerned with head-interaction techniques for first-person-shooter games. ",
        "cbStatement": "Through an online study of head interaction techniques, we show that classification and regression trees provide a practical way to analyse the large and complex datasets typical of online HCI.",
        "bookmarks": 153,
        "keywords": [
            "Online Studies",
            "Decision Trees",
            "Parametric",
            "Non-parametric",
            "Games",
            "Classification",
            "Regression"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi1644-file5.mp4",
        "session": {
            "id": "s281",
            "name": "Automated Usability / Evaluation Methods"
        },
        "room": "351",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth34715",
                "givenName": "Torben",
                "middleInitial": "H",
                "familyName": "Sko",
                "email": "torben.sko@anu.edu.au",
                "primary": {
                    "dept": "Research School of Computer Science",
                    "institution": "Australian National University",
                    "city": "Canberra",
                    "state": "ACT",
                    "country": "Australia"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth9632",
                "givenName": "Henry",
                "middleInitial": "J",
                "familyName": "Gardner",
                "email": "Henry.Gardner@anu.edu.au",
                "primary": {
                    "dept": "Research School of Computer Science",
                    "institution": "Australian National University",
                    "city": "Canberra",
                    "country": "Australia"
                },
                "role": "presenter"
            },
            {
                "id": "auth29991",
                "givenName": "Michael",
                "middleInitial": "A",
                "familyName": "Martin",
                "email": "michael.martin@anu.edu.au",
                "primary": {
                    "dept": "Research School of Finance, Actuarial Studies and Applied Statistics",
                    "institution": "Australian National University",
                    "city": "Canberra",
                    "state": "ACT",
                    "country": "Australia"
                }
            }
        ]
    },
    {
        "id": 242,
        "name": "Benevolent Deception in Human Computer Interaction",
        "type": "paper",
        "abstract": "Though it has been asserted that “good design is honest,” [42] deception exists throughout human-computer interaction research and practice. Because of the stigma associated with deception—in many cases rightfully so—the research community has focused its energy on eradicating malicious deception, and ignored instances in which deception is positively employed. In this paper we present the notion of benevolent deception, deception aimed at benefitting the user as well as the developer. We frame our discussion using a criminology-inspired model and ground components in various examples. We assert that this provides us with a set of tools and principles that not only helps us with system and interface design, but that opens new research areas. After all, as Cockton claims in his 2004 paper “Value-Centered HCI” [13], “Traditional disciplines have delivered truth. The goal of HCI is to deliver value.”",
        "cbStatement": "In this work we analyze deception intended to help the user.  Using a criminology-inspired metaphor we describe the means, motive, and opportunities for deception and ideas for future research.",
        "bookmarks": 166,
        "keywords": [
            "Benevolent deception",
            "criminology",
            "design principles"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi1655-file5.mp4",
        "session": {
            "id": "s278",
            "name": "HCI Ethics"
        },
        "room": "351",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth6196",
                "givenName": "Eytan",
                "familyName": "Adar",
                "email": "eadar@umich.edu",
                "primary": {
                    "institution": "University of Michigan",
                    "city": "Ann Arbor",
                    "state": "Michigan",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1564",
                "givenName": "Desney",
                "middleInitial": "S",
                "familyName": "Tan",
                "email": "desney@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth2948",
                "givenName": "Jaime",
                "familyName": "Teevan",
                "email": "teevan@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 243,
        "name": "Analyzing Users' Narratives to Understand Experience with Interactive Products",
        "type": "paper",
        "abstract": "Recent research in user experience (UX) has studied narratives, users' account of their interaction with technology. It has emphasized specific constructs (e.g., affect, needs, hedonics) and their interrelation, but rarely analyzed the content of the narratives. We analyze the content and structure of 691 user-generated narratives on positive and negative experiences with technology. We use a multi-method approach consisting of manual (structural analysis of narratives) as well as of automated content analysis methods (psycholinguistic analysis and machine learning). These analyses show converging evidence that positive narratives predominantly concern social aspects such as family and friends. In addition, technology is positively experienced when it enables users to do things more efficiently or in a new way. In contrast, negative narratives often express anger and frustration due to technological failures. Our multi-method approach illustrates the potential of automated (as opposed to manual) content analysis methods for studying text-based experience reports. ",
        "cbStatement": "Analyzes narratives of experience with interactive technology with manual and automatic methods. Helps understand the content of such experiences and the relative benefits of methods for studying them. ",
        "bookmarks": 141,
        "keywords": [
            "User experience"
        ],
        "communities": [],
        "video": "chi1676-file5.mp4",
        "session": {
            "id": "s281",
            "name": "Automated Usability / Evaluation Methods"
        },
        "room": "351",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth17088",
                "givenName": "Alexandre",
                "middleInitial": "N",
                "familyName": "Tuch",
                "email": "a.tuch@unibas.ch",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Copenhagen",
                    "city": "Copenhagen",
                    "country": "Denmark"
                },
                "role": "presenter"
            },
            {
                "id": "auth30676",
                "givenName": "Rune",
                "familyName": "Trusell",
                "email": "runetrusell@gmail.com",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Copenhagen",
                    "city": "Copenhagen",
                    "country": "Denmark"
                }
            },
            {
                "id": "auth1245",
                "givenName": "Kasper",
                "familyName": "Hornbæk",
                "email": "kash@diku.dk",
                "primary": {
                    "institution": "University of Copenhagen",
                    "city": "Copenhagen",
                    "country": "Denmark"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 244,
        "name": "Mind the Theoretical Gap: Interpreting, Using, and Developing Behavioral Theory in HCI Research",
        "type": "paper",
        "abstract": "Researchers in HCI and behavioral science are increasingly exploring the use of technology to support behavior change in domains such as health and sustainability. This work, however, remain largely siloed within the two communities. We begin to address this silo problem by attempting to build a bridge between the two disciplines at the level of behavioral theory. Specifically, we define core theoretical terms to create shared understanding about what theory is, discuss ways in which behavioral theory can be used to inform research on behavior change technologies, identify shortcomings in current behavioral theories, and outline ways in which HCI researchers can not only interpret and utilize behavioral science theories but also contribute to improving them.",
        "cbStatement": "Are you trying to use behavioral theory in your work?  Our paper will help by providing a context and organizing framework for interpreting, using, and developing behavioral theory. ",
        "bookmarks": 199,
        "keywords": [
            "behavior change",
            "behavioral science",
            "theory",
            "persuasive technology",
            "health",
            "sustainability",
            "behavior change technologies"
        ],
        "communities": [
            "design",
            "health",
            "sustainability"
        ],
        "video": "chi1678-file5.mp4",
        "session": {
            "id": "s272",
            "name": "Different Perspectives"
        },
        "room": "241",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth24240",
                "givenName": "Eric",
                "middleInitial": "B.",
                "familyName": "Hekler",
                "email": "ehekler@asu.edu",
                "primary": {
                    "dept": "School of Nutrition and Health Promotion",
                    "institution": "Arizona State University",
                    "city": "Phoenix",
                    "state": "Arizona",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth8119",
                "givenName": "Predrag",
                "familyName": "Klasnja",
                "email": "klasnja@umich.edu",
                "primary": {
                    "institution": "University of Michigan",
                    "city": "Ann Arbor",
                    "state": "Michigan",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth6165",
                "givenName": "Jon",
                "middleInitial": "E.",
                "familyName": "Froehlich",
                "email": "jonf@cs.umd.edu",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                }
            },
            {
                "id": "auth30636",
                "givenName": "Matthew",
                "middleInitial": "P.",
                "familyName": "Buman",
                "email": "mbuman@asu.edu",
                "primary": {
                    "dept": "School of Nutrition and Health Promotion",
                    "institution": "Arizona State University",
                    "city": "Phoenix",
                    "state": "Arizona",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 245,
        "name": "Investigating Self-Reporting Behavior In Long-Term Studies",
        "type": "paper",
        "abstract": "Self-reporting techniques, such as data logging or a diary, are frequently used in long-term studies, but prone to subjects' forgetfulness and other sources of inaccuracy. \\ We conducted a six-week self-reporting study on smartphone usage in order to investigate the accuracy of self-reported information, and used logged data as ground truth to compare the subjects' reports against. \\ Subjects never recorded more than 70% and, depending on the requested reporting interval, down to less than 40% of actual app usages. They significantly overestimated how long they used apps. \\ While subjects forgot self-reports when no automatic reminders were sent, a high reporting frequency was perceived as uncomfortable and burdensome. Most significantly, self-reporting even changed the actual app usage of users and hence can lead to deceptive measures if a study relies on no other data sources. \\  \\ With this contribution, we provide empirical quantitative long-term data on the reliability of self-reported data collected with mobile devices. We aim to make researchers aware of the caveats of self-reporting and give recommendations for maximizing the reliability of results when conducting large-scale, long-term app usage studies. ",
        "cbStatement": "We provide empirical quantitative long-term data on the reliability of self-reported data collected with mobile devices. We give recommendations for maximizing the reliability of results when conducting long-term app usage studies.",
        "bookmarks": 156,
        "keywords": [
            "Self-reporting",
            "Survey",
            "Long-term study",
            "Application usage"
        ],
        "communities": [],
        "video": "chi1683-file5.mp4",
        "session": {
            "id": "s280",
            "name": "Evaluation Methods 2"
        },
        "room": "351",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth20848",
                "givenName": "Andreas",
                "familyName": "Möller",
                "email": "andreas.moeller@tum.de",
                "primary": {
                    "institution": "Technische Universität München",
                    "city": "Munich",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth6761",
                "givenName": "Matthias",
                "familyName": "Kranz",
                "email": "matthias.kranz@googlemail.com",
                "primary": {
                    "institution": "Universität Passau",
                    "city": "Passau",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30040",
                "givenName": "Barbara",
                "familyName": "Schmid",
                "email": "barbara.elisabeth.schmid@mytum.de",
                "primary": {
                    "institution": "Technische Universität München",
                    "city": "Munich",
                    "country": "Germany"
                }
            },
            {
                "id": "auth24595",
                "givenName": "Luis",
                "familyName": "Roalter",
                "email": "roalter@tum.de",
                "primary": {
                    "institution": "Technische Universität München",
                    "city": "Munich",
                    "country": "Germany"
                }
            },
            {
                "id": "auth30028",
                "givenName": "Stefan",
                "familyName": "Diewald",
                "email": "stefan.diewald@tum.de",
                "primary": {
                    "institution": "Technische Universität München",
                    "city": "Munich",
                    "country": "Germany"
                }
            }
        ]
    },
    {
        "id": 246,
        "name": "The Dubuque Electricity Portal: Evaluation of a City-Scale Residential Electricity Consumption Feedback System",
        "type": "paper",
        "abstract": "This paper describes the Dubuque Electricity Portal, a city-scale system aimed at supporting voluntary reductions of electricity consumption. The Portal provided each household with fine-grained feedback on its electricity use, as well as using incentives, comparisons, and goal setting to encourage conservation. Logs, a survey and interviews were used to evaluate the user experience of the Portal during a 20-week pilot with 765 volunteer households. Although the volunteers had already made a wide range of changes to conserve electricity prior to the pilot, those who used the Portal decreased their electricity use by about 3.7%. They also reported increased understanding of their usage, and reported taking an array of actions ¬ – both changing their behavior and their electricity infrastructure. The paper discusses the experience of the system’s users, and describes challenges for the design of ECF systems, including balancing accessibility and security, a preference for time-based visualizations, and the advisability of multiple modes of feedback, incentives and information presentation.",
        "cbStatement": "Evaluation of an electricity portal deployed to 765 homes for 20 weeks that used feedback and social techniques to support decreased electricity consumption. Can assist designers of residential feedback \\ systems. \\ ",
        "bookmarks": 64,
        "keywords": [
            "Electricity",
            "smart meters",
            "sustainability",
            "behavior change",
            "ECF",
            "consumption feedback systems",
            "social comparison"
        ],
        "communities": [
            "ux",
            "sustainability"
        ],
        "video": "chi1685-file5.mp4",
        "session": {
            "id": "s259",
            "name": "Energy / Sustainability"
        },
        "room": "blue",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth1002",
                "givenName": "Thomas",
                "middleInitial": "D",
                "familyName": "Erickson",
                "email": "snowfall@us.ibm.com",
                "primary": {
                    "institution": "IBM T.J. Watson Research Center",
                    "city": "Yorktown Heights",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30909",
                "givenName": "Ming",
                "familyName": "Li",
                "email": "liming@us.ibm.com",
                "primary": {
                    "institution": "IBM T.J. Watson Research Center",
                    "city": "Yorktown Heights",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth30910",
                "givenName": "Younghun",
                "familyName": "Kim",
                "email": "kimy@us.ibm.com",
                "primary": {
                    "institution": "IBM T.J. Watson Research Center",
                    "city": "Yorktown Heights",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth30918",
                "givenName": "Ajay",
                "familyName": "Deshpande",
                "email": "ajayd@us.ibm.com",
                "primary": {
                    "institution": "IBM T.J. Watson Research Center",
                    "city": "Yorktown Heights",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth30911",
                "givenName": "Sambit",
                "familyName": "Sahu",
                "email": "sambits@us.ibm.com",
                "primary": {
                    "institution": "IBM T.J. Watson Research Center",
                    "city": "Yorktown Heights",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth30912",
                "givenName": "Tian",
                "familyName": "Chao",
                "email": "tian@us.ibm.com",
                "primary": {
                    "institution": "IBM T.J. Watson Research Center",
                    "city": "Yorktown Heights",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth1092",
                "givenName": "Piyawadee",
                "middleInitial": "\"Noi\"",
                "familyName": "Sukaviriya",
                "email": "noi@us.ibm.com",
                "primary": {
                    "institution": "IBM T.J. Watson Research Center",
                    "city": "Yorktown Heights",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth30913",
                "givenName": "Milind",
                "familyName": "Naphade",
                "email": "naphade@us.ibm.com",
                "primary": {
                    "institution": "IBM T.J. Watson Research Center",
                    "city": "Yorktown Heights",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 247,
        "name": "Toying with Time: Considering Temporal Themes in Interactive Artifacts",
        "type": "paper",
        "abstract": "This paper argues that there is a value in deliberately and systematically exploring potential temporal behaviors of an interactive artifact, either as a means to add new functions, or to change the interaction with it. An improved version of Temporal Themes – a vocabulary describing how software can “use” time or sequences of events – will be presented, alongside a series of design cases. These exemplify how adding or changing temporal themes in existing applications can enhance functionality and/or interaction. Moreover, the cases also serve as a basis for a discussion of the issues coupled to temporality, control and interaction strategies. Finally, a design approach with focus on temporal aspects is outlined. As a result, the paper opens up for a more conscious use of time and temporality in interaction design.    ",
        "cbStatement": "This paper proposes:  1) A framework describing use of time in interactive artifacts, and 2) An ideation method for deliberately and systematically exploring potential temporal behaviors of an interactive artifact. ",
        "bookmarks": 121,
        "keywords": [
            "Temporality",
            "interaction design",
            "design method",
            "time",
            "temporal themes"
        ],
        "communities": [
            "design"
        ],
        "video": "chi1698-file5.mp4",
        "session": {
            "id": "s216",
            "name": "Design and Time: Long-term User Involvment and temporal themes"
        },
        "room": "havane",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth20932",
                "givenName": "Sus",
                "familyName": "Lundgren",
                "email": "sus.lundgren@chalmers.se",
                "primary": {
                    "dept": "Interaction Design",
                    "institution": "Chalmers University of Technology",
                    "city": "Gothenburg",
                    "country": "Sweden"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 248,
        "name": "Unlimited Editions: Three Approaches to the Dissemination and Display of Digital Art",
        "type": "paper",
        "abstract": "The paper reflects on three approaches to the dissemination and display of digital art. “s[edition]” is a novel, web-based service that offers limited editions of “digital prints”. Analysis of user comments suggests that the metaphor of a “limited digital edition” raises issues and to some extent is resisted. The second approach is the Flickr Brushes Gallery, where digital painters post images and comment on one another’s work. Analysis of comment boards indicates that the shared art and comments are a form of gift exchange. Finally, the paper discusses a field study in which artists exhibited their work as it develops over time in digital frames and also in an immersive digital projection room. Analysis of field notes and interviews indicate that the digital frame approach was unsuccessful because of aesthetic and environmental concerns. The immersive projection suggested that more experiential approaches may be more interesting. It is argued that there is an inherent resistance in digital media to previous models of art commoditization. None of the approaches discussed here resolve the dilemma but rather indicate the scope and complexity of the issues.",
        "cbStatement": "Three approaches to digital art are explored: in “s[editon]” a limited digital editions website, the iPad “Brushes” Gallery and a field study using digital frames and an immersive projection room.",
        "bookmarks": 173,
        "keywords": [
            "Interaction design",
            "ethnography",
            "art",
            "digital culture."
        ],
        "communities": [
            "design",
            "ux",
            "arts"
        ],
        "video": "chi1699-file5.mp4",
        "session": {
            "id": "s246",
            "name": "Touching Experiences: tangible computing & trajectories"
        },
        "room": "351",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth1332",
                "givenName": "Mark",
                "familyName": "Blythe",
                "email": "mark.blythe@northumbria.ac.uk",
                "primary": {
                    "dept": "School of Design",
                    "institution": "Northumbria University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth26845",
                "givenName": "Jo",
                "familyName": "Briggs",
                "email": "jo.briggs@northumbria.ac.uk",
                "primary": {
                    "dept": "School of Design",
                    "institution": "Northumbria University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth11918",
                "givenName": "Jonathan",
                "familyName": "Hook",
                "email": "jonathan.hook@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth9063",
                "givenName": "Peter",
                "middleInitial": "C",
                "familyName": "Wright",
                "email": "p.c.wright@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth5105",
                "givenName": "Patrick",
                "middleInitial": "L",
                "familyName": "Olivier",
                "email": "p.l.olivier@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 249,
        "name": "Tailoring Persuasive Health Games to Gamer Type",
        "type": "paper",
        "abstract": "Persuasive games are an effective approach for motivating health behavior, and recent years have seen an increase in games designed for changing human behaviors or attitudes. However, these games are limited in two major ways: first, they are not based on theories of what motivates healthy behavior change. This makes it difficult to evaluate why a persuasive approach works. Second, most persuasive games treat players as a monolithic group. As an attempt to resolve these weaknesses, we conducted a large-scale survey of 642 gamers’ eating habits and their associated determinants of healthy behavior to understand how health behavior relates to gamer type. We developed seven different models of healthy eating behavior for the gamer types identified by BrainHex. We then explored the differences between the models and created two approaches for effective persuasive game design based on our results. The first is a one-size-fits-all approach that will motivate the majority of the population, while not demotivating any players. The second is a personalized approach that will best motivate a particular type of gamer. Finally, to make our approaches actionable in persuasive game design, we map common game mechanics to the determinants of healthy behavior.",
        "cbStatement": "We developed models of the efficacy of different motivators of health behavior. Serious game designers can use our results to tailor their games to different player types, potentially increasing the efficacy of persuasive health games",
        "bookmarks": 110,
        "keywords": [
            "Games design",
            "persuasive game",
            "gamer types",
            "serious games",
            "health",
            "behavior theory, HBM, player typology"
        ],
        "communities": [
            "health",
            "games"
        ],
        "video": "chi0170-file5.mp4",
        "session": {
            "id": "s263",
            "name": "Food"
        },
        "room": "351",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth28728",
                "givenName": "Rita",
                "familyName": "Orji",
                "email": "rita.orji@usask.ca",
                "primary": {
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                },
                "secondary": {
                    "dept": "MADMUC Lab, Computer Science Department",
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatoon",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth3590",
                "givenName": "Regan",
                "middleInitial": "L.",
                "familyName": "Mandryk",
                "email": "regan@cs.usask.ca",
                "primary": {
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth13760",
                "givenName": "Julita",
                "familyName": "Vassileva",
                "email": "jiv@cs.usask.ca",
                "primary": {
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                }
            },
            {
                "id": "auth22264",
                "givenName": "Kathrin",
                "middleInitial": "Maria",
                "familyName": "Gerling",
                "email": "kathrin.gerling@usask.ca",
                "primary": {
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 250,
        "name": "“I read my Twitter the next morning and was astonished” A Conversational Perspective on Twitter Regrets",
        "type": "paper",
        "abstract": "We present the results of an online survey of 1,221 Twitter users, comparing messages individuals regretted either saying during in-person conversations or posting on Twitter. Participants generally reported similar types of regrets in person and on Twitter. In particular, they often regretted messages that were critical of others. However, regretted messages that were cathartic/expressive or revealed too much information were reported at a higher rate for Twitter. Regretted messages on Twitter also reached broader audiences. In addition, we found that participants who posted on Twitter became aware of, and tried to repair, regret more slowly than those reporting in-person regrets. From this comparison of Twitter and in-person regrets, we provide preliminary ideas for tools to help Twitter users avoid and cope with regret. ",
        "cbStatement": "Presents the results of a large-scale online survey that compares regretted tweets and regrets from in-person conversations. Examines the context, timing, means of awareness, and repair strategies for the regrettable messages.",
        "bookmarks": 35,
        "keywords": [
            "Twitter",
            "regrets",
            "messaging",
            "conversation",
            "survey"
        ],
        "communities": [],
        "video": "chi1701-file5.mp4",
        "session": {
            "id": "s200",
            "name": "Online Sorrows Shared: Online dealing with problems"
        },
        "room": "havane",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth16640",
                "givenName": "Manya",
                "familyName": "Sleeper",
                "email": "msleeper@cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth18321",
                "givenName": "Justin",
                "familyName": "Cranshaw",
                "email": "jcransh@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth11379",
                "givenName": "Patrick Gage",
                "familyName": "Kelley",
                "email": "me@patrickgage.com",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of New Mexico",
                    "city": "Albuquerque",
                    "state": "New Mexico",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth23062",
                "givenName": "Blase",
                "familyName": "Ur",
                "email": "bur@cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "PA",
                    "country": "United States"
                }
            },
            {
                "id": "auth6477",
                "givenName": "Alessandro",
                "familyName": "Acquisti",
                "email": "acquisti@andrew.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth1992",
                "givenName": "Lorrie Faith",
                "familyName": "Cranor",
                "email": "lorrie@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth14558",
                "givenName": "Norman",
                "familyName": "Sadeh",
                "email": "sadeh@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 251,
        "name": "Delivering Patients to Sacré Coeur: Collective Intelligence in Digital Volunteer Communities",
        "type": "paper",
        "abstract": "This study examines the information-processing activities of digital volunteers and other connected ICT users in the wake of crisis events. Synthesizing findings from several previous research studies of digital volunteerism, this paper offers a new approach for conceptualizing the activities of digital volunteers, shifting from a focus on organizing to a focus on information movement. Using the lens of distributed cognition, this research describes collective intelligence as transformations of information within a system where cognition is distributed socially across individuals as well as through their tools and resources. This paper demonstrates how digital volunteers, through activities such as relaying, amplifying, verifying, and structuring information, function as a collectively intelligent cognitive system in the wake of disaster events.",
        "cbStatement": "This study examines the activities of digital volunteers during crisis events, using a distributed cognition perspective to demonstrate how individual ICT users function together as a collectively intelligent cognitive system.",
        "bookmarks": 83,
        "keywords": [
            "Crisis informatics",
            "collective intelligence",
            "distributed cognition",
            "crowdsourcing "
        ],
        "communities": [],
        "video": "chi1711-file5.mp4",
        "session": {
            "id": "s260",
            "name": "Crowdsource Activism Volunteering Citizen Science"
        },
        "room": "bordeaux",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth28625",
                "givenName": "Kate",
                "familyName": "Starbird",
                "email": "kstarbi@uw.edu",
                "primary": {
                    "dept": "Human Centered Design & Engineering",
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 252,
        "name": "Accessible Photo Album: Enhancing the Photo Sharing Experience for People with Visual Impairment",
        "type": "paper",
        "abstract": "While a photograph is a visual artifact, studies reveal that a number of people with visual impairments are also interested in being able to share their memories and experiences with their sighted counterparts in the form of a photograph. We conducted an online survey to better understand the challenges faced by people with visual impairments in sharing and organizing photos, and reviewed existing tools and their limitations. Based on our analysis, we developed an accessible mobile application that enables a visually impaired user to capture photos along with audio recordings for the ambient sound and memo description and to browse through them eyes-free. Five visually impaired participants took part in a study in which they used our app to take photographs in naturalistic settings and to share them later with a sighted viewer. The participants were able to use our app to identify each photograph on their own during the photo sharing session, and reported high satisfaction in having been able to take the initiative during the process.",
        "cbStatement": "Study of how to support people with visual impairments to partake in photo capturing and sharing activities. Results from online survey and user study evaluation of custom accessible iPhone app.",
        "bookmarks": 55,
        "keywords": [
            "Visual impairment",
            "blind",
            "photo sharing",
            "audiophotography"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi1713-file5.mp4",
        "session": {
            "id": "s292",
            "name": "Blindness and Design"
        },
        "room": "242ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth7619",
                "givenName": "Susumu",
                "familyName": "Harada",
                "email": "haradas@jp.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "Tokyo",
                    "country": "Japan"
                },
                "role": "presenter"
            },
            {
                "id": "auth15679",
                "givenName": "Daisuke",
                "familyName": "Sato",
                "email": "dsato@jp.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "Tokyo",
                    "country": "Japan"
                }
            },
            {
                "id": "auth27030",
                "givenName": "Dustin",
                "middleInitial": "W",
                "familyName": "Adams",
                "email": "duwadams@ucsc.edu",
                "primary": {
                    "institution": "University of California, Santa Cruz",
                    "city": "Santa Cruz",
                    "state": "California",
                    "country": "Santa Cruz"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1322",
                "givenName": "Sri",
                "familyName": "Kurniawan",
                "email": "srikur@soe.ucsc.edu",
                "primary": {
                    "institution": "University of California, Santa Cruz",
                    "city": "Santa Cruz",
                    "state": "California",
                    "country": "Santa Cruz"
                }
            },
            {
                "id": "auth14568",
                "givenName": "Hironobu",
                "familyName": "Takagi",
                "email": "takagih@jp.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "Tokyo",
                    "country": "Japan"
                }
            },
            {
                "id": "auth15063",
                "givenName": "Chieko",
                "familyName": "Asakawa",
                "email": "chie@jp.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "Tokyo",
                    "country": "Japan"
                }
            }
        ]
    },
    {
        "id": 253,
        "name": "Binocular Cursor: Enabling Selection on Transparent Displays Troubled by Binocular Parallax",
        "type": "paper",
        "abstract": "Binocular parallax is a problem for any interaction system that has a transparent display and objects behind it, as users will see duplicated and overlapped images. In this note, we propose a quantitative measure called Binocular Selectability Discriminant (BSD) to predict the ability of the user to perform selection task in such a setup. In addition, we propose a technique called Binocular Cursor (BC) which takes advantage of this duplicating and overlapping phenomenon, rather than being hampered by it, to resolve binocular selection ambiguity by visualizing the correct selection point. An experiment shows that selection with BC is not slower than monocular selection, and that it can be significantly more precise, depending on the design of BC.",
        "cbStatement": "Transparent displays are about to be commercialized, yet it is troubled by binocular parallax. We propose a measure to quantify the usability degradation caused by binocular parallax, and an interaction strategy.",
        "bookmarks": 37,
        "keywords": [
            "Transparent display",
            "binocular parallax."
        ],
        "communities": [
            "design"
        ],
        "video": "chi1728-file5.mp4",
        "authors": [
            {
                "id": "auth27369",
                "givenName": "Joon Hyub",
                "familyName": "Lee",
                "email": "joonhyub.lee@kaist.ac.kr",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth17771",
                "givenName": "Seok-Hyung",
                "familyName": "Bae",
                "email": "seokhyung.bae@kaist.ac.kr",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 254,
        "name": "DesignLibs: A Scenario-Based Design Method for Ideation",
        "type": "paper",
        "abstract": "Generating potential design ideas through ideation often benefits from the spontaneity of random ideas. Having po-tential users participate in this process can be beneficial, but is often difficult to implement. We present a new method for generating design ideas with potential users. The meth-od uses scenarios with missing words, which potential users fill in to generate ideas for features and attributes of new technology designs, similar to the children’s game of Mad Libs. We developed three different formats of DesignLibs, including 1) “Mad Libs-style:” blanks presented before seeing the scenario, 2) “Fill-in-the-Blanks:” blanks present-ed within the context of the scenario, and 3) “Q&A:” blanks presented as questions and answers. We found that Design-Libs generated a number of new ideas, with the Fill-in-the-Blanks method providing the highest ratings for usefulness, feasibility, and diversity of answers. All three formats pro-vided equal ratings for creativity.",
        "cbStatement": "This note provides a study of a new design method we developed called “DeisgnLibs”. DesignLibs is an ideation technique with potential users inspired by the children’s game Mad Libs.",
        "bookmarks": 142,
        "keywords": [
            "Scenarios",
            "user-centered design",
            "design methods",
            "ideation."
        ],
        "communities": [
            "design"
        ],
        "video": "chi0173-file5.m4v",
        "session": {
            "id": "s214",
            "name": "Design Research, Paradigm and Theory"
        },
        "room": "havane",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth14763",
                "givenName": "Jared",
                "middleInitial": "S",
                "familyName": "Bauer",
                "email": "jaredsb@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth5566",
                "givenName": "Julie",
                "middleInitial": "A",
                "familyName": "Kientz",
                "email": "jkientz@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 255,
        "name": "Memorability of Pre-designed and User-defined Gesture Sets",
        "type": "paper",
        "abstract": "We studied the memorability of free-form gesture sets for invoking actions. We compared three types of gesture sets: user-defined gesture sets, gesture sets designed by the authors, and random gesture sets in three studies with 33 participants in total. We found that user-defined gestures are easier to remember, both immediately after creation and on the next day (up to a 24% difference in recall rate compared to pre-designed gestures). We also discovered that the differences between gesture sets are mostly due to association errors (rather than gesture form errors), that participants prefer user-defined sets, and that they think user-defined gestures take less time to learn. Finally, we contribute a qualitative analysis of the tradeoffs involved in gesture type selection and share our data and a video corpus of 66 gestures for replicability and further analysis.",
        "cbStatement": "We analyze memorability aspects of gesture sets, comparing gesture sets created by users, gesture sets created by designers, and stock gesture sets. We present evidence from three studies.",
        "bookmarks": 71,
        "keywords": [
            "gesture sets",
            "gesture memorability",
            "user-defined gestures"
        ],
        "communities": [],
        "video": "chi1734-file5.mp4",
        "session": {
            "id": "s253",
            "name": "Gestures studies / empirical"
        },
        "room": "241",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth6171",
                "givenName": "Miguel",
                "middleInitial": "A.",
                "familyName": "Nacenta",
                "email": "mans@st-andrews.ac.uk",
                "primary": {
                    "dept": "School of Computer Science",
                    "institution": "University of St Andrews",
                    "city": "St Andrews",
                    "state": "Fife",
                    "country": "United Kingdom"
                },
                "secondary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Calgary",
                    "city": "Calgary",
                    "state": "Alberta",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth30201",
                "givenName": "Yemliha",
                "familyName": "Kamber",
                "email": "yemyem1@gmail.com",
                "primary": {
                    "dept": "School of Computer Science",
                    "institution": "University of St Andrews",
                    "city": "St Andrews",
                    "state": "Fife",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth30202",
                "givenName": "Yizhou",
                "familyName": "Qiang",
                "email": "yq7@st-andrews.ac.uk",
                "primary": {
                    "dept": "School of Computer Science",
                    "institution": "University of St Andrews",
                    "city": "St Andrews",
                    "state": "Fife",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth3496",
                "givenName": "Per Ola",
                "familyName": "Kristensson",
                "email": "kristensson@gmail.com",
                "primary": {
                    "dept": "School of Computer Science",
                    "institution": "University of St Andrews",
                    "city": "St Andrews",
                    "state": "Fife",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 256,
        "name": "The Effect of Global Instructions on Think-aloud Testing",
        "type": "paper",
        "abstract": "Verbal protocols are the primary tool for understanding users’ task-solving behaviors during usability testing. We investigated whether the classic think-aloud and a think-aloud with an explicit instruction leads to different task-solving performance compared to silent working.   The results suggest that the classic method had no impact on task performance whereas the explicit instruction led to an increase in within-page and between-page navigation and scrolling activity.  The classic method was linked to an increase in mental workload in terms of effort and frustration. The explicit think-aloud led to an increase in mental demand, performance, effort and frustration.",
        "cbStatement": "This study investigates whether deviating from the classic concurrent think-aloud instructions during usability testing induces reactivity: a change in participants’ cognitive processing, which affects task performance measures.",
        "bookmarks": 68,
        "keywords": [
            "Think-aloud testing",
            "think-aloud instructions",
            "reactivity"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi1742-file5.mp4",
        "session": {
            "id": "s280",
            "name": "Evaluation Methods 2"
        },
        "room": "351",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth6465",
                "givenName": "Sharon",
                "familyName": "McDonald",
                "email": "sharon.mcdonald@sunderland.ac.uk",
                "primary": {
                    "institution": "University of Sunderland",
                    "city": "Sunderland",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth34671",
                "givenName": "Helen",
                "familyName": "Petrie",
                "email": "helen.petrie@york.ac.uk",
                "primary": {
                    "institution": "University of York",
                    "city": "York",
                    "state": "North Yorkshire",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 257,
        "name": "Tactile Perceptions of Digital Textiles: A Design Research Approach",
        "type": "paper",
        "abstract": "Current interactive media presentations of textiles provide an impoverished communication of their ‘textile hand’, that is their weight, drape, how they feel to touch. These are complex properties experienced through the visual, tactile, auditory and proprioceptive senses and are currently lost when textile materials are presented in interactive video. This paper offers a new perspective from which the production of multi-touch interactive video representations of the tactile qualities of materials is considered. Through an understanding of hand properties of textiles and how people inherently touch and handle them, we are able to develop methods to animate and bring these properties alive using design methods. Observational studies were conducted, noting gestures consumers used to evaluate textile hand. Replicating the appropriate textile deformations for these gestures in interactive video was explored as a design problem. The resulting digital textile swatches and their interactive behavior were then evaluated for their ability to communicate tactile qualities similar to those of the real textiles.",
        "cbStatement": "This paper contributes a methodology to explore the real-life gestures used to understand tactile qualities of deformable materials and re-create their visual and proprioceptive experience in multi-gesture interactive video. ",
        "bookmarks": 63,
        "keywords": [
            "Design research",
            "User interactions",
            "Visualisation",
            "Methodology",
            "Design methods",
            "Multimodal interfaces."
        ],
        "communities": [
            "design"
        ],
        "video": "chi1745-file5.mp4",
        "session": {
            "id": "s228",
            "name": "Tactile Presentation Theory"
        },
        "room": "blue",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth22113",
                "givenName": "Douglas",
                "middleInitial": "S",
                "familyName": "Atkinson",
                "email": "douglas.atkinson@brunel.ac.uk",
                "primary": {
                    "institution": "Brunel University",
                    "city": "London",
                    "state": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth23488",
                "givenName": "Pawel",
                "middleInitial": "M",
                "familyName": "Orzechowski",
                "email": "po38@hw.ac.uk",
                "primary": {
                    "institution": "Heriot-Watt University",
                    "city": "Edinburgh",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth30639",
                "givenName": "Bruna",
                "middleInitial": "B",
                "familyName": "Petreca",
                "email": "bruna.petreca@brunel.ac.uk",
                "primary": {
                    "institution": "Brunel University",
                    "city": "London",
                    "state": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth7706",
                "givenName": "Nadia",
                "familyName": "Bianchi-Berthouze",
                "email": "n.berthouze@ucl.ac.uk",
                "primary": {
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30640",
                "givenName": "Penelope",
                "familyName": "Watkins",
                "email": "penelopewatkins@aol.com",
                "primary": {
                    "institution": "Brunel University",
                    "city": "London",
                    "state": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth8333",
                "givenName": "Sharon",
                "middleInitial": "L",
                "familyName": "Baurley",
                "email": "sharon.baurley@brunel.ac.uk",
                "primary": {
                    "institution": "Brunel University",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth28737",
                "givenName": "Stefano",
                "familyName": "Padilla",
                "email": "S.Padilla@hw.ac.uk",
                "primary": {
                    "institution": "Heriot-Watt University",
                    "city": "Edinburgh",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth23511",
                "givenName": "Mike",
                "middleInitial": "J",
                "familyName": "Chantler",
                "email": "mjc@macs.hw.ac.uk",
                "primary": {
                    "institution": "Heriot-Watt University",
                    "city": "Edinburgh",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 258,
        "name": "Favors from Facebook Friends: Unpacking Dimensions of Social Capital",
        "type": "paper",
        "abstract": "Past research has demonstrated a link between perceptions of social capital and use of the popular social network site, Facebook. Williams’ Internet Social Capital Scales, based on Putnam’s formulation, tap into sub-dimensions of social capital that have not been broadly used yet may enlighten our understanding of the different ways in which connecting with others online can facilitate access to resources embedded within our social relationships. In this study, we segment Williams’ Internet Social Capital Scales into various sub-dimensions using factor analysis and explicate the distinct facets of social capital through a lab experiment in which Facebook users (N=98) request a small favor from their Facebook network. We find that some sub-dimensions play a significant role in getting favors from Facebook friends while bonding and bridging social capital do not significantly predict responses to favor requests.",
        "cbStatement": "This paper provides an innovative way of using Williams’ (2006) social capital measures which are the most widely-used social capital measures in social media studies.",
        "bookmarks": 87,
        "keywords": [
            "Social capital",
            "Favor asking",
            "Facebook network"
        ],
        "communities": [],
        "session": {
            "id": "s205",
            "name": "Look how popular I am: managing social media platforms"
        },
        "room": "blue",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth30060",
                "givenName": "Yumi",
                "familyName": "Jung",
                "email": "yumijung7@gmail.com",
                "primary": {
                    "dept": "Telecommunication",
                    "institution": "Michigan State Univeristy",
                    "city": "East Lansing",
                    "state": "MI",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth21319",
                "givenName": "Rebecca",
                "familyName": "Gray",
                "email": "grayreb2@msu.edu",
                "primary": {
                    "institution": "Michigan State Univeristy",
                    "city": "East Lansing",
                    "state": "Michigan",
                    "country": "United States"
                }
            },
            {
                "id": "auth8048",
                "givenName": "Cliff",
                "familyName": "Lampe",
                "email": "cacl@umich.edu",
                "primary": {
                    "institution": "University of Michigan",
                    "city": "Ann Arbor",
                    "state": "Michigan",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth10244",
                "givenName": "Nicole",
                "familyName": "Ellison",
                "email": "enicole@umich.edu",
                "primary": {
                    "dept": "School of Information",
                    "institution": "University of Michigan",
                    "city": "Ann Arbor",
                    "state": "Michigan",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 259,
        "name": "Understanding Motivations for Facebook Use: Usage Metrics, Network Structure, and Privacy",
        "type": "paper",
        "abstract": "This study explores the links between motives for using a social network service and numerical measures of that activity. Specifically, it identified motives for Facebook use by employing a Uses and Gratifications (U&G) approach and then investigated the extent to which these motives can be predicted through usage and network metrics collected automatically via the Facebook API. In total, 11 Facebook usage metrics and eight personal network metrics served as predictors. Results showed that all three variable types in this expanded U&G frame of analysis (covering social antecedents, usage metrics, and personal network metrics) effectively predicted motives and highlighted interesting behaviors. To further illustrate the power of this framework, the intricate nature of privacy in social media was explored and relationships drawn between privacy attitudes (and acts) and measures of use and network structure.",
        "cbStatement": "A study on motivations for Facebook use that couples social science methods with information captured by the Facebook API in the form of detailed usage data and personal network metrics.",
        "bookmarks": 66,
        "keywords": [
            "Uses and gratifications",
            "social network sites",
            "social networks",
            "Facebook",
            "privacy",
            "computer-mediated communication"
        ],
        "communities": [],
        "video": "chi1751-file5.mp4",
        "session": {
            "id": "s275",
            "name": "Consent and Integrity"
        },
        "room": "251",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth15767",
                "givenName": "Tasos",
                "familyName": "Spiliotopoulos",
                "email": "tspiliot@gmail.com",
                "primary": {
                    "institution": "University of Madeira",
                    "city": "Funchal",
                    "country": "Portugal"
                },
                "role": "presenter"
            },
            {
                "id": "auth1336",
                "givenName": "Ian",
                "familyName": "Oakley",
                "email": "ian.r.oakley@gmail.com",
                "primary": {
                    "institution": "University of Madeira",
                    "city": "Funchal",
                    "country": "Portugal"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 260,
        "name": "What is \"Critical\" About Critical Design?",
        "type": "paper",
        "abstract": "Critical design is a research through design methodology that foregrounds the ethics of design practice, reveals potentially hidden agendas and values, and explores alternative design values. While it seems to be a timely fit for today’s socially, aesthetically, and ethically oriented approaches to HCI, its adoption seems surprisingly limited. We argue that its central concepts and methods are unclear and difficult to adopt. Rather than merely attempting to decode the intentions of its originators, Dunne and Raby, we instead turn to traditions of critical thought in the past 150 years to explore a range of critical ideas and their practical uses. We then suggest ways that these ideas and uses can be leveraged as practical resources for HCI researchers interested in critical design. We also offer readings of two designs, which are not billed as critical designs, but which we argue are critical using a broader formulation of the concept than the one found in the current literature. ",
        "cbStatement": "We provide a critique of Critical Design and propose a broader, more practical reframing, based on humanistic scholarship on critical theory and criticism.",
        "bookmarks": 198,
        "keywords": [
            "HCI",
            "critical design",
            "critical theory",
            "design methodology"
        ],
        "communities": [
            "design",
            "arts"
        ],
        "video": "chi1765-file5.mp4",
        "session": {
            "id": "s272",
            "name": "Different Perspectives"
        },
        "room": "241",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth7080",
                "givenName": "Jeffrey",
                "familyName": "Bardzell",
                "email": "jbardzel@indiana.edu",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth7081",
                "givenName": "Shaowen",
                "familyName": "Bardzell",
                "email": "selu@indiana.edu",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 261,
        "name": "Understanding the Conflicting Demands of Family Caregivers Caring for Depressed Family Members",
        "type": "paper",
        "abstract": "Depression is one of the most common disabilities in developed countries. Despite its often devastating impact on families, scant research has focused on how to facilitate the well-being of family caregivers. The aim of this paper is to uncover the challenges faced by family caregivers and support their well-being with the use of technologies. To understand the emotional and social burden of caregivers and how they handle their stress, we conducted in-depth interviews with 15 individuals who have cared for a depressed family member. Our findings reveal the multifaceted dilemma of caring for a depressed family member as well as the various strategies engaged in by caregivers to improve their own situations. Based on our findings, we suggest design implications for healthcare technologies to improve the wellness of caregivers who are looking after depressed family members.",
        "cbStatement": "Uncovers the challenges faced by family caregivers of depressed sufferes. Suggest design implications for technologies to improve the wellness of such family caregivers.",
        "bookmarks": 119,
        "keywords": [
            "Depression",
            "family caregivers",
            "stress",
            "healthcare technology."
        ],
        "communities": [],
        "video": "chi1768-file5.mp4",
        "session": {
            "id": "s297",
            "name": "Desing in a Psychiatric Setting"
        },
        "room": "242ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth7086",
                "givenName": "Naomi",
                "familyName": "Yamashita",
                "email": "naomiy@acm.org",
                "primary": {
                    "institution": "NTT Communication Science Laboratories",
                    "city": "Soraku-gun",
                    "state": "Kyoto",
                    "country": "Japan"
                },
                "role": "presenter"
            },
            {
                "id": "auth2965",
                "givenName": "Hideaki",
                "familyName": "Kuzuoka",
                "email": "kuzuoka@iit.tsukuba.ac.jp",
                "primary": {
                    "institution": "University of Tsukuba",
                    "city": "Tsukuba",
                    "state": "Ibaraki",
                    "country": "Japan"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30160",
                "givenName": "Keiji",
                "familyName": "Hirata",
                "email": "hirata@fun.ac.jp",
                "primary": {
                    "institution": "Future University Hakodate",
                    "city": "Hakodate",
                    "country": "Japan"
                }
            },
            {
                "id": "auth30161",
                "givenName": "Takashi",
                "familyName": "Kudo",
                "email": "takashikudo33@gmail.com",
                "primary": {
                    "dept": "Department of Psychiatry",
                    "institution": "Osaka University",
                    "city": "Osaka",
                    "country": "Japan"
                }
            }
        ]
    },
    {
        "id": 262,
        "name": "The Challenges and Potential of End-User Gesture Customization",
        "type": "paper",
        "abstract": "The vast majority of work on understanding and supporting the gesture creation process has focused on professional designers. In contrast, gesture customization by end users—which may offer better memorability, efficiency and accessibility than pre-defined gestures—has received little attention. To understand the end-user gesture creation process, we conducted a study where 20 participants were asked to: (1) exhaustively create new gestures for an open-ended use case; (2) exhaustively create new gestures for 12 specific use cases; (3) judge the saliency of different touchscreen gesture features. Our findings showed that even when asked to create novel gestures, participants tended to focus on the familiar. Misconceptions about the gesture recognizer’s abilities were also evident, and in some cases constrained the range of gestures that participants created. Finally, as a calibration point for future research, we used a simple gesture recognizer ($N) to analyze recognition accuracy of the participants’ custom gesture sets: accuracy was 68–88% on average, depending on the amount of training and the customization scenario. We conclude with implications for the design of a mixed-initiative approach to support custom gesture creation.",
        "cbStatement": "We present a study on end-user gesture creation to understand users’ thought processes and the challenges encountered. Our findings provide insight for how to better support gesture customization. ",
        "bookmarks": 170,
        "keywords": [
            " Touchscreen",
            "gestures",
            "customization",
            "personalization",
            ""
        ],
        "communities": [
            "ux"
        ],
        "video": "chi1770-file5.mp4",
        "session": {
            "id": "s253",
            "name": "Gestures studies / empirical"
        },
        "room": "241",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth29638",
                "givenName": "Uran",
                "familyName": "Oh",
                "email": "uranoh@cs.umd.edu",
                "primary": {
                    "dept": "Human Computer Interaction Lab",
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth3198",
                "givenName": "Leah",
                "familyName": "Findlater",
                "email": "leah.findlater@gmail.com",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 263,
        "name": "Improving Digital Object Handoff Using the Space Above the Table",
        "type": "paper",
        "abstract": "Object handoff – that is, passing an object or tool to another person – is an extremely common activity in collaborative tabletop work. On digital tables, object handoff is typically accomplished by sliding them on the table surface – but surface-only interactions can be slow and error-prone, particularly when there are multiple people carrying out multiple handoffs. An alternative approach is to use the space above the table for object handoff; this provides more room to move, but requires above-surface tracking. We have developed two above-the-surface handoff techniques that use simple and inexpensive tracking: a force-field technique that uses a depth camera to determine hand proximity, and an electromagnetic-field technique called ElectroTouch that provides positive indication when people touch hands over the table. We compared the new techniques to three kinds of surface-only handoff (sliding, flicking, and surface-only Force-Fields). The study showed that the above-surface techniques significantly improved both speed and accuracy, and that ElectroTouch was the best technique overall. This work provides designers with practical new techniques for substantially increasing performance and interaction richness on digital tables.",
        "cbStatement": "We developed and evaluated two new above-the-table digital object handoff techniques, Force-Field and a new innovation ElectroTouch, and found they are significantly faster and less error-prone than traditional surface-only techniques.",
        "bookmarks": 178,
        "keywords": [
            "Digital tables",
            "coordination",
            "digital object handoff"
        ],
        "communities": [],
        "video": "chi0179-file5.mp4",
        "session": {
            "id": "s223",
            "name": "Table and Floors"
        },
        "room": "352ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth28800",
                "givenName": "Steven",
                "middleInitial": "W.T.",
                "familyName": "Sutcliffe",
                "email": "steve.sutcliffe@usask.ca",
                "primary": {
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth28604",
                "givenName": "Zenja",
                "familyName": "Ivkovic",
                "email": "izenja@gmail.com",
                "primary": {
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                }
            },
            {
                "id": "auth12764",
                "givenName": "David",
                "middleInitial": "R",
                "familyName": "Flatla",
                "email": "david.flatla@usask.ca",
                "primary": {
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1892",
                "givenName": "Andriy",
                "familyName": "Pavlovych",
                "email": "andriyp@gmail.com",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                }
            },
            {
                "id": "auth14075",
                "givenName": "Ian",
                "familyName": "Stavness",
                "email": "stavness@cs.usask.ca",
                "primary": {
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                }
            },
            {
                "id": "auth1181",
                "givenName": "Carl",
                "familyName": "Gutwin",
                "email": "gutwin@cs.usask.ca",
                "primary": {
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 264,
        "name": "Community Insights: Helping Community Leaders Enhance the Value of Enterprise Online Communities",
        "type": "paper",
        "abstract": "Online communities are increasingly being deployed in enterprises to increase productivity and share expertise. Community leaders are critical for fostering successful communities, but existing technologies rarely support leaders directly, both because of a lack of clear data about leader needs, and because existing tools are member- rather than leader-centric. We present the evidence-based design and evaluation of a novel tool for community leaders, Community Insights (CI). CI provides actionable analytics that help community leaders foster healthy communities, providing value to both members and the organization. We describe empirical and system contributions derived from a long-term deployment of CI to leaders of 470 communities over 10 months. Empirical contributions include new data showing: (a) which metrics are most useful for leaders to assess community health, (b) the need for and how to design actionable metrics, (c) the need for and how to design contextualized analytics to support sensemaking about community data. These findings motivate a novel community system that provides leaders with useful, actionable and contextualized analytics.",
        "cbStatement": "Evidence-based design and evaluation of a novel tool that provides community leaders with useful, actionable, and contextualized analytics. Benefits designers of and practitioners using analytic tools to foster successful communities.",
        "bookmarks": 3,
        "keywords": [
            "Online communities",
            "community leaders",
            "iterative design",
            "system evaluation",
            "enterprise",
            "workplace."
        ],
        "communities": [],
        "video": "chi1800-file5.mp4",
        "session": {
            "id": "s201",
            "name": "Enterprise and online communities: the best of both worlds"
        },
        "room": "havane",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth4598",
                "givenName": "Tara",
                "familyName": "Matthews",
                "email": "tlmatthe@us.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth13221",
                "givenName": "Steve",
                "familyName": "Whittaker",
                "email": "stevejohnwhittaker@gmail.com",
                "primary": {
                    "dept": "HCI Lab",
                    "institution": "University of California at Santa Cruz",
                    "city": "Santa Cruz",
                    "state": "California",
                    "country": "USA"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth16430",
                "givenName": "Hernan",
                "familyName": "Badenes",
                "email": "hbadenes@ar.ibm.com",
                "primary": {
                    "institution": "IBM",
                    "city": "Buenos Aires",
                    "country": "Argentina"
                }
            },
            {
                "id": "auth29584",
                "givenName": "Barton",
                "middleInitial": "A.",
                "familyName": "Smith",
                "email": "barton.smith@us.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth1047",
                "givenName": "Michael",
                "familyName": "Muller",
                "email": "michael_muller@us.ibm.com",
                "primary": {
                    "institution": "IBM",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth1318",
                "givenName": "Kate",
                "familyName": "Ehrlich",
                "email": "katee@us.ibm.com",
                "primary": {
                    "institution": "IBM",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth4587",
                "givenName": "Michelle",
                "middleInitial": "X.",
                "familyName": "Zhou",
                "email": "mzhou@us.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "IBM Research",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth5106",
                "givenName": "Tessa",
                "familyName": "Lau",
                "email": "tlau@tlau.org",
                "primary": {
                    "institution": "Willow Garage",
                    "city": "Menlo Park",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 265,
        "name": "Visual Challenges in the Everyday Lives of Blind People",
        "type": "paper",
        "abstract": "The challenges faced by blind people in their everyday lives are not well understood. In this paper, we report on the findings of a large-scale study of the visual questions that blind people would like to have answered. As part of this year-long study, 5,329 blind users asked 40,748 questions about photographs that they took from their iPhones using an application called VizWiz Social. We present a taxonomy of the types of questions asked, report on a number of features of the questions and accompanying photographs, and discuss how individuals changed how they used VizWiz Social over time. These results improve our understanding of the problems blind people face, and may help motivate new projects more accurately targeted to help blind people live more independently in their everyday lives.",
        "cbStatement": "Our results improve the understanding of the visual problems blind people face everyday by examining a sample of the 40,000 questions asked by blind VizWiz Social users.",
        "bookmarks": 106,
        "keywords": [
            "Blind Users",
            "Q&A",
            "Accessibility",
            "Crowdsourcing",
            "Mobile"
        ],
        "communities": [],
        "video": "chi0181-file5.mp4",
        "session": {
            "id": "s292",
            "name": "Blindness and Design"
        },
        "room": "242ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth25134",
                "givenName": "Erin",
                "familyName": "Brady",
                "email": "brady@cs.rochester.edu",
                "primary": {
                    "institution": "University of Rochester",
                    "city": "Rochester",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth2137",
                "givenName": "Meredith",
                "middleInitial": "Ringel",
                "familyName": "Morris",
                "email": "merrie@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth25904",
                "givenName": "Yu",
                "familyName": "Zhong",
                "email": "zyu@cs.rochester.edu",
                "primary": {
                    "institution": "University of Rochester",
                    "city": "Rochester",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth16204",
                "givenName": "Samuel",
                "middleInitial": "C",
                "familyName": "White",
                "email": "samuel.white@rochester.edu",
                "primary": {
                    "institution": "University of Rochester",
                    "city": "Rochester",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth8964",
                "givenName": "Jeffrey",
                "middleInitial": "P",
                "familyName": "Bigham",
                "email": "jbigham@cs.rochester.edu",
                "primary": {
                    "institution": "University of Rochester",
                    "city": "Rochester",
                    "state": "New York",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 266,
        "name": "TapBoard: Making a Touch Screen Keyboard More Touchable",
        "type": "paper",
        "abstract": "A physical keyboard key has three states, whereas a touch screen usually has only two. Due to this difference, the state corresponding to the touched state of a physical key is missing in a touch screen keyboard. This touched state is an important factor in the usability of a keyboard. In order to recover the role of a touched state in a touch screen, we propose the TapBoard, a touch screen software keyboard that regards tapping actions as keystrokes and other touches as the touched state. In a series of user studies, we validate the effectiveness of the TapBoard concept. First, we show that tapping to type is in fact compatible with the existing typing skill of most touch screen keyboard users. Second, users quickly adapt to the TapBoard and learn to rest their fingers in the touched state. Finally, we confirm by a controlled experiment that there is no difference in text-entry performance between the TapBoard and a traditional touch screen software keyboard. In addition to these experimental results, we demonstrate a few new interaction techniques that will be made possible by the TapBoard.",
        "cbStatement": "TapBoard is a touch screen software keyboard that regards tapping actions as keystrokes and enables other touches for more useful operations; such as resting, feeling surface textures, and making gestures.",
        "bookmarks": 164,
        "keywords": [
            "TapBoard",
            "text-entry method",
            "touch screen keyboard"
        ],
        "communities": [
            "engineering"
        ],
        "video": "chi1813-file5.mp4",
        "session": {
            "id": "s255",
            "name": "Hotkeys / Touch keyboards"
        },
        "room": "241",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth15397",
                "givenName": "Sunjun",
                "familyName": "Kim",
                "email": "kuaa.net@gmail.com",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                },
                "role": "presenter"
            },
            {
                "id": "auth25796",
                "givenName": "Jeongmin",
                "familyName": "Son",
                "email": "jenius17@kaist.ac.kr",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth5474",
                "givenName": "Geehyuk",
                "familyName": "Lee",
                "email": "geehyuk@gmail.com",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                }
            },
            {
                "id": "auth25834",
                "givenName": "Hwan",
                "familyName": "Kim",
                "email": "iamhwankim@gmail.com",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                }
            },
            {
                "id": "auth2551",
                "givenName": "Woohun",
                "familyName": "Lee",
                "email": "leewh@kaist.ac.kr",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                }
            }
        ]
    },
    {
        "id": 267,
        "name": "Beyond Being Green: Simple Living Families and ICT",
        "type": "paper",
        "abstract": "Motivated by a need in sustainable HCI for studies of everyday practices, and a belief that a holistic view on sustainability is crucial to deeper understanding of how to design ICT to support sustainability, we here present a qualitative study of 11 simple living families in the US. Simple living refers to a lifestyle which is voluntarily simple out of concern for both the environment and quality of life. Our goal was to learn about a holistic view on sustainability and the role of ICT in helping and hindering families to live simply. The study contributes new insights about how holistic sustainability could be a valuable lens for HCI, revealing that sustainability is important to a wider range of areas in HCI than previously discussed. We conclude with implications for HCI for how to support sustainable practices beyond being “about” being green.",
        "cbStatement": "Presents a qualitative study of simple living families' practices and use of ICT. Demonstrates how a holistic perspective on sustainability broadens opportunities for \"green\" design in HCI.",
        "bookmarks": 172,
        "keywords": [
            "Sustainability",
            "sustainable HCI",
            "simple living",
            "families",
            "qualitative studies",
            "holistic sustainability"
        ],
        "communities": [
            "sustainability"
        ],
        "video": "chi1817-file5.mp4",
        "session": {
            "id": "s261",
            "name": "Sustainability / MISC"
        },
        "room": "bordeaux",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth2451",
                "givenName": "Maria",
                "familyName": "Håkansson",
                "email": "mch267@cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Södertörn University",
                    "city": "Huddinge",
                    "country": "Sweden"
                },
                "role": "presenter"
            },
            {
                "id": "auth1423",
                "givenName": "Phoebe",
                "familyName": "Sengers",
                "email": "pjs54@cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 268,
        "name": "A Conversation Between Trees: What Data Feels Like In The Forest",
        "type": "paper",
        "abstract": "A study of an interactive artwork shows how artists engaged the public with scientific climate change data. The artwork visualised live environmental data collected from remote trees, alongside both historical and forecast global CO2 data. Visitors also took part in a mobile sensing experience in a nearby forest. Our study draws on the perspectives of the artists, visitors and a climate scientist to reveal how the work was designed and experienced. We show that the artists adopted a distinct approach that fostered an emotional engagement with data rather than an informative or persuasive one. We chart the performative strategies they used to achieve this including sensory engagement with data, a temporal structure that balanced liveness with slowness, and the juxtaposition of different treatments of the data to enable interpretation and dialogue.",
        "cbStatement": "Study of an environmentally engaged artwork reveals how artists’ strategies of embodying, performing and juxtaposing different views of climate data fostered emotional engagement and interpretation among visitors.",
        "bookmarks": 120,
        "keywords": [
            "Environmentally engaged art, sustainability, climate, slowness, liveness, sensory, embodied, performance"
        ],
        "communities": [
            "sustainability",
            "arts"
        ],
        "video": "chi1818-file5.mp4",
        "session": {
            "id": "s246",
            "name": "Touching Experiences: tangible computing & trajectories"
        },
        "room": "351",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth30186",
                "givenName": "Rachel",
                "familyName": "Jacobs",
                "email": "rachel@active-ingredient.co.uk",
                "primary": {
                    "dept": "Mixed Reality Laboratory",
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                },
                "secondary": {
                    "institution": "Active Ingredient",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth1508",
                "givenName": "Steve",
                "familyName": "Benford",
                "email": "sdb@cs.nott.ac.uk",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "state": "Nottinghamshire",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth16125",
                "givenName": "Mark",
                "familyName": "Selby",
                "email": "psxms3@nottingham.ac.uk",
                "primary": {
                    "dept": "Mixed Reality Laboratory",
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth26047",
                "givenName": "Michael",
                "familyName": "Golembewski",
                "email": "mike.golembewski@gmail.com",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth32984",
                "givenName": "Dominic",
                "familyName": "Price",
                "email": "dominic.price@notttingham.ac.uk",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth20716",
                "givenName": "Gabriella",
                "familyName": "Giannachi",
                "email": "g.giannachi@exeter.ac.uk",
                "primary": {
                    "institution": "The University of Exeter",
                    "city": "Exeter",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 269,
        "name": "Combining Crowdsourcing and Google Street View to Identify Street-level Accessibility Problems",
        "type": "paper",
        "abstract": "Poorly maintained sidewalks, missing curb ramps, and other obstacles pose considerable accessibility challenges; however, there are currently few, if any, mechanisms to determine accessible areas of a city a priori. In this paper, we investigate the feasibility of using untrained crowd workers from Amazon Mechanical Turk (turkers) to find, label, and assess sidewalk accessibility problems in Google Street View imagery. We report on two studies: Study 1 examines the feasibility of this labeling task with six dedicated labelers including three wheelchair users; Study 2 investigates the comparative performance of turkers. In all, we collected 13,379 labels and 19,189 verification labels from a total of 402 turkers. We show that turkers are capable of determining the presence of an accessibility problem with 81% accuracy. With simple quality control methods, this number increases to 93%. Our work demonstrates a promising new, highly scalable method for acquiring knowledge about sidewalk accessibility.",
        "cbStatement": "In this paper, we investigate the feasibility of using untrained crowd workers from Amazon Mechanical Turk (turkers) to find, label, and assess sidewalk accessibility problems in Google Street View imagery",
        "bookmarks": 25,
        "keywords": [
            "Crowdsourcing accessibility, accessible urban navigation, Google Street View, Mechanical Turk, data collection"
        ],
        "communities": [],
        "session": {
            "id": "s204",
            "name": "Smart Tools for Smart Work Environments: working with the crowds"
        },
        "room": "havane",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth22643",
                "givenName": "Kotaro",
                "familyName": "Hara",
                "email": "kotaro@cs.umd.edu",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30206",
                "givenName": "Vicki",
                "familyName": "Le",
                "email": "vnle@umd.edu",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                }
            },
            {
                "id": "auth6165",
                "givenName": "Jon",
                "familyName": "Froehlich",
                "email": "jonf@cs.umd.edu",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 270,
        "name": "Democratizing Technology: Pleasure, Utility and Expressiveness in DIY and Maker Practice",
        "type": "paper",
        "abstract": "DIY, hacking, and craft have recently drawn attention in HCI and CSCW, largely as a collaborative and creative hobbyist practice. We shift the focus from the recreational elements of this practice to the ways in which it democratizes design and manufacturing. This democratized technological practice, we argue, unifies playfulness, utility, and expressiveness, relying on some industrial infrastructures while creating demand for new types of tools and literacies. Thriving on top of collaborative digital systems, the Maker movement both implicates and impacts professional designers. As users move more towards personalization and reappropriation, new design opportunities are created for HCI.",
        "cbStatement": "A critical analysis of the practices, values, and politics of Maker and DIY Culture and its implications for HCI Research.",
        "bookmarks": 85,
        "keywords": [
            "DIY",
            "Appropriation",
            "Design Theory",
            "Maker Culture",
            "Steampunk",
            "Hacking",
            "Craft"
        ],
        "communities": [
            "design"
        ],
        "video": "chi1843-file5.mp4",
        "session": {
            "id": "s227",
            "name": "Fabrication"
        },
        "room": "352ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth17138",
                "givenName": "Joshua",
                "middleInitial": "G",
                "familyName": "Tanenbaum",
                "email": "joshuat@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth6203",
                "givenName": "Amanda",
                "middleInitial": "M",
                "familyName": "Williams",
                "email": "metamanda@gmail.com",
                "primary": {
                    "institution": "Wyld Collective Ltd",
                    "city": "Montréal",
                    "state": "Quebec",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth19949",
                "givenName": "Audrey",
                "familyName": "Desjardins",
                "email": "adesjard@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            },
            {
                "id": "auth11743",
                "givenName": "Karen",
                "familyName": "Tanenbaum",
                "email": "karen.tanenbaum@gmail.com",
                "primary": {
                    "dept": "Interactive Arts & Technology",
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "secondary": {
                    "dept": "Interaction & Experience Research",
                    "institution": "Intel Labs",
                    "city": "Hillsboro ",
                    "state": "Oregon",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 271,
        "name": "Preference-based Location Sharing: Are More Privacy Options Really Better?",
        "type": "paper",
        "abstract": "We examine the effect of coarse-grained vs. fine-grained location sharing options on users’ disclosure decisions when configuring a sharing profile in a location-sharing service. Our results from an online user experiment (N=291) indicate that users who would otherwise select one of the finer-grained options will employ a compensatory decision strategy when this option is removed. This means that they switch either in the direction of more privacy and less benefit, or less privacy and more benefit, depending on the subjective distance between the omitted option and the remaining options. This explanation of users’ disclosure behavior is in line with fundamental decision theories, as well as the well-established notion of “privacy calculus”. Two alternative hypotheses that we tested were not supported by our experimental data.",
        "cbStatement": "Users of a location-sharing service opt for more or less granular disclosure when one granularity level is omitted, depending on the subjective distance between the omitted and remaining options.",
        "bookmarks": 8,
        "keywords": [
            "privacy calculus",
            "information disclosure",
            "decision making",
            "location-sharing services"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi1845-file5.mp4",
        "session": {
            "id": "s275",
            "name": "Consent and Integrity"
        },
        "room": "251",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth9061",
                "givenName": "Bart",
                "middleInitial": "P",
                "familyName": "Knijnenburg",
                "email": "bart.k@uci.edu",
                "primary": {
                    "dept": "Donald Bren School of Information and Computer Sciences",
                    "institution": "University of California, Irvine",
                    "city": "Irvine",
                    "state": "California",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Samsung R&D Research Center",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth3608",
                "givenName": "Alfred",
                "familyName": "Kobsa",
                "email": "kobsa@uci.edu",
                "primary": {
                    "dept": "Donald Bren School of Information and Computer Sciences",
                    "institution": "University of California, Irvine",
                    "city": "Irvine",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30260",
                "givenName": "Hongxia",
                "familyName": "Jin",
                "email": "hongxia.jin@sisa.samsung.com",
                "primary": {
                    "institution": "Samsung R&D Research Center",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 272,
        "name": "Pirates of the Search Results Page",
        "type": "paper",
        "abstract": "Search malware redirects nearly 100% of infected users’ clicks on web search results to unintended websites. Most published research details how web-based malware works and technological interventions to stop it before users ever see it; however, the constant evolution of obfuscation techniques makes it difficult to prevent infection altogether. User interventions in the form of toolbars, dialogs, and user education have seen limited success. Previous research has focused on a prototypical type of malware; a sophisticated program that conceals itself (e.g., surreptitious download onto a host computer) or tries to fool the user by mimicking known, trusted websites (e.g., phishing attacks). The goal of our research is to understand users’ experience, understanding of and response to search malware. The present research shows that even when confronted with blatantly unusual search behavior, people are unlikely to attribute blame to malware or to engage in behavior that may remedy the situation.",
        "cbStatement": "Usability evaluation and interview findings provide insight into users’ experiences, behaviors, and self-blame in response to search malware; suggests domain familiarity is not enough to recognize a malware-impaired experience.",
        "bookmarks": 195,
        "keywords": [
            "Search malware",
            "user experience",
            "redirect",
            "detection"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi1846-file5.mp4",
        "session": {
            "id": "s265",
            "name": "Search and Find"
        },
        "room": "havane",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth5922",
                "givenName": "Kathy",
                "middleInitial": "K",
                "familyName": "Baxter",
                "email": "kathykbaxter@gmail.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30227",
                "givenName": "Lori",
                "middleInitial": "Wu",
                "familyName": "Malahy",
                "email": "loriwu@gmail.com",
                "primary": {
                    "dept": "Department of Psychology",
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth34802",
                "givenName": "Jeremy",
                "familyName": "Lubin",
                "email": "jeremy.lubin@gmail.com",
                "primary": {
                    "institution": "Capriza",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 273,
        "name": "Indirect Shear Force Estimation for Multi-Point Shear Force Operations",
        "type": "paper",
        "abstract": "The possibility of using shear forces is being explored recently as a method to enrich touch screen interaction. However, most of the related studies are restricted to the case of single-point shear forces, possibly owing to the difficulty of independently sensing shear forces at multiple touch points. In this paper, we propose indirect methods to estimate shear forces using the movement of contact areas. These methods enable multi-point shear force estimation, where the estimation is done for each finger independently. We show the feasibility of these methods through an informal user study with a demo application utilizing these methods.",
        "cbStatement": "We designed a novel method to indirectly estimate shear forces at multiple points. We show the feasibility by implementing a prototype and a demo application.",
        "bookmarks": 92,
        "keywords": [
            "Shear force, multi-touch, force sensing, touch screen"
        ],
        "communities": [
            "design",
            "engineering"
        ],
        "video": "chi1873-file5.mp4",
        "session": {
            "id": "s221",
            "name": "Multitouch and Gestures"
        },
        "room": "352ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth10604",
                "givenName": "Seongkook",
                "familyName": "Heo",
                "email": "seongkook@kaist.ac.kr",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                },
                "role": "presenter"
            },
            {
                "id": "auth5474",
                "givenName": "Geehyuk",
                "familyName": "Lee",
                "email": "geehyuk@gmail.com",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 274,
        "name": "The Design Space of Body Games: Technological, Physical, and Social Design.",
        "type": "paper",
        "abstract": "The past decade has seen an increased focus on body movement in computer games. We take a step further to look at body games: games in which the main source of enjoyment comes from bodily engagement. We argue that for these games, the physical and social settings become just as important design resources as the technology. Although all body games benefit from an integrated design approach, the social and physical setting become particularly useful as design resources when the technology has limited sensing capabilities. We develop our understanding of body games through a literature study and a concrete design experiment with designing multiplayer games for the BodyBug, a mobile device with limited sensing capabilities. Although the device was designed for free and natural movements, previous games fell short in realizing this design ideal. By designing the technology function together with its physical and social context, we were able to overcome device limitations. One of the games was subsequently incorporated in its commercial release.",
        "cbStatement": "Movement-based games are in the limelight today. We argue that for these games, the physical and social settings become just as important design resources as the technology.",
        "bookmarks": 106,
        "keywords": [
            "Body Game",
            "Exertion Game",
            "Gesture",
            "Movement",
            "Design",
            "Sensing",
            "Game",
            "Dance",
            "Children",
            "Play",
            "Interactive Toy",
            "BodyBug",
            "Oriboo",
            "Social Play."
        ],
        "communities": [
            "design",
            "ux",
            "games"
        ],
        "video": "chi1874-file5.mp4",
        "session": {
            "id": "s239",
            "name": "Phyisical Excersion"
        },
        "room": "242b",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth23178",
                "givenName": "Elena",
                "familyName": "Márquez Segura",
                "email": "elena@mobilelifecentre.org",
                "primary": {
                    "institution": "Mobile Life @ SICS Swedish ICT AB",
                    "city": "Kista",
                    "country": "Sweden"
                },
                "role": "presenter"
            },
            {
                "id": "auth2725",
                "givenName": "Annika",
                "familyName": "Waern",
                "email": "annikaw@dsv.su.se",
                "primary": {
                    "institution": "Mobile Life @ Stockholm University",
                    "city": "Kista",
                    "country": "Sweden"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth20149",
                "givenName": "Carolina",
                "familyName": "Johansson",
                "email": "carolina.v.b.johansson@gmail.com",
                "primary": {
                    "institution": "Mobile Life @ Stockholm University",
                    "city": "Kista",
                    "country": "Sweden"
                },
                "secondary": {
                    "institution": "Interactive Institute",
                    "city": "Kista",
                    "country": "Sweden"
                }
            },
            {
                "id": "auth30304",
                "givenName": "Jin",
                "familyName": "Moen",
                "email": "jin.moen@movintofun.com",
                "primary": {
                    "dept": "Movinto Fun AB",
                    "institution": "Movinto Fun AB",
                    "city": "Are",
                    "country": "Sweden"
                }
            }
        ]
    },
    {
        "id": 275,
        "name": "Limiting, Leaving, and (re)Lapsing: An Exploration of Facebook Non-Use Practices and Experiences",
        "type": "paper",
        "abstract": "Despite the abundance of research on social networking sites, relatively little research has studied those who choose not to use such sites. This paper presents results from a questionnaire of over 400 Internet users, focusing specifically on Facebook and those users who have left the service. Results show the lack of a clear, binary distinction between use and non-use, that various practices enable diverse ways and degrees of engagement with and disengagement from Facebook. Furthermore, qualitative analysis reveals numerous complex and interrelated motivations and justifications, both for leaving and for maintaining some type of connection. These motivations include: privacy, data misuse, productivity, banality, addiction, and external pressures. These results not only contribute to our understanding of online sociality by examining this under-explored area, but they also build on previous work to help advance how we conceptually account for the sociological processes of non-use.",
        "cbStatement": "This paper reports on a survey about non-use of Facebook. Results show the prevalence of non-use, the variety of types of non-use, and motivations and justifications given for non-use.",
        "bookmarks": 71,
        "keywords": [
            "Facebook",
            "non-use",
            "technology refusal"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi1876-file5.mp4",
        "session": {
            "id": "s200",
            "name": "Online Sorrows Shared: Online dealing with problems"
        },
        "room": "havane",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth7663",
                "givenName": "Eric",
                "middleInitial": "P. S.",
                "familyName": "Baumer",
                "email": "ericpsb@cornell.edu",
                "primary": {
                    "dept": "Communication Department",
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                },
                "secondary": {
                    "dept": "Information Science Department",
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "NY",
                    "country": "United States"
                }
            },
            {
                "id": "auth17522",
                "givenName": "Phil",
                "familyName": "Adams",
                "email": "pja22@cornell.edu",
                "primary": {
                    "dept": "Department of Information Science",
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth18162",
                "givenName": "Vera",
                "middleInitial": "D",
                "familyName": "Khovanskaya",
                "email": "vdk9@cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth30052",
                "givenName": "Tony",
                "middleInitial": "C.",
                "familyName": "Liao",
                "email": "cl566@cornell.edu",
                "primary": {
                    "dept": "Communication",
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "NY",
                    "country": "United States"
                }
            },
            {
                "id": "auth21216",
                "givenName": "Madeline",
                "middleInitial": "E.",
                "familyName": "Smith",
                "email": "madsesmith@u.northwestern.edu",
                "primary": {
                    "institution": "Northwestern University",
                    "city": "Evanston",
                    "state": "Illinois",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth16346",
                "givenName": "Victoria",
                "familyName": "Schwanda Sosik",
                "email": "vls48@cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth15820",
                "givenName": "Kaiton",
                "familyName": "Williams",
                "email": "kaiton@cs.cornell.edu",
                "primary": {
                    "dept": "Information Science",
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 276,
        "name": "GravitySpace: Tracking Users and Their Poses in a Smart Room Using a Pressure-Sensing Floor",
        "type": "paper",
        "abstract": "We explore how to track people and furniture based on a high-resolution pressure-sensitive floor. Gravity pushes people and objects against the floor, causing them to leave imprints of pressure distributions across the surface. While the sensor is limited to sensing direct contact with the surface, we can sometimes conclude what takes place above the surface, such as users’ poses or collisions with virtual objects. We demonstrate how to extend the range of this approach by sensing through passive furniture that propagates pressure to the floor. To explore our approach, we have created an 8 m2 back-projected floor prototype, termed GravitySpace, a set of passive touch-sensitive furniture, as well as algorithms for identifying users, furniture, and poses. Pressure-based sensing on the floor offers four potential benefits over camera-based solutions: (1) it provides consistent coverage of rooms wall-to-wall, (2) is less susceptible to occlusion between users, (3) allows for the use of simpler recognition algorithms, and (4) intrudes less on users’ privacy.",
        "cbStatement": "Introduces new approach to tracking people and objects in smart rooms based on a high-resolution pressure-sensitive floor. Provides consistent wall-to-wall coverage, is less susceptible and less privacy-critical than camera-based systems.",
        "bookmarks": 146,
        "keywords": [
            "iInteractive floor",
            "smart rooms",
            "ubicomp",
            "multitoe",
            "multitouch",
            "FTIR",
            "tabletop",
            "vision"
        ],
        "communities": [
            "engineering"
        ],
        "video": "chi1883-file5.mp4",
        "session": {
            "id": "s223",
            "name": "Table and Floors"
        },
        "room": "352ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth30220",
                "givenName": "Alan",
                "familyName": "Bränzel",
                "email": "alan.braenzel@student.hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                }
            },
            {
                "id": "auth12941",
                "givenName": "Christian",
                "familyName": "Holz",
                "email": "christian.holz@hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30203",
                "givenName": "Daniel",
                "familyName": "Hoffmann",
                "email": "daniel.hoffmann@student.hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                }
            },
            {
                "id": "auth28799",
                "givenName": "Dominik",
                "familyName": "Schmidt",
                "email": "dominik.schmidt@hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth28509",
                "givenName": "Marius",
                "familyName": "Knaust",
                "email": "marius.knaust@student.hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                }
            },
            {
                "id": "auth30198",
                "givenName": "Patrick",
                "familyName": "Lühne",
                "email": "patrick.luehne@student.hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                }
            },
            {
                "id": "auth30204",
                "givenName": "René",
                "familyName": "Meusel",
                "email": "rene.meusel@student.hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                }
            },
            {
                "id": "auth23243",
                "givenName": "Stephan",
                "middleInitial": "R",
                "familyName": "Richter",
                "email": "stephan.richter@student.hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                }
            },
            {
                "id": "auth1437",
                "givenName": "Patrick",
                "familyName": "Baudisch",
                "email": "patrick.baudisch@hpi.uni-potsdam.de",
                "primary": {
                    "institution": "Hasso Plattner Institute",
                    "city": "Potsdam",
                    "country": "Germany"
                }
            }
        ]
    },
    {
        "id": 277,
        "name": "Categorised Ethical Guidelines for Large Scale Mobile HCI",
        "type": "paper",
        "abstract": "The recent rise in large scale trials of mobile software using `app stores' has moved current researcher practice beyond available ethical guidelines. By surveying this recent and growing body of literature, as well as established professional principles adopted in psychology, we propose a set of ethical guidelines for large scale HCI user trials. These guidelines come in two parts: a set of general principles and a framework into which individual app store-based trials can be assessed and ethical concerns exposed. We categorise existing literature using our scheme, and explain how researchers could use our framework to classify their future user trials to determine ethical responsibility, and the steps required to meet these obligations. ",
        "cbStatement": "A discussion of ethical challenges in large scale mobile HCI trials. We identify anonymisation and user expectation as key factors and present proportional guidelines that reflect risks in these areas.",
        "bookmarks": 165,
        "keywords": [
            "Ethics",
            "large-scale trials",
            "mass participation",
            "app stores"
        ],
        "communities": [],
        "video": "chi1894-file5.mp4",
        "session": {
            "id": "s278",
            "name": "HCI Ethics"
        },
        "room": "351",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth15587",
                "givenName": "Donald",
                "familyName": "McMillan",
                "email": "don@desl.co.uk",
                "primary": {
                    "dept": "Mobile Life Centre",
                    "institution": "Mobile Life @ Stockholm University",
                    "city": "Kista",
                    "state": "Stockholm",
                    "country": "Sweden"
                },
                "role": "presenter"
            },
            {
                "id": "auth6348",
                "givenName": "Alistair",
                "familyName": "Morrison",
                "email": "alistair.morrison@glasgow.ac.uk",
                "primary": {
                    "institution": "University of Glasgow",
                    "city": "Glasgow",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth3404",
                "givenName": "Matthew",
                "familyName": "Chalmers",
                "email": "matthew@dcs.gla.ac.uk",
                "primary": {
                    "institution": "University of Glasgow",
                    "city": "Glasgow",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 278,
        "name": "Analyzing User-Generated YouTube Videos to Understand Touchscreen Use by People with Motor Impairments",
        "type": "paper",
        "abstract": "Most work on the usability of touchscreen interaction for people with motor impairments has focused on lab studies with relatively few participants and small cross-sections of the population. To develop a richer characterization of use, we turned to a previously untapped source of data: YouTube videos. We collected and analyzed 187 non-commercial videos uploaded to YouTube that depicted a person with a physical disability interacting with a mainstream mobile touchscreen device. We coded the videos along a range of dimensions to characterize the interaction, the challenges encountered, and the adaptations being adopted in daily use. To complement the video data, we also invited the video uploaders to complete a survey on their ongoing use of touchscreen technology. Our findings show that, while many people with motor impairments find these devices empowering, accessibility issues still exist. In addition to providing implications for more accessible touchscreen design, we reflect on the application of user-generated content to study user interface design.",
        "cbStatement": "To inform accessible touchscreen design, we analyzed 187 YouTube videos depicting people with physical disabilities interacting with mobile touchscreen devices. We report on challenges observed and user-initiated adaptations being made.",
        "bookmarks": 137,
        "keywords": [
            "Touchscreen",
            "motor impairments",
            "physical disabilities",
            "assistive technology",
            "YouTube",
            "iPad",
            "iPhone"
        ],
        "communities": [],
        "video": "chi0190-file5.mp4",
        "session": {
            "id": "s291",
            "name": "Impairment and Rehabilitation"
        },
        "room": "242ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth3141",
                "givenName": "Lisa",
                "familyName": "Anthony",
                "email": "lanthony@umbc.edu",
                "primary": {
                    "dept": "Information Systems Department",
                    "institution": "University of Maryland, Baltimore County",
                    "city": "Baltimore",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth29560",
                "givenName": "YooJin",
                "familyName": "Kim",
                "email": "ykim0710@umd.edu",
                "primary": {
                    "dept": "College of Information Studies",
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                }
            },
            {
                "id": "auth3198",
                "givenName": "Leah",
                "familyName": "Findlater",
                "email": "leah.findlater@gmail.com",
                "primary": {
                    "dept": "College of Information Studies",
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 279,
        "name": "Analyzing Crowd Workers in Mobile Pay-for-Answer Q&A",
        "type": "paper",
        "abstract": "Despite the popularity of mobile pay-for-answer Q&A services, little is known about the people who answer questions on these services. In this paper we examine 18.8 million question and answer pairs from Jisiklog, the largest mobile pay-foranswer Q&A service in Korea, and the results of a complementary survey study of 245 Jisiklog workers. The data are used to investigate key motivators of participation, working strategies of experienced users, and longitudinal interaction dynamics. We find that answerers are rarely motivated by social factors but are motivated by financial incentives and intrinsic motives. Additionally, although answers are provided quickly, an answerer's topic selection tends to be broad, with experienced workers employing unique strategies to answer questions and judge relevance. Finally, analysis of longitudinal working patterns and community dynamics demonstrate the robustness of mobile pay-for-answer Q&A. These findings have significant implications on the design of mobile pay-for-answer Q&A.",
        "cbStatement": "We studied one of the largest mobile pay-for-answer Q&A services called Jisiklog to understand behaviors of crowdworkers: key motivators of participation, working strategies of experienced users, and longitudinal interaction dynamics.",
        "bookmarks": 139,
        "keywords": [
            "Mobile Pay-for-Answer Q&A",
            "User Behavior"
        ],
        "communities": [],
        "video": "chi1901-file5.mp4",
        "session": {
            "id": "s201",
            "name": "Enterprise and online communities: the best of both worlds"
        },
        "room": "havane",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth22799",
                "givenName": "Uichin",
                "familyName": "Lee",
                "email": "uclee@kaist.edu",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                },
                "role": "presenter"
            },
            {
                "id": "auth27729",
                "givenName": "Jihyoung",
                "familyName": "Kim",
                "email": "jhkim@cs.ucla.edu",
                "primary": {
                    "institution": "University of California, Los Angeles",
                    "city": "Los Angeles",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth22783",
                "givenName": "Eunhee",
                "familyName": "Yi",
                "email": "eunhee.yi@kaist.ac.kr",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth27704",
                "givenName": "Juyup",
                "familyName": "Sung",
                "email": "juyup.sung@kaist.ac.kr",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "state": "Daejeon-si",
                    "country": "Republic of Korea"
                }
            },
            {
                "id": "auth30803",
                "givenName": "Mario",
                "familyName": "Gerla",
                "email": "gerla@cs.ucla.edu",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "University of California, Los Angeles",
                    "city": "Los Angeles",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 280,
        "name": "The Effect of Time-based Cost of Error in Target-directed Pointing Tasks",
        "type": "paper",
        "abstract": "One of the fundamental operations in today’s user interfaces is pointing to targets, such as menus, buttons, and text. Making an error when selecting those targets in real-life user interfaces often results in some cost to the user. However, the existing target-directed pointing models do not consider the cost of error when predicting task completion time. In this paper, we present a model based on expected value theory that predicts the impact of the error cost on the user’s completion time for target-directed pointing tasks. We then present a target-directed pointing user study, which results show that time-based costs of error significantly impact the user’s performance. Our results also show that users perform according to an expected completion time utility function and that optimal performance computed using our model gives good prediction of the observed task completion times.",
        "cbStatement": "This paper present a model based on Fitts’ law that predicts the impact of the error cost on the user’s task completion time for target-directed pointing tasks.",
        "bookmarks": 1,
        "keywords": [
            "Fitts’ law",
            "movement time",
            "pointing time",
            "pointing errors",
            "error cost",
            "speed-accuracy tradeoff"
        ],
        "communities": [],
        "video": "chi1903-file5.mp4",
        "session": {
            "id": "s252",
            "name": "Pointing and Fitts Law"
        },
        "room": "241",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth18709",
                "givenName": "Nikola",
                "familyName": "Banovic",
                "email": "nbanovic@cs.cmu.edu",
                "primary": {
                    "dept": "Human-Computer Interaction Institute",
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Autodesk Research",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth1476",
                "givenName": "Tovi",
                "familyName": "Grossman",
                "email": "tovi.grossman@autodesk.com",
                "primary": {
                    "institution": "Autodesk Research",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1229",
                "givenName": "George",
                "familyName": "Fitzmaurice",
                "email": "George.Fitzmaurice@autodesk.com",
                "primary": {
                    "institution": "Autodesk Research",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 281,
        "name": "A Longitudinal Study of Follow Predictors on Twitter",
        "type": "paper",
        "abstract": "Follower count is important to Twitter users: it can indicate popularity and prestige. Yet, holistically, little is understood about what factors – like social behavior, message content, and network structure – lead to more followers. Such information could help technologists design and build tools that help users grow their audiences. In this paper, we study 507 Twitter users and a half-million of their tweets over 15 months. Marrying a longitudinal approach with a negative binomial auto-regression model, we find that variables for message content, social behavior, and network structure should be given equal consideration when predicting link formations on Twitter.  To our knowledge, this is the first longitudinal study of follow predictors, and the first to show that the relative contributions of social behavior and message content are just as impactful as factors related to social network structure for predicting growth of online social networks. We conclude with practical and theoretical implications for designing social media technologies. ",
        "cbStatement": "Comparing across many variables related to message content, social behavior, and network structure allows us to interpret their relative effect on follower growth from different theoretical perspectives.",
        "bookmarks": 199,
        "keywords": [
            "Social networks",
            "social media",
            "computer-mediated communication"
        ],
        "communities": [],
        "video": "chi1907-file5.mp4",
        "session": {
            "id": "s210",
            "name": "Creative Source Unitied: Crowdsourcing used in colaborative creation"
        },
        "room": "bordeaux",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth30301",
                "givenName": "C.J.",
                "familyName": "Hutto",
                "email": "cjhutto@gatech.edu",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth7571",
                "givenName": "Eric",
                "familyName": "Gilbert",
                "email": "gilbert@cc.gatech.edu",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth28619",
                "givenName": "Sarita Yardi",
                "familyName": "Schoenebeck",
                "email": "yardi@umich.edu",
                "primary": {
                    "dept": "School of Information",
                    "institution": "University of Michigan",
                    "city": "Ann Arbor",
                    "state": "Michigan",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 282,
        "name": "Challenges and Opportunities for Technology in Foreign Language Classrooms",
        "type": "paper",
        "abstract": "We present the results of a two-month ethnographic study of three introductory Russian classrooms. Through observation and interviews, we identify several distinct roles played by physical artifacts in the classrooms, such as providing a reference to necessary foreign-language material and serving as props in creative role-play. The range of roles taken on by artifacts and the attitudes students have toward them provide a basis for our discussion about how technology might be more effectively introduced into the socially negotiated environment of the introductory foreign-language classroom. We identify the need to balance between collaborative and personal technology in a stressful, but social, context. Our findings inform a range of roles that technology can undertake in replacing or augmenting existing classroom artifacts.",
        "cbStatement": "The roles of artifacts in language learning, based on ethnographic study of introductory Russian classrooms, informing design for this stressful, yet creative, cooperative environment.",
        "bookmarks": 145,
        "keywords": [
            "Language",
            "language-learning",
            "foreign",
            "classroom",
            "communication",
            "Russian",
            "artifact",
            "textbook",
            "students"
        ],
        "communities": [],
        "video": "chi1913-file5.mp4",
        "session": {
            "id": "s285",
            "name": "Classrooms"
        },
        "room": "blue",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth21890",
                "givenName": "Katie",
                "familyName": "Kuksenok",
                "email": "kuksenok@cs.washington.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth23452",
                "givenName": "Michael",
                "familyName": "Brooks",
                "email": "mjbrooks@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth23833",
                "givenName": "Qian",
                "familyName": "Wang",
                "email": "qianqian@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth7074",
                "givenName": "Charlotte",
                "middleInitial": "P.",
                "familyName": "Lee",
                "email": "cplee@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 283,
        "name": "PT Viz: Towards a Wearable Device for Visualizing Knee Rehabilitation Exercises",
        "type": "paper",
        "abstract": "We present a wearable sensory display for visualizing knee rehabilitation as part of an in-home physical therapy program. Currently, patients undergoing knee rehabilitation have limited ways of assessing exercise form and extent of movement at home. To address this issue, we developed an exploratory wearable electronic prototype to visualize knee bend. We evaluated the device with physical therapy patients to get feedback on the design and to help us understand some of the challenges they face. We discovered that our current design is better suited for patients recovering from surgery as opposed to patients with chronic conditions.",
        "cbStatement": "PT Viz is a wearable electronic prototype for visualizing knee rehabilitation that was used to explore the needs of physical therapy patients when performing exercises away from the clinic. ",
        "bookmarks": 85,
        "keywords": [
            "Knee rehabilitation",
            "wearable display",
            "user interface device"
        ],
        "communities": [
            "health"
        ],
        "video": "chi1927-file5.mp4",
        "session": {
            "id": "s291",
            "name": "Impairment and Rehabilitation"
        },
        "room": "242ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth17636",
                "givenName": "Swamy",
                "familyName": "Ananthanarayan",
                "email": "ananthas@colorado.edu",
                "primary": {
                    "institution": "University of Colorado",
                    "city": "Boulder",
                    "state": "CO",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30660",
                "givenName": "Miranda",
                "familyName": "Sheh",
                "email": "Miranda.Sheh@colorado.edu",
                "primary": {
                    "institution": "University of Colorado",
                    "city": "Boulder",
                    "state": "Colorado",
                    "country": "United States"
                }
            },
            {
                "id": "auth30661",
                "givenName": "Alice",
                "familyName": "Chien",
                "email": "Alice.Chien@colorado.edu",
                "primary": {
                    "institution": "University of Colorado",
                    "city": "Boulder",
                    "state": "Colorado",
                    "country": "United States"
                }
            },
            {
                "id": "auth26168",
                "givenName": "Halley",
                "familyName": "Profita",
                "email": "halley.profita@colorado.edu",
                "primary": {
                    "institution": "University of Colorado",
                    "city": "Boulder",
                    "state": "Colorado",
                    "country": "United States"
                }
            },
            {
                "id": "auth9129",
                "givenName": "Katie",
                "middleInitial": "A",
                "familyName": "Siek",
                "email": "ksiek@cs.colorado.edu",
                "primary": {
                    "institution": "University of Colorado",
                    "city": "Boulder",
                    "state": "Colorado",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 284,
        "name": "ContextType: Using Hand Posture Information to Improve Mobile Touch Screen Text Entry",
        "type": "paper",
        "abstract": "The challenge of mobile text entry is exacerbated as mobile devices are used in a number of situations and with a number of hand postures. We introduce ContextType, an adaptive text entry system that leverages information about a user’s hand posture (using two thumbs, the left thumb, the right thumb, or the index finger) to improve mobile touch screen text entry. ContextType switches between various keyboard models based on hand posture inference while typing. ContextType combines the user’s posture-specific touch pattern information with a language model to classify the user’s touch events as pressed keys. To create our models, we collected usage patterns from 16 participants in each of the four postures. In a subsequent study with the same 16 participants comparing ContextType to a control condition, ContextType reduced total text entry error rate by 20.6%. ",
        "cbStatement": "ContextType is an adaptive text entry system that leverages information about a user’s hand posture to improve mobile touch screen text entry by 20.6%.",
        "bookmarks": 124,
        "keywords": [
            "Touch screen",
            "situational impairments",
            "mobile devices",
            "hand posture",
            "grip",
            "text entry",
            "virtual keyboard"
        ],
        "communities": [
            "ux"
        ],
        "session": {
            "id": "s254",
            "name": "Mobile keyboard / text entry"
        },
        "room": "241",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth22935",
                "givenName": "Mayank",
                "familyName": "Goel",
                "email": "mayank@cs.washington.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth16770",
                "givenName": "Alex",
                "familyName": "Jansen",
                "email": "ajansen7@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30786",
                "givenName": "Travis",
                "familyName": "Mandel",
                "email": "tmandel@cs.washington.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth4536",
                "givenName": "Shwetak",
                "middleInitial": "N",
                "familyName": "Patel",
                "email": "shwetak@cs.washington.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth1537",
                "givenName": "Jacob",
                "middleInitial": "O.",
                "familyName": "Wobbrock",
                "email": "wobbrock@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 285,
        "name": "Community Enhanced Tutorials: Improving Tutorials with Multiple Demonstrations",
        "type": "paper",
        "abstract": "Web-based tutorials are a popular help resource for learning how to perform unfamiliar tasks in complex software. However, in their current form, web tutorials are isolated from the applications that they support. In this paper we present FollowUs, a web-tutorial system that integrates a fully-featured application into a web-based tutorial. This novel architecture enables community enhanced tutorials, which continuously improve as more users work with them. FollowUs captures video demonstrations of users as they perform a tutorial. Subsequent users can use the original tutorial, or choose from a library of captured community demonstrations of each tutorial step. We conducted a user study to test the benefits of making multiple demonstrations available to users, and found that users perform significantly better using our system with a library of multiple demonstrations in comparison to its equivalent baseline system with only the original authored content.",
        "cbStatement": "We propose a novel web-based tutorial system that gathers video demonstrations from its users. An initial study shows the presence of multiple demonstrations can help users when following a tutorial.",
        "bookmarks": 65,
        "keywords": [
            "Tutorials",
            "Learning",
            "Community",
            "Help."
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi1940-file5.mp4",
        "authors": [
            {
                "id": "auth14011",
                "givenName": "Benjamin",
                "familyName": "Lafreniere",
                "email": "bjlafren@cs.uwaterloo.ca",
                "primary": {
                    "institution": "University of Waterloo",
                    "city": "Waterloo",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "secondary": {
                    "institution": "Autodesk Research",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth1476",
                "givenName": "Tovi",
                "familyName": "Grossman",
                "email": "tovi.grossman@autodesk.com",
                "primary": {
                    "institution": "Autodesk Research",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1229",
                "givenName": "George",
                "familyName": "Fitzmaurice",
                "email": "George.Fitzmaurice@autodesk.com",
                "primary": {
                    "institution": "Autodesk Research",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 286,
        "name": "Designing with Traces",
        "type": "paper",
        "abstract": "This paper draws on new materialist perspectives to introduce the analytic category of “material traces” to the field of human-computer interaction (HCI). Material traces reveal the dynamic and evocative nature of form by concretizing a unique location in time and space. Traces of skill, use, and time, for example, are valued for their emotional resonance in addition to the pragmatic goals in which they are embedded. Using this category, we develop a framework for design pedagogy that offers the lenses of attributes, entanglements, and trajectories as tools for gaining critical purchase on the objects produced. Mobilizing this framework within a classroom, design students envision poignant relationships to the non-human, engaged physics learning, and opportunities for reflection around breakage and repair. These design examples reveal how the category of material traces comes alive in practice and pedagogy. We end by discussing how this study of traces points to new opportunities for critical reflection in HCI.",
        "cbStatement": "This paper introduces the analytic category of “material traces,” which with design students envision poignant relationships to the non-human, engaged physics learning, and reflection around breakage. ",
        "bookmarks": 196,
        "keywords": [
            "Design theory",
            "traces",
            "craft",
            "materiality",
            "temporality",
            "prove-nance",
            "archeology",
            "critical making",
            "design pedagogy"
        ],
        "communities": [
            "design"
        ],
        "video": "chi1943-file5.mp4",
        "session": {
            "id": "s216",
            "name": "Design and Time: Long-term User Involvment and temporal themes"
        },
        "room": "havane",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth9749",
                "givenName": "Daniela",
                "middleInitial": "K",
                "familyName": "Rosner",
                "email": "daniela.rosner@gmail.com",
                "primary": {
                    "dept": "Science, Technology, and Society Program",
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "secondary": {
                    "dept": "Design ",
                    "institution": "California College of the Arts",
                    "city": "San Francisco",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth34776",
                "givenName": "Miwa",
                "familyName": "Ikemiya",
                "email": "mdikemiya@gmail.com",
                "primary": {
                    "dept": "Design",
                    "institution": "California College of the Arts",
                    "city": "San Francisco",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth30404",
                "givenName": "Diana",
                "familyName": "Kim",
                "email": "miss.diana.kim@gmail.com",
                "primary": {
                    "dept": "Design",
                    "institution": "California College of the Arts",
                    "city": "San Francisco",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth30564",
                "givenName": "Kristin",
                "familyName": "Koch",
                "email": "koch.kristin@gmail.com",
                "primary": {
                    "dept": "Design",
                    "institution": "California College of the Arts",
                    "city": "San Francisco",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 287,
        "name": "The Power of Mobile Notifications to Increase Wellbeing Logging Behavior",
        "type": "paper",
        "abstract": "Self-logging is a critical component to many wellbeing systems. However, self-logging often is difficult to sustain at regular intervals over many weeks. We demonstrate the power of passive mobile notifications to increase logging of wellbeing data, particularly food intake, in a mobile health service. Adding notifications increased the frequency of logging from 12% in a one-month, ten-user pilot study without reminders to 63% in the full 60-user study with reminders included. We will discuss the benefits of passive notifications over existing interruptive methods.",
        "cbStatement": "We demonstrate the power of passive mobile notifications to increase logging of wellbeing data, particularly food intake, in a mobile health service by 5x.",
        "bookmarks": 5,
        "keywords": [
            "Mobile",
            "Notifications",
            "Behavior Change",
            "Wellbeing",
            "Logging",
            "Personal Informatics"
        ],
        "communities": [
            "design",
            "ux",
            "health"
        ],
        "video": "chi0195-file5.m4v",
        "session": {
            "id": "s290",
            "name": "Technologies for Life 2"
        },
        "room": "242ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth6239",
                "givenName": "Frank",
                "familyName": "Bentley",
                "email": "f.bentley@motorola.com",
                "primary": {
                    "institution": "Motorola Mobility Inc.",
                    "city": "Libertyville",
                    "state": "Illinois",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth14730",
                "givenName": "Konrad",
                "familyName": "Tollmar",
                "email": "konrad@kth.se",
                "primary": {
                    "institution": "KTH",
                    "city": "Kista",
                    "country": "Sweden"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 288,
        "name": "When the Price Is Right: Enabling Time-Dependent Pricing of Broadband Data",
        "type": "paper",
        "abstract": "In an era of 108% annual growth in demand for mobile data and $10/GB overage fees, Internet Service Providers (ISPs) are experiencing severe congestion and in turn are hurting consumers with aggressive pricing measures. But smarter practices, such as time-dependent pricing (TDP), reward users for shifting their non-critical demand to off-peak hours and can potentially benefit both users and ISPs. Although dynamic TDP ideas have existed for many years, dynamic pricing for mobile data is only now gaining interest among ISPs. Yet TDP plans require not only systems engineering but also an understanding of economic incentives, user behavior and interface design. In particular, the HCI aspects of communicating price feedback signals from the network and the response of mobile data users need to be studied in the real world. But investigating these issues by deploying a virtual TDP data plan for real ISP customers is challenging and rarely explored. To this end, we carried out the first TDP trial for mobile data in the US with 10 families. We describe the insights gained from the trial, which can help the HCI community as well as ISPs, app developers and designers create tools that empower users to better control their usage and save on their monthly bills, while also alleviating network congestion.",
        "cbStatement": "We study economics and user behavior jointly within HCI and report on qualitative findings from a trial of time-dependent pricing for mobile data to help reduce network congestion.",
        "bookmarks": 78,
        "keywords": [
            "Broadband access pricing",
            "Dynamic pricing",
            "Time- and usage-based pricing",
            "Mobile application interface",
            "Economics"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi1952-file5.mp4",
        "session": {
            "id": "s241",
            "name": "Mobile 1: Mobile Phones: pricing, Emotions, looks, and positioning"
        },
        "room": "241",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth30711",
                "givenName": "Soumya",
                "familyName": "Sen",
                "email": "soumyas@princeton.edu",
                "primary": {
                    "institution": "Princeton University",
                    "city": "Princeton",
                    "state": "New Jersey",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30331",
                "givenName": "Carlee",
                "familyName": "Joe-Wong",
                "email": "cjoe@princeton.edu",
                "primary": {
                    "institution": "Princeton University",
                    "city": "Princeton",
                    "state": "New Jersey",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30712",
                "givenName": "Sangtae",
                "familyName": "Ha",
                "email": "sangtaeh@princeton.edu",
                "primary": {
                    "institution": "Princeton University",
                    "city": "Princeton",
                    "state": "New Jersey",
                    "country": "United States"
                }
            },
            {
                "id": "auth34758",
                "givenName": "Jasika",
                "familyName": "Bawa",
                "email": "jbawa@gmail.com",
                "primary": {
                    "institution": "Princeton University",
                    "city": "Princeton",
                    "state": "New Jersey",
                    "country": "United States"
                }
            },
            {
                "id": "auth34759",
                "givenName": "Mung",
                "familyName": "Chiang",
                "email": "chiangm@princeton.edu",
                "primary": {
                    "institution": "Princeton University",
                    "city": "Princeton",
                    "state": "New Jersey",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 289,
        "name": "WorldKit: Rapid and Easy Creation of Ad-hoc Interactive Applications on Everyday Surfaces",
        "type": "paper",
        "abstract": "Instant access to computing, when and where we need it, has long been one of the aims of research areas such as ubiquitous computing. In this paper, we describe the WorldKit system, which makes use of a paired depth camera and projector to make ordinary surfaces instantly interactive. Using this system, touch-based interactivity can, without prior calibration, be placed on nearly any unmodified surface literally with a wave of the hand, as can other new forms of sensed interaction. From a user perspective, such interfaces are easy enough to instantiate that they could, if desired, be recreated or modified \"each time we sat down\" by \"painting\" them next to us. From the programmer's perspective, our system encapsulates these capabilities in a simple set of abstractions that make the creation of interfaces quick and easy. Further, it is extensible to new, custom interactors in a way that closely mimics conventional 2D graphical user interfaces, hiding much of the complexity of working in this new domain. We detail the hardware and software implementation of our system, and several example applications built using the library.",
        "cbStatement": "Describes a paired depth-camera and projector system for on-the-world interaction and a software kit for application development: provides an inexpensive way to support interactions on everyday surfaces.",
        "bookmarks": 87,
        "keywords": [
            "Interactive spaces",
            "sensors",
            "touch screens",
            "smart rooms",
            "augmented reality",
            "depth sensing cameras",
            "ubiquitous computing",
            "surface computing"
        ],
        "communities": [],
        "video": "chi1961-file5.mp4",
        "session": {
            "id": "s220",
            "name": "Interaction around Devices"
        },
        "room": "352ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth27250",
                "givenName": "Robert",
                "familyName": "Xiao",
                "email": "brx@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth10923",
                "givenName": "Chris",
                "familyName": "Harrison",
                "email": "chris.harrison@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1007",
                "givenName": "Scott",
                "middleInitial": "E",
                "familyName": "Hudson",
                "email": "scott.hudson@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 290,
        "name": "Designing Web-Connected Physical Artefacts for the ‘Aesthetic’ of the Home",
        "type": "paper",
        "abstract": "Web-based technologies are often built to capitalize on the flexibility and fluidity that is supported by the internet, with the value of ‘access anywhere’ underpinning a blurring of boundaries across home and work. Yet the home is well known in HCI to have a unique set of qualities that can use-fully be drawn upon when designing to support domestic life. In this paper we ask what it means to design domestic web-connected technologies, placing the aesthetic and ma-terial properties intrinsic to the home and home life at the centre of our design exploration. We present three concepts that were selected and prototyped from a broader process of research-through-design: Tokens of Search provides tangi-ble handles to web resources; Hole in Space connects the home intimately to a remote place; and Manhattan enables the tangible exploration of events in the community, putting the home at the centre. Discussions in the paper consider not only how aesthetics is articulated in the material and digital properties of the artefacts, but also how a considera-tion of the properties of the home can create a potentially new design space to explore.",
        "cbStatement": "In this paper we ask what it means to design domestic web-connected technologies, placing the aesthetic of the home and home life at the centre of our design exploration.",
        "bookmarks": 34,
        "keywords": [
            "Research through design",
            "Domestic",
            "Tangible",
            "Search"
        ],
        "communities": [
            "design"
        ],
        "video": "chi1965-file5.mp4",
        "session": {
            "id": "s215",
            "name": "Design for the Home"
        },
        "room": "242ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth11740",
                "givenName": "Salu",
                "middleInitial": "P",
                "familyName": "Ylirisku",
                "email": "salu.ylirisku@aalto.fi",
                "primary": {
                    "institution": "Aalto University",
                    "city": "Helsinki",
                    "state": "Uusima",
                    "country": "Finland"
                },
                "role": "presenter"
            },
            {
                "id": "auth2278",
                "givenName": "Siân",
                "middleInitial": "E",
                "familyName": "Lindley",
                "email": "sianl@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "state": "Cambridgeshire",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth7424",
                "givenName": "Giulio",
                "familyName": "Jacucci",
                "email": "giulio.jacucci@hiit.fi",
                "primary": {
                    "institution": "Helsinki Institute for Information Technology",
                    "city": "Helsinki",
                    "country": "Finland"
                }
            },
            {
                "id": "auth8851",
                "givenName": "Richard",
                "middleInitial": "M",
                "familyName": "Banks",
                "email": "rbanks@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth12710",
                "givenName": "Craig",
                "middleInitial": "D",
                "familyName": "Stewart",
                "email": "craig@craigsprojects.com",
                "primary": {
                    "institution": "University of Dundee",
                    "city": "Dundee",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth1515",
                "givenName": "Abigail",
                "middleInitial": "J",
                "familyName": "Sellen",
                "email": "asellen@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth5139",
                "givenName": "Richard",
                "middleInitial": "H",
                "familyName": "Harper",
                "email": "r.harper@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth2003",
                "givenName": "Tim",
                "familyName": "Regan",
                "email": "timregan@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "UK"
                }
            }
        ]
    },
    {
        "id": 291,
        "name": "Promoting Hotkey Use through Rehearsal with ExposeHK",
        "type": "paper",
        "abstract": "Keyboard shortcuts allow fast interaction, but they are known to be infrequently used, with most users relying heavily on traditional pointer-based selection for most commands. We describe the goals, design, and evaluation of ExposeHK, a new interface mechanism that aims to increase hotkey use. ExposeHK’s four key design goals are: 1) enable users to browse hotkeys; 2) allow non-expert users to issue hotkey commands as a physical rehearsal of expert performance; 3) exploit spatial memory to assist non-expert users in identifying hotkeys; and 4) maximise expert performance by using consistent shortcuts in a flat command hierarchy. ExposeHK supports these objectives by displaying hotkeys overlaid on their associated commands when a modifier key is pressed. We evaluated ExposeHK in three empirical studies using toolbars, menus, and a tabbed ‘ribbon’ toolbar. Results show that participants used more hotkeys, and used them more often, with ExposeHK than with other techniques; they were faster with ExposeHK than with either pointing or other hotkey methods; and they strongly preferred ExposeHK. Our research shows that ExposeHK can substantially improve the user’s transition from a ‘beginner mode’ of interaction to a higher level of expertise.",
        "cbStatement": "Introduces ExposeHK, a new interface that promotes hotkey selection. Presents results of three studies showing that ExposeHK increases hotkey use, improves performance and was strongly prefered.",
        "bookmarks": 108,
        "keywords": [
            "Hotkeys",
            "Keyboard Shortcuts",
            "Rehearsal",
            "Menus",
            "Command Selection",
            "Novice Mode",
            "Expert Mode"
        ],
        "communities": [],
        "video": "chi0197-file5.mp4",
        "session": {
            "id": "s255",
            "name": "Hotkeys / Touch keyboards"
        },
        "room": "241",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth11388",
                "givenName": "Sylvain",
                "familyName": "Malacria",
                "email": "sylvain@malacria.fr",
                "primary": {
                    "institution": "University of Canterbury",
                    "city": "Christchurch",
                    "state": "Canterbury",
                    "country": "New Zealand"
                },
                "role": "presenter"
            },
            {
                "id": "auth9471",
                "givenName": "Gilles",
                "familyName": "Bailly",
                "email": "gillesbailly1@gmail.com",
                "primary": {
                    "dept": "Quality and Usability Lab",
                    "institution": "Telekom Innovation Laboratories, TU Berlin",
                    "city": "Berlin",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth28807",
                "givenName": "Joel",
                "familyName": "Harrison",
                "email": "jeh94@uclive.ac.nz",
                "primary": {
                    "institution": "University of Canterbury",
                    "city": "Christchurch",
                    "country": "New Zealand"
                }
            },
            {
                "id": "auth1057",
                "givenName": "Andy",
                "familyName": "Cockburn",
                "email": "andy@cosc.canterbury.ac.nz",
                "primary": {
                    "institution": "University of Canterbury",
                    "city": "Christchurch",
                    "country": "New Zealand"
                }
            },
            {
                "id": "auth1181",
                "givenName": "Carl",
                "familyName": "Gutwin",
                "email": "gutwin@cs.usask.ca",
                "primary": {
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 292,
        "name": "inAir: A Longitudinal study of Indoor Air Quality Measurements and Visualizations",
        "type": "paper",
        "abstract": "Indoor air quality (IAQ) is important for health as people spend the majority of time indoors, and it is particularly interesting over outdoor air because it strongly ties to indoor activities. Some activities easily exacerbate IAQ, resulting in serious pollution. However, people may not notice such changes because many pollutants are colorless and odorless, while many activities are inconspicuous and routine. We implemented inAir, a system that measures and visualizes IAQ that households appropriate and integrate into everyday life. The research goals of this work include understanding the IAQ dynamics with respect to habitual behaviors and analyzing behavioral and quantitative changes towards improving IAQ by the use of inAir. From our longitudinal study for four months, we found that inAir successfully elicited the reflection upon, and the modification of habitual behaviors for healthy domestic environments, which resulted in the significant improvement of IAQ.",
        "cbStatement": "This work aims at understanding the indoor air quality dynamics with respect to indoor activities and analyzing behavioral and quantitative changes towards improving air quality from a longitudinal deployment study. ",
        "bookmarks": 191,
        "keywords": [
            "Air quality",
            "health",
            "sustainability",
            "domestic computing"
        ],
        "communities": [
            "design",
            "health",
            "sustainability"
        ],
        "video": "chi1972-file5.mp4",
        "session": {
            "id": "s261",
            "name": "Sustainability / MISC"
        },
        "room": "bordeaux",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth13125",
                "givenName": "Sunyoung",
                "familyName": "Kim",
                "email": "shallyya@gmail.com",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1921",
                "givenName": "Eric",
                "familyName": "Paulos",
                "email": "eric@paulos.net",
                "primary": {
                    "institution": "University of California, Berkeley",
                    "city": "Berkeley",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1182",
                "givenName": "Jennifer",
                "familyName": "Mankoff",
                "email": "jmankoff@cs.cmu.edu",
                "primary": {
                    "dept": "HCII",
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 293,
        "name": "What Makes You Click: Exploring Visual Signals to Entice Interaction on Public Displays",
        "type": "paper",
        "abstract": "Most studies take for granted the critical first steps that prelude interaction with a public display: awareness of the interactive affordances of the display, and enticement to interact. In this paper we investigate mechanisms for enticing interaction on public displays, and study the effectiveness of visual signals in overcoming the ‘first click’ problem. We combined 3 atomic visual elements (color/greyscale, animation/static, and icon/text) to form 8 visual signals that were deployed on 8 interactive public displays on a university campus for 8 days. Our findings show that text is more effective in enticing interaction than icons, color more than greyscale, and static signals are more effective than animated. Further, we identify gender differences in the effectiveness of these signals. Finally, we identify a behavior termed “display avoidance” that people exhibit with interactive public displays. ",
        "cbStatement": "We investigate mechanisms for enticing interaction on public displays. Eight visual signals were developed and deployed on a university campus to study which visual elements work best at enticing interaction.",
        "bookmarks": 170,
        "keywords": [
            "Public displays",
            "interaction",
            "attracting attention",
            "visual signals"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi1977-file5.mp4",
        "session": {
            "id": "s247",
            "name": "Displays in public space"
        },
        "room": "241",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth14302",
                "givenName": "Hannu",
                "familyName": "Kukka",
                "email": "hannu.kukka@ee.oulu.fi",
                "primary": {
                    "institution": "University of Oulu",
                    "city": "Oulu",
                    "country": "Finland"
                },
                "role": "presenter"
            },
            {
                "id": "auth30385",
                "givenName": "Heidi",
                "familyName": "Oja",
                "email": "heidi.oja@gmail.com",
                "primary": {
                    "institution": "University of Oulu",
                    "city": "Oulu",
                    "country": "Finland"
                }
            },
            {
                "id": "auth6145",
                "givenName": "Vassilis",
                "familyName": "Kostakos",
                "email": "vassilis@ee.oulu.fi",
                "primary": {
                    "dept": "Department of Computer Science and Engineering",
                    "institution": "University of Oulu",
                    "city": "Oulu",
                    "country": "Finland"
                }
            },
            {
                "id": "auth22362",
                "givenName": "Jorge",
                "familyName": "Gonçalves",
                "email": "jgoncalv@ee.oulu.fi",
                "primary": {
                    "institution": "University of Oulu",
                    "city": "Oulu",
                    "country": "Finland"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth17646",
                "givenName": "Timo",
                "familyName": "Ojala",
                "email": "timo.ojala@ee.oulu.fi",
                "primary": {
                    "institution": "University of Oulu",
                    "city": "Oulu",
                    "country": "Finland"
                }
            }
        ]
    },
    {
        "id": 294,
        "name": "Understanding the Privacy-Personalization Dilemma for Web Search: A User Perspective",
        "type": "paper",
        "abstract": "Contemporary search engines use a variety of techniques to personalize search results based on users' past queries. While studies have found that users generally prefer personalized search results to non-personalized ones, recent surveys also indicate growing reservations with respect to personalization because of its privacy implications. In this paper, we take a deeper look at privacy considerations of users during web search and explore how users' preferences for privacy and personalization interact when undertaking this activity. We conduct an empirical study over Google search, involving 25 participants in India and their respective web search histories. Our finding is that users exhibit a slight preference for personalization in their search results but are usually willing to ``give up'' personalization when searching for topics they deem sensitive. We discuss implications of these results for the design of privacy-preserving tools for web search.",
        "cbStatement": "This paper aims to understand users’ perceptions of privacy in web search and how these perceptions interact with their desire for personalized search results.",
        "bookmarks": 137,
        "keywords": [
            "Privacy",
            "personalization",
            "web search",
            "user study."
        ],
        "communities": [
            "design"
        ],
        "video": "chi2012-file5.mp4",
        "session": {
            "id": "s274",
            "name": "Privacy"
        },
        "room": "251",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth18345",
                "givenName": "Saurabh",
                "familyName": "Panjwani",
                "email": "saurabh.panjwani@gmail.com",
                "primary": {
                    "institution": "Alcatel-Lucent Bell Labs",
                    "city": "Bangalore",
                    "country": "India"
                },
                "role": "presenter"
            },
            {
                "id": "auth30067",
                "givenName": "Nisheeth",
                "familyName": "Shrivastava",
                "email": "nisheeth.shrivastava@alcatel-lucent.com",
                "primary": {
                    "institution": "Alcatel-Lucent Bell Labs",
                    "city": "Bangalore",
                    "country": "India"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30039",
                "givenName": "Saurabh",
                "familyName": "Shukla",
                "email": "saurabh.shukla@cse.iitkgp.ernet.in",
                "primary": {
                    "dept": "Computer Science & Engineering",
                    "institution": "Indian Institute of Technology Kharagpur",
                    "city": "Kharagpur",
                    "state": "West Bengal",
                    "country": "India"
                }
            },
            {
                "id": "auth29744",
                "givenName": "Sharad",
                "familyName": "Jaiswal",
                "email": "sharad.jaiswal@alcatel-lucent.com",
                "primary": {
                    "institution": "Alcatel-Lucent Bell Labs",
                    "city": "Bangalore",
                    "country": "India"
                }
            }
        ]
    },
    {
        "id": 295,
        "name": "Stories of the Smartphone in Everyday Discourse: Conflict, Tension & Instability",
        "type": "paper",
        "abstract": "As the smartphone proliferates in American society, so too do stories about its value and impact. In this paper we draw on advertisements and news articles to analyze cultural discourse about the smartphone. We highlight two common tropes: one calling for increased technological integration, the other urging individuals to dis-integrate the smartphone from daily life. We examine the idealized subject positions of these two stories and show how both simplistic tropes call on the same overarching values to compel individuals to take opposing actions. We then reflect on the conflicts individuals experience in trying to align and account for their actions in relation to multiple contradictory narratives. Finally, we call for CHI researchers to tell and provoke more complicated stories of technologies and their relationships with values in conversations, publications, and future designs.",
        "cbStatement": "This analysis of popular stories about the smartphone highlights three areas of conflict, tension and instability relevant to the relationships among values, mobile ICTs, user experience, and everyday practice.",
        "bookmarks": 11,
        "keywords": [
            "smartphones",
            "cultural discourse",
            "values and design"
        ],
        "communities": [],
        "video": "chi2015-file5.mp4",
        "session": {
            "id": "s242",
            "name": "Mobile 2: Very Moving: reflection in mobile technologies"
        },
        "room": "351",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth6985",
                "givenName": "Ellie",
                "familyName": "Harmon",
                "email": "ellie.harmon@uci.edu",
                "primary": {
                    "dept": "Department of Informatics",
                    "institution": "University of California, Irvine",
                    "city": "Irvine",
                    "state": "CA",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth16412",
                "givenName": "Melissa",
                "familyName": "Mazmanian",
                "email": "mmazmani@uci.edu",
                "primary": {
                    "institution": "University of California, Irvine",
                    "city": "Irvine",
                    "state": "California",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "University of California, Irvine",
                    "city": "Irvine",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 296,
        "name": "CommunityCompare: Visually Comparing Communities for Online Community Leaders in the Enterprise",
        "type": "paper",
        "abstract": "Online communities are important in enterprises, helping workers to build skills and collaborate. Despite their unique and critical role fostering successful communities, community leaders have little direct support in existing technologies. We introduce CommunityCompare, an interactive visual analytic system to enable leaders to make sense of their community’s activity with comparisons. Composed of a parallel coordinates plot, various control widgets, and a preview of example posts from communities, the system supports comparisons with hundreds of related communities on multiple metrics and the ability to learn by example. We motivate and inform the system design with formative interviews of community leaders. From additional interviews, a field deployment, and surveys of leaders, we show how the system enabled leaders to assess community performance in the context of other comparable communities, learn about community dynamics through data exploration, and identify examples of top performing communities from which to learn. We conclude by discussing how our system and design lessons generalize.",
        "cbStatement": "Design and evaluation of a new visual, comparison-based analytic system, CommunityCompare, to help leaders assess and identify actions to improve community health. Can enhance design of systems for community leaders.",
        "bookmarks": 197,
        "keywords": [
            "Online communities",
            "community leaders",
            "visualization",
            "iterative design",
            "system evaluation",
            "enterprise",
            "workplace"
        ],
        "communities": [],
        "video": "chi0202-file5.mp4",
        "session": {
            "id": "s201",
            "name": "Enterprise and online communities: the best of both worlds"
        },
        "room": "havane",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth16372",
                "givenName": "Anbang",
                "familyName": "Xu",
                "email": "xu26@illinois.edu",
                "primary": {
                    "institution": "University of Illinois at Urbana-Champaign",
                    "city": "Urbana",
                    "state": "Illinois",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth11709",
                "givenName": "Jilin",
                "familyName": "Chen",
                "email": "jilinc@us.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth4598",
                "givenName": "Tara",
                "middleInitial": "L",
                "familyName": "Matthews",
                "email": "tlmatthe@us.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1047",
                "givenName": "Michael",
                "familyName": "Muller",
                "email": "michael_muller@us.ibm.com",
                "primary": {
                    "institution": "IBM T.J. Watson Research",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth16430",
                "givenName": "Hernan",
                "familyName": "Badenes",
                "email": "hbadenes@ar.ibm.com",
                "primary": {
                    "institution": "IBM",
                    "city": "Buenos Aires",
                    "country": "Argentina"
                }
            }
        ]
    },
    {
        "id": 297,
        "name": "Protecting the Home: Exploring the Roles of Technology and Citizen Activism from a Burglar's Perspective",
        "type": "paper",
        "abstract": "For decades, HCI scholars have designed technology for the domestic space. Many of these systems aim to protect the home and its residents by requesting help from local authorities during emergency situations. While the use of these systems have been examined, few studies attempt to understand the behavior of potential offenders who can create such emergency situations (e.g., by attempting a burglary). This paper analyzes three panel sessions with 15 people who have been convicted of burglarizing homes, cars, and/or businesses. Participants describe in detail what they looked for when deciding to burglarize a home and what deterred them. Technologies such as security systems, alarms, and cameras do not dissuade burglars. Instead, evidence of neighborhood cohesion was named the strongest deterrent. This paper presents implications for designing technologies that will effectively discourage burglary and support citizen activism.",
        "cbStatement": "Examines how burglars perceive deterrents. Finds that alarms, cameras, etc. do not dissuade burglars. In-person citizen activism is the strongest deterrent. Presents implications for crime prevention technology and activist research.",
        "bookmarks": 93,
        "keywords": [
            "crime prevention technology",
            "burglary",
            "domestic space"
        ],
        "communities": [],
        "session": {
            "id": "s262",
            "name": "Crime, Conflicts, and Resolution"
        },
        "room": "blue",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth8835",
                "givenName": "Sheena",
                "middleInitial": "Lewis",
                "familyName": "Erete",
                "email": "sheena@u.northwestern.edu",
                "primary": {
                    "dept": "Technology and Social Behavior",
                    "institution": "Northwestern University",
                    "city": "Evanston",
                    "state": "Illinois",
                    "country": "United States"
                },
                "secondary": {
                    "dept": "Technology and Social Behavior",
                    "institution": "Northwestern University",
                    "city": "Evanston",
                    "state": "Illinois",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 298,
        "name": "A Pilot Study of Using Crowds in the Classroom",
        "type": "paper",
        "abstract": "Industry relies on higher education to prepare students for careers in innovation. Fulfilling this obligation is especially difficult in classroom settings, which often lack authentic interaction with the outside world. Online crowdsourcing has the potential to change this. Our research explores if and how online crowds can support student learning in the classroom. We explore how scalable, diverse, immediate (and often ambiguous and conflicting) input from online crowds affects student learning and motivation for project-based innovation work. In a pilot study with three classrooms, we explore interactions with the crowd at four key stages of the innovation process: needfinding, ideating, testing, and pitching. Students reported that online crowds helped them quickly and inexpensively identify needs and uncover issues with early-stage prototypes, although they favored face-to-face interactions for more contextual feed-back. We share early evidence and discuss implications for creating a socio-technical infrastructure to more effectively use crowdsourcing in education.",
        "cbStatement": "We contribute early evidence and discuss implications for creating a socio-technical infrastructure to use online crowds to increase the authenticity of innovation education.",
        "bookmarks": 151,
        "keywords": [
            "Crowdsourcing",
            "innovation",
            "education",
            "feedback"
        ],
        "communities": [
            "design"
        ],
        "video": "chi2044-file5.mp4",
        "session": {
            "id": "s209",
            "name": "Power to the People: utalizing crowdsourcing"
        },
        "room": "241",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth2727",
                "givenName": "Steven",
                "middleInitial": "P",
                "familyName": "Dow",
                "email": "spdow@cs.cmu.edu",
                "primary": {
                    "dept": "HCI Institute",
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth7739",
                "givenName": "Elizabeth",
                "middleInitial": "M",
                "familyName": "Gerber",
                "email": "egerber@northwestern.edu",
                "primary": {
                    "institution": "Northwestern University",
                    "city": "Evanston",
                    "state": "Illinois",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30745",
                "givenName": "Audris",
                "familyName": "Wong",
                "email": "ahwong@andrew.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 299,
        "name": "Prototyping in PLACE: A Scalable Approach to Developing Location-Based Apps and Games",
        "type": "paper",
        "abstract": "The rising popularity of location-based applications and games (LBAGs) that break spatial, temporal, and social boundaries creates new challenges for designers. This paper introduces PLACE, an iterative, mixed-fidelity approach to Prototyping Location, Activities, Collective experience, and Experience over time in LBAGs. PLACE consists of 6 design principles: start small and scale up the fidelity, treat participants as co-designers, test in a representative space, focus on activities more than interfaces, respect authentic social experience, and represent time authentically. The effectiveness of PLACE was evaluated by prototyping   Floracaching, a geocaching game for citizen science. This revealed the types of insights that PLACE provides, best practices for implementing PLACE, and how PLACE com-pares to other prototyping methods.",
        "cbStatement": "PLACE is a framework for prototyping location-based apps and games that considers location, activities, and collective experience over time.  PLACE is evaluated with Floracaching, a Geocaching game for citizen science.  ",
        "bookmarks": 33,
        "keywords": [
            "Mixed-fidelity prototype",
            "PLACE",
            "location",
            "mobile apps",
            "location-based games",
            "co-design"
        ],
        "communities": [
            "design",
            "games"
        ],
        "session": {
            "id": "s282",
            "name": "Game Design"
        },
        "room": "251",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth30430",
                "givenName": "Anne",
                "middleInitial": "E",
                "familyName": "Bowser",
                "email": "anne.bowser@gmail.com",
                "primary": {
                    "dept": "iSchool",
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth6547",
                "givenName": "Derek",
                "middleInitial": "L",
                "familyName": "Hansen",
                "email": "dlhansen@byu.edu",
                "primary": {
                    "institution": "Brigham Young University",
                    "city": "Provo",
                    "state": "Utah",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30489",
                "givenName": "Jocelyn",
                "familyName": "Raphael",
                "email": "jocelyn.n.raphael@gmail.com",
                "primary": {
                    "institution": "Brigham Young University",
                    "city": "Provo",
                    "state": "Utah",
                    "country": "United States"
                }
            },
            {
                "id": "auth30488",
                "givenName": "Matthew",
                "familyName": "Reid",
                "email": "matthewreid007@gmail.com",
                "primary": {
                    "institution": "Brigham Young University",
                    "city": "Provo",
                    "state": "Utah",
                    "country": "United States"
                }
            },
            {
                "id": "auth30490",
                "givenName": "Ryan",
                "middleInitial": "J",
                "familyName": "Gamett",
                "email": "jaycen88gm@gmail.com",
                "primary": {
                    "dept": "Plant and Wildlife Sciences",
                    "institution": "Brigham Young University",
                    "city": "Provo",
                    "state": "Utah",
                    "country": "United States"
                }
            },
            {
                "id": "auth27831",
                "givenName": "Yurong",
                "middleInitial": "R",
                "familyName": "He",
                "email": "heeyes@gmail.com",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                }
            },
            {
                "id": "auth13078",
                "givenName": "Dana",
                "familyName": "Rotman",
                "email": "danarot@gmail.com",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                }
            },
            {
                "id": "auth2714",
                "givenName": "Jennifer",
                "middleInitial": "J",
                "familyName": "Preece",
                "email": "preece@umd.edu",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 300,
        "name": "A Comparative Evaluation of Multiple Chat Stream Interfaces for Information-intensive Environments",
        "type": "paper",
        "abstract": "For information workers who monitor numerous constantly updating data streams, conserving cognitive resources is crucial. This study evaluated how an interface affects information workers’ ability to grasp critical information from multiple text-based chat streams under time pressure. We designed and built a working prototype that displays ten chat streams simultaneously in standard chat windows (ST) and ticker tapes (TT). We conducted a lab experiment to evaluate differences in how these two interfaces support signal and context detection. We found that with ST, participants detected significantly more target words (SAT words) with rarer frequency and significantly more context information (disaster facts) than with TT. Our results show that while TT is potentially better for overview scanning of multiple streams, ST is likely to be better for multi-tasking. Our study informs the design of future multi-chat systems so that large amounts of information can be easier to detect and process.",
        "cbStatement": "We evaluated two text-based chat interfaces to inform the design of large-scale text information visualizations for information workers who monitor real-time text streams.",
        "bookmarks": 91,
        "keywords": [
            "Monitoring multiple text-based streams",
            "interface evaluation",
            "information workers",
            "empirical study"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi2051-file5.mp4",
        "session": {
            "id": "s233",
            "name": "Text Visualization"
        },
        "room": "bordeaux",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth21365",
                "givenName": "Yiran",
                "familyName": "Wang",
                "email": "wyr4137@gmail.com",
                "primary": {
                    "institution": "University of California, Irvine",
                    "city": "Irvine",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth15759",
                "givenName": "Andy",
                "familyName": "Echenique",
                "email": "apexinandy@gmail.com",
                "primary": {
                    "institution": "University of California, Irvine",
                    "city": "Irvine",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth30480",
                "givenName": "Martin",
                "familyName": "Shelton",
                "email": "mshelton@uci.edu",
                "primary": {
                    "institution": "University of California, Irvine",
                    "city": "Irvine",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth1172",
                "givenName": "Gloria",
                "middleInitial": "J",
                "familyName": "Mark",
                "email": "gmark@ics.uci.edu",
                "primary": {
                    "institution": "University of California, Irvine",
                    "city": "Irvine",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 301,
        "name": "Using an Open Card Sort with Children to Categorize Games in a Mobile Phone Application Store",
        "type": "paper",
        "abstract": "This paper presents a study aimed at better understanding how children categorize different games. The paper reports the results of an open card sort where participants were asked to categorize games from the Google Play Store (formerly the ‘Android Marketplace’). The key contribution of the paper is that when compared with existing categories in the Google Play Store, children used categorization criteria much more aligned to the goals of the game rather than more abstract categories currently found in mobile phone application stores. The paper provides examples of existing categories that are not generally used by children and provides new examples of categorization criteria that are used by children to categorize existing games.",
        "cbStatement": "The paper found that when compared with existing categories, children chose categories more aligned to a games goals/aims rather than the more abstract categories currently found in app stores.",
        "bookmarks": 13,
        "keywords": [
            "Children",
            "games",
            "categorization",
            "card sort",
            "information retrieval",
            "recall",
            "cluster analysis",
            "classification",
            "mobile"
        ],
        "communities": [
            "games",
            "cci"
        ],
        "video": "chi2060-file5.mp4",
        "session": {
            "id": "s286",
            "name": "Design for the Classroom"
        },
        "room": "251",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth14147",
                "givenName": "Brendan",
                "middleInitial": "M",
                "familyName": "Cassidy",
                "email": "bcassidy1@uclan.ac.uk",
                "primary": {
                    "institution": "University of Central Lancashire",
                    "city": "Preston",
                    "state": "Lancashire",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth30493",
                "givenName": "Dipti",
                "middleInitial": "S",
                "familyName": "Antani",
                "email": "dsantani@uclan.ac.uk",
                "primary": {
                    "institution": "University of Central Lancashire",
                    "city": "Preston",
                    "state": "Lancashire",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth2823",
                "givenName": "Janet C",
                "middleInitial": "C",
                "familyName": "Read",
                "email": "jcread@uclan.ac.uk",
                "primary": {
                    "institution": "University of Central Lancashire",
                    "city": "Preston",
                    "state": "Lancashire",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 302,
        "name": "8D: Interacting with a Relightable Glasses-Free 3D Display",
        "type": "paper",
        "abstract": "Imagine a display that behaves like a window. Glancing through it, viewers perceive a virtual 3D scene with correct parallax, without the need to wear glasses or track the user. Light that passes through the display correctly illuminates both virtual objects on the display and physical objects in the environment. While researchers have considered such displays, or prototyped subsets of these capabilities, we contribute a relightable, interactive display which simultaneously captures a 4D light field and displays a 4D light field. This 8-dimensional display attains a new degree of realism by reacting to incident environmental and user controlled light sources. We demonstrate two interaction techniques enabled by our lens-array-based hardware prototype, and real-time GPU-accelerated software pipeline. Additionally, we present a path to deploying such displays in commodity hardware, using current Sensor-in-Pixel (SIP) LCD panels, which physically collocate sensing and display elements.",
        "cbStatement": "We contribute a real-time, relightable, glasses-free 3D display with horizontal and vertical parallax, two interaction scenarios: relightable objects and virtual x-ray, and propose an architecture for future light field interaction devices.",
        "bookmarks": 74,
        "keywords": [
            "Glasses-Free 3D",
            "Relightable Display",
            "Light Fields",
            "Light-based interaction"
        ],
        "communities": [],
        "video": "chi2065-file5.mp4",
        "session": {
            "id": "s250",
            "name": "Beyond Desktop Interaction"
        },
        "room": "242a",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth19322",
                "givenName": "Matthew",
                "familyName": "Hirsch",
                "email": "mhirsch@media.mit.edu",
                "primary": {
                    "dept": "Media Lab",
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth6284",
                "givenName": "Shahram",
                "familyName": "Izadi",
                "email": "shahrami@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "state": "Cambridgeshire",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth7805",
                "givenName": "Henry",
                "familyName": "Holtzman",
                "email": "holtzman@media.mit.edu",
                "primary": {
                    "dept": "Media Lab",
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth5232",
                "givenName": "Ramesh",
                "familyName": "Raskar",
                "email": "raskar@media.mit.edu",
                "primary": {
                    "dept": "Media Lab",
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 303,
        "name": "An Interactive Belt-worn Badge",
        "type": "paper",
        "abstract": "In this paper we explore a new type of wearable computing device, an interactive identity badge. An embedded LCD presents dynamic information to the wearer and interaction is facilitated by sensing movement of the retractable string which attaches the unit to the wearer’s belt. This form-factor makes it possible to interact using a single hand, providing lightweight and immediate access to a variety of information when it’s not convenient to pick up, unlock and interact directly with a device like a smartphone. In this paper we present our prototype interactive badge, demonstrate the underlying technology and describe a number of usage scenarios and interaction techniques",
        "cbStatement": "This paper explores an interactive identity badge with an embedded LCD and an input mechanism based on sensing built into the retractable string which attaches it to the wearer’s belt.",
        "bookmarks": 19,
        "keywords": [
            "Smart interactive badge",
            "memory LCD",
            "retractable string",
            "interaction techniques"
        ],
        "communities": [],
        "video": "chi2085-file5.mp4",
        "session": {
            "id": "s224",
            "name": "Displays and Wearable"
        },
        "room": "352ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth29521",
                "givenName": "Norman",
                "familyName": "Pohl",
                "email": "Norman.Pohl@vis.uni-stuttgart.de",
                "primary": {
                    "dept": "Human-Computer-Interaction",
                    "institution": "University of Stuttgart",
                    "city": "Stuttgart",
                    "state": "Baden-Württemberg",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth5135",
                "givenName": "Steve",
                "familyName": "Hodges",
                "email": "shodges@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth12221",
                "givenName": "John",
                "familyName": "Helmes",
                "email": "johnhelmes@gmail.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth6224",
                "givenName": "Nicolas",
                "familyName": "Villar",
                "email": "nvillar@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "state": "Cambridgeshire",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth3214",
                "givenName": "Tim",
                "familyName": "Paek",
                "email": "timpaek@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 304,
        "name": "UMUX-LITE – When There’s No Time for the SUS",
        "type": "paper",
        "abstract": "In this paper we present the UMUX-LITE, a two-item questionnaire based on the Usability Metric for User Experience (UMUX) [6].  The UMUX-LITE items are “This system’s capabilities meet my requirements” and “This system is easy to use.”  Data from two independent surveys demonstrated adequate psychometric quality of the questionnaire.  Estimates of reliability were .82 and .83 – excellent for a two-item instrument.  Concurrent validity was also high, with significant correlation with the SUS (.81, .81) and with likelihood-to-recommend (LTR) scores (.74, .73).  The scores were sensitive to respondents’ frequency-of-use.  UMUX-LITE score means were slightly lower than those for the SUS, but easily adjusted using linear regression to match the SUS scores.  Due to its parsimony (two items), reliability, validity, structural basis (usefulness and usability) and, after applying the corrective regression formula, its correspondence to SUS scores, the UMUX-LITE appears to be a promising alternative to the SUS when it is not desirable to use a 10-item instrument.",
        "cbStatement": "The UMUX-LITE is a concise (two-item) usability satisfaction questionnaire.  Psychometric evaluation indicates its potential usefulness when it is critical to quickly obtain a SUS-like measurement.",
        "bookmarks": 105,
        "keywords": [
            "System Usability Scale",
            "SUS",
            "Usability Metric for User Experience",
            "UMUX",
            "UMUX-LITE",
            "psychometric evaluation",
            "usability evaluation",
            "standardized questionnaires",
            "satisfaction measures"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi2089-file5.mp4",
        "session": {
            "id": "s281",
            "name": "Automated Usability / Evaluation Methods"
        },
        "room": "351",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth10259",
                "givenName": "James",
                "middleInitial": "R.",
                "familyName": "Lewis",
                "email": "jimlewis@us.ibm.com",
                "primary": {
                    "institution": "IBM Software Group",
                    "city": "Boca Raton",
                    "state": "Florida",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30516",
                "givenName": "Brian",
                "middleInitial": "S.",
                "familyName": "Utesch",
                "email": "butesch@us.ibm.com",
                "primary": {
                    "institution": "IBM Software Group",
                    "city": "Durham",
                    "state": "North Carolina",
                    "country": "United States"
                }
            },
            {
                "id": "auth30517",
                "givenName": "Deborah",
                "middleInitial": "E.",
                "familyName": "Maher",
                "email": "debmaher@us.ibm.com",
                "primary": {
                    "institution": "IBM Software Group",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 305,
        "name": "Exploring Personality-Targeted UI Design in Online Social Participation Systems",
        "type": "paper",
        "abstract": "We present a theoretical foundation and empirical findings demonstrating the effectiveness of personality-targeted design. Much like a medical treatment applied to a person based on his specific genetic profile, we argue that theory-driven, personality-targeted UI design can be more effective than design applied to the entire population. The empirical exploration focused on two settings, two populations and two personality traits: Study 1 shows that users’ extraversion level moderates the relationship between the UI cue of audience size and users’ contribution. Study 2 demonstrates that the effectiveness of social anchors in encouraging online contributions depends on users’ level of emotional stability. Taken together, the findings demonstrate the potential and robustness of the interactionist approach to UI design. The findings contribute to the HCI community, and in particular to designers of social systems, by providing guidelines to targeted design that can increase online participation. ",
        "cbStatement": "We show how personality-targeted UI design can be more effective than design applied to entire populations – much like a medical treatment applied to a person based on his genetic profile.",
        "bookmarks": 11,
        "keywords": [
            "Theory-driven design",
            "user interface",
            "personality",
            "extraversion",
            "emotional stability",
            "audience size",
            "anchoring."
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi2096-file5.mp4",
        "session": {
            "id": "s248",
            "name": "Mobiles and more"
        },
        "room": "havane",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth9731",
                "givenName": "Oded",
                "familyName": "Nov",
                "email": "onov@poly.edu",
                "primary": {
                    "institution": "Polytechnic Institute of New York University",
                    "city": "Brooklyn",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth13138",
                "givenName": "Ofer",
                "familyName": "Arazy",
                "email": "ofer.arazy@ualberta.ca",
                "primary": {
                    "institution": "University of Alberta",
                    "city": "Edmonton",
                    "state": "Alberta",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth27866",
                "givenName": "Claudia",
                "familyName": "López",
                "email": "lopezmoncada@gmail.com",
                "primary": {
                    "institution": "University of Pittsburgh",
                    "city": "Pittsburgh",
                    "state": "PA",
                    "country": "US"
                }
            },
            {
                "id": "auth11897",
                "givenName": "Peter",
                "familyName": "Brusilovsky",
                "email": "peterb@mail.sis.pitt.edu",
                "primary": {
                    "institution": "University of Pittsburgh",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 306,
        "name": "A Tribute to Mad Skill: Expert Amateur Visuality and World of Warcraft Machinima",
        "type": "paper",
        "abstract": "In this paper, we look at the prominent World of Warcraft machinima community as an expert amateur online com-munity and present a multi-part study of a canon of the most successful works (i.e., machinima videos) produced by this community. By focusing our study on its roughly 300 most successful examples, the determination of which we explain in the paper, we are able to highlight the evolv-ing visual practices, tools, and aesthetic sensibilities of the community. Chiefly, our study identifies how creativity support tools and visual practices are inextricably linked and mutually support the in-kind development of the other. For WoW machinima and its producers, the affordance of creativity tools and the cultivation of visual skill synced at key moments and in powerful ways to support the rapid growth, experimentation, and refinement of amateur exper-tise at the individual and community levels.",
        "cbStatement": "Analyzing a canon of 300 World of Warcraft machinima, we present findings on the role of creativity support tools in fostering visual design skills among expert amateur machinimators.",
        "bookmarks": 0,
        "keywords": [
            "Visuality",
            "Expert Amateurs",
            "Machinima",
            "Creativity"
        ],
        "communities": [
            "design",
            "games"
        ],
        "video": "chi2104-file5.mp4",
        "authors": [
            {
                "id": "auth9125",
                "givenName": "Tyler",
                "familyName": "Pace",
                "email": "tympace@indiana.edu",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth20085",
                "givenName": "Austin",
                "middleInitial": "L",
                "familyName": "Toombs",
                "email": "altoombs@indiana.edu",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                }
            },
            {
                "id": "auth20806",
                "givenName": "Shad",
                "middleInitial": "D.",
                "familyName": "Gross",
                "email": "shadgross@gmail.com",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30131",
                "givenName": "Tony",
                "familyName": "Pattin",
                "email": "tpattin@umail.iu.edu",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                }
            },
            {
                "id": "auth7080",
                "givenName": "Jeffrey",
                "familyName": "Bardzell",
                "email": "jbardzel@indiana.edu",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                }
            },
            {
                "id": "auth7081",
                "givenName": "Shaowen",
                "familyName": "Bardzell",
                "email": "selu@indiana.edu",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 307,
        "name": "Brainstorm, Chainstorm, Cheatstorm, Tweetstorm: New Ideation Strategies for Distributed HCI Design",
        "type": "paper",
        "abstract": "In this paper we describe the results of a design-driven study of collaborative ideation. Based on preliminary findings that identified a novel digital ideation paradigm we refer to as chainstorming, or online communication brainstorming, two exploratory studies were performed. First, we developed and tested a distributed method of ideation we call cheatstorming, in which previously generated brainstorm ideas are delivered to targeted local contexts in response to a prompt. We then performed a more rigorous case study to examine the cheatstorming method and consider its possible implementation in the context of a distributed online ideation tool. Based on observations from these studies, we conclude with the somewhat provocative suggestion that ideation need not require the generation of new ideas. Rather, we present a model of ideation suggesting that its value has less to do with the generation of novel ideas than the cultural influence exerted by unconventional ideas on the ideating team. Thus brainstorming is more than the pooling of “invented” ideas, it involves the sharing and interpretation of concepts in unintended and (ideally) unanticipated ways.",
        "cbStatement": "In this paper we describe the results of a design-driven study of “cheatstorming,” a new collaborative ideation technique, to demonstrate how ideation need not require the generation of new ideas.",
        "bookmarks": 113,
        "keywords": [
            "Ideation",
            "brainstorming",
            "chainstorming",
            "cheatstorming",
            "tweetstormer;"
        ],
        "communities": [
            "design"
        ],
        "video": "chi2105-file5.mp4",
        "session": {
            "id": "s217",
            "name": "Design Ideation Methods"
        },
        "room": "342a",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth17461",
                "givenName": "Haakon",
                "familyName": "Faste",
                "email": "hfaste@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30592",
                "givenName": "Nir",
                "familyName": "Rachmel",
                "email": "nir.rachmel@gmail.com",
                "primary": {
                    "dept": "Human-Computer Interaction Institute",
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30594",
                "givenName": "Russell",
                "familyName": "Essary",
                "email": "russell.essary@gmail.com",
                "primary": {
                    "dept": "Masters of Human-Computer Interaction",
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth30596",
                "givenName": "Evan",
                "familyName": "Sheehan",
                "email": "wesheehan@gmail.com",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 308,
        "name": "Why Do They Still Use Paper? Understanding Data Collection and Use in Autism Education",
        "type": "paper",
        "abstract": "Autism education programs for children collect and use large amounts of behavioral data on each student. Staff use paper almost exclusively to collect these data, despite significant problems they face in tracking student data in situ, filling out data sheets and graphs on a daily basis, and using the sheets in collaborative decision making. We conducted fieldwork to understand data collection and use in the domain of autism education to explain why current technology had not met staff needs. We found that data needs are complex and unstandardized, immediate demands of the job interfere with staff ability to collect in situ data, and existing technology for data collection is inadequate. We also identified opportunities for technology to improve sharing and use of data. We found that data sheets are idiosyncratic and not useful without human mediation; improved communication with parents could benefit children’s development; and staff are willing, and even eager, to incorporate technology. These factors explain the continued dependence on paper for data collection in this environment, and reveal opportunities for technology to support data collection and improve use of collected data. ",
        "cbStatement": "We conducted fieldwork to understand data collection and use in the domain of autism education to explain why current technology had not met staff needs.",
        "bookmarks": 8,
        "keywords": [
            "Fieldwork",
            "Contextual inquiry",
            "CSCW"
        ],
        "communities": [],
        "video": "chi2119-file5.mp4",
        "session": {
            "id": "s293",
            "name": "Autism"
        },
        "room": "blue",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth15579",
                "givenName": "Gabriela",
                "familyName": "Marcu",
                "email": "gmarcu@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth34855",
                "givenName": "Kevin",
                "familyName": "Tassini",
                "email": "tassini@punchcut.com",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth34856",
                "givenName": "Quintin",
                "familyName": "Carlson",
                "email": "qcc@andrew.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth34857",
                "givenName": "Jillian",
                "familyName": "Goodwyn",
                "email": "jgoodwyn@andrew.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth30557",
                "givenName": "Gabrielle",
                "familyName": "Rivkin",
                "email": "grivkin@andrew.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth30558",
                "givenName": "Kevin",
                "middleInitial": "J",
                "familyName": "Schaefer",
                "email": "kjschaef@andrew.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth1090",
                "givenName": "Anind",
                "middleInitial": "K",
                "familyName": "Dey",
                "email": "anind@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1474",
                "givenName": "Sara",
                "familyName": "Kiesler",
                "email": "kiesler@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 309,
        "name": "Testing the Robustness and Performance of Spatially Consistent Interfaces",
        "type": "paper",
        "abstract": "Relative spatial consistency – that is, the stable arrangement of objects in a 2D presentation – provides several benefits for interactive interfaces. Spatial consistency allows users to develop memory of object locations, reducing the time needed for visual search, and because spatial memory is long lasting and has a large capacity these performance benefits are enduring and scalable. This suggests that spatial consistency could be used as a fundamental principle for the design of interfaces. However, there are many display situations where the standard presentation is altered in some way: e.g., a window is moved to a new location, scaled, or rotated on a mobile or tabletop display. It is not known whether the benefits of spatial organization are robust to these common kinds of view transformation. To assess these effects, we tested user performance with a spatial interface that had been transformed in several ways, including different degrees of translation, rotation, scaling, and perspective change. We found that performance was not strongly affected by the changes, except in the case of large rotations. To demonstrate the value of spatial consistency over existing mechanisms for dealing with view changes, we compared user performance with a spatially-stable presentation (using scaling) with that of a 'reflowing' presentation (widely used in current interfaces). This study showed that spatial stability with scaling dramatically outperforms reflowing. This research provides new evidence of spatial consistency's value in interface design: it is robust to the view transformations that occur in typical environments, and it provides substantial performance advantages over traditional methods.",
        "cbStatement": "Examines how view transformations such as scaling and rotation influence item selection time. Demonstrates that scaling, which maintains spatial consistency, allows faster performance than the commonly used 'reflow' layout scheme.",
        "bookmarks": 93,
        "keywords": [
            "Expertise",
            "spatial memory",
            "revisitation"
        ],
        "communities": [],
        "video": "chi0213-file5.mp4",
        "session": {
            "id": "s211",
            "name": "Designs on Design 1: Exploring Design Approaches and Constructs"
        },
        "room": "bordeaux",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth16719",
                "givenName": "Joey",
                "familyName": "Scarr",
                "email": "joey.scarr@gmail.com",
                "primary": {
                    "institution": "University of Canterbury",
                    "city": "Christchurch",
                    "country": "New Zealand"
                },
                "role": "presenter"
            },
            {
                "id": "auth1057",
                "givenName": "Andy",
                "familyName": "Cockburn",
                "email": "andy@cosc.canterbury.ac.nz",
                "primary": {
                    "institution": "University of Canterbury",
                    "city": "Christchurch",
                    "country": "New Zealand"
                }
            },
            {
                "id": "auth1181",
                "givenName": "Carl",
                "familyName": "Gutwin",
                "email": "gutwin@cs.usask.ca",
                "primary": {
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                }
            },
            {
                "id": "auth11388",
                "givenName": "Sylvain",
                "familyName": "Malacria",
                "email": "sylvain@malacria.fr",
                "primary": {
                    "institution": "University of Canterbury",
                    "city": "Christchurch",
                    "state": "Canterbury",
                    "country": "New Zealand"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 310,
        "name": "‘Digital Motherhood’: How does technology help new mothers?",
        "type": "paper",
        "abstract": "New mothers can experience social exclusion, particularly during the early weeks when infants are solely dependent on their mothers. We used ethnographic methods to investigate whether technology plays a role in supporting new mothers. Our research identified two core themes: (1) the need to improve confidence as a mother; and (2) the need to be more than ‘just’ a mother. We reflect on these findings both in terms of those interested in designing applications and services for motherhood and also the wider CHI community.",
        "cbStatement": "This research identified two themes where technology supports mothers: improving confidence and being more than ‘just’ a mother. Findings have implications for digital engagement, digital identity and social networking.",
        "bookmarks": 33,
        "keywords": [
            "Motherhood",
            "new mothers",
            "social support",
            "ethnography"
        ],
        "communities": [],
        "video": "chi2137-file5.mp4",
        "session": {
            "id": "s290",
            "name": "Technologies for Life 2"
        },
        "room": "242ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth12467",
                "givenName": "Lorna",
                "familyName": "Gibson",
                "email": "lgibson@computing.dundee.ac.uk",
                "primary": {
                    "institution": "University of Dundee",
                    "city": "Dundee",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth3493",
                "givenName": "Vicki",
                "middleInitial": "L",
                "familyName": "Hanson",
                "email": "vlh@computing.dundee.ac.uk",
                "primary": {
                    "institution": "University of Dundee",
                    "city": "Dundee",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 311,
        "name": "Labor Dynamics in a Mobile Micro-Task Market",
        "type": "paper",
        "abstract": "The ubiquity of smartphones has led to the emergence of mobile crowdsourcing markets, where smartphone users participate to perform tasks in the physical world. Mobile crowdsourcing markets are uniquely different from their online counterparts in that they require spatial mobility, and are therefore impacted by geographic factors and constraints that are not present in the online case. Despite the emergence and importance of such mobile marketplaces, little to none is known about the labor dynamics and mobility patterns of agents. \\  \\ This paper provides an in-depth exploration of labor dynamics in mobile task markets based on a year-long dataset from a leading mobile crowdsourcing platform.  We find that a small core group of workers (< 10%) account for a disproportionately large proportion of activity (> 80%) generated in the market. We find that these super agents are more efficient than other agents across several dimensions: a) they are willing to move longer distances to perform tasks, yet they amortize travel across more tasks, b) they work and search for tasks more efficiently, c) they have higher data quality in terms of accepted submissions, and d) they improve in almost all of these efficiency measures over time. We find that super agent efficiency stems from two simple optimizations --- they are 3x more likely than other agents to chain tasks and they pick fewer lower priced tasks than other agents. We compare mobile and online micro-task markets, and discuss differences in demographics, data quality, and time of use, as well as similarities in super agent behavior. We conclude with a discussion of how a mobile micro-task market might leverage some of our results to improve performance.",
        "cbStatement": "This paper provides an in-depth exploration of labor dynamics in mobile task markets which require spatial mobility based on a year-long dataset from a leading mobile crowdsourcing platform.  ",
        "bookmarks": 53,
        "keywords": [
            "crowdsourcing",
            "mobile crowdsourcing",
            "micro task markets",
            "labor mobility"
        ],
        "communities": [
            "design",
            "management"
        ],
        "session": {
            "id": "s204",
            "name": "Smart Tools for Smart Work Environments: working with the crowds"
        },
        "room": "havane",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth30545",
                "givenName": "Mohamed",
                "familyName": "Musthag",
                "email": "musthag@cs.umass.edu",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "University of Massachusetts",
                    "city": "Amherst",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30609",
                "givenName": "Deepak",
                "familyName": "Ganesan",
                "email": "dganesan@cs.umass.edu",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "University of Massachusetts",
                    "city": "Amherst",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 312,
        "name": "Webzeitgeist: Design Mining the Web",
        "type": "paper",
        "abstract": "Advances in data mining and knowledge discovery have transformed the way Web sites are designed. However, while visual presentation is an intrinsic part of the Web, traditional data mining techniques ignore render-time page structures and their attributes.  This paper introduces design mining for the Web: using knowledge discovery techniques to understand design demographics, automate design curation, and support data-driven design tools.  This idea is manifest in Webzeitgeist, a platform for large-scale design mining comprising a repository of over 100,000 Web pages and 100 million design elements. This paper describes the principles driving design mining, the implementation of the Webzeitgeist architecture, and the new class of data-driven design applications it enables.",
        "cbStatement": "This paper introduces design mining for the Web: using knowledge discovery techniques to understand design demographics, automate design curation, and support data-driven design tools.",
        "bookmarks": 53,
        "keywords": [
            "Web design",
            "data mining"
        ],
        "communities": [
            "design",
            "engineering",
            "ux"
        ],
        "video": "chi0215-file5.mp4",
        "session": {
            "id": "s230",
            "name": "Uis for Software Development"
        },
        "room": "blue",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth13333",
                "givenName": "Ranjitha",
                "familyName": "Kumar",
                "email": "ranju@stanford.edu",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth20049",
                "givenName": "Arvind",
                "familyName": "Satyanarayan",
                "email": "arvindsatya@cs.stanford.edu",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth28809",
                "givenName": "Cesar",
                "middleInitial": "A",
                "familyName": "Torres",
                "email": "ctorres7@stanford.edu",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth25358",
                "givenName": "Maxine",
                "familyName": "Lim",
                "email": "maxinel@stanford.edu",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth17858",
                "givenName": "Salman",
                "middleInitial": "A",
                "familyName": "Ahmad",
                "email": "saahmad@stanford.edu",
                "primary": {
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth1104",
                "givenName": "Scott",
                "middleInitial": "R",
                "familyName": "Klemmer",
                "email": "srk@cs.stanford.edu",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth14175",
                "givenName": "Jerry",
                "middleInitial": "O",
                "familyName": "Talton",
                "email": "jerry.o.talton@intel.com",
                "primary": {
                    "institution": "Intel Corporation",
                    "city": "Hillsboro",
                    "state": "Oregon",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 313,
        "name": "Machinima Production Tools:  A Vernacular History of a Creative Medium",
        "type": "paper",
        "abstract": "In recent years, HCI has shown a rising interest in the creative practices associated with massive online communities, including crafters, hackers, DIY, and other expert amateurs. One strategy for researching creativity at this scale is through an analysis of a community’s outputs, including its creative works, custom created tools, and emergent practices. In this paper, we offer one such case study, a historical account of World of Warcraft (WoW) machinima (i.e., videos produced inside of video games), which shows how the aesthetic needs and requirements of video making community coevolved with the community-made creativity support tools in use at the time. We view this process as inhabiting different layers and practices of appropriation, and through an analysis of them, we trace the ways that support for emerging stylistic conventions become built into creativity support tools over time.",
        "cbStatement": "In this study of massive scale community creativity, we provide a diachronic analysis of the co-emergence of community-developed creativity tools and the expressive visual language of their medium.",
        "bookmarks": 100,
        "keywords": [
            "HCI",
            "creativity",
            "machinima",
            "medium"
        ],
        "communities": [],
        "video": "chi2153-file5.mp4",
        "session": {
            "id": "s207",
            "name": "Social Face: creativity unleashed online"
        },
        "room": "bordeaux",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth20806",
                "givenName": "Shad",
                "middleInitial": "D.",
                "familyName": "Gross",
                "email": "shagross@indiana.edu",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth9125",
                "givenName": "Tyler",
                "familyName": "Pace",
                "email": "tympace@indiana.edu",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth7080",
                "givenName": "Jeffrey",
                "familyName": "Bardzell",
                "email": "jbardzel@indiana.edu",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                }
            },
            {
                "id": "auth7081",
                "givenName": "Shaowen",
                "familyName": "Bardzell",
                "email": "selu@indiana.edu",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 314,
        "name": "Validating a Mobile Phone Application for the Everyday, Unobtrusive, Objective Measurement of Sleep",
        "type": "paper",
        "abstract": "There is an identified need for objective, reliable, and scalable methods of measuring and recording sleep. Such methods must be designed for easy integration into people’s lives in order to support both sleep therapy and everyday personal informatics. This paper describes the design and evaluation of a mobile phone application to record sleep, the design of which has substantive foundation in clinical sleep research. Two user studies were carried out which demonstrate that the application produces valid measurements of sleep quality and high levels of usability, whilst not seriously disturbing sleep or the sleep environment. These findings suggest that the app is suitable for both everyday sleep monitoring in a personal informatics context, and for integration into sleep interventions.",
        "cbStatement": "This paper describes the validation, using long standing methods from the sleep research community, of an Android phone app that can be used to record sleep and measure sleep efficiency.",
        "bookmarks": 138,
        "keywords": [
            "Sleep, insomnia, mobile computing, personal informatics"
        ],
        "communities": [
            "health"
        ],
        "video": "chi2154-file5.mp4",
        "session": {
            "id": "s240",
            "name": "Hedonism, narrative, materiality & Media (This that and the other)"
        },
        "room": "342a",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth3083",
                "givenName": "Shaun",
                "middleInitial": "W",
                "familyName": "Lawson",
                "email": "slawson@lincoln.ac.uk",
                "primary": {
                    "institution": "University of Lincoln",
                    "city": "Lincoln",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth22477",
                "givenName": "Sue",
                "familyName": "Jamison-Powell",
                "email": "sjp66@le.ac.uk",
                "primary": {
                    "institution": "University of Leicester",
                    "city": "Leicester",
                    "state": "Leicestershire",
                    "country": "UK"
                }
            },
            {
                "id": "auth23323",
                "givenName": "Andrew",
                "middleInitial": "Thomas",
                "familyName": "Garbett",
                "email": "a.garbett@newcastle.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth13937",
                "givenName": "Conor",
                "familyName": "Linehan",
                "email": "clinehan@lincoln.ac.uk",
                "primary": {
                    "institution": "University of Lincoln",
                    "city": "Lincoln",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29059",
                "givenName": "Erica",
                "familyName": "Kucharczyk",
                "email": "e.kucharczyk@lboro.ac.uk",
                "primary": {
                    "institution": "Loughborough University",
                    "city": "Loughborough",
                    "state": "Leicestershire",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth29841",
                "givenName": "Sanne",
                "familyName": "Verbaan",
                "email": "scverbaan@gmail.com",
                "primary": {
                    "institution": "The Hague University of Applied Sciences",
                    "city": "The Hague",
                    "country": "The Netherlands"
                }
            },
            {
                "id": "auth4864",
                "givenName": "Duncan",
                "middleInitial": "A",
                "familyName": "Rowland",
                "email": "drowland@lincoln.ac.uk",
                "primary": {
                    "institution": "University of Lincoln",
                    "city": "Lincoln",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth29060",
                "givenName": "Kevin",
                "familyName": "Morgan",
                "email": "k.morgan@lboro.ac.uk",
                "primary": {
                    "institution": "Loughborough University",
                    "city": "Loughborough",
                    "state": "Leicestershire",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 315,
        "name": "LongPad: A TouchPad Using the Entire Area below the Keyboard of a Laptop Computer",
        "type": "paper",
        "abstract": "In this paper, we explore the possibility of a long touchpad that utilizes the entire area below the keyboard of a laptop computer. An essential prerequisite for such a touchpad is a robust palm rejection method, which we satisfy using a proximity-sensing touchpad. We developed LongPad, a proximity-sensing optical touchpad that is as wide as a laptop keyboard, and implemented a palm rejection algorithm that utilizes proximity images from LongPad. In a user study conducted, we observed that LongPad rejected palm touches almost perfectly while participants were repeating typing and pointing tasks. We also summarize the new design space enabled by LongPad and demonstrate a few of the interaction techniques it facilitates.",
        "cbStatement": "We implemented a proximity- and force-sensing touchpad and explored the feasibility and new possibilities of a long touchpad that utilizes the entire area below the keyboard on a laptop computer.",
        "bookmarks": 167,
        "keywords": [
            "LongPad",
            "proximity-sensing",
            "per-finger force sensing",
            "palm rejection",
            "bimanual interaction"
        ],
        "communities": [],
        "video": "chi2157-file5.mp4",
        "session": {
            "id": "s225",
            "name": "Touch, Tangibles, Touch Sensor"
        },
        "room": "352ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth21839",
                "givenName": "Jiseong",
                "familyName": "Gu",
                "email": "gstarcastle@gmail.com",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                },
                "role": "presenter"
            },
            {
                "id": "auth10604",
                "givenName": "Seongkook",
                "familyName": "Heo",
                "email": "seongkook@kaist.ac.kr",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth17831",
                "givenName": "Jaehyun",
                "familyName": "Han",
                "email": "jay.jaehyun@gmail.com",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                }
            },
            {
                "id": "auth15397",
                "givenName": "Sunjun",
                "familyName": "Kim",
                "email": "kuaa.net@gmail.com",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                }
            },
            {
                "id": "auth5474",
                "givenName": "Geehyuk",
                "familyName": "Lee",
                "email": "geehyuk@gmail.com",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                }
            }
        ]
    },
    {
        "id": 316,
        "name": "Villains, Architects and Micro-Managers: What Tabula Rasa Teaches Us About Game Orchestration",
        "type": "paper",
        "abstract": "Players of digital games are limited by the constraints of the game’s implementation. Players cannot fly a kite, plant a tree or make friends with a dragon if these activities were not coded within the game. Game orchestration relaxes these restrictions by allowing players to create game narratives and settings as the game is being played. This enables players to express their creativity beyond the strictures of the game’s implementation. We present Tabula Rasa, a novel game orchestration tool based on an efficient tabletop interface. Based on a study of 20 game orchestration sessions using Tabula Rasa, we identify five behavioural patterns adopted by orchestrators, and four styles of collaborative interaction between orchestrators and players. Finally, we present recommendations for designers of game orchestration systems.",
        "cbStatement": "Describes how digital games can allow design like activities at play-time, and how players use them when playing games.",
        "bookmarks": 143,
        "keywords": [
            "Game orchestration",
            "game design",
            "tabletop gaming"
        ],
        "communities": [
            "games"
        ],
        "video": "chi2161-file5.mp4",
        "session": {
            "id": "s284",
            "name": "Nonkid Games"
        },
        "room": "251",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth6619",
                "givenName": "Nicholas",
                "familyName": "Graham",
                "email": "graham@cs.queensu.ca",
                "primary": {
                    "institution": "Queen's University",
                    "city": "Kingston",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth30611",
                "givenName": "Irina",
                "familyName": "Schumann",
                "email": "schumannirina@aol.com",
                "primary": {
                    "dept": "create",
                    "institution": "University of Magdeburg",
                    "city": "Magdeburg",
                    "country": "Germany"
                },
                "secondary": {
                    "dept": "create",
                    "institution": "Kingston University",
                    "city": "Kingston",
                    "state": "Ontario",
                    "country": "Canada"
                }
            },
            {
                "id": "auth30612",
                "givenName": "Mrunal",
                "familyName": "Patel",
                "email": "mrunal@cs.queensu.ca",
                "primary": {
                    "dept": "create",
                    "institution": "Kingston University",
                    "city": "Kingston",
                    "state": "Ontario",
                    "country": "Canada"
                }
            },
            {
                "id": "auth30613",
                "givenName": "Quentin",
                "familyName": "Bellay",
                "email": "quentin.bellay@hotmail.fr",
                "primary": {
                    "dept": "create",
                    "institution": "Kingston University",
                    "city": "Kingston",
                    "state": "Ontario",
                    "country": "Canada"
                }
            },
            {
                "id": "auth6857",
                "givenName": "Raimund",
                "familyName": "Dachselt",
                "email": "raimund.dachselt@tu-dresden.de",
                "primary": {
                    "dept": "Interactive Media Lab",
                    "institution": "Technische Universität Dresden",
                    "city": "Dresden",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 317,
        "name": "Indoor Weather Stations: Investigating a Ludic Approach to Environmental HCI Through Batch Prototyping",
        "type": "paper",
        "abstract": "In this project, we investigated how a ludic approach might open new possibilities for environmental HCI by designing three related devices that encourage environmental awareness while eschewing utilitarian or persuasive agendas. In addition, we extended our methodological approach by batch-producing multiple copies of each device and deploying them to 20 households for several months, gathering a range of accounts about how people engaged and used them.  The devices, collectively called the ‘Indoor Weather Stations’, reveal the home’s microclimate by highlighting small gusts of wind, the colour of ambient light, and temperature differentials within the home. We found that participants initially tended to relate to the devices in line with two ‘orienting narratives’ of environmental tools or ludic designs, finding the devices disappointing from either perspective. Most of our participants showed lingering affection for the devices, however, for a variety of reasons. We discuss the implications of this ‘sporadic interaction’, and the more general lessons from the project, both for environmental HCI and ludic design. ",
        "cbStatement": "Three ‘weatherstations’, designed to take a ludic approach to environmental issues, were deployed to twenty households. The result is a distinctive example of environmental HCI, batch production, and ludic design.",
        "bookmarks": 104,
        "keywords": [
            "Research through design",
            "environmental HCI",
            "ludic design",
            "ubiquitous computing",
            "sensing"
        ],
        "communities": [
            "design",
            "ux",
            "sustainability"
        ],
        "video": "chi2163-file5.mp4",
        "session": {
            "id": "s212",
            "name": "Designs on Design 2: Exploring Design Approaches and Constructs"
        },
        "room": "bordeaux",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth1184",
                "givenName": "William",
                "middleInitial": "W",
                "familyName": "Gaver",
                "email": "w.gaver@gold.ac.uk",
                "primary": {
                    "dept": "Interaction Research Studio",
                    "institution": "Goldsmiths, University of London",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth30646",
                "givenName": "John",
                "familyName": "Bowers",
                "email": "john.m.bowers@gmail.com",
                "primary": {
                    "dept": "Interaction Research Studio",
                    "institution": "Goldsmiths, University of London",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30647",
                "givenName": "Kirsten",
                "familyName": "Boehner",
                "email": "k.boehner@gold.ac.uk",
                "primary": {
                    "dept": "Interaction Research Studio",
                    "institution": "Goldsmiths, University of London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth16921",
                "givenName": "Andy",
                "familyName": "Boucher",
                "email": "a.boucher@gold.ac.uk",
                "primary": {
                    "dept": "Interaction Research Studio",
                    "institution": "Goldsmiths, University of London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth16867",
                "givenName": "David",
                "middleInitial": "W T",
                "familyName": "Cameron",
                "email": "d.cameron@gold.ac.uk",
                "primary": {
                    "dept": "Interaction Research Studio",
                    "institution": "Goldsmiths, University of London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth30648",
                "givenName": "Mark",
                "familyName": "Hauenstein",
                "email": "m.hauenstein@gold.ac.uk",
                "primary": {
                    "dept": "Interaction Research Studio",
                    "institution": "Goldsmiths, University of London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth16938",
                "givenName": "Nadine",
                "familyName": "Jarvis",
                "email": "n.jarvis@gold.ac.uk",
                "primary": {
                    "dept": "Interaction Research Studio",
                    "institution": "Goldsmiths, University of London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth30649",
                "givenName": "Sarah",
                "familyName": "Pennington",
                "email": "s.pennington@gold.ac.uk",
                "primary": {
                    "dept": "Interaction Research Studio",
                    "institution": "Goldsmiths, University of London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 318,
        "name": "Access Lens: A Gesture-Based Screen Reader for Real-World Documents",
        "type": "paper",
        "abstract": "Gesture-based touch screen user interfaces, when designed to be accessible to blind users, can be an effective mode of interaction for those users. However, current accessible touch screen interaction techniques suffer from one serious limitation: they are only usable on devices that have been explicitly designed to support them. Access Lens is a new interaction method that uses computer vision-based gesture tracking to enable blind people to use accessible gestures on paper documents and other physical objects, such as product packages, device screens, and home appliances. This paper describes the development of Access Lens hardware and software, the iterative design of Access Lens in collaboration with blind computer users, and opportunities for future development.",
        "cbStatement": "Introduces Access Lens, a computer vision-based system that comboines gesture tracking and optical character recognition to enable blind people to explore physical documents using accessible gestures.",
        "bookmarks": 27,
        "keywords": [
            "Accessibility",
            "blindness",
            "gestures",
            "computer vision",
            "augmented reality"
        ],
        "communities": [],
        "video": "chi2165-file5.mp4",
        "session": {
            "id": "s289",
            "name": "Technologies for Life"
        },
        "room": "242ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth8212",
                "givenName": "Shaun",
                "middleInitial": "K.",
                "familyName": "Kane",
                "email": "skane@umbc.edu",
                "primary": {
                    "institution": "University of Maryland, Baltimore County",
                    "city": "Baltimore",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth23224",
                "givenName": "Brian",
                "familyName": "Frey",
                "email": "frey1@umbc.edu",
                "primary": {
                    "institution": "University of Maryland, Baltimore County",
                    "city": "Baltimore",
                    "state": "Maryland",
                    "country": "United States"
                }
            },
            {
                "id": "auth1537",
                "givenName": "Jacob",
                "middleInitial": "O.",
                "familyName": "Wobbrock",
                "email": "wobbrock@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 319,
        "name": "Same Translation but Different Experience: The Effects of Highlighting on Machine-Translated Conversations",
        "type": "paper",
        "abstract": "Machine translation (MT) has the potential to allow members of multilingual organizations to interact via their own native languages, but issues with the quality of MT output have made it difficult to realize this potential. We hypothesized that highlighting keywords in MT output might make it easier for people to overlook translation errors and focus on what was intended by the message. To test this hypothesis, we conducted a laboratory experiment in which native English speakers interacted with a Mandarin-speaking confederate using machine translation. Participants performed three brainstorming tasks, under each of three conditions: no highlighting, keyword highlighting, and random highlighting. Our results indicated that people consider the identical messages clearer and less distracting when the keywords in the message are highlighted. Keyword highlighting also improved subjective impressions of the partner and the quality of the collaboration. These findings inform the design of future communication tools to support multilingual communications. ",
        "cbStatement": "This study demonstrates that keyword highlighting is useful for improving the quality of MT-mediated communication. It informs the design of tools to support communication and collaboration across language boundaries.",
        "bookmarks": 54,
        "keywords": [
            "Multilingual Communication",
            "Brainstorming",
            "Machine Translation",
            "Highlighting"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi2166-file5.mp4",
        "session": {
            "id": "s266",
            "name": "Language"
        },
        "room": "blue",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth24744",
                "givenName": "Ge",
                "familyName": "Gao",
                "email": "gg365@cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth27772",
                "givenName": "Hao-Chuan",
                "familyName": "Wang",
                "email": "haochuan@cs.nthu.edu.tw",
                "primary": {
                    "institution": "National Tsing Hua University",
                    "city": "HsinChu",
                    "country": "Taiwan"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth2110",
                "givenName": "Dan",
                "familyName": "Cosley",
                "email": "drc44@cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth1053",
                "givenName": "Susan",
                "middleInitial": "R.",
                "familyName": "Fussell",
                "email": "sfussell@cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 320,
        "name": "Designing Reusable Alternate Reality Games",
        "type": "paper",
        "abstract": "Successful Alternate Reality Games (ARGs), such as The Lost Experience, I Love Bees and Urgent EVOKE have solicited thousands of active participants and, often, millions of spectators from around the world. ARGs require significant resources not only in terms of initial design, but also in implementation, since live, dynamic interplay between players and designers is an inherent aspect of their interactive storylines. This paper outlines a novel design framework for creating reusable ARGs that will help extend the lifespan of ARGs and allow them to permeate new domains such as education. The framework includes three key reusable design objectives (replayability, adaptability, extensibility), each of which can be enacted at different levels of depth. We also identify barriers to reusable ARGs and design strategies for overcoming those barriers, drawing upon ARG designer interviews and existing ARGs. ",
        "cbStatement": "This paper presents a framework for making Alternate Reality Games reusable, including replayable, adaptable, and extensible, and presents design strategies for implementing them.",
        "bookmarks": 123,
        "keywords": [
            "Alternate Reality Games",
            "serious games",
            "design",
            "replayable",
            "extensible",
            "adaptable",
            "reusable"
        ],
        "communities": [
            "design",
            "games"
        ],
        "video": "chi2169-file5.mp4",
        "session": {
            "id": "s282",
            "name": "Game Design"
        },
        "room": "251",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth6547",
                "givenName": "Derek",
                "middleInitial": "L",
                "familyName": "Hansen",
                "email": "dlhansen@byu.edu",
                "primary": {
                    "institution": "Brigham Young University",
                    "city": "Provo",
                    "state": "Utah",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth15706",
                "givenName": "Elizabeth",
                "middleInitial": "M",
                "familyName": "Bonsignore",
                "email": "ebonsign@umd.edu",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30617",
                "givenName": "Marc",
                "familyName": "Ruppel",
                "email": "marc.ruppel@gmail.com",
                "primary": {
                    "institution": "National Endowment for the Humanities",
                    "city": "Washington D.C.",
                    "state": "District of Columbia",
                    "country": "United States"
                }
            },
            {
                "id": "auth23899",
                "givenName": "Amanda",
                "familyName": "Visconti",
                "email": "amandavisconti@gmail.com",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "MD",
                    "country": "United States"
                }
            },
            {
                "id": "auth23900",
                "givenName": "Kari",
                "familyName": "Kraus",
                "email": "karimkraus@gmail.com",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 321,
        "name": "Optimizing Challenge in an Educational Game Using Large-Scale Design Experiments",
        "type": "paper",
        "abstract": "Online games can serve as research instruments to explore the effects of game design elements on motivation and learning. In our research, we manipulated the design of an online math game to investigate the effect of challenge on player motivation and learning. To test the “Inverted-U Hypothesis”, which predicts that maximum game engagement will occur with moderate challenge, we produced two large-scale (10K and 70K subjects), multi-factor (2x3 and 2x9x8x4x25) online experiments. We found that, in almost all cases, subjects were more engaged and played longer when the game was easier, which seems to contradict the generality of the Inverted-U Hypothesis. Troublingly, we also found that the most engaging design conditions produced the slowest rates of learning. Based on our findings, we describe several design implications that may increase challenge-seeking in games, such as providing feedforward about the anticipated degree of challenge. ",
        "cbStatement": "Online experiments (>80,000 game players in >14,400 conditions) optimized challenge to maximize engagement and learning in an educational game. Alas, what was optimal for engagement was not optimal for learning.",
        "bookmarks": 22,
        "keywords": [
            "Games",
            "Education",
            "Crowdsourcing",
            "Design"
        ],
        "communities": [
            "design",
            "games",
            "cci"
        ],
        "session": {
            "id": "s288",
            "name": "Learning"
        },
        "room": "251",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth17440",
                "givenName": "Derek",
                "familyName": "Lomas",
                "email": "dereklomas@gmail.com",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth18711",
                "givenName": "Kishan",
                "familyName": "Patel",
                "email": "kishaniit@gmail.com",
                "primary": {
                    "institution": "DA-IICT",
                    "city": "Gandhinagar",
                    "state": "Gujarat",
                    "country": "India"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1028",
                "givenName": "Jodi",
                "middleInitial": "L",
                "familyName": "Forlizzi",
                "email": "forlizzi@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth30050",
                "givenName": "Kenneth",
                "middleInitial": "R",
                "familyName": "Koedinger",
                "email": "krk@cs.cmu.edu",
                "primary": {
                    "dept": "HCII",
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 322,
        "name": "AD-Binning: Leveraging Around Device Space for Storing, Browsing and Retrieving Mobile Device Content",
        "type": "paper",
        "abstract": "Exploring information content on mobile devices can be tedious and time consuming. We present Around-Device Binning, or AD-Binning, a novel mobile user interface that allows users to off-load mobile content in the space around the device. We informed our implementation of AD-Binning by exploring various design factors, such as the minimum around-device target size, suitable item selection methods, and techniques for placing content in off-screen space. In a task requiring exploration, we find that AD-Binning improves browsing efficiency by avoiding the minute selection and flicking mechanisms needed for on-screen interaction. We conclude with design guidelines for off screen content storage and browsing. ",
        "cbStatement": "Presents AD-Binning, a novel interface for future small-screen mobile devices equipped with around-device sensing capabilities, with which screen content can be off-loaded in around-device-space to improve browsing and interaction efficiency.",
        "bookmarks": 26,
        "keywords": [
            "Around-device Interaction",
            "Off-screen Discretization",
            "Data Analytics",
            "Visual Analytics"
        ],
        "communities": [],
        "video": "chi2179-file5.mp4",
        "session": {
            "id": "s220",
            "name": "Interaction around Devices"
        },
        "room": "352ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth18067",
                "givenName": "Khalad",
                "familyName": "Hasan",
                "email": "khalad@cs.umanitoba.ca",
                "primary": {
                    "institution": "University of Manitoba",
                    "city": "Winnipeg",
                    "state": "Manitoba",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth4563",
                "givenName": "David",
                "familyName": "Ahlström",
                "email": "david.ahlstroem@aau.at",
                "primary": {
                    "institution": "Alpen-Adria-Universität Klagenfurt",
                    "city": "Klagenfurt",
                    "country": "Austria"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth2567",
                "givenName": "Pourang",
                "familyName": "Irani",
                "email": "irani@cs.umanitoba.ca",
                "primary": {
                    "institution": "University of Manitoba",
                    "city": "Winnipeg",
                    "state": "Manitoba",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 323,
        "name": "Octopus: Evaluating Touchscreen Keyboard Correction and Recognition Algorithms via “Remulation”",
        "type": "paper",
        "abstract": "The time and labor demanded by a typical laboratory-based keyboard evaluation are limiting resources for algorithmic adjustment and optimization. We propose Remulation, a complementary method for evaluating touchscreen keyboard correction and recognition algorithms. It replicates prior user study data through real-time, on-device simulation. We have developed Octopus, a Remulation-based evaluation tool that enables keyboard developers to efficiently measure and inspect the impact of algorithmic changes without conducting resource-intensive user studies. It can also be used to evaluate third-party keyboards in a “black box” fashion, without access to their algorithms or source code. Octopus can evaluate both touch keyboards and word-gesture keyboards. Two empirical examples show that Remulation can efficiently and effectively measure many aspects of touch screen keyboards at both macro and micro levels. Additionally, we contribute two new metrics to measure keyboard accuracy at the word level: the Ratio of Error Reduction (RER) and the Word Score. ",
        "cbStatement": "Proposed and tested remulation, an efficient method for evaluating touchscreen keyboards by replicating prior user study data in real-time, on-device simulation. Implemented Octopus, a remulation-based evaluation tool.",
        "bookmarks": 86,
        "keywords": [
            "Simulation",
            "Text entry",
            "Touch Screen Interaction"
        ],
        "communities": [
            "engineering"
        ],
        "video": "chi2191-file5.mp4",
        "session": {
            "id": "s255",
            "name": "Hotkeys / Touch keyboards"
        },
        "room": "241",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth9137",
                "givenName": "Xiaojun",
                "familyName": "Bi",
                "email": "xjunbi@gmail.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth18183",
                "givenName": "Shiri",
                "familyName": "Azenkot",
                "email": "shiri@cs.washington.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth4635",
                "givenName": "Kurt",
                "familyName": "Partridge",
                "email": "kepart@gmail.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth1220",
                "givenName": "Shumin",
                "familyName": "Zhai",
                "email": "zhai@acm.org",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 324,
        "name": "In Search of Learning: Facilitating Data Analysis in Educational Games",
        "type": "paper",
        "abstract": "The field of Educational Games has seen many calls for added rigor. One avenue for improving the rigor of the field is developing more generalizable methods for measuring student learning within games. Throughout the process of development, what is relevant to measure and assess may change as a game evolves into a finished product. The field needs an approach for game developers and researchers to be able to prototype and experiment with different measures that can stand up to rigorous scrutiny, as well as provide insight into possible new directions for development. We demonstrate a toolkit and analysis tools that capture and analyze students’ performance within open educational games. The system records relevant events during play, which can be used for analysis of player learning by designers. The tools support replaying student sessions within the original game’s environment, which allows researchers and developers to explore possible explanations for student behavior. Using this system, we were able to facilitate a number of analyses of student learning in an open educational game developed by a team of our collaborators as well as gain greater insight into student learning with the game and where to focus as we iterate.",
        "cbStatement": "We present a toolkit and methodology for recording and analyzing player log data in educational games, that allows game designers and researches multiple ways to explore student learning.",
        "bookmarks": 12,
        "keywords": [
            "Educational Games, Analysis of Learning, Toolkits,  Logging"
        ],
        "communities": [
            "games",
            "cci"
        ],
        "video": "chi2198-file5.mp4",
        "session": {
            "id": "s288",
            "name": "Learning"
        },
        "room": "251",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth30589",
                "givenName": "Erik",
                "familyName": "Harpstead",
                "email": "eharpste@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1085",
                "givenName": "Brad",
                "middleInitial": "A.",
                "familyName": "Myers",
                "email": "bam@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30548",
                "givenName": "Vincent",
                "familyName": "Aleven",
                "email": "aleven@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 325,
        "name": "Reasons to Question Seven Segment Displays",
        "type": "paper",
        "abstract": "Seven segment number displays are ubiquitous and popular. They are simple and familiar. They seem to make economic sense, and with only seven segments they require little wiring and electronics to support. They are cheap to buy and cheap to use; they make seemingly effective and unproblematic products.  \\  \\ This paper illustrates many examples of problematic uses of seven segment displays that could have been avoided. More generally, the paper raises design questions and some solutions to be considered when designing numerical displays, and certainly before uncritically using seven segment displays. Although there are markets and applications where cost may be an overriding consideration, for safety critical and other dependable types of use (including general purpose devices that may sometimes be used for critical tasks) more legible alternatives than standard seven segment displays should be preferred. ",
        "cbStatement": "Seven segment displays are familiar and ubiquitous, yet their use is problematic. This paper reviews many readability and use problems, and provides a range design questions and fixes.",
        "bookmarks": 113,
        "keywords": [
            "Seven segment display",
            "number display",
            "number error",
            "dependable interaction",
            "calculators",
            "procurement"
        ],
        "communities": [
            "design",
            "engineering",
            "health"
        ],
        "video": "chi0220-file5.mp4",
        "session": {
            "id": "s224",
            "name": "Displays and Wearable"
        },
        "room": "352ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth7168",
                "givenName": "Harold",
                "familyName": "Thimbleby",
                "email": "harold@thimbleby.net",
                "primary": {
                    "institution": "Swansea University",
                    "city": "Swansea",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 326,
        "name": "Codeable Objects: Computational Design and Digital Fabrication for Novice Programmers",
        "type": "paper",
        "abstract": "The combination of computational design and digital fabrication offers many exciting possibilities for art, design, and creative expression. We seek to make computational design accessible by developing tools that allow novices to use programming and digital fabrication to produce personal and functional objects. In this paper, we describe our development of Codeable Objects, a preliminary computational-design programing tool developed to work in conjunction with digital-fabrication machines. We also present our evaluation of the tool based on a set of user studies in which people built computationally generated crafts, clothing, and accessories. These studies illuminated the viability (and challenges) of engaging novice programmers through design and digital fabrication, and provide a platform for future work in developing programming tools to support personal expression.",
        "cbStatement": "The combination of programing and digital fabrication offers compelling new opportunities for creative expression. Codeable Objects is a computational-design tool to support novice programmers in production of personal, physical artifacts.",
        "bookmarks": 184,
        "keywords": [
            "Software",
            "Accessibility",
            "Art and Craft",
            "Computational Design."
        ],
        "communities": [
            "design",
            "cci",
            "arts"
        ],
        "video": "chi2207-file5.mp4",
        "session": {
            "id": "s264",
            "name": "Novel Programming"
        },
        "room": "351",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth23305",
                "givenName": "Jennifer",
                "middleInitial": "M",
                "familyName": "Jacobs",
                "email": "jacobsj@media.mit.edu",
                "primary": {
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth9751",
                "givenName": "Leah",
                "familyName": "Buechley",
                "email": "leah@media.mit.edu",
                "primary": {
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 327,
        "name": "Regularly Visited Patches in Human Mobility",
        "type": "paper",
        "abstract": "In this paper, we propose a new analytic unit for human mobility analysis – the patch. We developed a process to identify Regularly Visited Patches (RVP) and a set of metrics to characterize and measure their spatial patterns.  Using a large dataset of Foursquare check-ins as a test bed, we show that RVP analysis reveals fundamental patterns of human mobility and will lead to promising research with strong implications for businesses. ",
        "cbStatement": "This paper proposes a new analytic unit for human mobility research – the patch. Regularly Visited Patches (RVP) identified from GPS-based location data were analyzed, revealing fundamental mobility patterns.\t",
        "bookmarks": 1,
        "keywords": [
            "Human Mobility",
            "Regularly Visited Patches",
            "OPTICS"
        ],
        "communities": [],
        "video": "chi2208-file5.mp4",
        "session": {
            "id": "s241",
            "name": "Mobile 1: Mobile Phones: pricing, Emotions, looks, and positioning"
        },
        "room": "241",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth30635",
                "givenName": "Yan",
                "familyName": "Qu",
                "email": "qqlike@gmail.com",
                "primary": {
                    "institution": "placenous.com",
                    "city": "Hamden",
                    "state": "Connecticut",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth4047",
                "givenName": "Jun",
                "familyName": "Zhang",
                "email": "jun.zhang@pb.com",
                "primary": {
                    "institution": "Pitney Bowes Inc.",
                    "city": "Shelton",
                    "state": "Connecticut",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 328,
        "name": "Three Tensions in Participatory Design for Inclusion",
        "type": "paper",
        "abstract": "One ideal of Participatory Design (PD) is active involvement by all \\ stakeholders as co-designers.  However, when PD is applied to real \\ projects, certain compromises are unavoidable, no matter what \\ stakeholders are involved.  With this paper we want to shed light on \\ some of the challenges in implementing \"true\" PD in the case of \\ designing with children, in particular children with severe \\ disabilities.  We do this work to better understand challenges in an \\ ongoing project, RHYME, and by doing so we hope to provide insight and \\ inspiration for others. \\ ",
        "cbStatement": "In this paper we identify three tensions between the ideals of Participatory Design (PD) and the application of PD approaches in projects including children with severe disabilities.",
        "bookmarks": 86,
        "keywords": [
            "Participatory Design",
            "Inclusion",
            "Universal Design",
            "Familiarity"
        ],
        "communities": [
            "design",
            "cci"
        ],
        "video": "chi2210-file5.mp4",
        "session": {
            "id": "s327",
            "name": "Children"
        },
        "room": "bordeaux",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth30546",
                "givenName": "Harald",
                "familyName": "Holone",
                "email": "h@hiof.no",
                "primary": {
                    "dept": "Faculty of Computer Sciences",
                    "institution": "Østfold University College",
                    "city": "Halden",
                    "country": "Norway"
                },
                "role": "presenter"
            },
            {
                "id": "auth30665",
                "givenName": "Jo",
                "familyName": "Herstad",
                "email": "johe@ifi.uio.no",
                "primary": {
                    "dept": "Department of Informatics",
                    "institution": "University of Oslo",
                    "city": "Oslo",
                    "country": "Norway"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 329,
        "name": "Messaging to Your Doctors: Understanding Patient-Provider Communications via a Portal System",
        "type": "paper",
        "abstract": "The patient portal is a relatively new healthcare information technology that enables patients more convenient access to their healthcare information and allows them to send messages to their doctors. Our study examines the themes discussed in these messages and the different ways in which patients communicate with their providers via a portal employed in a large medical center. We also explore the differences between the patient portal and more traditional communication media, and investigated the advantages and potential problems of the portal system. Our findings show a wide variety of topics discussed in the communication messages (such as medication, appointments, laboratory tests, etc.) and how patients provide information, consult with their providers, and express psychosocial and emotional needs. We argue that the patient portal improves the accuracy of communication and could facilitate illness management for patients, especially over a longer term. However, messaging through the patient portal is not popular among patients and the simultaneous use of multiple communication media may create information gaps. More research is needed to better elucidate barriers to the use of patient portals and the optimal methods of communication and information integration given different contexts.",
        "cbStatement": "The paper presents a qualitative study on patient-provider communication messages via a patient portal system. We analyze communication themes and investigate portal's impacts on healthcare delivery and information management issues.",
        "bookmarks": 82,
        "keywords": [
            "Patient portal",
            "patient-provider communication",
            "computer mediated communication",
            "health information system",
            "EMR"
        ],
        "communities": [
            "health"
        ],
        "video": "chi2216-file5.mp4",
        "session": {
            "id": "s295",
            "name": "Health, Information, and Communication"
        },
        "room": "242ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth30563",
                "givenName": "Si",
                "familyName": "Sun",
                "email": "sisun@eden.rutgers.edu",
                "primary": {
                    "dept": "School of Communication and Information",
                    "institution": "Rutgers University",
                    "city": "New Brunswick",
                    "state": "NJ",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth21626",
                "givenName": "Xiaomu",
                "familyName": "Zhou",
                "email": "xmyzhou@rutgers.edu",
                "primary": {
                    "institution": "Rutgers University",
                    "city": "New Brunswick",
                    "state": "New Jersey",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30868",
                "givenName": "Joshua",
                "middleInitial": "C.",
                "familyName": "Denny",
                "email": "josh.denny@vanderbilt.edu",
                "primary": {
                    "dept": "Department of Biomedical Informatics School of Medicine",
                    "institution": "Vanderbilt University",
                    "city": "Nashville",
                    "state": "Tennessee",
                    "country": "United States"
                }
            },
            {
                "id": "auth30869",
                "givenName": "Trent",
                "middleInitial": "S.",
                "familyName": "Rosenbloom",
                "email": "trent.rosenbloom@vanderbilt.edu",
                "primary": {
                    "dept": "Department of Biomedical Informatics School of Medicine",
                    "institution": "Vanderbilt University",
                    "city": "Nashville",
                    "state": "Tennessee",
                    "country": "United States"
                },
                "secondary": {
                    "dept": "Department of Internal Medicine and Pediatrics",
                    "institution": "Vanderbilt University",
                    "city": "Nashville",
                    "state": "Tennessee",
                    "country": "United States"
                }
            },
            {
                "id": "auth30870",
                "givenName": "Hua",
                "familyName": "Xu",
                "email": "hua.xu@vanderbilt.edu",
                "primary": {
                    "dept": "Department of Biomedical Informatics School of Medicine",
                    "institution": "Vanderbilt University",
                    "city": "Nashville",
                    "state": "Tennessee",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 330,
        "name": "Swifter: Improved Online Video Scrubbing",
        "type": "paper",
        "abstract": "Online streaming video systems have become extremely popular, yet navigating to target scenes of interest can be a challenge. While recent techniques have been introduced to enable real-time seeking, they break down for large videos, where scrubbing the timeline causes video frames to skip and flash too quickly to be comprehendible. We present Swifter, a new video scrubbing technique that displays a grid of pre-cached thumbnails during scrubbing actions. In a series of studies, we first investigate possible design variations of the Swifter technique, and the impact of those variations on its performance. Guided by these results we compare an implementation of Swifter to the previously published Swift technique, in addition to the approaches utilized by YouTube and Netfilx. Our results show that Swifter significantly outperforms each of these techniques in a scene locating task, by a factor of up to 48%.",
        "cbStatement": "Swifter is a new technique for navigating streaming videos which presents a grid of thumbnail images during scrubbing operations, and allows the user to directly select the desired playback location.",
        "bookmarks": 161,
        "keywords": [
            "Video",
            "Video Navigation",
            "Online Streaming"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi2218-file5.mp4",
        "session": {
            "id": "s234",
            "name": "Video"
        },
        "room": "bordeaux",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth11856",
                "givenName": "Justin",
                "familyName": "Matejka",
                "email": "Justin.Matejka@autodesk.com",
                "primary": {
                    "institution": "Autodesk Research",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth1476",
                "givenName": "Tovi",
                "familyName": "Grossman",
                "email": "tovi.grossman@autodesk.com",
                "primary": {
                    "institution": "Autodesk Research",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1229",
                "givenName": "George",
                "familyName": "Fitzmaurice",
                "email": "George.Fitzmaurice@autodesk.com",
                "primary": {
                    "institution": "Autodesk Research",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 331,
        "name": "iRotateGrasp: Automatic Screen Rotation based on Grasp of Mobile Devices",
        "type": "paper",
        "abstract": "Automatic screen rotation improves viewing experience and usability of mobile devices, but current gravity-based approaches do not support postures such as lying on one side, and manual rotation switches require explicit user input. iRotateGrasp automatically rotates screens of mobile devices to match users’ viewing orientations based on how users are grasping the devices. Our insight is that users’ grasps are consistent for each orientation, but significantly differ between different orientations. Our prototype used a total of 44 capacitive sensors along the four sides and the back of an iPod Touch, and uses support vector machine (SVM) to recognize grasps at 25Hz. We collected 6-users’ usage under 108 different combinations of posture, orienta-tion, touchscreen operation, and left/right/both hands. Our offline analysis showed that our grasp-based approach is promising, with 80.9% accuracy when training and testing on different users, and up to 96.7% if users are willing to train the system. Our user study (N=16) showed that iRo-tateGrasp had an accuracy of 78.8% and was 31.3% more accurate than gravity-based rotation. ",
        "cbStatement": "Our paper shows that grasps can be used to rotate screens to more accurately match users’ view orientation in both upright and horizontal postures by implementing and evaluating a real-time grasp sensing and recognition prototype.",
        "bookmarks": 2,
        "keywords": [
            "Auto rotation",
            "grasp recognition",
            "mobile device",
            "adaptive user interface",
            "device orientation"
        ],
        "communities": [
            "engineering",
            "ux"
        ],
        "video": "chi0222-file5.mp4",
        "session": {
            "id": "s219",
            "name": "Mobile Gestures and Grasp"
        },
        "room": "352ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth17012",
                "givenName": "Lung-Pan",
                "familyName": "Cheng",
                "email": "xmanlch@gmail.com",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth17250",
                "givenName": "Meng Han",
                "familyName": "Lee",
                "email": "sunrisedm4@gmail.com",
                "primary": {
                    "dept": "create",
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                }
            },
            {
                "id": "auth27187",
                "givenName": "Che-Yang",
                "familyName": "Wu",
                "email": "b98902113@ntu.edu.tw",
                "primary": {
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                }
            },
            {
                "id": "auth16968",
                "givenName": "Fang-I",
                "familyName": "Hsiao",
                "email": "kamebkj@gmail.com",
                "primary": {
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                }
            },
            {
                "id": "auth22760",
                "givenName": "Yen-Ting",
                "familyName": "Liu",
                "email": "b97901121@ntu.edu.tw",
                "primary": {
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                }
            },
            {
                "id": "auth27186",
                "givenName": "Hsiang-Sheng",
                "familyName": "Liang",
                "email": "b97901125@ntu.edu.tw",
                "primary": {
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                },
                "role": "presenter"
            },
            {
                "id": "auth34091",
                "givenName": "Yi-Ching",
                "familyName": "Chiu",
                "email": "b99901146@ntu.edu.tw",
                "primary": {
                    "dept": "National Taiwan University",
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                }
            },
            {
                "id": "auth34125",
                "givenName": "Ming-Sui",
                "familyName": "Lee",
                "email": "mslee@csie.ntu.edu.tw",
                "primary": {
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                }
            },
            {
                "id": "auth6300",
                "givenName": "Mike Y.",
                "familyName": "Chen",
                "email": "mikechen@csie.ntu.edu.tw",
                "primary": {
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                }
            }
        ]
    },
    {
        "id": 332,
        "name": "EventHurdle: Supporting Designers’ Exploratory Interaction Prototyping with Gesture-Based Sensors",
        "type": "paper",
        "abstract": "Prototyping of gestural interactions in the early phase of design is one of the most challenging tasks for designers without advanced programming skills. Relating users’ input from gesture-based sensor values requires a great deal of effort on the designer’s part and disturbs their reflective and creative thinking. To deal with this problem, we present EventHurdle, a visual gesture-authoring tool to support designers’ explorative prototyping. It supports remote gestures from a camera, handheld gestures with physical sensors, and touch gestures by utilizing touch screens. EventHurdle allows designers to visually define and modify gestures through interaction workspace and graphical markup language with hurdles. Because the created gestures can be integrated into a prototype as programming code and automatically recognized, designers do not need to pay attention in sensor-related implementation. Two user studies and a recognition test are reported to discuss the acceptance and implications of explorative prototyping tools for designers. ",
        "cbStatement": "This paper presents EventHurdle, a visual gesture authoring tool for designers that supports connecting gesture-based sensors, visually intuitive gesture definitions, and easy prototyping without programming expertise.",
        "bookmarks": 0,
        "keywords": [
            "Gesture-Based Interaction",
            "Exploratory Prototyping",
            "Visual Programming"
        ],
        "communities": [
            "design"
        ],
        "video": "chi2220-file5.mp4",
        "session": {
            "id": "s221",
            "name": "Multitouch and Gestures"
        },
        "room": "352ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth12718",
                "givenName": "Ju-Whan",
                "familyName": "Kim",
                "email": "juwhan.k@gmail.com",
                "primary": {
                    "dept": "Department of Industrial Design",
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                },
                "role": "presenter"
            },
            {
                "id": "auth2587",
                "givenName": "Tek-Jin",
                "familyName": "Nam",
                "email": "tjnam@kaist.ac.kr",
                "primary": {
                    "dept": "Department of Industrial Design",
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "state": "Chung-Cheong Nam do",
                    "country": "Republic of Korea"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 333,
        "name": "Fighting against the Wall: Social Media use by Political Activists in a Palestinian Village",
        "type": "paper",
        "abstract": "We analyze practices of political activists in a Palestinian village located in the West Bank. Activists organize weekly demonstrations against Israel’s settlement policy and the separation wall. Over a period of 28 months, we conducted a field study consisting of eight days ‘on the ground’ observation and interviewing, and extensive monitoring of Internet communication. We describe the activists’ background and their efforts to organize these demonstrations under conditions of military occupation. Over time, we observe the role both digital and material factors play in the organization of protest. Specifically, we analyze how Email and Facebook were appropriated to facilitate interaction ‘on the ground’.",
        "cbStatement": "We analyze practices of political activists in a Palestinian village, who demonstrate against Israel’s settlement policy and the separation wall. We describe how social media is appropriated to facilitate interaction ‘on the ground’.",
        "bookmarks": 41,
        "keywords": [
            "Social Media",
            "field study",
            "appropriation",
            "political protest"
        ],
        "communities": [],
        "video": "chi2222-file5.mp4",
        "session": {
            "id": "s257",
            "name": "Crowds and activism"
        },
        "room": "blue",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth1678",
                "givenName": "Volker",
                "familyName": "Wulf",
                "email": "volker.wulf@uni-siegen.de",
                "primary": {
                    "institution": "University of Siegen",
                    "city": "Siegen",
                    "state": "NRW",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth30736",
                "givenName": "Konstantin",
                "familyName": "Aal",
                "email": "konstantin.aal@uni-siegen.de",
                "primary": {
                    "dept": "Institute for Information Systems",
                    "institution": "University of Siegen",
                    "city": "Siegen",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30738",
                "givenName": "Ibrahim",
                "familyName": "Abu Kteish",
                "email": "ikteish@birzeit.edu",
                "primary": {
                    "dept": "Najjad Zeenai IT Center of Excellence",
                    "institution": "Birzeit University",
                    "city": "Birzeit",
                    "country": "Israel"
                }
            },
            {
                "id": "auth28628",
                "givenName": "Meryem",
                "familyName": "Atam",
                "email": "meryem_atam@web.de",
                "primary": {
                    "institution": "University of Siegen",
                    "city": "Siegen",
                    "state": "NRW",
                    "country": "Germany"
                }
            },
            {
                "id": "auth4246",
                "givenName": "David",
                "middleInitial": "William",
                "familyName": "Randall",
                "email": "D.Randall@mmu.ac.uk",
                "primary": {
                    "dept": "Institute for Information Systems",
                    "institution": "University of Siegen",
                    "city": "Siegen",
                    "country": "Germany"
                }
            },
            {
                "id": "auth30740",
                "givenName": "Markus",
                "familyName": "Rohde",
                "email": "markus.rohde@uni-siegen.de",
                "primary": {
                    "dept": "Institute for Information Systems",
                    "institution": "University of Siegen",
                    "city": "Siegen",
                    "country": "Germany"
                }
            },
            {
                "id": "auth10372",
                "givenName": "Kai",
                "familyName": "Schubert",
                "email": "kai.schubert@uni-siegen.de",
                "primary": {
                    "dept": "Institute for Information Systems",
                    "institution": "University of Siegen",
                    "city": "Siegen",
                    "country": "Germany"
                }
            },
            {
                "id": "auth30742",
                "givenName": "George",
                "familyName": "Yerousis",
                "email": "gyerousis@birzeit.edu",
                "primary": {
                    "dept": "Najjad Zeenai IT Center of Excellence",
                    "institution": "Birzeit University",
                    "city": "Birzeit",
                    "country": "Israel"
                }
            }
        ]
    },
    {
        "id": 334,
        "name": "BeThere: 3D Mobile Collaboration with Spatial Input",
        "type": "paper",
        "abstract": "We present BeThere, a proof-of-concept system designed to explore 3D input for mobile collaborative interactions. With BeThere, we explore 3D gestures and spatial input which al- low remote users to perform a variety of virtual interactions in a local user’s physical environment. Our system is completely self-contained and uses depth sensors to track the location of a user’s fingers as well as to capture the 3D shape of objects in front of the sensor. We illustrate the unique capabilities of our system through a series of interactions that allow users to control and manipulate 3D virtual content. We also pro- vide qualitative feedback from a preliminary user study which confirmed that users can complete a shared collaborative task using our system.",
        "cbStatement": "We contribute a proof-of-concept system and interactions that show how mobile devices equipped with depth sensors can leverage spatial input and knowledge of our 3D environment to enrich communication.",
        "bookmarks": 89,
        "keywords": [
            "Around Device Interaction",
            "Collaboration",
            "Depth Sensors",
            "Augmented Reality"
        ],
        "communities": [
            "design",
            "engineering",
            "games"
        ],
        "video": "chi2234-file5.mp4",
        "session": {
            "id": "s251",
            "name": "3D Uis"
        },
        "room": "241",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth13066",
                "givenName": "Rajinder",
                "middleInitial": "S",
                "familyName": "Sodhi",
                "email": "rsodhi2@illinois.edu",
                "primary": {
                    "institution": "University of Illinois at Urbana-Champaign",
                    "city": "Urbana",
                    "state": "Illinois",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth15916",
                "givenName": "Brett",
                "middleInitial": "R",
                "familyName": "Jones",
                "email": "brjones2@illinois.edu",
                "primary": {
                    "institution": "University of Illinois at Urbana-Champaign",
                    "city": "Urbana",
                    "state": "Illinois",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29514",
                "givenName": "David",
                "familyName": "Forsyth",
                "email": "daf@illinois.edu",
                "primary": {
                    "institution": "University of Illinois at Urbana-Champaign",
                    "city": "Urbana",
                    "state": "Illinois",
                    "country": "United States"
                }
            },
            {
                "id": "auth1391",
                "givenName": "Brian",
                "middleInitial": "P",
                "familyName": "Bailey",
                "email": "bpbailey@illinois.edu",
                "primary": {
                    "institution": "University of Illinois at Urbana-Champaign",
                    "city": "Urbana",
                    "state": "Illinois",
                    "country": "United States"
                }
            },
            {
                "id": "auth27013",
                "givenName": "Giuliano",
                "familyName": "Maciocci",
                "email": "gmaciocc@qti.qualcomm.com",
                "primary": {
                    "institution": "Qualcomm Corporate R&D",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 335,
        "name": "How Does It Play Better? Exploring User Testing and Biometric Storyboards in Games User Research",
        "type": "paper",
        "abstract": "Improving game design is a hard task. Few methods are available in games user research (GUR) to test formally how game designs work for players. In particular, the usefulness of user tests (UTs) for game designers has not been fully studied in the CHI community. We propose a novel GUR method called Biometric Storyboards (BioSt) and present a study demonstrating how a Classic UT and a BioSt UT both help designers create a better gameplay experience. In addition, we show that BioSt can help designers deliver significantly better visuals, more fun, and higher gameplay quality than designing without UTs and that classic UTs do not provide this significant advantage. Our interviews support the idea that BioSt provides more nuanced game design improvement. The design implication is that a game designed with the BioSt method will result in high gameplay quality.",
        "cbStatement": "Our paper is the first study of its kind presented at CHI to report on the value of game user testing and physiological evaluation in providing formative feedback for game development. \\ ",
        "bookmarks": 38,
        "keywords": [
            "Games",
            "Games User Research",
            "User Testing",
            "Storyboards",
            "Physiological Measures",
            "User Experience",
            "Visualization"
        ],
        "communities": [
            "design",
            "ux",
            "games"
        ],
        "video": "chi0224-file5.mp4",
        "session": {
            "id": "s282",
            "name": "Game Design"
        },
        "room": "251",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth18112",
                "givenName": "Pejman",
                "familyName": "Mirza-Babaei",
                "email": "pm75@sussex.ac.uk",
                "primary": {
                    "institution": "University of Sussex, Brighton, East Sussex",
                    "city": "Brighton",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth10385",
                "givenName": "Lennart",
                "middleInitial": "E",
                "familyName": "Nacke",
                "email": "Lennart.Nacke@acm.org",
                "primary": {
                    "dept": "GAMER Lab",
                    "institution": "University of Ontario Institute of Technology",
                    "city": "Oshawa",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29057",
                "givenName": "John",
                "familyName": "Gregory",
                "email": "john.gregory@mycampus.uoit.ca",
                "primary": {
                    "dept": "GAMER Lab",
                    "institution": "University of Ontario Institute of Technology",
                    "city": "Oshawa",
                    "state": "Ontario",
                    "country": "Canada"
                }
            },
            {
                "id": "auth10062",
                "givenName": "Nick",
                "familyName": "Collins",
                "email": "N.Collins@sussex.ac.uk",
                "primary": {
                    "institution": "University of Sussex",
                    "city": "Brighton",
                    "state": "East Sussex",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth1025",
                "givenName": "Geraldine",
                "familyName": "Fitzpatrick",
                "email": "geraldine.fitzpatrick@tuwien.ac.at",
                "primary": {
                    "institution": "Vienna University of Technology",
                    "city": "Vienna",
                    "country": "Austria"
                }
            }
        ]
    },
    {
        "id": 336,
        "name": "Designing Graphical Menus for Novices and Experts: Connecting Design Characteristics with Design Goals",
        "type": "paper",
        "abstract": "This paper presents a design space for graphical menus. We model the design space as a set of design goals, a set of design characteristics, and connections between the two. The design goals are based on novice and expert behaviors. The connections link the choices for design characteristics with the positive or negative effects that these choices have on the design goals. The paper further synthesizes the design space into a succinct form of structured design recommendations. A case study demonstrates how these recommendations can be used to assess and compare the strengths and weaknesses of two menu designs.",
        "cbStatement": "This paper contributes a design space for graphical menus. It connects a set of design goals with a set of design characteristics. The design space helps create better menus.",
        "bookmarks": 123,
        "keywords": [
            "Graphical menus",
            "radial menus",
            "cascading menus",
            "menus",
            "design space",
            "design characteristics",
            "guides",
            "guidelines."
        ],
        "communities": [
            "design"
        ],
        "video": "chi2240-file5.mp4",
        "session": {
            "id": "s211",
            "name": "Designs on Design 1: Exploring Design Approaches and Constructs"
        },
        "room": "bordeaux",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth9833",
                "givenName": "Krystian",
                "familyName": "Samp",
                "email": "krystian.samp@deri.org",
                "primary": {
                    "institution": "Digital Enterprise Research Institute",
                    "city": "Galway",
                    "state": "Galway",
                    "country": "Ireland"
                },
                "secondary": {
                    "institution": "National University of Ireland, Galway",
                    "city": "Galway",
                    "state": "NA",
                    "country": "Ireland"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 337,
        "name": "From Competition to Metacognition: Designing Diverse, Sustainable Educational Games",
        "type": "paper",
        "abstract": "We investigate the unique educational benefits of 1-on-1 competitive games, arguing that such games can be just as easy to design as single-player educational games, while yielding a more diverse and sustainable learning experience.  We present a study of chess and StarCraft II in order to inform the design of similar educational games and their communities.  We discuss a competitive game we designed to teach Java programming.  We evaluate the game by discussing its user study. \\  \\ Our main contributions are 1) an argument that the use of 1-on-1 competition can solve two existing problems inherent to single-player games, 2) an analysis of the features that make competitive games effective learning environments, and 3) an early but encouraging description of the emergent learning environment one can expect from designing an educational game with these features.",
        "cbStatement": "Educational games are traditionally single-player games.  We evaluate commercial multiplayer games in order to inform the design of educational multiplayer games.",
        "bookmarks": 39,
        "keywords": [
            "Education",
            "Games"
        ],
        "communities": [
            "design",
            "ux",
            "games"
        ],
        "video": "chi2247-file5.m4v",
        "session": {
            "id": "s288",
            "name": "Learning"
        },
        "room": "251",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth30457",
                "givenName": "Stephen",
                "middleInitial": "R",
                "familyName": "Foster",
                "email": "srfoster@cs.ucsd.edu",
                "primary": {
                    "dept": "Computer Science and Engineering",
                    "institution": "UC San Diego",
                    "city": "La Jolla",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30684",
                "givenName": "Sarah",
                "familyName": "Esper",
                "email": "sesper@cs.ucsd.edu",
                "primary": {
                    "dept": "Computer Science and Engineering",
                    "institution": "University of California, San Diego",
                    "city": "San Diego",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth3725",
                "givenName": "William",
                "middleInitial": "G",
                "familyName": "Griswold",
                "email": "wgg@cs.ucsd.edu",
                "primary": {
                    "institution": "UC San Diego",
                    "city": "La Jolla",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 338,
        "name": "Crowdsourcing Performance Evaluations of User Interfaces",
        "type": "paper",
        "abstract": "Online labor markets, such as Amazon's Mechanical Turk (MTurk), provide an attractive platform for conducting human subjects experiments because the relative ease of recruitment, low cost, and a diverse pool of potential participants enable larger-scale experimentation and faster experimental revision cycle compared to lab-based settings.  However, because the experimenter gives up the direct control over the participants' environments and behavior, concerns about the quality of the data collected in online settings are pervasive.  In this paper, we investigate the feasibility of conducting online performance evaluations of user interfaces with anonymous, unsupervised, paid participants recruited via MTurk. We implemented three performance experiments to re-evaluate three previously well-studied user interface designs. We conducted each experiment both in lab and online with participants recruited via MTurk.  The analysis of our results did not yield any evidence of significant or substantial differences in the data collected in the two settings: All statistically significant differences detected in lab were also present on MTurk and the effect sizes were similar. In addition, there were no significant differences between the two settings in the raw task completion times, error rates, consistency, or the rates of utilization of the novel interaction mechanisms introduced in the experiments.  These results suggest that MTurk may be a productive setting for conducting performance evaluations of user interfaces providing a complementary approach to existing methodologies.",
        "cbStatement": "We explored the feasibility of using Amazon Mechanical Turk for user interface evaluation by replicating three well-known UI experiments both in lab and online. ",
        "bookmarks": 107,
        "keywords": [
            "Crowdsourcing",
            "Mechanical Turk",
            "User Interface Evaluation"
        ],
        "communities": [],
        "video": "chi2248-file5.mp4",
        "session": {
            "id": "s209",
            "name": "Power to the People: utalizing crowdsourcing"
        },
        "room": "241",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth30685",
                "givenName": "Steven",
                "familyName": "Komarov",
                "email": "stkomarov@gmail.com",
                "primary": {
                    "institution": "Harvard University",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Harvard University",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth10757",
                "givenName": "Katharina",
                "familyName": "Reinecke",
                "email": "reinecke@seas.harvard.edu",
                "primary": {
                    "institution": "Harvard University",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Harvard University",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth4508",
                "givenName": "Krzysztof",
                "middleInitial": "Z.",
                "familyName": "Gajos",
                "email": "kgajos@eecs.harvard.edu",
                "primary": {
                    "dept": "SEAS",
                    "institution": "Harvard University",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Harvard University",
                    "city": "Cambridge",
                    "state": "MA",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 339,
        "name": "Creativity Support for Novice Digital Filmmaking",
        "type": "paper",
        "abstract": "Machinima is a new form of creative digital filmmaking that leverages the real time graphics rendering of computer game engines. Because of the low barrier to entry, machinima has become a popular creative medium for hobbyists and novices while still retaining borrowed conventions from professional filmmaking. Can novice machinima creators benefit from creativity support tools? A preliminary study shows novices generally have difficulty adhering to cinematographic conventions. We identify and document four cinematic conventions novices typically violate. We report on a Wizard-of-Oz study showing a rule-based intelligent system that can reduce the frequency of errors that novices make by providing information about rule violations without prescribing solutions. We discuss the role of error reduction in creativity support tools.",
        "cbStatement": "We show that novice digital filmmakers have difficulty adhering to certain cinematographic conventions. Our subsequent Wizard-of-Oz study showed that a rule-based cinematic critic can reduce the frequency of errors.",
        "bookmarks": 175,
        "keywords": [
            "Creativity Support Tools",
            "Digital Filmmaking"
        ],
        "communities": [
            "arts"
        ],
        "video": "chi2249-file5.mp4",
        "session": {
            "id": "s269",
            "name": "Creating and Authoring"
        },
        "room": "241",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth25745",
                "givenName": "Nicholas",
                "familyName": "Davis",
                "email": "nicholas.davis10@gmail.com",
                "primary": {
                    "institution": "Georgia Institute of Technology ",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth23915",
                "givenName": "Alexander",
                "familyName": "Zook",
                "email": "a.zook@gatech.edu",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            },
            {
                "id": "auth12696",
                "givenName": "Brian",
                "familyName": "O'Neill",
                "email": "boneill@cc.gatech.edu",
                "primary": {
                    "dept": "School of Interactive Computing",
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            },
            {
                "id": "auth30864",
                "givenName": "Ashton",
                "familyName": "Grosz",
                "email": "grosz@gatech.edu",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            },
            {
                "id": "auth30865",
                "givenName": "Brandon",
                "familyName": "Headrick",
                "email": "hozuko@gmail.com",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            },
            {
                "id": "auth13243",
                "givenName": "Michael",
                "familyName": "Nitsche",
                "email": "michael.nitsche@lcc.gatech.edu",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            },
            {
                "id": "auth2859",
                "givenName": "Mark",
                "familyName": "Riedl",
                "email": "riedl@cc.gatech.edu",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 340,
        "name": "Footprint Tracker: Supporting Diary Studies with Lifelogging",
        "type": "paper",
        "abstract": "As HCI shifts “to the wild”, in-situ methods such as Diary Methods and the Experience Sampling Method are gaining momentum. However, researchers have acknowledged the intrusiveness and lack of realism in these methods and have proposed solutions, notably through lightweight and rich media capture. In this paper we explore the concept of lifelogging as an alternative solution to these two challenges. We describe Footprint Tracker, a tool that allows the review of lifelogs with the aim to support recall and reflection over daily activities and experiences. In a field trial, we study how four different types of cues, namely visual, location, temporal and social context, trigger memories of recent events and associated emotions. We conclude with a number of implications for the design of lifelogging systems that support recall and reflection upon recent events as well as ones lying further in our past.",
        "cbStatement": "Study of how visual, location, temporal and social context life logs support recall and reflection over daily activities and experiences in the context of diary studies.",
        "bookmarks": 23,
        "keywords": [
            "Diary methods",
            "lifelogging",
            "experience sampling"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi2253-file5.mp4",
        "session": {
            "id": "s280",
            "name": "Evaluation Methods 2"
        },
        "room": "351",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth27113",
                "givenName": "Rúben",
                "familyName": "Gouveia",
                "email": "rubahfgouveia@gmail.com",
                "primary": {
                    "institution": "Madeira Institute of Technology",
                    "city": "Funchal",
                    "state": "Madeira",
                    "country": "Portugal"
                },
                "role": "presenter"
            },
            {
                "id": "auth16855",
                "givenName": "Evangelos",
                "familyName": "Karapanos",
                "email": "e.karapanos@gmail.com",
                "primary": {
                    "institution": "Madeira Interactive Technologies Institute",
                    "city": "Funchal",
                    "state": "Madeira",
                    "country": "Portugal"
                },
                "secondary": {
                    "institution": "Madeira Interactive Technologies Institute",
                    "city": "Funchal",
                    "state": "Madeira",
                    "country": "Portugal"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 341,
        "name": "Beyond Digital and Physical Objects: The Intellectual Work as a Concept of Interest for HCI",
        "type": "paper",
        "abstract": "To understand activities of personal collecting and preservation, HCI researchers have investigated why people become attached to particular objects. These studies have examined ways that people relate to physical and digital objects, observing, for example, that people tend to cherish physical objects more than digital ones. This paper proposes that the value of digital objects may inhere less in an object’s identity as a particular item and more in the object’s ability to provide access to an intellectual work. The work, a familiar concept in information studies and textual studies, designates a general product of intellectual creation that may be instantiated in many versions. (For example, Shakespeare’s Hamlet exists in many editions and forms, which may differ in both content and carrier and yet still are all Hamlet.) The paper demonstrates how the concept of the work can extend research on the perceived value of digital objects. It also shows how a flexible definition of the work can reveal new aspects of a design situation.",
        "cbStatement": "Demonstrates how the concept of the work can extend research on the perceived value of digital objects. Shows how a flexible definition of the work can reveal new aspects of a design situation. ",
        "bookmarks": 165,
        "keywords": [
            "Works",
            "texts",
            "documents",
            "digital media",
            "textual studies, information studies",
            "design",
            "collecting",
            "preserving",
            "memory"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0226-file5.mp4",
        "session": {
            "id": "s272",
            "name": "Different Perspectives"
        },
        "room": "241",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth22148",
                "givenName": "Melanie",
                "middleInitial": "D",
                "familyName": "Feinberg",
                "email": "feinberg@ischool.utexas.edu",
                "primary": {
                    "institution": "The University of Texas at Austin",
                    "city": "Austin",
                    "state": "Texas",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 342,
        "name": "Privacy as Part of the App Decision-Making Process",
        "type": "paper",
        "abstract": "Smartphones have unprecedented access to sensitive personal information. While users report having privacy concerns, they may not actively consider privacy while downloading apps from smartphone application marketplaces. Currently, Android users have only the Android permissions display, which appears after they have selected an app to download, to help them understand how applications access their information. We investigate how permissions and privacy could play a more active role in app-selection decisions. We designed a short \"Privacy Facts'' display, which we  tested in a 20-participant lab study and a 366-participant online experiment. We found that by bringing privacy information to the user when they were making the decision and by presenting it in a clearer fashion, we could assist users in choosing applications that request fewer permissions.",
        "cbStatement": "We found that presenting privacy information to users more clearly and at the time they were making decisions made them more likely to choose Android applications that requested fewer permissions.",
        "bookmarks": 35,
        "keywords": [
            "Privacy",
            "Android",
            "Mobile",
            "Interface",
            "Decision-making"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi2278-file5.mp4",
        "session": {
            "id": "s274",
            "name": "Privacy"
        },
        "room": "251",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth11379",
                "givenName": "Patrick Gage",
                "familyName": "Kelley",
                "email": "me@patrickgage.com",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of New Mexico",
                    "city": "Albuquerque",
                    "state": "New Mexico",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1992",
                "givenName": "Lorrie Faith",
                "familyName": "Cranor",
                "email": "lorrie@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth14558",
                "givenName": "Norman",
                "familyName": "Sadeh",
                "email": "sadeh@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 343,
        "name": "Turkopticon: Interrupting Worker Invisibility in Amazon Mechanical Turk",
        "type": "paper",
        "abstract": "As HCI researchers have explored the possibilities of human computation, they have paid less attention to ethics and values of crowdwork. This paper offers an analysis of Amazon Mechanical Turk, a popular human computation system, as a site of technically mediated worker-employer relations. We argue that human computation currently relies on worker invisibility. We then present Turkopticon, an activist system that allows workers to publicize and evaluate their relationships with employers. As a common infrastructure, Turkopticon also enables workers to engage one another in mutual aid. We conclude by discussing the potentials and challenges of sustaining activist technologies that intervene in large, existing socio-technical systems. ",
        "cbStatement": "With Turkopticon, we contribute an example of a long-term systems building project that reworks employer-worker relations in Amazon Mechanical Turk.  We analyze the system in feminist, infrastrastructural, and political terms.  ",
        "bookmarks": 161,
        "keywords": [
            "Activism",
            "infrastructure",
            "human computation",
            "Amazon Mechanical Turk",
            "design",
            "ethics"
        ],
        "communities": [
            "design",
            "hci4d"
        ],
        "video": "chi2280-file5.mp4",
        "session": {
            "id": "s204",
            "name": "Smart Tools for Smart Work Environments: working with the crowds"
        },
        "room": "havane",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth7578",
                "givenName": "Lilly",
                "middleInitial": "C",
                "familyName": "Irani",
                "email": "lirani@ics.uci.edu",
                "primary": {
                    "dept": "Informatics",
                    "institution": "University of California, Irvine",
                    "city": "Irvine",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth22891",
                "givenName": "M.",
                "familyName": "Silberman",
                "email": "six@economicinterpretation.org",
                "primary": {
                    "institution": "Bureau of Economic Interpretation",
                    "city": "Berkeley",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 344,
        "name": "Mobiles, Music, and Materiality",
        "type": "paper",
        "abstract": "Building on recent HCI contributions that assert the materiality of digital information, we examine the material nature of digital media and information technology in the context of mobile music production, reproduction, and reception in rural and semi-urban India. We use ethnographic methods to study the recent adoption and use of mobile technology and discuss our findings in relation to the evolving materiality of music. We also investigate the sociotechnical configurations that emerge as a consequence of this materiality. Thus we contribute to HCI research by showing how the material representations of digital media affect the interactions of humans with technology.",
        "cbStatement": "Building on recent research that highlights the materiality of digital information, we examine the materiality of digital media in mobile music production, reproduction, and reception practices of small town India. ",
        "bookmarks": 129,
        "keywords": [
            "Materiality",
            "Music",
            "Mobile",
            "Media",
            "HCI4D",
            "ICTD"
        ],
        "communities": [
            "hci4d"
        ],
        "video": "chi2290-file5.mp4",
        "session": {
            "id": "s240",
            "name": "Hedonism, narrative, materiality & Media (This that and the other)"
        },
        "room": "342a",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth15363",
                "givenName": "Neha",
                "familyName": "Kumar",
                "email": "neha.kumar@gmail.com",
                "primary": {
                    "dept": "School of Information",
                    "institution": "University of California, Berkeley",
                    "city": "Berkeley",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth4720",
                "givenName": "Tapan",
                "middleInitial": "S.",
                "familyName": "Parikh",
                "email": "parikh@berkeley.edu",
                "primary": {
                    "dept": "School of Information",
                    "institution": "University of California, Berkeley",
                    "city": "Berkeley",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 345,
        "name": "All the News that’s Fit to Read: A Study of Social Annotations for News Reading",
        "type": "paper",
        "abstract": "As news reading becomes more social, how do different types of \\ annotations affect people's selection of news articles?  This paper \\ reports on results from two experiments looking at social annotations \\ in two different news reading contexts.  The first experiment \\ simulates a logged-out experience with annotations from strangers, a \\ computer agent, and a branded company.  Results indicate that, perhaps \\ unsurprisingly, annotations by strangers have no persuasive \\ effects. However, surprisingly, unknown branded companies still had a \\ persuasive effect.  The second experiment simulates a logged-in \\ experience with annotations from friends, finding that friend \\ annotations are both persuasive and improve user satisfaction over \\ their article selections.  In post-experiment interviews, we found \\ that this increased satisfaction is due partly because of the context \\ that annotations add. That is, friend annotations both help people \\ decide what to read, and provide social context that improves \\ engagement.  Interviews also suggest subtle expertise effects. We \\ discuss implications for design of social annotation systems and \\ suggestions for future research. \\ ",
        "cbStatement": "Compares annotations for news in logged-in and logged-out contexts. When logged-out, annotations by companies are persuasive, but by strangers aren't. When logged-in, friend annotations are persuasive and improve satisfaction.",
        "bookmarks": 80,
        "keywords": [
            "Social Computing",
            "Social annotation",
            "news reading",
            "recommendations",
            "experiment",
            "user study."
        ],
        "communities": [],
        "video": "chi2291-file5.mp4",
        "session": {
            "id": "s267",
            "name": "Shopping and Tagging"
        },
        "room": "241",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth10611",
                "givenName": "Chinmay",
                "middleInitial": "Eishan",
                "familyName": "Kulkarni",
                "email": "chinmay007@gmail.com",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "CA",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1100",
                "givenName": "Ed",
                "middleInitial": "H",
                "familyName": "Chi",
                "email": "chi@acm.org",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 346,
        "name": "Costs and Benefits of Structured Information Foraging",
        "type": "paper",
        "abstract": "People spend an enormous amount of time searching for and saving information online. Existing tools capture only a small portion of the cognitive processing a user engages in while making sense of a new domain. In this paper we introduce a novel interface for capturing online infor-mation in a structured but lightweight way. We use this in-terface as a platform to experimentally characterize the costs and benefits of structuring information during the sensemaking process. Our results contribute empirical knowledge relevant to theories of information seeking and sensemaking, and practical implications for the develop-ment of tools to capture and share online information.",
        "cbStatement": "We introduce a novel interface for capturing online information in a structured but lightweight way and use it to experimentally characterize the costs and benefits of structured sensemaking.",
        "bookmarks": 108,
        "keywords": [
            "Sensemaking",
            "search",
            "foraging",
            "structure"
        ],
        "communities": [],
        "video": "chi2303-file5.mp4",
        "session": {
            "id": "s265",
            "name": "Search and Find"
        },
        "room": "havane",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth7954",
                "givenName": "Aniket",
                "familyName": "Kittur",
                "email": "nkittur@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30797",
                "givenName": "Andrew",
                "middleInitial": "M",
                "familyName": "Peters",
                "email": "andrewpe@cs.cmu.edu",
                "primary": {
                    "dept": "Human-Computer Interaction Institute",
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "PA",
                    "country": "United States"
                }
            },
            {
                "id": "auth29384",
                "givenName": "Abdigani",
                "familyName": "Diriye",
                "email": "adiriye@andrew.cmu.edu",
                "primary": {
                    "dept": "Human Computer Interaction Institute",
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth34770",
                "givenName": "Trupti",
                "familyName": "Telang",
                "email": "ttelang@andrew.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth34771",
                "givenName": "Michael",
                "middleInitial": "R",
                "familyName": "Bove",
                "email": "mbove@andrew.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 347,
        "name": "Leading People to Longer Queries",
        "type": "paper",
        "abstract": "Although longer queries can produce better results for information seeking tasks, people tend to type short queries. We created an interface designed to encourage people to type longer queries, and evaluated it in two Mechanical Turk experiments. Results suggest that our interface manipulation may be effective for eliciting longer queries.  ",
        "cbStatement": "An experiment to test the effects of halos on query length was conducted. Results suggest that the interface may be effective for eliciting longer queries. \\ ",
        "bookmarks": 51,
        "keywords": [
            "Interactive information seeking",
            "query construction",
            "persuasive computing"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi2305-file5.m4v",
        "session": {
            "id": "s265",
            "name": "Search and Find"
        },
        "room": "havane",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth17979",
                "givenName": "Elena",
                "familyName": "Agapie",
                "email": "eagapie@seas.harvard.edu",
                "primary": {
                    "institution": "Harvard University",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "FX Palo Alto Laboatory, Inc.",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1016",
                "givenName": "Gene",
                "familyName": "Golovchinsky",
                "email": "gene@fxpal.com",
                "primary": {
                    "institution": "FX Palo Alto Laboatory, Inc.",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth2629",
                "givenName": "Pernilla",
                "familyName": "Qvarfordt",
                "email": "pernilla@fxpal.com",
                "primary": {
                    "institution": "FX Palo Alto Laboatory, Inc.",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 348,
        "name": "The Power of Play: Design Lessons for Increasing the Lifespan of Outdated Computers",
        "type": "paper",
        "abstract": "One consequence of rapid advances in computer technology is the obsolescence of hundreds of millions of computers each year. This paper explores strategies for increasing the reuse of outdated computers through an investigation of an 8-bit home computer that is still popular in developing countries. We observed the use of the computers in 16 households in Ahmedabad and Bangalore, India in order to gain insight into the contextual factors that support the continued popularity of the device. While most computers become obsolete in less than a decade, this 30-year-old computer technology remains useful because it provides exciting, multi-user family entertainment. While having minimal processing power and virtually no connectivity, the 8-bit computer supports input and output channels that are especially suited for co-located social game play. In contrast, PCs are primarily designed for individual use. Therefore, we offer low-cost design recommendations that would enable outdated PCs to support greater shared use and increased utility within the constrained material context of low-income households. These simple interventions, if adopted by computer refurbishment industries, have the potential to significantly extend the useful lifespan of PCs.",
        "cbStatement": "Why is Visicalc obsolete, but not Super Mario Bros? The continued success of 8-bit computers in developing countries shows how hedonic utility (aka fun) can dramatically extend computer lifespans.",
        "bookmarks": 184,
        "keywords": [
            "Sustainability",
            "HCI4D",
            "ICT4D",
            "social computing",
            "ethnography",
            "games",
            "obsolescence",
            "abandonware"
        ],
        "communities": [
            "games",
            "sustainability",
            "cci",
            "hci4d"
        ],
        "session": {
            "id": "s261",
            "name": "Sustainability / MISC"
        },
        "room": "bordeaux",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth17440",
                "givenName": "Derek",
                "familyName": "Lomas",
                "email": "dereklomas@gmail.com",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth18711",
                "givenName": "Kishan",
                "familyName": "Patel",
                "email": "kishaniit@gmail.com",
                "primary": {
                    "institution": "DA-IICT",
                    "city": "Gandhinagar",
                    "state": "Gujarat",
                    "country": "India"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth21980",
                "givenName": "Dixie",
                "familyName": "Ching",
                "email": "dixie@nyu.edu",
                "primary": {
                    "dept": "Games for Learning Institute",
                    "institution": "NYU",
                    "city": "New York",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth23729",
                "givenName": "Meera",
                "familyName": "Lakshmanan",
                "email": "meeragargi@gmail.com",
                "primary": {
                    "institution": "Not presently affiliated",
                    "city": "Bangalore",
                    "country": "India"
                }
            },
            {
                "id": "auth3375",
                "givenName": "Matthew",
                "familyName": "Kam",
                "email": "mkam@air.org",
                "primary": {
                    "dept": "International Development Program",
                    "institution": "American Institutes for Research",
                    "city": "Washington",
                    "state": "D.C.",
                    "country": "United States"
                }
            },
            {
                "id": "auth14117",
                "givenName": "Anuj",
                "familyName": "Kumar",
                "email": "anujk1@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth1028",
                "givenName": "Jodi",
                "middleInitial": "L",
                "familyName": "Forlizzi",
                "email": "forlizzi@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 349,
        "name": "Gesture Studio: Authoring Multi-Touch Interactions through Demonstration and Declaration",
        "type": "paper",
        "abstract": "The prevalence of multi-touch devices opens the space for rich interactions. However, the complexity for creating multi-touch interactions hinders this potential. In this paper, we present Gesture Studio, a tool for creating multi-touch interaction behaviors by combining the strength of two distinct but complementary approaches: programming by demonstration and declaration. We employ an intuitive video-authoring metaphor for developers to demonstrate touch gestures, compose complicated behaviors, test these behaviors in the tool and export them as source code that can be integrated into the developers’ project.",
        "cbStatement": "We present Gesture Studio, a tool for creating multi-touch interactions. It combines the strengths of both programming by demonstration and declaration in an intuitive UI based on video-editing metaphor.",
        "bookmarks": 116,
        "keywords": [
            "Multi-touch gestures",
            "programming by demonstration",
            "declaration",
            "probabilistic reasoning",
            "state machines"
        ],
        "communities": [
            "engineering"
        ],
        "video": "chi2321-file5.mp4",
        "session": {
            "id": "s221",
            "name": "Multitouch and Gestures"
        },
        "room": "352ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth18383",
                "givenName": "Hao",
                "familyName": "Lü",
                "email": "ryan.hlv@gmail.com",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "WA",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth3340",
                "givenName": "Yang",
                "familyName": "Li",
                "email": "yangli@acm.org",
                "primary": {
                    "institution": "Google Research",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 350,
        "name": "Using Contextual Integrity to Examine Interpersonal Information Boundary on Social Network Sites",
        "type": "paper",
        "abstract": "Although privacy problems in Social Network Sites (SNS) have become more salient than ever in recent years, interpersonal privacy issues in SNS remain understudied. This study aims to generate insights in understanding users' interpersonal privacy concerns by expounding interpersonal privacy boundaries in SNS. Through a case analysis of Friendship Pages on Facebook, this paper identifies users' interpersonal privacy concerns that are rooted from informational norms outlined in the theory of contextual integrity, as well as the tensions that occur within and cross these informational norms. This paper concludes with a discussion of design implications and future research.",
        "cbStatement": "Through a case analysis of Friendship Pages on Facebook, this paper identifies users' interpersonal privacy concerns that are rooted from informational norms outlined in the theory of contextual integrity.",
        "bookmarks": 34,
        "keywords": [
            "Interpersonal privacy concerns",
            "Social network sites (SNS)",
            "Privacy boundary",
            "Facebook",
            "Friendship Pages"
        ],
        "communities": [
            "management",
            "ux"
        ],
        "video": "chi2330-file5.mp4",
        "session": {
            "id": "s205",
            "name": "Look how popular I am: managing social media platforms"
        },
        "room": "blue",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth17374",
                "givenName": "Pan",
                "familyName": "Shi",
                "email": "pzs125@psu.edu",
                "primary": {
                    "dept": "College of Information Sciences and Technology",
                    "institution": "The Pennsylvania State University",
                    "city": "University Park",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth9278",
                "givenName": "Heng",
                "familyName": "Xu",
                "email": "hxu@ist.psu.edu",
                "primary": {
                    "institution": "The Pennsylvania State University",
                    "city": "University Park",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth13111",
                "givenName": "Yunan",
                "familyName": "Chen",
                "email": "yunanc@ics.uci.edu",
                "primary": {
                    "institution": "University of California, Irvine",
                    "city": "Irvine",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 351,
        "name": "Adaptive Automation and Cue Invocation: The Effect of Cue Timing on Operator Error",
        "type": "paper",
        "abstract": "Adaptive automation (AA) can improve performance while addressing the problems associated with a fully automated system.  The best way to invoke AA is unclear, but two ways include critical events and the operator’s state. A hybrid model of AA invocation, the dynamic model of operator overload (DMOO), that takes into account critical events and the operator’s state was recently shown to improve performance.  The DMOO initiates AA using critical events and attention allocation, informed by eye movements.  We compared the DMOO with an inaccurate automation invocation system and a system that invoked AA based only on critical events. Fewer errors were made with DMOO than with the inaccurate system.  In the critical event condition, where automation was invoked at an earlier point in time, there were more memory and planning errors, while for the DMOO condition, which invocated automation at a later point in time, there were more perceptual errors.  These findings provide a framework for reducing specific types of errors through different automation invocation. ",
        "cbStatement": "Hybrid adaptive automation, which uses critical-events and eye-movements, was compared with critical-event invocation.  Both systems reduced errors, but cue timing affected the types of errors made in a supervisory-control task.",
        "bookmarks": 63,
        "keywords": [
            "Adaptive Automation",
            "Situation Awareness",
            "Fan-out",
            "Trust in Automation",
            "Eye Tracking",
            "Errors",
            "Supervisory Control"
        ],
        "communities": [
            "design",
            "engineering",
            "ux"
        ],
        "video": "chi2338-file5.mp4",
        "session": {
            "id": "s270",
            "name": "Untitled (Automotive and Awareness)"
        },
        "room": "241",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth30814",
                "givenName": "Daniel",
                "middleInitial": "I",
                "familyName": "Gartenberg",
                "email": "gartenbergdaniel@gmail.com",
                "primary": {
                    "dept": "Psychology/George Mason University/Human Factors and Applied Cognition",
                    "institution": "George Mason University",
                    "city": "Fairfax",
                    "state": "VA",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30922",
                "givenName": "Leonard",
                "familyName": "Breslow",
                "email": "len.breslow@nrl.navy.mil",
                "primary": {
                    "dept": "Navy Center for Applied Research in Artificial Intelligence",
                    "institution": "Naval Research Laboratory",
                    "city": "Washington",
                    "state": "District of Columbia",
                    "country": "United States"
                }
            },
            {
                "id": "auth30923",
                "givenName": "Joo",
                "familyName": "Park",
                "email": "park.joo@gmail.com",
                "primary": {
                    "dept": "Psychology",
                    "institution": "George Mason University",
                    "city": "Fairfax",
                    "state": "Virginia",
                    "country": "United States"
                }
            },
            {
                "id": "auth30924",
                "givenName": "Malcolm",
                "familyName": "McCurry",
                "email": "mccurry@itd.nrl.navy.mil",
                "primary": {
                    "dept": "Navy Center For Applied Researh in Artificial Intelligence",
                    "institution": "Naval Research Laboratory",
                    "city": "Washington",
                    "state": "District of Columbia",
                    "country": "United States"
                }
            },
            {
                "id": "auth14794",
                "givenName": "Greg",
                "familyName": "Trafton",
                "email": "greg.trafton@nrl.navy.mil",
                "primary": {
                    "dept": "Naval Research Laboratory",
                    "institution": "Naval Research Laboratory",
                    "city": "Washington",
                    "state": "District of Columbia",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 352,
        "name": "Infrastructure and Vocation: Field, Calling, and Computation in Ecology",
        "type": "paper",
        "abstract": "HCI studies of computational change in the sciences have made important design and analytic contributions, to other fields of science and to HCI itself. But some of the longer-term effects and complexities of infrastructural change in the sciences aren’t easily captured under short-term, design- or artifact-centered accounts. Drawing on extended ethnographic study of computational development in ecology, this paper explores the relationship between new computational infrastructure and the nature of ecology as a vocation: roughly, the deeply held sense of what it means to ‘be’ an ecologist, and to ‘do’ ecology. We analyze in particular the nature of the field and field work as a central site of ecological practice and identity; how new computational developments are remediating this crucial relation; and the emergent vocational values that new and more computationally-intensive forms of ecology may give rise to.",
        "cbStatement": "Ethnographic study exploring relationship between computational change and ecology as a vocation. Argues that new computational development remediates ecology's crucial field relations, with implications for design and engagement.",
        "bookmarks": 131,
        "keywords": [
            "Infrastructure",
            "collaboration",
            "science",
            "ecology",
            "vocation",
            "values in design."
        ],
        "communities": [],
        "authors": [
            {
                "id": "auth7190",
                "givenName": "Steven",
                "middleInitial": "J",
                "familyName": "Jackson",
                "email": "sjj54@cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth28006",
                "givenName": "Sarah",
                "familyName": "Barbrow",
                "email": "sbarbrow@umich.edu",
                "primary": {
                    "institution": "University of Michigan",
                    "city": "Ann Arbor",
                    "state": "Michigan",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 353,
        "name": "Multiple Notification Modalities and Older Users",
        "type": "paper",
        "abstract": "Multimodal interaction can make home care reminder systems more accessible to their users, most of whom are older and/or have sensory impairments. Existing research into the properties of different notification modalities have used younger participants rather than members of the older population at which they are aimed. This paper presents the results of a user study with older adults that examined how different notification modalities affected (a) performance in a card matching game and (b) how effective the different modalities were at delivering information. Participants were all aged over 50 and notifications were delivered using textual, pictographic, abstract visual, speech, Earcon, Auditory Icon, tactile and olfactory modalities while playing the game. The results showed that older users were influenced by the same factors as younger users, yet there were subjective differences. The implications for the design of multimodal reminder systems for home care are discussed.",
        "cbStatement": "An experiment tested the way older users react to notifications delivered in 8 different modalities. Interesting differences were found between notifications requiring a response and ones that should be ignored.",
        "bookmarks": 76,
        "keywords": [
            "Multimodal",
            "Older Users",
            "Notifications",
            "Reminders"
        ],
        "communities": [
            "design"
        ],
        "video": "chi2340-file5.mp4",
        "session": {
            "id": "s290",
            "name": "Technologies for Life 2"
        },
        "room": "242ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth20597",
                "givenName": "David",
                "familyName": "Warnock",
                "email": "warnockd@dcs.gla.ac.uk",
                "primary": {
                    "institution": "University of Glasgow",
                    "city": "Glasgow",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth1374",
                "givenName": "Stephen",
                "middleInitial": "A",
                "familyName": "Brewster",
                "email": "stephen.brewster@glasgow.ac.uk",
                "primary": {
                    "institution": "University of Glasgow",
                    "city": "Glasgow",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth7922",
                "givenName": "Marilyn",
                "middleInitial": "R",
                "familyName": "McGee-Lennon",
                "email": "Marilyn.McGee-Lennon@glasgow.ac.uk",
                "primary": {
                    "dept": "School of Computing Science",
                    "institution": "University of Glasgow",
                    "city": "Glasgow",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 354,
        "name": "The Space Between the Notes: Adding Expressive Pitch Control to the Piano Keyboard",
        "type": "paper",
        "abstract": "This paper addresses the question of how to extend the capabilities of a well-established interface in a way that respects users' existing expertise. The piano-style keyboard is among the most widely used and versatile of digital musical interfaces. However, it lacks the ability to alter the pitch of a note after it has been played, a limitation which prevents the performer from executing common expressive techniques including vibrato and pitch bending. We present a system for controlling pitch from the keyboard surface using capacitive touch sensors to measure the locations of the player's fingers on the keys. The large community of trained pianists makes the keyboard a compelling target for augmentation, but it also poses a challenge: how can a musical interface be extended while making use of the existing techniques performers have spent thousands of hours learning? In this paper, user studies with conservatory pianists explore the constraints of traditional keyboard technique and evaluate the usability of the continuous pitch control system. The paper also discusses implications for the extension of other established interfaces in musical and non-musical contexts.",
        "cbStatement": "This paper presents an extended keyboard interface that engages with pianists' existing training and expertise. Touch sensors add expressive vibrato and pitch bend capabilities without interfering with traditional technique.",
        "bookmarks": 36,
        "keywords": [
            "Piano keyboard",
            "musical interfaces",
            "capacitive touch sensing",
            "performance technique",
            "expressivity",
            "digital arts"
        ],
        "communities": [
            "design",
            "engineering",
            "ux",
            "arts"
        ],
        "video": "chi2344-file5.mp4",
        "session": {
            "id": "s236",
            "name": "Performing on Stage"
        },
        "authors": [
            {
                "id": "auth14963",
                "givenName": "Andrew",
                "middleInitial": "P",
                "familyName": "McPherson",
                "email": "andrew.p.mcpherson@gmail.com",
                "primary": {
                    "dept": "Centre for Digital Music",
                    "institution": "Queen Mary, University of London",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth30881",
                "givenName": "Adrian",
                "familyName": "Gierakowski",
                "email": "adriang@eecs.qmul.ac.uk",
                "primary": {
                    "dept": "Centre for Digital Music",
                    "institution": "Queen Mary, University of London",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30882",
                "givenName": "Adam",
                "middleInitial": "M",
                "familyName": "Stark",
                "email": "adam.stark@eecs.qmul.ac.uk",
                "primary": {
                    "dept": "Centre for Digital Music",
                    "institution": "Queen Mary, University of London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 355,
        "name": "Informal Cognitive Walkthroughs (ICW): Paring Down and Pairing Up for an Agile World",
        "type": "paper",
        "abstract": "Agile software teams’ frequent releases and fast iterations present a growing need for rigorous user experience research methods that are faster, lighter-weight, and more flexible. To this end, we developed the Informal Cognitive Walkthrough (ICW). This agile research methodology grew organically, over the course of three years, while working with a very large agile software development team. ICWs involve conducting one or more Simplified ‘Streamlined Cognitive Walkthroughs’ (SSCW), followed by one or more Simplified ‘Pluralistic Walkthroughs’ (SPW). In this paper, we present the ICW and provide a real-world example of its application. Preliminary experiences with the method revealed potential advantages over traditional lab studies, ranging from more quickly uncovering and fixing usability issues, to a stronger collaboration between the disciplines, and to acting as a forcing function in aligning diverse engineers to deliver on a common user goal.",
        "cbStatement": "We present the Informal Cognitive Walkthrough (ICW): an agile user experience research methodology, developed and perfected over three years to meet the needs of a large agile software development team.",
        "bookmarks": 41,
        "keywords": [
            "Agile",
            "Usability testing",
            "User-centered design"
        ],
        "communities": [
            "design",
            "engineering",
            "ux"
        ],
        "video": "chi2346-file5.mp4",
        "session": {
            "id": "s279",
            "name": "Evaluation Methods 1"
        },
        "room": "351",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth7915",
                "givenName": "Valentina",
                "middleInitial": "I",
                "familyName": "Grigoreanu",
                "email": "valentina32@msn.com",
                "primary": {
                    "institution": "Microsoft Corporation",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30862",
                "givenName": "Manal",
                "familyName": "Mohanna",
                "email": "manalmo@microsoft.com",
                "primary": {
                    "institution": "Microsoft Corporation",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 356,
        "name": "FFitts Law: Modeling Finger Touch with Fitts’ Law",
        "type": "paper",
        "abstract": "Fitts’ law has proven to be a strong predictor of pointing performance under a wide range of conditions. However, it has been insufficient in modeling small-target acquisition with finger-touch based input on screens. We propose a dual-distribution hypothesis to interpret the distribution of the endpoints in finger touch input. We hypothesize the movement endpoint distribution as a sum of two independent normal distributions. One distribution reflects the relative precision governed by the speed-accuracy tradeoff rule in the human motor system, and the other captures the absolute precision of finger touch independent of the speed-accuracy tradeoff effect. Based on this hypothesis, we derived the FFitts model—an expansion of Fitts’ law for finger touch input. We present three experiments in 1D target acquisition, 2D target acquisition and touchscreen keyboard typing tasks respectively. The results showed that FFitts law is more accurate than Fitts’ law in modeling finger input on touchscreens. At 0.91 or a greater R2 value, FFitts’ index of difficulty is able to account for significantly more variance than conventional Fitts’ index of difficulty based on either a nominal target width or an effective target width in all the three experiments. ",
        "cbStatement": "Proposed and validated a dual Gaussian distribution hypothesis, from which we derived FFitts law, a novel expansion of Fitts’ law to more reliably model touchscreen target acquisition with finger.",
        "bookmarks": 163,
        "keywords": [
            "Fitts’ law",
            "Touchscreen",
            "Finger input"
        ],
        "communities": [
            "engineering"
        ],
        "video": "chi2353-file5.mp4",
        "session": {
            "id": "s252",
            "name": "Pointing and Fitts Law"
        },
        "room": "241",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth9137",
                "givenName": "Xiaojun",
                "familyName": "Bi",
                "email": "xjunbi@gmail.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth3340",
                "givenName": "Yang",
                "familyName": "Li",
                "email": "yangli@acm.org",
                "primary": {
                    "institution": "Google Research",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth1220",
                "givenName": "Shumin",
                "familyName": "Zhai",
                "email": "zhai@acm.org",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 357,
        "name": "Factors Impacting Community Response in an Interest-Sharing Network",
        "type": "paper",
        "abstract": "The arrival of a new interest-sharing network, So.cl, provides for a new opportunity to explore human behavior as it relates to constructing public contributions and receiving community response. This study looks at archival data in order to better understand how types of shared content receive interaction from others. The results suggest that a So.cl user should include more photos and less links on their post to increase the quantity of likes and comments the community gives to the post, among other discoveries.",
        "cbStatement": "This study looks at archival data from a new interest-sharing network, So.cl, in order to better understand what user-shared content receives most interaction from others in the community. ",
        "bookmarks": 43,
        "keywords": [
            "Social networks",
            "Log analysis"
        ],
        "communities": [],
        "video": "chi2355-file5.mp4",
        "session": {
            "id": "s260",
            "name": "Crowdsource Activism Volunteering Citizen Science"
        },
        "room": "bordeaux",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth16822",
                "givenName": "Iris",
                "familyName": "Howley",
                "email": "ihowley@andrew.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30890",
                "givenName": "Todd",
                "familyName": "Newman",
                "email": "toddne@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 358,
        "name": "Influencing Visual Judgment through Affective Priming",
        "type": "paper",
        "abstract": "Recent research suggests that individual personality differences can influence performance with visualizations. \\ In addition to stable personality traits, research in psychology has found that temporary changes in affect (emotion) can also significantly impact performance during cognitive tasks. \\ In this paper, we show that affective priming also influences user performance on visual judgment tasks through an experiment that combines affective priming with longstanding graphical perception experiments. \\ Our results suggest that affective priming can influence accuracy in common graphical perception tasks. \\ We discuss possible explanations for these findings, and describe how these findings can be applied to design visualizations that are less (or more) susceptible to error in common visualization contexts. ",
        "cbStatement": "Affective priming (positive and negative emotion) is shown to significantly influence accuracy in visual judgment tasks for several common chart types.",
        "bookmarks": 141,
        "keywords": [
            "Visualization",
            "Affect",
            "Emotion",
            "Charts"
        ],
        "communities": [
            "design",
            "management"
        ],
        "video": "chi2358-file5.mp4",
        "session": {
            "id": "s232",
            "name": "Visual perception"
        },
        "room": "blue",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth30840",
                "givenName": "Lane",
                "familyName": "Harrison",
                "email": "ltharri1@uncc.edu",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "University of North Carolina at Charlotte",
                    "city": "Charlotte",
                    "state": "North Carolina",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30880",
                "givenName": "Drew",
                "familyName": "Skau",
                "email": "dwskau@uncc.edu",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "University of North Carolina at Charlotte",
                    "city": "Charlotte",
                    "state": "North Carolina",
                    "country": "United States"
                }
            },
            {
                "id": "auth22576",
                "givenName": "Steven",
                "familyName": "Franconeri",
                "email": "franconeri@gmail.com",
                "primary": {
                    "dept": "Cognitive Psychology",
                    "institution": "Northwestern University",
                    "city": "Evanston",
                    "state": "Illinois",
                    "country": "United States"
                }
            },
            {
                "id": "auth12254",
                "givenName": "Aidong",
                "familyName": "Lu",
                "email": "aidong.lu@uncc.edu",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "University of North Carolina at Charlotte",
                    "city": "Charlotte",
                    "state": "North Carolina",
                    "country": "United States"
                }
            },
            {
                "id": "auth19370",
                "givenName": "Remco",
                "familyName": "Chang",
                "email": "remco@cs.tufts.edu",
                "primary": {
                    "institution": "Tufts University",
                    "city": "Medford",
                    "state": "MA",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 359,
        "name": "Revisiting Social Practices Surrounding Music",
        "type": "paper",
        "abstract": "Music shapes our social lives. While previous research has provided a foundational understanding of the social affordances surrounding people’s interactions with music, there is a need to update this understanding in light of recent key developments in our digital technological landscape. This paper describes a qualitative study of people’s social activities and practices around music in households. It extends previous research by revealing the impact key technologies have on how, where, when, and with who people’s interactions surrounding music occur. It also reveals people’s creative attempts to design their musical experiences with others through reconfiguring and connecting to various digital technologies and digital platforms in order to pursue more opportunities for communicating, sharing, bonding, and celebrating lives with others.",
        "cbStatement": "This paper extends and contributes to our understanding of social practices and sociality surrounding music in light of recent key technological developments.",
        "bookmarks": 181,
        "keywords": [
            "Digital music",
            "Household",
            "Sociality",
            "Design;"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0239-file5.m4v",
        "session": {
            "id": "s207",
            "name": "Social Face: creativity unleashed online"
        },
        "room": "bordeaux",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth7738",
                "givenName": "Tuck",
                "middleInitial": "W",
                "familyName": "Leong",
                "email": "tuckwah@gmail.com",
                "primary": {
                    "dept": "Interaction Design and Human Practice Lab",
                    "institution": "University of Technology, Sydney",
                    "city": "Sydney",
                    "country": "Australia"
                },
                "secondary": {
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth9063",
                "givenName": "Peter",
                "familyName": "Wright",
                "email": "p.c.wright@newcastle.ac.uk",
                "primary": {
                    "institution": "Newcastle University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 360,
        "name": "FreeD – A Freehand Digital Sculpting Tool",
        "type": "paper",
        "abstract": "In this paper, we present an approach to combining digital fabrication and craft, emphasizing the user experience. While many researchers strive to enable makers to design and produce 3D objects, our research seeks to present a new fabrication approach to make unique, one-of-a-kind artifacts. To that end, we developed the FreeD, a hand-held digital milling device. The system is guided and monitored by a computer while preserving the maker’s freedom to sculpt and carve, and to manipulate the work in many creative ways. Relying on a predesigned 3D model, the computer gets into action only when the milling bit risks the object’s integrity, by slowing down the spindle’s speed or by drawing back the shaft, while the rest of the time it allows complete gestural freedom. We describe the key concepts of our work and its motivation, present the FreeD’s architecture and technology, and discuss two projects made with the tool.",
        "cbStatement": "This paper explores the intersection of craft and digital fabrication through the FreeD, a handheld milling device, preserving the maker’s freedom to sculpt and carve based on virtual 3D models.  ",
        "bookmarks": 169,
        "keywords": [
            "Computer-Aided Design (CAD)",
            "Craft",
            "Digital Fabrication",
            "Carving",
            "Milling"
        ],
        "communities": [
            "design",
            "engineering",
            "ux",
            "arts"
        ],
        "video": "chi0241-file5.mp4",
        "session": {
            "id": "s227",
            "name": "Fabrication"
        },
        "room": "352ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth11607",
                "givenName": "Amit",
                "familyName": "Zoran",
                "email": "amitz@mit.edu",
                "primary": {
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth4140",
                "givenName": "Joseph",
                "middleInitial": "A.",
                "familyName": "Paradiso",
                "email": "joep@media.mit.edu",
                "primary": {
                    "dept": "Massachusetts Institute of Technology, Cambridge, Massachusetts, United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 361,
        "name": "SpaceTop: Integrating 2D and Spatial 3D Interactions  in a See-through Desktop Environment",
        "type": "paper",
        "abstract": "SpaceTop is a concept that fuses spatial 2D and 3D interactions in a single workspace. It extends the traditional desktop interface with interaction technology and visualization techniques that enable seamless transitions between 2D and 3D manipulations. SpaceTop allows users to type, click, draw in 2D, and directly manipulate interface elements that float in the 3D space above the keyboard. It makes it possible to easily switch from one modality to another, or to simultaneously use two modalities with different hands. We introduce hardware and software configurations for co-locating these various interaction modalities in a unified workspace using depth cameras and a transparent display. We describe new interaction and visualization techniques that allow users to interact with 2D elements floating in 3D space. We present the results from a preliminary user study that indicates the benefit of such hybrid workspaces. ",
        "cbStatement": "SpaceTop is a concept that integrates 2D and 3D spatial interactions in a desktop workspace. It extends the desktop interface with interaction technology and visualization techniques that enable seamless transitions between 2D and 3D manipulations.",
        "bookmarks": 56,
        "keywords": [
            "3D UI",
            "Augmented Reality",
            "Desktop Management"
        ],
        "communities": [
            "design",
            "engineering",
            "ux"
        ],
        "video": "chi0250-file5.mp4",
        "session": {
            "id": "s251",
            "name": "3D Uis"
        },
        "room": "241",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth15276",
                "givenName": "Jinha",
                "familyName": "Lee",
                "email": "jinhalee@media.mit.edu",
                "primary": {
                    "dept": "MIT",
                    "institution": "Media Lab",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "secondary": {
                    "dept": "Microsoft",
                    "institution": "Applied Sciences Group",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth4018",
                "givenName": "Alex",
                "familyName": "Olwal",
                "email": "olwal@mit.edu",
                "primary": {
                    "dept": "MIT",
                    "institution": "Media Lab",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth2008",
                "givenName": "Hiroshi",
                "familyName": "Ishii",
                "email": "ishii@media.mit.edu",
                "primary": {
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth21094",
                "givenName": "Cati",
                "familyName": "Boulanger",
                "email": "catib@microsoft.com",
                "primary": {
                    "institution": "Microsoft Applied Sciences Group",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 362,
        "name": "Graduate Student Use of a Multi-Slate Reading System",
        "type": "paper",
        "abstract": "In laboratory studies, multi-surface slate-based reading systems have shown great promise as platforms for active reading. However, the true utility of such a system can only be ascertained through the rigors of real world use. We conducted month-long deployments of a multi-slate reading system to support the active reading activities of graduate students in the humanities. During these deployments we documented how the added display area and increased micro-mobility of multiple devices enhanced navigation and reading comfort. We also noted the essential role of writing and annotation. Finally, we observed how electronic affordances like synchronization across devices helped provide functionality that would not have been possible with paper documents. This paper contributes new information about how electronic reading solutions fit into real world reading workflows.",
        "cbStatement": "We conducted month-long deployments of a multi-slate active reading system with graduate students in the humanities. Results confirm the importance of added display space, mobility, and support for writing.",
        "bookmarks": 77,
        "keywords": [
            "reading",
            "e-book",
            "e-reading",
            "multi-slate",
            "tablet",
            "multi-screen computing",
            "deployment",
            "graduate students",
            "academia"
        ],
        "communities": [],
        "video": "chi0253-file5.mp4",
        "session": {
            "id": "s287",
            "name": "Online Classrooms"
        },
        "room": "251",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth6000",
                "givenName": "Nicholas",
                "middleInitial": "Y",
                "familyName": "Chen",
                "email": "nchen@cs.umd.edu",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                },
                "secondary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1483",
                "givenName": "François",
                "middleInitial": "V",
                "familyName": "Guimbretière",
                "email": "francois@cs.cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "NY",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1515",
                "givenName": "Abigail",
                "middleInitial": "J",
                "familyName": "Sellen",
                "email": "asellen@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 363,
        "name": "WatchIt: Simple Gestures and Eyes-free Interaction for Wristwatches and Bracelets",
        "type": "paper",
        "abstract": "We present WatchIt, a prototype device that extends interaction beyond the watch surface to the wristband, and two interaction techniques for command selection and execution. Because the small screen of wristwatch computers suffers from visual occlusion and the fat finger problem, we investigated the use of the wristband as an available interaction resource. Not only does WatchIt use a cheap, energy efficient and invisible technology, but it involves simple, basic gestures that allow good performance after little training, as suggested by the results of a pilot study. We propose a novel gesture technique and an adaptation of an existing menu technique suitable for wristband interaction. In a user study, we investigated their usage in eyes-free contexts, finding that they perform well. Finally, we present techniques where the bracelet is used in addition to the screen to provide precise continuous control over list scrolling. We also report on a preliminary survey of traditional and digital jewelry that points to the high frequency of watches and bracelets in both genders and gives a sense of the tasks people feel like performing on such devices. ",
        "cbStatement": "WatchIt is a prototype device that extends interaction from a watch screen to a wristband or bracelet.  We evaluate its use for discrete gestures, continuous control, and eyes-free usage.",
        "bookmarks": 109,
        "keywords": [
            "Digital jewelry",
            "wearable computing",
            "watch",
            "watchstrap",
            "watchband",
            "watch bracelet",
            "input",
            "eyes-free interaction",
            "continuous input",
            "scrolling"
        ],
        "communities": [],
        "video": "chi0267-file5.mp4",
        "session": {
            "id": "s224",
            "name": "Displays and Wearable"
        },
        "room": "352ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth16597",
                "givenName": "Simon",
                "middleInitial": "T",
                "familyName": "PERRAULT",
                "email": "perrault@telecom-paristech.fr",
                "primary": {
                    "institution": "Telecom ParisTech",
                    "city": "Paris",
                    "country": "France"
                },
                "role": "presenter"
            },
            {
                "id": "auth3666",
                "givenName": "Eric",
                "familyName": "Lecolinet",
                "email": "eric.lecolinet@enst.fr",
                "primary": {
                    "institution": "Telecom ParisTech",
                    "city": "Paris",
                    "country": "France"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth5893",
                "givenName": "James",
                "familyName": "Eagan",
                "email": "eagan@telecom-paristech.fr",
                "primary": {
                    "institution": "Telecom ParisTech – CNRS LTCI UMR 5141 ",
                    "city": "Paris",
                    "country": "France"
                }
            },
            {
                "id": "auth1912",
                "givenName": "Yves",
                "familyName": "GUIARD",
                "email": "yves.guiard@telecom-paristech.fr",
                "primary": {
                    "institution": "Telecom ParisTech",
                    "city": "Paris",
                    "country": "France"
                }
            }
        ]
    },
    {
        "id": 364,
        "name": "Domestic Food and Sustainable Design:  A Study of University Student Cooking and its Impacts",
        "type": "paper",
        "abstract": "In four university student kitchens over twenty-one days, we captured participants' food preparation activity, quantified the greenhouse gas emissions and direct energy connected to the food and cooking, and talked to participants about their food practices.  Grounded in this uniquely detailed micro-account, our findings inform sustainable design for cooking and eating at home and quantify the potential impacts.  We outline the relation of the impacts to our participants' approaches to everyday food preparation, the organisation of their time, and the role of social meals.  Our technique allows evaluation of opportunities for sustainable intervention design: at the appliance, in the digitally-mediated organisation of meals and inventory management, and more broadly in reflecting upon and reshaping diet.",
        "cbStatement": "523 meals over 21 days:  705 kg carbon, 325 kWh of electricity.  Interviews, cameras and power meters reveal food's impacts, situated within everyday life.  Come ponder the sustainable design challenges.",
        "bookmarks": 122,
        "keywords": [
            "sustainability",
            "food",
            "practices",
            "everyday life",
            "energy",
            "greenhouse gas"
        ],
        "communities": [
            "sustainability"
        ],
        "video": "chi0273-file5.mp4",
        "session": {
            "id": "s263",
            "name": "Food"
        },
        "room": "351",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth22623",
                "givenName": "Adrian",
                "middleInitial": "K",
                "familyName": "Clear",
                "email": "a.clear@lancaster.ac.uk",
                "primary": {
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth7362",
                "givenName": "Mike",
                "familyName": "Hazas",
                "email": "hazas@comp.lancs.ac.uk",
                "primary": {
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "state": "Lancashire",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth23935",
                "givenName": "Janine",
                "familyName": "Morley",
                "email": "j.morley@lancaster.ac.uk",
                "primary": {
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "state": "Lancashire",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth8353",
                "givenName": "Adrian",
                "familyName": "Friday",
                "email": "adrian@comp.lancs.ac.uk",
                "primary": {
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "state": "Lancashire",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth23937",
                "givenName": "Oliver",
                "familyName": "Bates",
                "email": "o.bates@lancaster.ac.uk",
                "primary": {
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "state": "Lancashire",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 365,
        "name": "Augmented Letters: Mnemonic Gesture-Based Shortcuts",
        "type": "paper",
        "abstract": "We propose Augmented Letters, a new technique aimed at augmenting gesture-based techniques such as Marking Menus by giving them natural, mnemonic associations. Augmented Letters gestures consist of the initial of command names, sketched by hand in the Unistroke style, and affixed with a straight tail. We designed a tentative touch device interaction technique that supports fast interactions with large sets of commands, is easily discoverable, improves user’s recall at no speed cost, and supports fluid transition from novice to expert mode. An experiment suggests that Augmented Letters outperform Marking Menu in terms of user recall.",
        "cbStatement": "Appending a tail to the first letter of a command: Augmented Letters allows users to memorize larger command shortcut vocabularies than Marking Menus, with no overall speed cost.",
        "bookmarks": 155,
        "keywords": [
            "Handwriting",
            "Gestures",
            "Semantics",
            "Learning",
            "Recall",
            "Unistroke"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi0289-file5.mp4",
        "session": {
            "id": "s222",
            "name": "Touch"
        },
        "room": "352ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth28660",
                "givenName": "Quentin",
                "familyName": "Roy",
                "email": "quentin@quentinroy.fr",
                "primary": {
                    "dept": "Telecom ParisTech",
                    "institution": "CNRS LTCI UMR 5141",
                    "city": "Paris",
                    "country": "France"
                },
                "secondary": {
                    "institution": "GE HealthCare",
                    "city": "Buc",
                    "country": "France"
                },
                "role": "presenter"
            },
            {
                "id": "auth11388",
                "givenName": "Sylvain",
                "familyName": "Malacria",
                "email": "sylvain@malacria.fr",
                "primary": {
                    "institution": "University of Canterbury",
                    "city": "Christchurch",
                    "state": "Canterbury",
                    "country": "New Zealand"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1912",
                "givenName": "Yves",
                "familyName": "Guiard",
                "email": "yves.guiard@telecom-paristech.fr",
                "primary": {
                    "institution": "Telecom ParisTech – CNRS LTCI UMR 5141",
                    "city": "Paris",
                    "country": "France"
                }
            },
            {
                "id": "auth3666",
                "givenName": "Eric",
                "familyName": "Lecolinet",
                "email": "eric.lecolinet@enst.fr",
                "primary": {
                    "institution": "Telecom ParisTech",
                    "city": "Paris",
                    "country": "France"
                }
            },
            {
                "id": "auth5893",
                "givenName": "James",
                "familyName": "Eagan",
                "email": "eagan@telecom-paristech.fr",
                "primary": {
                    "institution": "Telecom ParisTech – CNRS LTCI UMR 5141 ",
                    "city": "Paris",
                    "country": "France"
                }
            }
        ]
    },
    {
        "id": 366,
        "name": "Direct Manipulation Video Navigation in 3D",
        "type": "paper",
        "abstract": "Direct Manipulation Video Navigation (DMVN) systems allow a user to navigate a video by dragging an object along its motion trajectory. These systems have been shown effective for space-centric video browsing. Their performance, however, is often limited by temporal ambiguities in a video with complex motion, such as recurring motion, self-intersecting motion, and pauses. The ambiguities come from reducing the 3D spatial-temporal motion (x, y, t) to the 2D spatial motion (x, y) in visualizing the motion and dragging the object. In this paper, we present a 3D DMVN system that maps the spatial-temporal motion (x, y, t) to 3D space (x, y, z) by mapping time t to depth z, visualizes the motion and video frame in 3D, and allows to navigate the video by spatial-temporally manipulating the object in 3D. We show that since our 3D DMVN system preserves all the motion information, it resolves the temporal ambiguities and supports intuitive navigation on challenging videos with complex motion.",
        "cbStatement": "This paper presents a 3D DMVN system that visualizes the video frame and motion in 3D, resolves temporal ambiguities, and allows a user to manipulate an object along its trajectory. \\ ",
        "bookmarks": 188,
        "keywords": [
            "Video navigation",
            "direct manipulation",
            "3D visualization"
        ],
        "communities": [
            "engineering"
        ],
        "video": "chi0292-file5.mp4",
        "session": {
            "id": "s234",
            "name": "Video"
        },
        "room": "bordeaux",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth22178",
                "givenName": "Cuong",
                "familyName": "Nguyen",
                "email": "cuong3@pdx.edu",
                "primary": {
                    "institution": "Portland State University",
                    "city": "Portland",
                    "state": "Oregon",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth22168",
                "givenName": "Yuzhen",
                "familyName": "Niu",
                "email": "yuzhen@cs.pdx.edu",
                "primary": {
                    "institution": "Portland State University",
                    "city": "Portland",
                    "state": "Oregon",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth5695",
                "givenName": "Feng",
                "familyName": "Liu",
                "email": "fliu@cs.pdx.edu",
                "primary": {
                    "institution": "Portland State University",
                    "city": "Portland",
                    "state": "Oregon",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 367,
        "name": "Bezel-Tap Gestures: Quick Activation of Commands from Sleep Mode on Tablets",
        "type": "paper",
        "abstract": "We present Bezel-Tap Gestures, a novel family of interaction techniques for immediate interaction on handheld tablets regardless of whether the device is alive or in sleep mode. The technique rests on the close succession of two input events: first a bezel tap, whose detection by accelerometers will awake an idle tablet almost instantly, then a screen contact. Field studies confirmed that the probability of this input sequence occurring by chance is very low, excluding the accidental activation concern. One experiment examined the optimal size of the vocabulary of commands for all four regions of the bezel (top, bottom, left, right). Another experiment evaluated two variants of the technique which both allow two-level selection in a hierarchy of commands, the initial bezel tap being followed by either two screen taps or a screen slide. The data suggests that Bezel-Tap Gestures may serve to design large vocabularies of micro-interactions with a sleeping tablet.",
        "cbStatement": "Mobile devices constantly switch to sleep mode to save energy. Our contribution is an  always-available shortcuts technique based on combining a bezel tap and a touchscreen contact. ",
        "bookmarks": 20,
        "keywords": [
            "Interaction techniques",
            "Mobile devices",
            "Bezel Gestures",
            "Accelerometers",
            "Micro-Interaction",
            "Marking Menus."
        ],
        "communities": [
            "design"
        ],
        "video": "chi0293-file5.mp4",
        "session": {
            "id": "s219",
            "name": "Mobile Gestures and Grasp"
        },
        "room": "352ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth10750",
                "givenName": "Marcos",
                "familyName": "Serrano",
                "email": "marcanudo@gmail.com",
                "primary": {
                    "institution": "Telecom ParisTech",
                    "city": "Paris",
                    "country": "France"
                },
                "role": "presenter"
            },
            {
                "id": "auth3666",
                "givenName": "Eric",
                "familyName": "Lecolinet",
                "email": "eric.lecolinet@enst.fr",
                "primary": {
                    "institution": "Telecom ParisTech",
                    "city": "Paris",
                    "country": "France"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1912",
                "givenName": "Yves",
                "familyName": "GUIARD",
                "email": "yves.guiard@enst.fr",
                "primary": {
                    "institution": "Telecom ParisTech",
                    "city": "Paris",
                    "country": "France"
                }
            }
        ]
    },
    {
        "id": 368,
        "name": "NoteVideo: Facilitating Navigation of Blackboard-style Lecture Videos",
        "type": "paper",
        "abstract": "Khan Academy's pre-recorded blackboard-style lecture videos attract millions of online users every month. However, current video navigation tools do not adequately support the kinds of goals that students typically have, like quickly finding a particular concept in a blackboard-style lecture video. This paper reports on the development and evaluation of the new NoteVideo and its improved version, NoteVideo+, systems for identifying the conceptual ‘objects’ of a blackboard-based video – and then creating a summarized image of the video and using it as an in-scene navigation interface that allows users to directly jump to the video frame where that object first appeared instead of navigating it linearly through time. The research consisted of iteratively implementing the system and then having users perform four different navigation tasks using three different interfaces: Scrubbing, Transcript, and NoteVideo. Results of the study show that participants perform significantly better on all four tasks while using the NoteVideo and its improved version - NoteVideo+ - as compared to others.",
        "cbStatement": "We create a summarized image of the video and using it as an in-scene navigation interface that allows users to directly jump to the video frame of choice.",
        "bookmarks": 105,
        "keywords": [
            "NoteVideo",
            "NoteVideo+",
            "Video",
            "Video Navigation",
            "Online Streaming",
            "Video summary",
            "Blackboard-style videos"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0299-file5.mp4",
        "session": {
            "id": "s234",
            "name": "Video"
        },
        "room": "bordeaux",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth25432",
                "givenName": "Toni-Jan Keith",
                "middleInitial": "Palma",
                "familyName": "Monserrat",
                "email": "tjmonsi@gmail.com",
                "primary": {
                    "institution": "National University of Singapore",
                    "city": "Singapore",
                    "state": "Singapore",
                    "country": "Singapore"
                },
                "role": "presenter"
            },
            {
                "id": "auth3430",
                "givenName": "Shengdong",
                "familyName": "Zhao",
                "email": "zhaosd@comp.nus.edu.sg",
                "primary": {
                    "institution": "National University of Singapore",
                    "city": "Singapore",
                    "country": "Singapore"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth2434",
                "givenName": "Kevin",
                "familyName": "McGee",
                "email": "mckevin@nus.edu.sg",
                "primary": {
                    "institution": "National University of Singapore",
                    "city": "Singapore",
                    "country": "Singapore"
                }
            },
            {
                "id": "auth26195",
                "givenName": "Anshul Vikram",
                "familyName": "Pandey",
                "email": "anshul.vpandey@gmail.com",
                "primary": {
                    "institution": "National University of Singapore",
                    "city": "Singapore",
                    "country": "Singapore"
                }
            }
        ]
    },
    {
        "id": 369,
        "name": "AutoGami: A Low-cost Rapid Prototyping Toolkit for Automated Movable Paper Craft",
        "type": "paper",
        "abstract": "AutoGami is a toolkit for designing automated movable paper craft using the technology of selective inductive power transmission. AutoGami has hardware and software components that allow users to design and implement automated movable paper craft without any prerequisite knowledge of electronics; it also supports rapid prototyping. Apart from developing the toolkit, we have analyzed the design space of movable paper craft and developed a taxonomy to facilitate the design of automated paper craft. AutoGami made consistently strong showings in design workshops, confirming its viability in supporting engagement and creativity as well as its usability in storytelling through paper craft. Additional highlights include rapid prototyping of product design as well as interaction design such as human-robot interactions.",
        "cbStatement": "We presents a systematic analysis of the design space for automated movable paper craft, and developed a low-cost rapid prototyping toolkit for automated movable paper craft using the technology of selective inductive power transmission. \\ ",
        "bookmarks": 138,
        "keywords": [
            "Automated paper craft, paper computing, toolkit, selective inductive power transmission"
        ],
        "communities": [
            "design",
            "engineering"
        ],
        "video": "chi0300-file5.mp4",
        "session": {
            "id": "s269",
            "name": "Creating and Authoring"
        },
        "room": "241",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth12491",
                "givenName": "Kening",
                "familyName": "Zhu",
                "email": "zhukening@nus.edu.sg",
                "primary": {
                    "institution": "National University of Singapore",
                    "city": "Singapore",
                    "country": "Singapore"
                },
                "role": "presenter"
            },
            {
                "id": "auth3430",
                "givenName": "Shengdong",
                "familyName": "Zhao",
                "email": "zhaosd@comp.nus.edu.sg",
                "primary": {
                    "institution": "National University of Singapore",
                    "city": "Singapore",
                    "country": "Singapore"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 370,
        "name": "Design Research by Proxy: using Children as Researchers to gain Contextual Knowledge about User Experience.",
        "type": "paper",
        "abstract": "This paper explores the use of participants as research collaborators in the domain of contextual user research. In participatory- and co-design, users participate increasingly early in the design process. When conducting user research in order to gain contextual knowledge about the lives, experiences and wishes of users, collaborators can be of help in setting up, conducting research and analyzing the data. A case study was conducted to investigate if and how children are able to perform as research collaborators. Children conducted interviews with other participants, and in doing increased their knowledge about people close to them, and about themselves. The gained insights were personal and the used personas proved to be a valuable tool. In the role of researcher, the children discovered similarities and differences between themselves and others. Besides gaining valuable insights from their participants, they accessed and shared their own experiences, so while listening to others, the children got sensitized themselves. In other words, the current study found that next to gathering more data, “super-sources” are created when children become research collaborators.",
        "cbStatement": "This paper explores the use of participants as research collaborators in contextual user research. A case study was conducted to investigate if and how children can perform as research collaborators. ",
        "bookmarks": 148,
        "keywords": [
            "Design research",
            "research collaborators",
            "contextual user research",
            "co-research",
            "children"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi0312-file5.mp4",
        "session": {
            "id": "s327",
            "name": "Children"
        },
        "room": "bordeaux",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth28839",
                "givenName": "Fenne",
                "familyName": "van Doorn",
                "email": "f.a.p.vandoorn@tudelft.nl",
                "primary": {
                    "dept": "create",
                    "institution": "TU Delft - Studiolab",
                    "city": "Delft",
                    "country": "Netherlands"
                },
                "role": "presenter"
            },
            {
                "id": "auth12197",
                "givenName": "Pieter Jan",
                "familyName": "Stappers",
                "email": "p.j.stappers@tudelft.nl",
                "primary": {
                    "dept": "create",
                    "institution": "TU Delft - Studiolab",
                    "city": "Delft",
                    "country": "Netherlands"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth32378",
                "givenName": "Mathieu",
                "familyName": "Gielen",
                "email": "m.a.gielen@tudelft.nl",
                "primary": {
                    "dept": "create",
                    "institution": "TU Delft - Studiolab",
                    "city": "Delft",
                    "country": "Netherlands"
                }
            }
        ]
    },
    {
        "id": 371,
        "name": "Crossing the Bridge over Norman's Gulf of Execution: Revealing Feedforward's True Identity",
        "type": "paper",
        "abstract": "Feedback and affordances are two of the most well-known principles in interaction design. Unfortunately, the related and equally important notion of feedforward has not been given as much consideration. Nevertheless, feedforward is a powerful design principle for bridging Norman’s Gulf of Execution. We reframe feedforward by disambiguating it from related design principles such as feedback and perceived affordances, and identify new classes of feedforward. In addition, we present a reference framework that provides a means for designers to explore and recognize different opportunities for feedforward.",
        "cbStatement": "We reframe feedforward and disambiguate it from feedback and perceived affordances. We describe a reference framework for designers that allows them to explore and recognize different opportunities for feedforward.",
        "bookmarks": 72,
        "keywords": [
            "feedforward",
            "affordances",
            "feedback",
            "design",
            "theory"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0317-file5.mp4",
        "session": {
            "id": "s214",
            "name": "Design Research, Paradigm and Theory"
        },
        "room": "havane",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth12515",
                "givenName": "Jo",
                "familyName": "Vermeulen",
                "email": "jo.vermeulen@uhasselt.be",
                "primary": {
                    "dept": "Expertise Centre for Digital Media",
                    "institution": "Hasselt University - tUL - iMinds",
                    "city": "Diepenbeek",
                    "country": "Belgium"
                },
                "role": "presenter"
            },
            {
                "id": "auth2807",
                "givenName": "Kris",
                "familyName": "Luyten",
                "email": "kris.luyten@uhasselt.be",
                "primary": {
                    "dept": "Expertise Centre for Digital Media",
                    "institution": "Hasselt University - tUL - iMinds",
                    "city": "Diepenbeek",
                    "country": "Belgium"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth2058",
                "givenName": "Elise",
                "familyName": "van den Hoven",
                "email": "e.v.d.hoven@tue.nl",
                "primary": {
                    "dept": "Design, Architecture & Building",
                    "institution": "University of Technology, Sydney",
                    "city": "Sydney",
                    "country": "Australia"
                },
                "secondary": {
                    "dept": "Industrial Design Department",
                    "institution": "Eindhoven University of Technology",
                    "city": "Eindhoven",
                    "country": "The Netherlands"
                }
            },
            {
                "id": "auth9363",
                "givenName": "Karin",
                "familyName": "Coninx",
                "email": "karin.coninx@uhasselt.be",
                "primary": {
                    "dept": "Expertise Centre for Digital Media",
                    "institution": "Hasselt University - tUL - iMinds",
                    "city": "Diepenbeek",
                    "country": "Belgium"
                }
            }
        ]
    },
    {
        "id": 372,
        "name": "Tables in the Wild: Lessons Learned from a Large-Scale Multi-Tabletop Deployment",
        "type": "paper",
        "abstract": "This paper presents the results and experiences of a six-week deployment of multiple digital tabletops in a school. Dillenbourg’s orchestration framework was used both to guide the design and analysis of the study. Four themes, which directly relate to the design of the technology for the classroom, out of the 15 orchestration factors are considered. For each theme, we present our design choices, the relevant observations, feedback from teachers and students, and we conclude with a number of lessons learned in the form of design recommendations. The distinguishing factors of our study are its scale (in terms of duration, number of classes, subjects, and teachers), and its ‘in-the-wild’ character, with the entire study being conducted in a school, led by the teachers, and using teacher-prepared, curriculum-based tasks. Our primary contributions are the analysis of our observations and design recommendations for future multi-tabletop applications designed for and deployed within the classroom. Our analyses and recommendations meaningfully extend HCI’s current design understandings of such settings. ",
        "cbStatement": "The paper presents the analysis of our observations and design recommendations for multi-tabletop applications designed for and deployed within a realistic classroom setting.",
        "bookmarks": 149,
        "keywords": [
            "Tabletops",
            "collaborative learning",
            "classroom orchestration"
        ],
        "communities": [
            "cci"
        ],
        "video": "chi0339-file5.mp4",
        "session": {
            "id": "s285",
            "name": "Classrooms"
        },
        "room": "blue",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth10954",
                "givenName": "Ahmed",
                "familyName": "Kharrufa",
                "email": "ahmed@reflectivethinking.com",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                },
                "secondary": {
                    "institution": "Reflective Thinking",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth8726",
                "givenName": "Madeline",
                "familyName": "Balaam",
                "email": "madeline.balaam@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth26084",
                "givenName": "Phil",
                "familyName": "Heslop",
                "email": "philip.heslop@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth26680",
                "givenName": "David",
                "familyName": "Leat",
                "email": "david.leat@ncl.ac.uk",
                "primary": {
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth29146",
                "givenName": "Paul",
                "familyName": "Dolan",
                "email": "paulmichaeldolan@gmail.com",
                "primary": {
                    "institution": "Northumbria University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth5105",
                "givenName": "Patrick",
                "familyName": "Olivier",
                "email": "p.l.olivier@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 373,
        "name": "Reducing Disruption from Subtle Information Delivery during a Conversation: Mode and Bandwidth Investigation",
        "type": "paper",
        "abstract": "With proliferation of mobile devices that provide ubiqui-tous access to information, the question arises of how dis-tracting processing information in social settings can be, especially during face-to-face conversations. However, relevant information presented at opportune moments may help enhance conversation quality. In this paper, we study how much information users can consume during a conversation and what information delivery mode, via audio or visual aids, helps them effectively conceal the fact that they are receiving information. We observe that users can internalize more information while still disguising this fact the best when information is delivered visually in batches (multiple pieces of information at a time) and perform better on both dimensions if information is delivered while they are not speaking. Interestingly, participants qualitatively did not prefer this mode as being the easiest to use, preferring modes that displayed one piece of information at a time.  ",
        "cbStatement": "We study how much information and via what mode people can receive and process information in the background while not disrupting a face-to-face conversation they are engaged in. ",
        "bookmarks": 169,
        "keywords": [
            "Augmented Reality",
            "Attention",
            "Design",
            "Human Factors"
        ],
        "communities": [],
        "video": "chi0359-file5.mp4",
        "session": {
            "id": "s266",
            "name": "Language"
        },
        "room": "blue",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth27276",
                "givenName": "Eyal",
                "familyName": "Ofek",
                "email": "eyalofek@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth3851",
                "givenName": "Shamsi",
                "middleInitial": "T",
                "familyName": "Iqbal",
                "email": "shamsi@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29197",
                "givenName": "Karin",
                "familyName": "Strauss",
                "email": "kstrauss@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 374,
        "name": "Write Here, Write Now!: An Experimental Study of Group Maintenance in Collaborative Writing",
        "type": "paper",
        "abstract": "Writing documents together using collaborative editing tools has become extremely common with the widespread availability of tools such as Google Docs. The design of such tools, rooted in early CSCW research, has historically been focused on providing awareness of the presence and activities of one’s collaborators. Evidence from a recent qualitative study, however, suggests that people are also concerned about how their behaviors – and they themselves – will be perceived by others; and take steps to mitigate possible negative perceptions. We present an experimental study of dyads composing documents together, focusing in particular on group maintenance, impression management and relationship-focused behavior. Results suggest that communication is positively related to social relations, but only for synchronous writing in a shared space; the reverse can be true in asynchronous commenting and editing. ",
        "cbStatement": "We present a laboratory study of dyads writing together. Results suggest that communication via comments and chat is positively related to social outcomes in synchronous, but not asynchronous, writing.",
        "bookmarks": 84,
        "keywords": [
            "Collaborative writing",
            "awareness",
            "group maintenance."
        ],
        "communities": [],
        "video": "chi0368-file5.mp4",
        "session": {
            "id": "s207",
            "name": "Social Face: creativity unleashed online"
        },
        "room": "bordeaux",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth29499",
                "givenName": "Jeremy",
                "familyName": "Birnholtz",
                "email": "jeremyb@northwestern.edu",
                "primary": {
                    "institution": "Northwestern University",
                    "city": "Evanston",
                    "state": "Illinois",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth20637",
                "givenName": "Stephanie",
                "familyName": "Steinhardt",
                "email": "sbg94@cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth2247",
                "givenName": "Antonella",
                "familyName": "Pavese",
                "email": "Antonellap@google.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "New York",
                    "state": "New York",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 375,
        "name": "Pass the iPad: Collaborative Creating and  Sharing in Family Groups",
        "type": "paper",
        "abstract": "The increasingly cross-generational use of personal technology portrays families each absorbed in individual devices. Tablets potentially support multi-user working but are currently used as personal devices primarily for consumption, or individual or web-based games. Could tablets support creative co-located groupwork in families and how does such creative work differ from the same task on paper? We designed and evaluated an app requiring individual and group co-creation in families. 262 family groups visiting a science fair played the collaborative drawing game on paper and iPads. Group creations were rated significantly more original and cohesive on iPads than paper. Detailed video analysis of seven family groups showed how tablets support embodiment and use of digital traces, and how the different media sustain individual and shared actions at different stages in the creative process. We sketch out implications for ownership and ‘scrap computers’: going beyond personally-owned devices and developing collaborative apps to support groupwork with tablets.",
        "cbStatement": "Reports two studies of a tablet app to support co-creation in family groups. Relates findings to use of tablets as 'scrap computers'.",
        "bookmarks": 43,
        "keywords": [
            "Tablets",
            "collaboration",
            "families",
            "shareable interfaces",
            "group working",
            "creation",
            "scrap computers"
        ],
        "communities": [
            "design",
            "games",
            "cci"
        ],
        "video": "chi0371-file5.mp4",
        "session": {
            "id": "s206",
            "name": "Colaborative Technology: I share, you share, we share"
        },
        "room": "havane",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth14139",
                "givenName": "Nicola",
                "familyName": "Yuill",
                "email": "nicolay@sussex.ac.uk",
                "primary": {
                    "institution": "University of Sussex",
                    "city": "Brighton",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth2879",
                "givenName": "Yvonne",
                "familyName": "Rogers",
                "email": "y.rogers@ucl.ac.uk",
                "primary": {
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth10984",
                "givenName": "Jochen",
                "familyName": "Rick",
                "email": "self@je77.com",
                "primary": {
                    "institution": "Saarland University",
                    "city": "Saarbrücken",
                    "country": "Germany"
                }
            }
        ]
    },
    {
        "id": 376,
        "name": "Taking Data Exposure into Account: How Does It Affect the Choice of Sign-in Accounts?",
        "type": "paper",
        "abstract": "Online services collect personal data from their users, sometimes with no clear need. We studied how users sign-in to web sites using federated IDs, and found that most survey respondents were not aware of the data they expose. However, when presented with the tradeoffs behind each sign-in option, respondents reported a willingness to change how they sign-in to reduce their data exposure or, in fewer cases, to increase it to receive more benefits from the service. Our findings suggest that data exposure is a concern for users, and that there is a need for finding clearer ways for communicating it for each sign-in option.",
        "cbStatement": "We surveyed 575 people to investigate awareness of data exposure when using federated accounts, and willingness to switch accounts given clearer information on data exposure and benefits provided by each.",
        "bookmarks": 140,
        "keywords": [
            "Online services",
            "sign in",
            "federated identity",
            "data exposure"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi0380-file5.mp4",
        "session": {
            "id": "s274",
            "name": "Privacy"
        },
        "room": "251",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth34632",
                "givenName": "Shahar",
                "familyName": "Ronen",
                "email": "sronen@media.mit.edu",
                "primary": {
                    "dept": "Media Lab",
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "MA",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30468",
                "givenName": "Oriana",
                "familyName": "Riva",
                "email": "oriana@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth12758",
                "givenName": "Maritza",
                "familyName": "Johnson",
                "email": "maritzaj@cs.berkeley.edu",
                "primary": {
                    "institution": "University of California, Berkeley",
                    "city": "Berkeley",
                    "state": "CA",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30469",
                "givenName": "Donald",
                "familyName": "Thompson",
                "email": "donthom@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 377,
        "name": "Information Capacity of Full-Body Movements",
        "type": "paper",
        "abstract": "We present a novel metric for information capacity of full-body movements. It accommodates HCI scenarios involving continuous movement of multiple limbs. Throughput is calculated as mutual information in repeated motor sequences. It is affected by the complexity of movements and the precision with which an actor reproduces them. Computation requires decorrelating co-dependencies of movement features (e.g., wrist and elbow) and temporal alignment of sequences. HCI researchers can use the metric as an analysis tool when designing and studying user interfaces.",
        "cbStatement": "Presents a novel metric for the information capacity of full-body movements.",
        "bookmarks": 103,
        "keywords": [
            "Information capacity",
            "full-body movement",
            "measurement",
            "throughput",
            "gesture-based interfaces",
            "information theory"
        ],
        "communities": [],
        "video": "chi0384-file5.mp4",
        "session": {
            "id": "s250",
            "name": "Beyond Desktop Interaction"
        },
        "room": "242a",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth2881",
                "givenName": "Antti",
                "familyName": "Oulasvirta",
                "email": "antti.oulasvirta@mpii.de",
                "primary": {
                    "institution": "Max Planck Institute for Informatics",
                    "city": "Saarbruecken",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth29518",
                "givenName": "Teemu",
                "familyName": "Roos",
                "email": "teemu.roos@cs.helsinki.fi",
                "primary": {
                    "dept": "Helsinki Institute for Information Technology HIIT",
                    "institution": "University of Helsinki",
                    "city": "Helsinki",
                    "country": "Finland"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29519",
                "givenName": "Arttu",
                "middleInitial": "Aleksi",
                "familyName": "Modig",
                "email": "arttu.modig@aalto.fi",
                "primary": {
                    "dept": "School of Electronical Engineering",
                    "institution": "Aalto University",
                    "city": "Espoo",
                    "country": "Finland"
                }
            },
            {
                "id": "auth29520",
                "givenName": "Laura",
                "familyName": "Leppänen",
                "email": "laura.leppanen@cs.helsinki.fi",
                "primary": {
                    "dept": "create",
                    "institution": "University of Helsinki",
                    "city": "Helsinki",
                    "country": "Finland"
                }
            }
        ]
    },
    {
        "id": 378,
        "name": "In-body Experiences: Embodiment, Control, and Trust in Robot-Mediated Communication",
        "type": "paper",
        "abstract": "Communication technologies are becoming increasingly diverse in form and functionality, making it important to identify which aspects of these technologies actually improve geographically distributed communication.  Our study examines two potentially important aspects of communication technologies which appear in robot-mediated communication---physical embodiment and control of this embodiment.  We studied the impact of physical embodiment and control upon interpersonal trust in a controlled laboratory experiment using three different videoconferencing settings: (1) a handheld tablet controlled by a local user, (2) an embodied system controlled by a local user, and (3) an embodied system controlled by a remote user (n = 29 dyads).  We found that physical embodiment and control by the local user increased the amount of trust built between partners.  These results suggest that both physical embodiment and control of the system influence interpersonal trust in mediated communication and have implications for future system designs.",
        "cbStatement": "Presents empirical results of a controlled experiment on the effects of embodiment and control on trust in user interactions.  Offers design guidelines and theoretical implications for robot-mediated communication systems.",
        "bookmarks": 65,
        "keywords": [
            "Computer-supported collaborative work",
            "computer-mediated communication",
            "videoconferencing",
            "robot-mediated communication",
            "embodiment",
            "control",
            "trust"
        ],
        "communities": [],
        "video": "chi0385-file5.mp4",
        "session": {
            "id": "s237",
            "name": "Bodies Matter"
        },
        "room": "bordeaux",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth22498",
                "givenName": "Irene",
                "familyName": "Rae",
                "email": "irene@cs.wisc.edu",
                "primary": {
                    "institution": "University of Wisconsin, Madison",
                    "city": "Madison",
                    "state": "Wisconsin",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth2741",
                "givenName": "Leila",
                "middleInitial": "A",
                "familyName": "Takayama",
                "email": "takayama@willowgarage.com",
                "primary": {
                    "institution": "Willow Garage",
                    "city": "Menlo Park",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth6279",
                "givenName": "Bilge",
                "familyName": "Mutlu",
                "email": "bilge@cs.wisc.edu",
                "primary": {
                    "institution": "University of Wisconsin, Madison",
                    "city": "Madison",
                    "state": "Wisconsin",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 379,
        "name": "The Dynamics of Younger and Older Adult’s Paired Behavior when Playing an Interactive Silhouette Game",
        "type": "paper",
        "abstract": "In this paper, we report on the findings of an acute trial in which we evaluate the design of a novel gesture-based game. 60 younger and older players, divided into three separate group-types: (i) Young-Young, (ii) Old-Old, and (iii) Young-Old, took part in the study. The primary aim of this work was to evaluate the communicative and cooperative behavior of same-age and mixed-age pairs, with secondary interests in their perceived ease-of-use of the game. A mixed-method approach was used, comprising of direct observations, a post-game questionnaire and paired interviews. Our results identified noticeable differences between the group-types, with the Young-Old showing more physical cooperation, as compared to the same-age groups. The work elaborates on how the young and old differ in expectations and perceived interaction, and concludes with some recommendations for future research.",
        "cbStatement": "We present the design and evaluation of an intergenerational game with 60 younger and older players, and report on the communicative and cooperative interaction, with subsequent recommendations.",
        "bookmarks": 178,
        "keywords": [
            "Intergenerational relations",
            "older adults",
            "silhouette interaction",
            "cooperation",
            "digital games."
        ],
        "communities": [
            "games"
        ],
        "video": "chi0401-file5.mp4",
        "session": {
            "id": "s289",
            "name": "Technologies for Life"
        },
        "room": "242ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth9943",
                "givenName": "Mark",
                "familyName": "Rice",
                "email": "mdrice@i2r.a-star.edu.sg",
                "primary": {
                    "institution": "Institute for Infocomm Research",
                    "city": "Singapore ",
                    "country": "Singapore"
                },
                "role": "presenter"
            },
            {
                "id": "auth28908",
                "givenName": "Wah Pheow",
                "familyName": "Tan",
                "email": "wahpheow@tp.edu.sg",
                "primary": {
                    "institution": "Temasek Polytechnic ",
                    "city": "Singapore",
                    "country": "Singapore"
                }
            },
            {
                "id": "auth28909",
                "givenName": "Jeremy",
                "familyName": "Ong",
                "email": "jeremyongts92@gmail.com",
                "primary": {
                    "institution": "Institute for Infocomm Research ",
                    "city": "Singapore ",
                    "country": "Singapore"
                },
                "secondary": {
                    "institution": "Temasek Polytechnic",
                    "city": "Singapore",
                    "country": "Singapore"
                }
            },
            {
                "id": "auth25087",
                "givenName": "Lih Jie",
                "familyName": "Yau",
                "email": "yaulihjie@gmail.com",
                "primary": {
                    "institution": "Institute for Infocomm Research",
                    "city": "Singapore ",
                    "country": "Singapore"
                },
                "secondary": {
                    "institution": "Temasek Polytechnic",
                    "city": "Singapore",
                    "country": "Singapore"
                }
            },
            {
                "id": "auth22951",
                "givenName": "Marcus",
                "familyName": "Wan",
                "email": "tsmwan@i2r.a-star.edu.sg",
                "primary": {
                    "institution": "Institute for Infocomm Research",
                    "city": "Singapore ",
                    "country": "Singapore"
                }
            },
            {
                "id": "auth8601",
                "givenName": "Jamie",
                "familyName": "Ng",
                "email": "jamie@i2r.a-star.edu.sg",
                "primary": {
                    "institution": "Institute for Infocomm Research ",
                    "city": "Singapore ",
                    "country": "Singapore"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 380,
        "name": "Weighted Graph Comparison Techniques for Brain Connectivity Analysis",
        "type": "paper",
        "abstract": "The analysis of brain connectivity is a vast field in neuroscience with a frequent use of visual representations and an increasing need for visual analysis tools. Based on an in-depth literature review and interviews with neuroscientists, we explore high-level brain connectivity analysis tasks that need to \\ be supported by dedicated visual analysis tools. A significant example of such a task is the comparison of different connectivity data in the form of weighted graphs. Several approaches have been suggested for graph comparison within information visualization, but the comparison of weighted graphs has not \\ been addressed. We explored the design space of applicable visual representations and present augmented adjacency matrix and node-link visualizations. To assess which representation best support weighted graph comparison tasks, we performed a controlled experiment. Our findings suggest that matrices support these tasks well, outperforming node-link diagrams. These results have significant implications for the design of brain connectivity analysis tools that require weighted graph comparisons. They can also inform the design of visual analysis tools in other domains, e.g. comparison of weighted social networks or biological pathways.",
        "cbStatement": "This paper presents the design and evaluation of two visualizations for comparing weighted graphs. Results have implications for the design of brain connectivity analysis and other graph visualization tools.",
        "bookmarks": 46,
        "keywords": [
            "Graph comparison",
            "brain connectivity analysis",
            "brain connectivity visualization"
        ],
        "communities": [
            "health"
        ],
        "video": "chi0404-file5.mp4",
        "session": {
            "id": "s271",
            "name": "Brain Interfaces"
        },
        "room": "342a",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth17377",
                "givenName": "Basak",
                "familyName": "Alper",
                "email": "basakalper@umail.ucsb.edu",
                "primary": {
                    "institution": "University of California, Santa Barbara",
                    "city": "Santa Barbara",
                    "state": "California",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "INRIA",
                    "city": "Paris",
                    "country": "France"
                },
                "role": "presenter"
            },
            {
                "id": "auth20594",
                "givenName": "Benjamin",
                "familyName": "Bach",
                "email": "benjamin.bach@inria.fr",
                "primary": {
                    "institution": "INRIA",
                    "city": "Paris",
                    "country": "France"
                }
            },
            {
                "id": "auth7746",
                "givenName": "Nathalie",
                "familyName": "Henry Riche",
                "email": "nath@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth7662",
                "givenName": "Tobias",
                "familyName": "Isenberg",
                "email": "tobias.isenberg@inria.fr",
                "primary": {
                    "dept": "AVIZ",
                    "institution": "INRIA",
                    "city": "Saclay",
                    "country": "France"
                }
            },
            {
                "id": "auth1567",
                "givenName": "Jean-Daniel",
                "familyName": "Fekete",
                "email": "Jean-Daniel.Fekete@inria.fr",
                "primary": {
                    "institution": "INRIA",
                    "city": "Paris",
                    "country": "France"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 381,
        "name": "Swiss-Cheese Extended: An Object Recognition Method for Ubiquitous Interfaces based on Capacitive Proximity Sensing",
        "type": "paper",
        "abstract": "Swiss-Cheese Extended proposes a novel real-time method for recognizing objects with capacitive proximity sensors. Applying this technique to ubiquitous user interfaces, it is possible to detect the 3D-position of multiple human hands in different configurations above a surface that is equipped with a small number of sensors. The retrieved object configurations can significantly improve a user's interaction experience or an application's execution context, for example by detecting multi-hand zoom and rotation gestures or recognizing a grasping hand. We emphasize the broad applicability of the proposed method with a study of a multi-hand gesture recognition device.",
        "cbStatement": "Swiss-Cheese Extended proposes a novel real-time method for recognizing continuous object parameters with capacitive proximity sensors. The method is evaluated with a study of a multi-hand interaction device.",
        "bookmarks": 125,
        "keywords": [
            "capacitive proximity sensing",
            "capacitive sensing",
            "3D interaction",
            "ubiquitous interfaces",
            "object recognition",
            "object tracking"
        ],
        "communities": [
            "engineering",
            "ux",
            "games"
        ],
        "video": "chi0414-file5.mp4",
        "session": {
            "id": "s225",
            "name": "Touch, Tangibles, Touch Sensor"
        },
        "room": "352ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth28735",
                "givenName": "Tobias",
                "familyName": "Grosse-Puppendahl",
                "email": "tobias.grosse-puppendahl@igd.fraunhofer.de",
                "primary": {
                    "institution": "Fraunhofer IGD",
                    "city": "Darmstadt",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth28916",
                "givenName": "Andreas",
                "familyName": "Braun",
                "email": "andreas.braun@igd.fraunhofer.de",
                "primary": {
                    "institution": "Fraunhofer IGD",
                    "city": "Darmstadt",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth28917",
                "givenName": "Felix",
                "familyName": "Kamieth",
                "email": "felix.kamieth@igd.fraunhofer.de",
                "primary": {
                    "institution": "Fraunhofer IGD",
                    "city": "Darmstadt",
                    "country": "Germany"
                }
            },
            {
                "id": "auth34620",
                "givenName": "Arjan",
                "familyName": "Kuijper",
                "email": "arjan.kuijper@igd.fraunhofer.de",
                "primary": {
                    "institution": "Fraunhofer IGD",
                    "city": "Darmstadt",
                    "country": "Germany"
                }
            }
        ]
    },
    {
        "id": 382,
        "name": "A Comparative Evaluation of Touch-Based Methods to Bind Mobile Devices for Collaborative Interactions",
        "type": "paper",
        "abstract": "We present a comparative evaluation of two touch-based group-binding methods, a leader-driven method and a peer-based method, against a more conventional group-binding method based on scanning and passwords. The results indicate that the participants strongly preferred the touch-based methods in both pragmatic and hedonic qualities as well as in the overall attractiveness. While the leader-driven method allowed better control over the group and required only one participant to be able to form a group, the peer-based method helped to create a greater sense of community and scaled better for larger group sizes and distances. As the optimal group-binding method depends on the social situation and physical environment, the binding methods should be flexible, allowing the users to adapt them to different contexts of use. For determining the order of the devices, manual arrangement was preferred over defining the order by touching.",
        "cbStatement": "Reports a comparative evaluation of three different methods that allow collocated users to bind their mobile devices together. Crucial for enabling collaborative experiences such as sharing photos or playing games.",
        "bookmarks": 168,
        "keywords": [
            "Collocated interaction",
            "mobile phones",
            "user interfaces",
            "device ecosystem binding",
            "group association",
            "pairing"
        ],
        "communities": [],
        "video": "chi0417-file5.mp4",
        "session": {
            "id": "s218",
            "name": "Multi-device Interaction"
        },
        "room": "352ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth9618",
                "givenName": "Tero",
                "familyName": "Jokela",
                "email": "tero.jokela@nokia.com",
                "primary": {
                    "institution": "Nokia Research Center",
                    "city": "Tampere",
                    "country": "Finland"
                },
                "role": "presenter"
            },
            {
                "id": "auth5691",
                "givenName": "Andrés",
                "familyName": "Lucero",
                "email": "andres.lucero@nokia.com",
                "primary": {
                    "institution": "Nokia Research Center",
                    "city": "Tampere",
                    "country": "Finland"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 383,
        "name": "The Wheels are Turning: Content Rotation on Steering Wheel Displays",
        "type": "paper",
        "abstract": "The steering wheel is a promising space for the integration of displays since in the car there is very limited space for integrating interactive modalities for the driver that are close to the preferred field of view as well as in an easy to reach position. When the wheel is turned, the screen content could change its orientation to increase the readability and therefore reduce the distraction from the road. Thus, this paper describes three different content rotation behaviors for steering wheel displays. To investigate what effect these behaviors have on the driver in terms of visual distraction from the road we conducted a user study with eye tracking asking participants to read the current speed. We found no differences in terms of distraction and response time between the different rotation behaviors. Compared to a similar display in a dashboard position the visual distraction was reduced.",
        "cbStatement": "This paper investigates how the content of steering wheel mounted displays should react to a rotation of the wheel. Three alternatives are tested and compared with a dashboard display.",
        "bookmarks": 147,
        "keywords": [
            "Display, distraction, rotation, steering wheel"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0425-file5.mp4",
        "session": {
            "id": "s270",
            "name": "Untitled (Automotive and Awareness)"
        },
        "room": "241",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth9854",
                "givenName": "David",
                "familyName": "Wilfinger",
                "email": "david.wilfinger@sbg.ac.at",
                "primary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                },
                "role": "presenter"
            },
            {
                "id": "auth16954",
                "givenName": "Martin",
                "familyName": "Murer",
                "email": "martin.murer@sbg.ac.at",
                "primary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                }
            },
            {
                "id": "auth15247",
                "givenName": "Sebastian",
                "familyName": "Osswald",
                "email": "sebastian.osswald@sbg.ac.at",
                "primary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                }
            },
            {
                "id": "auth9353",
                "givenName": "Alexander",
                "familyName": "Meschtscherjakov",
                "email": "alexander.meschtscherjakov@sbg.ac.at",
                "primary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth3460",
                "givenName": "Manfred",
                "familyName": "Tscheligi",
                "email": "manfred.tscheligi@sbg.ac.at",
                "primary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                }
            }
        ]
    },
    {
        "id": 384,
        "name": "Designing for Perceptual Crossing: Designing and Comparing Three Behaviors",
        "type": "paper",
        "abstract": "Perceptual crossing is the reciprocal interplay of perceiving while being perceived. In this paper we discuss the last iteration of our ongoing research project on designing for perceptive qualities in systems of interactive products. We describe the design of explorative behavior in an artifact to enable the artifact and a person to engage in perceptual crossing. The explorative behavior is compared to the following and active behavior, the results of two earlier iterations. Through the iterations we formulated, applied and evaluated design relevant knowledge in the form of seven design notions. These notions inform design-researchers and design-practitioners on how to design for perceptive qualities in systems of interactive products. Here we specifically focus on how the artifact detects active perceptive behavior of a person, and how the artifact becomes aware of bygone perception and anticipates on future perception. An experiment shows how participants preferred the resulting explorative behavior that is closest to our theoretical framework based on phenomenology. ",
        "cbStatement": "We show how to design for perceptual crossing between person and artifact. An experiment shows that person and artifact engage in this strong reciprocal interplay of perceiving and being perceived. ",
        "bookmarks": 154,
        "keywords": [
            "Perceptual Crossing",
            "Perceptive Qualities",
            "Design Theory",
            "Phenomenology",
            "Product Behavior",
            "Research through Design"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0426-file5.mp4",
        "session": {
            "id": "s237",
            "name": "Bodies Matter"
        },
        "room": "bordeaux",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth16843",
                "givenName": "Eva",
                "familyName": "Deckers",
                "email": "e.j.l.deckers@tue.nl",
                "primary": {
                    "institution": "Eindhoven University of Technology",
                    "city": "Eindhoven",
                    "state": "Noord Brabant",
                    "country": "The Netherlands"
                },
                "role": "presenter"
            },
            {
                "id": "auth2617",
                "givenName": "Stephan",
                "familyName": "Wensveen",
                "email": "s.a.g.wensveen@mci.sdu.dk",
                "primary": {
                    "institution": "University of Southern Denmark",
                    "city": "Sønderborg",
                    "country": "Denmark"
                },
                "secondary": {
                    "dept": "Industrial Design",
                    "institution": "Eindhoven University of Technology",
                    "city": "Eindhoven",
                    "country": "The Netherlands"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth6962",
                "givenName": "Pierre",
                "familyName": "Levy",
                "email": "p.d.levy@tue.nl",
                "primary": {
                    "institution": "Eindhoven University of Technology",
                    "city": "Eindhoven",
                    "state": "Noord Brabant",
                    "country": "The Netherlands"
                }
            },
            {
                "id": "auth17791",
                "givenName": "Rene",
                "familyName": "Ahn",
                "email": "r.m.c.ahn@tue.nl",
                "primary": {
                    "dept": "Industrial Design",
                    "institution": "Eindhoven University of Technology",
                    "city": "Eindhoven",
                    "country": "The Netherlands"
                }
            }
        ]
    },
    {
        "id": 385,
        "name": "Touchbugs: Actuated Tangibles on Multi-Touch Tables",
        "type": "paper",
        "abstract": "We present a novel approach to graspable interfaces using Touchbugs, actuated physical objects for interacting with interactive surface computing applications. Touchbugs are active tangibles that are able to move across surfaces by employing vibrating motors and can communicate with camera based multi-touch surfaces using infrared LEDs. Touchbug’s embedded inertial sensors and computational capabilities open a new interaction space by providing autonomous capabilities for tangibles that allow goal directed behavior.",
        "cbStatement": "We present a novel approach to graspable interfaces using Touchbugs, small tangibles that are able to move across surfaces by employing vibrating motors and to communicate with interactive surfaces by using infrared LEDs.",
        "bookmarks": 134,
        "keywords": [
            "User interface device",
            "actuated tangibles",
            "interactive tabletops."
        ],
        "communities": [
            "engineering"
        ],
        "video": "chi0434-file5.mp4",
        "session": {
            "id": "s223",
            "name": "Table and Floors"
        },
        "room": "352ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth27080",
                "givenName": "Diana",
                "familyName": "Nowacka",
                "email": "d.nowacka@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth17323",
                "givenName": "Karim",
                "familyName": "Ladha",
                "email": "karim.ladha@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth27135",
                "givenName": "Nils",
                "middleInitial": "Y.",
                "familyName": "Hammerla",
                "email": "nils.hammerla@newcastle.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth23379",
                "givenName": "Daniel",
                "familyName": "Jackson",
                "email": "dan.jackson@newcastle.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth29309",
                "givenName": "Cassim",
                "familyName": "Ladha",
                "email": "cassim.ladha@newcastle.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth9778",
                "givenName": "Enrico",
                "familyName": "Rukzio",
                "email": "enrico.rukzio@uni-ulm.de",
                "primary": {
                    "institution": "Ulm University",
                    "city": "Ulm",
                    "country": "Germany"
                }
            },
            {
                "id": "auth5105",
                "givenName": "Patrick",
                "familyName": "Olivier",
                "email": "p.l.olivier@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 386,
        "name": "Exploring & Designing Tools to Enhance Falls Rehabilitation in the Home",
        "type": "paper",
        "abstract": "Falls are the leading cause of accidental injury-related deaths in the elderly; a fall can lead to a loss of independence, and a fear of falling. Rehabilitation programmes involving exercise have proved the most successful way to reduce the risk of falls. However, the limitations of standard care (e.g. booklets) could prevent home users from receiving the full therapeutic benefit that rehabilitation offers. Having consulted users and health experts, we developed games, and visualizations for falls rehabilitation that we believe could potentially overcome the main barriers to effective rehabilitation in the home. In this paper, we describe user studies that we carried out with older adults to evaluate the use of these visual tools versus standard care, both in the laboratory and in the home.  Our main findings show that our visualizations and games were able to overcome the major limitations of standard care, and that they were usable and acceptable to the end users.  ",
        "cbStatement": "The studies described in the paper explored the usability and acceptance of two distinct types of visual feedback for unsupervised rehabilitation in the home. ",
        "bookmarks": 112,
        "keywords": [
            "Games",
            "User-Centered",
            "Falls",
            "Usability",
            "Rehabilitation",
            "Visualization"
        ],
        "communities": [
            "ux",
            "health"
        ],
        "video": "chi0438-file5.mp4",
        "session": {
            "id": "s291",
            "name": "Impairment and Rehabilitation"
        },
        "room": "242ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth23200",
                "givenName": "Stephen",
                "familyName": "Uzor",
                "email": "stephen.uzor@gcu.ac.uk",
                "primary": {
                    "dept": "Interactive and Trustworthy Technologies  Research Group",
                    "institution": "Glasgow Caledonian University",
                    "city": "Glasgow",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth2866",
                "givenName": "Lynne",
                "familyName": "Baillie",
                "email": "l.baillie@gcu.ac.uk",
                "primary": {
                    "dept": "Interactive and Trustworthy Technologies  Research Group",
                    "institution": "Glasgow Caledonian University",
                    "city": "Glasgow",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 387,
        "name": "Deep Conservation in Urban India and its Implications for the Design of Conservation Technologies",
        "type": "paper",
        "abstract": "Rapid depletion of fossil fuels and water resources has become an international problem. Urban residential households are among the primary consumers of resources and are deeply affected by resource shortages. Despite the global nature of these problems, most of the solutions being developed to address these issues are based on studies done in the developed world. We present a study of energy, water and fuel conservation practices in urban India. Our study highlights a culture of deep conservation and the results raise questions about the viability of typical solutions such as home energy monitors. We identify new opportunities for design such as point-of-use feedback technologies, modular solutions, distributed energy storage, harnessing by-products and automated load shifting.",
        "cbStatement": "We present a study of energy, water and fuel conservation practices in \\ urban India to highlight a culture of deep conservation and identify new \\ opportunities for relevant resource conservation technologies.",
        "bookmarks": 184,
        "keywords": [
            "Energy",
            "Sustainability",
            "Developing World;ICT4D"
        ],
        "communities": [
            "sustainability",
            "hci4d"
        ],
        "video": "chi0446-file5.mp4",
        "session": {
            "id": "s257",
            "name": "Crowds and activism"
        },
        "room": "blue",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth9696",
                "givenName": "Yedendra",
                "middleInitial": "B",
                "familyName": "Shrinivasan",
                "email": "yshriniv@in.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "Bangalore",
                    "country": "India"
                },
                "role": "presenter"
            },
            {
                "id": "auth28935",
                "givenName": "Mohit",
                "familyName": "Jain",
                "email": "mojain13@in.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "Bangalore",
                    "country": "India"
                },
                "secondary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth28936",
                "givenName": "Deva",
                "middleInitial": "P",
                "familyName": "Seetharam",
                "email": "dseetharam@in.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "Bangalore",
                    "country": "India"
                }
            },
            {
                "id": "auth28937",
                "givenName": "Abhishek",
                "familyName": "Choudhary",
                "email": "achoudhary@in.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "Bangalore",
                    "country": "India"
                }
            },
            {
                "id": "auth1976",
                "givenName": "Elaine",
                "middleInitial": "M",
                "familyName": "Huang",
                "email": "elainemayhuang@gmail.com",
                "primary": {
                    "institution": "University of Zurich",
                    "city": "Zurich",
                    "country": "Switzerland"
                }
            },
            {
                "id": "auth14525",
                "givenName": "Tawanna",
                "familyName": "Dillahunt",
                "email": "tdillahu@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth1182",
                "givenName": "Jennifer",
                "familyName": "Mankoff",
                "email": "jmankoff@cs.cmu.edu",
                "primary": {
                    "dept": "HCII",
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 388,
        "name": "Turbulence in the Clouds: Challenges of Cloud-Based Information Work",
        "type": "paper",
        "abstract": "We report on a qualitative study of the user experience of cloud-based information work. We characterize the information work practices and challenges that exist largely at the different intersections of three constructs—cloud-based services, collaborations, and digital identifiers. We also demonstrate how the misalignment of these three constructs is experienced as a “losing battle” that has led to miscommunication among collaborators, the abandonment of cloud-based services, and the irreparable blurring of digital identities.",
        "cbStatement": "Presents results of a qualitative study of information management in the cloud. Describes challenges that will be relevant to designers involved with both cloud-based services and federated identity management.",
        "bookmarks": 172,
        "keywords": [
            "Cloud computing",
            "digital identifiers",
            "information work",
            "information management"
        ],
        "communities": [],
        "session": {
            "id": "s208",
            "name": "Managment of Knowledge and Collaoration: brining the best out of teams"
        },
        "room": "blue",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth2135",
                "givenName": "Amy",
                "familyName": "Voida",
                "email": "amyvoida@gmail.com",
                "primary": {
                    "institution": "Univeristy of California, Irvine",
                    "city": "Irvine",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1082",
                "givenName": "Judith",
                "middleInitial": "S.",
                "familyName": "Olson",
                "email": "jsolson@uci.edu",
                "primary": {
                    "institution": "University of California, Irvine",
                    "city": "Irvine",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1565",
                "givenName": "Gary",
                "middleInitial": "M.",
                "familyName": "Olson",
                "email": "gary.olson@uci.edu",
                "primary": {
                    "institution": "University of California, Irvine",
                    "city": "Irvine",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 389,
        "name": "Still Looking: Investigating Seamless Gaze-supported Selection, Positioning, and Manipulation of Distant Targets",
        "type": "paper",
        "abstract": "We investigate how to seamlessly bridge the gap between users and distant displays for basic interaction tasks, such as object selection and manipulation. For this, we take advantage of very fast and implicit, yet imprecise gaze- and head-directed input in combination with ubiquitous smartphones for additional manual touch control. We have carefully elaborated two novel and consistent sets of gaze-supported interaction techniques based on touch-enhanced gaze pointers and local magnification lenses. These conflict-free sets allow for fluently selecting and positioning distant targets. Both sets were evaluated in a user study with 16 participants. Overall, users were fastest with a touch-enhanced gaze pointer for selecting and positioning an object after some training. While the positive user feedback for both sets suggests that our proposed gaze- and head-directed interaction techniques are suitable for a convenient and fluent selection and manipulation of distant targets, further improvements are necessary for more precise cursor control.",
        "cbStatement": "Describes and compares interaction techniques for combining gaze/head and touch input for fluently selecting, positioning and manipulating distant graphical objects. This can help supporting more seamless interactions with distant displays.",
        "bookmarks": 74,
        "keywords": [
            "Eye tracking",
            "gaze interaction",
            "visual attention",
            "mobile touch input",
            "distant displays",
            "selection",
            "positioning"
        ],
        "communities": [],
        "video": "chi0463-file5.mp4",
        "session": {
            "id": "s235",
            "name": "Gaze"
        },
        "room": "bordeaux",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth16951",
                "givenName": "Sophie",
                "familyName": "Stellmach",
                "email": "stellmach@acm.org",
                "primary": {
                    "dept": "Interactive Media Lab",
                    "institution": "Technische Universität Dresden",
                    "city": "Dresden",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth6857",
                "givenName": "Raimund",
                "familyName": "Dachselt",
                "email": "dachselt@acm.org",
                "primary": {
                    "dept": "Interactive Media Lab",
                    "institution": "Technische Universität Dresden",
                    "city": "Dresden",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 390,
        "name": "Stroke Rehabilitation with a Sensing Surface",
        "type": "paper",
        "abstract": "This paper presents a new sensing and interaction environment for post-stroke and upper extremity limb rehabilitation.  The device is a combination of camera-based multitouch sensing and a supporting therapeutic software application that advances the treatment, provides feedback, and records a user’s progress. The image-based analysis of hand position provided by a Microsoft Surface is used as an input into a tabletop game environment. Tailored image analysis algorithms assess rehabilitative hand movements. Visual feedback is provided in a game context. Experiments were conducted in a sub-acute rehabilitation center. Preliminary user studies with a stroke-afflicted population determined essential design criteria.  Hand and wrist sensing, as well as the goals of the supporting game environment, engage therapeutic flexion and extension as defined by consulted physicians.  Participants valued personalization of the activity, novelty, reward and the ability to work at their own pace in an otherwise repetitive therapeutic task.  A “character” – game element personifying the participant’s movement – was uniquely motivating relative to the media available in the typical therapeutic routine.",
        "cbStatement": "We propose a multisensory environment that tracks movements on a sensing platform for patients with a spectrum of cognitive and physical ability. Our study elaborates an interaction model that motivates patients in continued therapeutic engagement. \\ ",
        "bookmarks": 86,
        "keywords": [
            "HCI",
            "rehabilitation",
            "stroke",
            "tabletop",
            "gesture recognition."
        ],
        "communities": [
            "design",
            "health",
            "games"
        ],
        "video": "chi0464-file5.mp4",
        "session": {
            "id": "s291",
            "name": "Impairment and Rehabilitation"
        },
        "room": "242ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth21094",
                "givenName": "Cati",
                "familyName": "Boulanger",
                "email": "catib@microsoft.com",
                "primary": {
                    "institution": "Microsoft Applied Sciences Group",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Microsoft",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth29553",
                "givenName": "Adam",
                "familyName": "Boulanger",
                "email": "adam@hearforyourself.com",
                "primary": {
                    "institution": "Hear for Yourself",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29554",
                "givenName": "Lilian",
                "familyName": "de Greef",
                "email": "lilian_de_greef@hmc.edu",
                "primary": {
                    "institution": "Harvey Mudd College",
                    "city": "Claremont",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth29555",
                "givenName": "Andy",
                "familyName": "Kearney",
                "email": "kearneyandy@gmail.com",
                "primary": {
                    "institution": "Harvey Mudd College",
                    "city": "Claremont",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth29556",
                "givenName": "Kiley",
                "familyName": "Sobel",
                "email": "ksobel@hmc.edu",
                "primary": {
                    "dept": "Computer Science Department",
                    "institution": "Harvey Mudd College",
                    "city": "Claremont",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth29559",
                "givenName": "Russell",
                "familyName": "Transue",
                "email": "amazingracewashington@gmail.com",
                "primary": {
                    "institution": "Harvey Mudd College",
                    "city": "Claremont",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth29558",
                "givenName": "Z",
                "familyName": "Sweedyk",
                "email": "z@cs.hmc.edu",
                "primary": {
                    "institution": "Harvey Mudd College",
                    "city": "Claremont",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth3588",
                "givenName": "Paul",
                "middleInitial": "H",
                "familyName": "Dietz",
                "email": "pdietz@microsoft.com",
                "primary": {
                    "dept": "Applied Sciences Group",
                    "institution": "Microsoft",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth8273",
                "givenName": "Steven",
                "familyName": "Bathiche",
                "email": "stevieb@microsoft.com",
                "primary": {
                    "dept": "Applied Sciences Group",
                    "institution": "Microsoft",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 391,
        "name": "I Can Do Text Analytics! Designing Development Tools for Novice Developers",
        "type": "paper",
        "abstract": "Text analytics, an increasingly important application domain, is hampered by the high barrier to entry due to the many conceptual difficulties novice developers encounter. This work addresses the problem by developing a tool to guide novice developers to adopt the best practices employed by expert developers in text analytics and to quickly harness the full power of the underlying system. Taking a user centered task analytical approach, the tool development went through multiple design iterations and evaluation cycles. In the latest evaluation, we found that our tool enables novice developers to develop high quality extractors on par with the state of art within a few hours and with minimal training. Finally, we discuss our experience and lessons learned in the context of designing user interfaces to reduce the barriers to entry into complex domains of expertise. \\ ",
        "cbStatement": "Describe a user centered iterative design process that developed a tool for text analytics, which enables novice developers to write high quality information extractors on par with state of the art with minimal training.",
        "bookmarks": 141,
        "keywords": [
            "Novice developer",
            "text analytics",
            "best practices",
            "information extraction",
            "extraction plan",
            "workflow guide"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi0466-file5.mp4",
        "session": {
            "id": "s264",
            "name": "Novel Programming"
        },
        "room": "351",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth11502",
                "givenName": "Huahai",
                "familyName": "Yang",
                "email": "hyang@us.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30210",
                "givenName": "Daina",
                "familyName": "Pupons-Wickham",
                "email": "daina@us.ibm.com",
                "primary": {
                    "institution": "IBM Silicon Valley Lab",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth30209",
                "givenName": "Laura",
                "familyName": "Chiticariu",
                "email": "chiti@us.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth29650",
                "givenName": "Yunyao",
                "familyName": "Li",
                "email": "yunyaoli@us.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30211",
                "givenName": "Benjamin",
                "familyName": "Nguyen",
                "email": "nguyenb@us.ibm.com",
                "primary": {
                    "institution": "IBM Silicon Valley Lab",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth22345",
                "givenName": "Arnaldo",
                "familyName": "Carreno-Fuentes",
                "email": "acarren@us.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 392,
        "name": "Quantity Estimation in Visualizations of Tagged Text",
        "type": "paper",
        "abstract": "A valuable task in text visualization is to have viewers make judgments about text that has been annotated (either by hand or by some algorithm such as text clustering or entity extraction). In this work we look at the ability of viewers to make judgments about the relative quantities of tags in annotated text (specifically text tagged with one of a set of qualitatively distinct colors), and examine design choices that can improve performance at extracting statistical information from these texts. \\  \\ We find that viewers can efficiently and accurately estimate the proportions of tag levels over a range of situations; however accuracy can be improved through color choice and area adjustments.",
        "cbStatement": "We present results in the relatively unexplored \\ domain of text annotation. We \\ present empirical validation of performance \\ at estimation tasks for tagged text, and \\ further validate design choices that improve this ability.",
        "bookmarks": 137,
        "keywords": [
            "Text visualization",
            "text analytics",
            "information visualization",
            "perceptual study;"
        ],
        "communities": [],
        "video": "chi0476-file5.mp4",
        "session": {
            "id": "s233",
            "name": "Text Visualization"
        },
        "room": "bordeaux",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth23731",
                "givenName": "Michael",
                "middleInitial": "A.",
                "familyName": "Correll",
                "email": "mcorrell@cs.wisc.edu",
                "primary": {
                    "institution": "University of Wisconsin, Madison",
                    "city": "Madison",
                    "state": "Wisconsin",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth29257",
                "givenName": "Eric",
                "middleInitial": "C.",
                "familyName": "Alexander",
                "email": "ealexand@cs.wisc.edu",
                "primary": {
                    "dept": "Computer Sciences",
                    "institution": "University of Wisconsin, Madison",
                    "city": "Madison",
                    "state": "Wisconsin",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth12316",
                "givenName": "Michael",
                "familyName": "Gleicher",
                "email": "gleicher@cs.wisc.edu",
                "primary": {
                    "institution": "University of Wisconsin, Madison",
                    "city": "Madison",
                    "state": "Wisconsin",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 393,
        "name": "At the Interface of Biology and Computation",
        "type": "paper",
        "abstract": "Representing a new class of tool for biological modeling, Bio Model Analyzer (BMA) uses sophisticated computational techniques to determine stabilization in cellular networks. This paper presents designs aimed at easing the problems that can arise when such techniques—using distinct approaches to conceptualizing networks—are applied in biology. The work also engages with more fundamental issues being discussed in the philosophy of science and science studies. It shows how scientific ways of knowing are constituted in routine interactions with tools like BMA, where the emphasis is on the practical business at hand, even when seemingly deep conceptual problems exist. For design, this perspective refigures the frictions raised when computation is used to model biology. Rather than obstacles, they can be seen as opportunities for opening up different ways of knowing. ",
        "cbStatement": "Presents study of scientific tool for proving stabilization in biological systems. Shows how such tools, using new computational techniques, can introduce frictions but that these frictions can be used constructively.",
        "bookmarks": 84,
        "keywords": [
            "Computational biology, ethnography, philosophy of sci-ence, science studies, epistemology, materiality."
        ],
        "communities": [
            "design"
        ],
        "video": "chi0478-file5.mp4",
        "session": {
            "id": "s271",
            "name": "Brain Interfaces"
        },
        "room": "342a",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth2037",
                "givenName": "Alex",
                "middleInitial": "S",
                "familyName": "Taylor",
                "email": "ast@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth32882",
                "givenName": "Nir",
                "familyName": "Piterman",
                "email": "nir.piterman@le.ac.uk",
                "primary": {
                    "institution": "University of Leicester",
                    "city": "Leicester",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth32876",
                "givenName": "Samin",
                "familyName": "Ishtiaq",
                "email": "samin.ishtiaq@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth32877",
                "givenName": "Jasmin",
                "familyName": "Fisher",
                "email": "jasmin.fisher@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth32875",
                "givenName": "Byron",
                "familyName": "Cook",
                "email": "bycook@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth23239",
                "givenName": "Caitlin",
                "familyName": "Cockerton",
                "email": "c.cockerton@gmail.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth32883",
                "givenName": "Sam",
                "familyName": "Bourton",
                "email": "sam.bourton@quantumblack.com",
                "primary": {
                    "institution": "QuantumBlack",
                    "city": "London",
                    "country": "UK"
                }
            },
            {
                "id": "auth34609",
                "givenName": "David",
                "familyName": "Benque",
                "email": "mail@davidbenque.com",
                "primary": {
                    "institution": "Royal college of Art",
                    "city": "London",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 394,
        "name": "Powering the Cellphone Revolution: Findings from Mobile Phone Charging Trials in Off-Grid Kenya",
        "type": "paper",
        "abstract": "Can human-powered devices solve the electricity gap for the millions of rural Africans adopting mobile phones? Findings from our long-term evaluation of two personal crank-based charging systems in Kenya reveal that small hand and leg-powered devices do have potential to meet the needs of rural mobile phone users. Unfortunately, device breakage, theft and incompatibility with handsets, coupled with lack of consumer credit and poorly functioning markets for these goods mean these represent only a partial solution to the mobile phone charging problem. Drawing from our fieldwork, we motivate a HCI4D/ICTD design and evaluation agenda that better accounts for unique individuals’ geographic, financial, and economic circumstances or their “human computer ecosystem”. Key strategies for implementing this agenda are engaging with diverse users on their own terms and conducting long-term qualitative evaluations to reveal how acceptance and usability change over time.",
        "cbStatement": "We provide empirical evidence demonstrating the potential for human-powered devices to meet the phone charging needs of rural, off-grid, mobile phone users in Africa. ",
        "bookmarks": 123,
        "keywords": [
            "HCI4D/ICTD",
            "Design",
            "Human Factors",
            "Human-powered",
            "Off-grid power",
            "mobile phones",
            "rural Africa"
        ],
        "communities": [
            "design",
            "hci4d"
        ],
        "video": "chi0480-file5.mp4",
        "session": {
            "id": "s257",
            "name": "Crowds and activism"
        },
        "room": "blue",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth28618",
                "givenName": "Susan",
                "middleInitial": "P.",
                "familyName": "Wyche",
                "email": "spwyche@msu.edu",
                "primary": {
                    "dept": "Michigan State Univeristy, East Lansing, Michigan, United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth29202",
                "givenName": "Laura L.",
                "familyName": "Murphy",
                "email": "lmurphy2@tulane.edu",
                "primary": {
                    "institution": "Tulane University",
                    "city": "New Orleans",
                    "state": "Louisiana",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 395,
        "name": "Debugging Support for End User Mashup Programming",
        "type": "paper",
        "abstract": "Programming for the web can be an intimidating task,particularly for non-professional (“end-user”) programmers. Mashup programming environments attempt to remedy this by providing support for such programming. It is well known, however, that mashup programmers create applications that contain bugs. Furthermore, mashup programmers learn from examples and reuse other mashups, which causes bugs to propagate to other mashups. In this paper we classify the bugs that occur in a large corpus of Yahoo! Pipes mashups. We describe support we have implemented in the Yahoo! Pipes environment to provide automatic error detection techniques that help mashup programmers localize and correct these \\ bugs. We present the results of a think-aloud study comparing the experiences of end-user mashup programmers using and not using our support. Our results show that our debugging enhancements do help these programmers localize and \\ correct bugs more effectively and efficiently.",
        "cbStatement": "Debugging mashups is difficult and error-prone. We identify classes of faults in Yahoo! Pipes, present a prototype for automated fault localization, and illustrate its effectiveness via a user study. ",
        "bookmarks": 175,
        "keywords": [
            "End-user programming",
            "end-user software engineering",
            "mashups",
            "Yahoo! Pipes",
            "debugging",
            "programming barriers"
        ],
        "communities": [
            "engineering",
            "ux"
        ],
        "video": "chi0491-file5.mp4",
        "session": {
            "id": "s264",
            "name": "Novel Programming"
        },
        "room": "351",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth28954",
                "givenName": "Sandeep Kaur",
                "familyName": "Kuttal",
                "email": "skuttal@cse.unl.edu",
                "primary": {
                    "dept": "Computer Science and Engineering",
                    "institution": "University of Nebraska-Lincoln ",
                    "city": "Lincoln ",
                    "state": "Nebraska",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth9473",
                "givenName": "Anita",
                "familyName": "Sarma",
                "email": "asarma@cse.unl.edu",
                "primary": {
                    "dept": "Department of Computer Science and Engineering",
                    "institution": "University of Nebraska, Lincoln",
                    "city": "Lincoln",
                    "state": "Nebraska",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth28991",
                "givenName": "Gregg",
                "familyName": "Rothermel",
                "email": "gregg.rothermel@gmail.com",
                "primary": {
                    "dept": "Dept of Computer Science and Engineering",
                    "institution": "University of Nebraska, Lincoln",
                    "city": "Lincoln",
                    "state": "Nebraska",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 396,
        "name": "ZoomBoard: A Diminutive QWERTY Soft Keyboard Using Iterative Zooming for Ultra-Small Devices",
        "type": "paper",
        "abstract": "The proliferation of touchscreen devices has made soft keyboards a routine part of life. However, ultra-small computing platforms like the Sony SmartWatch and Apple iPod Nano lack a means of text entry. This limits their potential, despite the fact they are quite capable computers. In this work, we present a soft keyboard interaction technique called ZoomBoard that enables text entry on ultra-small devices. Our approach uses iterative zooming to enlarge otherwise impossibly tiny keys to comfortable size. We based our design on a QWERTY layout, so that it is immediately familiar to users and leverages existing skill. As the ultimate test, we ran a text entry experiment on a keyboard measuring just 16 x 6mm – smaller than a US penny. After eight practice trials, users achieved an average of 9.3 words per minute, with accuracy comparable to a full-sized physical keyboard. This compares favorably to existing mobile text input methods.",
        "cbStatement": "We present Zoomboard, a keyboard that uses iterative zooming to enlarge otherwise impossibly tiny keys to comfortable size.",
        "bookmarks": 97,
        "keywords": [
            "Text entry",
            "mobile input",
            "interaction technique",
            "handheld device",
            "fat finger",
            "zooming user interfaces"
        ],
        "communities": [
            "engineering"
        ],
        "video": "chi0492-file5.mp4",
        "session": {
            "id": "s254",
            "name": "Mobile keyboard / text entry"
        },
        "room": "241",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth14252",
                "givenName": "Stephen",
                "familyName": "Oney",
                "email": "soney@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth10923",
                "givenName": "Chris",
                "familyName": "Harrison",
                "email": "chris.harrison@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth3919",
                "givenName": "Amy",
                "familyName": "Ogan",
                "email": "aeo@andrew.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth14264",
                "givenName": "Jason",
                "familyName": "Wiese",
                "email": "jwwiese@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 397,
        "name": "A Trace-based Framework for Analyzing and Synthesizing Educational Progressions",
        "type": "paper",
        "abstract": "A key challenge in teaching a procedural skill is finding an effective progression of example problems that the learner can solve in order to internalize the procedure. In many learning domains, generation of such problems is typically done by hand and there are few tools to help automate this process. We reduce this effort by borrowing ideas from test input generation in software engineering. We show how we can use execution traces as a framework for abstracting the characteristics of a given procedure and defining a partial ordering that reflects the relative difficulty of two traces. We also show how we can use this framework to analyze the completeness of expert-designed progressions and fill in holes. Furthermore, we demonstrate how our framework can automatically synthesize new problems by generating large sets of problems for elementary and middle school mathematics and synthesizing hundreds of levels for a popular algebra-learning game. We present the results of a user study with this game confirming that our partial ordering can predict user evaluation of procedural difficulty better than baseline methods.",
        "cbStatement": "Proposes a framework for using program execution traces to automatically analyze and synthesize progressions of practice problems for any procedural task, focusing on grade-school mathematics and learning games.",
        "bookmarks": 89,
        "keywords": [
            "education",
            "problem generation",
            "execution traces",
            "games"
        ],
        "communities": [
            "games"
        ],
        "video": "chi0494-file5.mp4",
        "session": {
            "id": "s286",
            "name": "Design for the Classroom"
        },
        "room": "251",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth15291",
                "givenName": "Erik",
                "middleInitial": "L",
                "familyName": "Andersen",
                "email": "eland@cs.washington.edu",
                "primary": {
                    "dept": "Center for Game Science",
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth23804",
                "givenName": "Sumit",
                "familyName": "Gulwani",
                "email": "sumitg@microsoft.com",
                "primary": {
                    "institution": "Microsoft",
                    "city": "Redmond",
                    "state": "WA",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth16067",
                "givenName": "Zoran",
                "familyName": "Popovic",
                "email": "zoran@cs.washington.edu",
                "primary": {
                    "dept": "Center for Game Science",
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 398,
        "name": "Make It Move: A Movement Design Method of Simple Standing Products Based on Systematic Mapping of Torso Movements & Product Messages",
        "type": "paper",
        "abstract": "Human communication significantly relies on the expressivity of their body movements. Based on these body language experiences, humans tend to extract meanings even from movements of objects. This paper begins with the above human tendencies to create a design method that can help product designers make their products move to communicate. As a research vehicle, we created a robotic torso prototype and utilized it to collaborate with movement experts, and listed up possible expressive movement components. We then built a mapping matrix that links these movements to general product messages. A method which utilizes this mapping matrix was developed to help designers determine a set of effective movements that can communicate specific product messages. Lastly, a design workshop was conducted to identify the usefulness of the proposed method. We expect the procedures and findings of this study to help researchers and designers approach affective user experience through product movement design.",
        "cbStatement": "For affective movement design of daily products, this paper brought human movement expertise and product design expertise together through a step-by-step research procedure by using mediated prototyping, the robotic torso",
        "bookmarks": 12,
        "keywords": [
            "product movement",
            "design method"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0517-file5.mp4",
        "session": {
            "id": "s238",
            "name": "Playing with Body"
        },
        "room": "242b",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth22505",
                "givenName": "Jinyung",
                "familyName": "Jung",
                "email": "monagi@kaist.ac.kr",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                },
                "role": "presenter"
            },
            {
                "id": "auth17771",
                "givenName": "Seok-Hyung",
                "familyName": "Bae",
                "email": "seokhyung.bae@kaist.ac.kr",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth23564",
                "givenName": "Joon Hyub",
                "familyName": "Lee",
                "email": "taurere@kaist.ac.kr",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                }
            },
            {
                "id": "auth22445",
                "givenName": "Myung-Suk",
                "familyName": "Kim",
                "email": "mskim@kaist.ac.kr",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                }
            }
        ]
    },
    {
        "id": 399,
        "name": "iGrasp: Grasp-based Adaptive Keyboard for Mobile Devices",
        "type": "paper",
        "abstract": "Multitouch tablets, such as iPad and Android tablets, support virtual keyboards for text entry. Our 64-user study shows that 98% of the users preferred different keyboard layouts and positions depending on how they were holding these devices. However, current tablets either do not allow keyboard adjustment or require users to manually adjust the keyboards. We present iGrasp, which automatically adapts the layout and position of virtual keyboards based on how and where users are grasping the devices without requiring explicit user input. Our prototype uses 46 capacitive sensors positioned along the sides of an iPad to sense users’ grasps, and supports two types of grasp-based automatic adaptation: layout switching and continuous positioning. Our two 18-user studies show that participants were able to begin typing 42% earlier using iGrasp’s adaptive keyboard compared to the manually adjustable keyboard. Participants also rated iGrasp much easier to use than the manually adjustable keyboard (4.2 vs 2.9 on five-point Likert scale.)",
        "cbStatement": "We propose iGrasp, a novel approach that uses implicit grasps of a tablet device to automatically adapt the virtual keyboard’s layout and position to match users’ preferences and help users type earlier.",
        "bookmarks": 122,
        "keywords": [
            "Adaptive user interfaces",
            "grasp detection",
            "virtual keyboard",
            "mobile devices"
        ],
        "communities": [
            "engineering",
            "ux"
        ],
        "video": "chi0520-file5.mp4",
        "session": {
            "id": "s219",
            "name": "Mobile Gestures and Grasp"
        },
        "room": "352ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth17012",
                "givenName": "Lung-Pan",
                "familyName": "Cheng",
                "email": "xmanlch@gmail.com",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                },
                "role": "presenter"
            },
            {
                "id": "auth27186",
                "givenName": "Hsiang-Sheng",
                "familyName": "Liang",
                "email": "b97901125@ntu.edu.tw",
                "primary": {
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth27187",
                "givenName": "Che-Yang",
                "familyName": "Wu",
                "email": "b98902113@ntu.edu.tw",
                "primary": {
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                }
            },
            {
                "id": "auth6300",
                "givenName": "Mike Y.",
                "familyName": "Chen",
                "email": "mikechen@csie.ntu.edu.tw",
                "primary": {
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                }
            }
        ]
    },
    {
        "id": 400,
        "name": "How Low Can You Go? Human Limits in Small Unidirectional Mouse Movements",
        "type": "paper",
        "abstract": "Computer mouse sensors keep increasing in resolution. The smallest displacement they can detect gets smaller, but little is known on our ability to control such small movements. Small target acquisition has been previously tackled, but the findings do not apply to the problem of finding the useful resolution of a user with a mouse, which corresponds to the smallest displacement (s)he can reliably produce with that device. We detail this definition and provide an associated experimental protocol to measure it. We then report on the results of a study suggesting that high-end mice are not likely to be used to their full potential. We further comment on the different strategies used by participants to acheive best performance, and derive implications for user interfaces.",
        "cbStatement": "Presents an experimental protocol and corresponding findings for the mouse for measuring the smallest unidirectional movement people can perform. Details recommendation guidelines for user interfaces and devices design.",
        "bookmarks": 129,
        "keywords": [
            "Input device",
            "mouse",
            "resolution",
            "useful resolution"
        ],
        "communities": [
            "engineering"
        ],
        "video": "chi0528-file5.mp4",
        "session": {
            "id": "s252",
            "name": "Pointing and Fitts Law"
        },
        "room": "241",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth27322",
                "givenName": "Jonathan",
                "familyName": "Aceituno",
                "email": "jonathan.aceituno@inria.fr",
                "primary": {
                    "institution": "Inria Lille",
                    "city": "Villeneuve d'Ascq",
                    "country": "France"
                },
                "role": "presenter"
            },
            {
                "id": "auth3033",
                "givenName": "Géry",
                "familyName": "Casiez",
                "email": "gery.casiez@lifl.fr",
                "primary": {
                    "institution": "LIFL & INRIA Lille, University of Lille",
                    "city": "Villeneuve d'Ascq",
                    "country": "France"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1169",
                "givenName": "Nicolas",
                "familyName": "Roussel",
                "email": "nicolas.roussel@inria.fr",
                "primary": {
                    "institution": "Inria",
                    "city": "Lille",
                    "country": "France"
                }
            }
        ]
    },
    {
        "id": 401,
        "name": "Focused and Casual Interactions: Allowing Users to Vary Their Level of Engagement",
        "type": "paper",
        "abstract": "We describe the focused-casual continuum, a framework for describing interaction techniques according to the degree to which they allow users to adapt how much attention and effort they choose to invest in an interaction conditioned on their current situation. Casual interactions are particularly appropriate in scenarios where full engagement with devices is frowned upon socially, is unsafe, physically challenging or too mentally taxing. Novel sensing approaches which go beyond direct touch enable wider use of casual interactions, which will often be 'around device' interactions. We consider the degree to which previous commercial products and research prototypes can be considered as fitting the focused--casual framework, and describe the properties using control theoretic concepts. In an experimental study we observe that users naturally apply more precise and more highly engaged interaction techniques when faced with a more challenging task and use more relaxed gestures in easier tasks.",
        "cbStatement": "Investigates how to enable users to vary their engagement in \\ interactions, allowing them to use casual interactions for less \\ precision but also with less effort when e.g. tired or busy.",
        "bookmarks": 67,
        "keywords": [
            "casual interaction",
            "deliberate interaction",
            "sensing",
            "interaction techniques",
            "peripheral interaction",
            "foreground\\\\slash background"
        ],
        "communities": [],
        "video": "chi0529-file5.mp4",
        "session": {
            "id": "s243",
            "name": "Place meets Engagement"
        },
        "room": "342a",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth17146",
                "givenName": "Henning",
                "familyName": "Pohl",
                "email": "Henning@hci.uni-hannover.de",
                "primary": {
                    "dept": "FG Mensch-Computer-Interaktion",
                    "institution": "University of Hanover",
                    "city": "Hannover",
                    "country": "Germany"
                },
                "secondary": {
                    "dept": "School of Computing Science",
                    "institution": "University of Glasgow",
                    "city": "Glasgow",
                    "country": "UK"
                },
                "role": "presenter"
            },
            {
                "id": "auth4703",
                "givenName": "Roderick",
                "familyName": "Murray-Smith",
                "email": "rod@dcs.gla.ac.uk",
                "primary": {
                    "institution": "University of Glasgow",
                    "city": "Glasgow",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 402,
        "name": "Activity-Centric Support for Ad Hoc Knowledge Work - A Case Study of co-Activity Manager",
        "type": "paper",
        "abstract": "Modern knowledge work consists of both individual and highly collaborative activities that are typically composed of a  number of configuration, coordination and articulation processes. The desktop interface today, however, provides very little support for these processes and rather forces knowledge workers to adapt to the technology. We introduce co-Activity Manager,  an activity-centric desktop system that (i) provides tools for ad hoc dynamic configuration of a desktop working context, (ii) supports both explicit and implicit articulation of ongoing work through a built-in collaboration manager and (iii) provides the means to coordinate and share working context with other users and devices. \\ In this paper, we discuss the activity theory informed design of co-Activity Manager and report on a 14 day field deployment in a multi-disciplinary software development team.  \\ The study showed that the activity-centric workspace supports different individual and collaborative work configuration practices and that activity-centric collaboration is a two-phase process consisting of an activity sharing and per-activity coordination phase.",
        "cbStatement": "The core contribution of this paper is the design of a desktop manager that supports personal and collaborative activity-centric workflows with integrated activity-centric collaboration and interruption management tools.",
        "bookmarks": 96,
        "keywords": [
            "Activity Theory, Desktop Interface, Activity-Centric Computing,  Collaborative Work"
        ],
        "communities": [],
        "video": "chi0536-file5.mp4",
        "session": {
            "id": "s208",
            "name": "Managment of Knowledge and Collaoration: brining the best out of teams"
        },
        "room": "blue",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth17285",
                "givenName": "Steven",
                "familyName": "Houben",
                "email": "shou@itu.dk",
                "primary": {
                    "dept": "Pervasive Interaction Technology Lab",
                    "institution": "IT University of Copenhagen",
                    "city": "Copenhagen",
                    "country": "Denmark"
                },
                "role": "presenter"
            },
            {
                "id": "auth1962",
                "givenName": "Jakob",
                "middleInitial": "E",
                "familyName": "Bardram",
                "email": "bardram@itu.dk",
                "primary": {
                    "dept": "Pervasive Interaction Technology Lab",
                    "institution": "IT University of Copenhagen",
                    "city": "Copenhagen",
                    "country": "Denmark"
                }
            },
            {
                "id": "auth12515",
                "givenName": "Jo",
                "familyName": "Vermeulen",
                "email": "jo.vermeulen@uhasselt.be",
                "primary": {
                    "dept": "Expertise Centre for Digital Media",
                    "institution": "Hasselt University - tUL - iMinds",
                    "city": "Diepenbeek",
                    "country": "Belgium"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth2807",
                "givenName": "Kris",
                "familyName": "Luyten",
                "email": "kris.luyten@uhasselt.be",
                "primary": {
                    "dept": "Expertise Centre for Digital Media",
                    "institution": "Hasselt University - tUL - iMinds",
                    "city": "Diepenbeek",
                    "country": "Belgium"
                }
            },
            {
                "id": "auth9363",
                "givenName": "Karin",
                "familyName": "Coninx",
                "email": "karin.coninx@uhasselt.be",
                "primary": {
                    "dept": "Expertise Centre for Digital Media",
                    "institution": "Hasselt University - tUL - iMinds",
                    "city": "Diepenbeek",
                    "country": "Belgium"
                }
            }
        ]
    },
    {
        "id": 403,
        "name": "ARTFuL: Adaptive Review Technology for Flipped Learning",
        "type": "paper",
        "abstract": "Internet technology is revolutionizing education. Teachers are developing massive open online courses (MOOCs) and using innovative practices such as flipped learning in which students watch lectures at home and engage in hands-on, problem solving activities in class. This work seeks to explore the design space afforded by these novel educational paradigms and to develop technology for improving student learning. Our design, based on the technique of adaptive content review, monitors student attention during educational presentations and determines which lecture topic students might benefit the most from reviewing. An evaluation of our technology within the context of an online art history lesson demonstrated that adaptively reviewing lesson content improved student recall abilities 29% over a baseline system and was able to match recall gains achieved by a full lesson review in less time. Our findings offer guidelines for a novel design space in dynamic educational technology that might support both teachers and online tutoring systems.",
        "cbStatement": "Presents adaptive content review technology for students engaged in online learning and empirical results supporting student learning gains. Offers design guidelines for technological support for flipped learning.",
        "bookmarks": 139,
        "keywords": [
            "Massive open online course (MOOC)",
            "flipped learning",
            "adaptive user interfaces (AUI)",
            "brain-computer interfaces (BCI)",
            "electroencephalography (EEG)",
            "adaptive content review",
            "information recall",
            "learning"
        ],
        "communities": [],
        "video": "chi0538-file5.mp4",
        "session": {
            "id": "s285",
            "name": "Classrooms"
        },
        "room": "blue",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth22949",
                "givenName": "Daniel",
                "middleInitial": "J",
                "familyName": "Szafir",
                "email": "dszafir@wisc.edu",
                "primary": {
                    "institution": "University of Wisconsin, Madison",
                    "city": "Madison",
                    "state": "WI",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth6279",
                "givenName": "Bilge",
                "familyName": "Mutlu",
                "email": "bmutlu@wisc.edu",
                "primary": {
                    "institution": "University of Wisconsin, Madison",
                    "city": "Madison",
                    "state": "Wisconsin",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 404,
        "name": "Your Left Hand Can Do It Too! Investigating Intermanual, Symmetric Gesture Transfer on Touchscreens",
        "type": "paper",
        "abstract": "This work examines intermanual gesture transfer, i.e., learning a gesture with one hand and performing it with the other. Using a traditional retention and transfer paradigm from the motor learning literature, participants learned four gestures on a touchscreen. The study found that touchscreen gestures transfer, and do so symmetrically. Regardless of the hand used during training, gestures were performed with a comparable level of error and speed by the untrained hand, even after 24 hours. In addition, the form of a gesture, i.e., its length or curvature, was found to have no influence on transferability. These results have important implications for the design of stroke-based ges- tural interfaces: acquisition could occur with either hand and it is possible to interchange the hand used to perform gestures. The work concludes with a discussion of these implications and highlights how they can be applied to ges- ture learning and current gestural systems.",
        "cbStatement": "This work examines intermanual gesture transfer, i.e., learning a gesture with one hand and performing it with the other. It was found that stroke-based gestures transfer, and do so symmetrically.",
        "bookmarks": 100,
        "keywords": [
            "Touchscreen",
            "gestures",
            "gesture transfer",
            "intermanual trans- fer",
            "symmetric transfer",
            "skill acquisition",
            "motor learning"
        ],
        "communities": [],
        "video": "chi0540-file5.mp4",
        "session": {
            "id": "s253",
            "name": "Gestures studies / empirical"
        },
        "room": "241",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth11551",
                "givenName": "Michelle",
                "familyName": "Annett",
                "email": "mkannett@ualberta.ca",
                "primary": {
                    "institution": "University of Alberta",
                    "city": "Edmonton",
                    "state": "Alberta",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth25366",
                "givenName": "Walter",
                "middleInitial": "F",
                "familyName": "Bischof",
                "email": "wfb@ualberta.ca",
                "primary": {
                    "institution": "University of Alberta",
                    "city": "Edmonton",
                    "state": "Alberta",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 405,
        "name": "\"Everybody Knows What You’re Doing\": A Critical Design Approach to Personal Informatics",
        "type": "paper",
        "abstract": "We present an alternative approach to the design of personal informatics systems: instead of motivating people to examine their own behaviors, this approach promotes awareness of and reflection on the infrastructures behind personal informatics and the modes of engagement that they promote. Specifically, this paper presents an interface that displays personal web browsing data. The interface aims to reveal underlying infrastructure using several methods: drawing attention to the scope of mined data by displaying deliberately selected sensitive data, using purposeful malfunction as a way to encourage reverse engineering, and challenging normative expectations around data mining by displaying information in unconventional ways. Qualitative results from a two-week deployment show that these strategies can raise people’s awareness about data mining, promote efficacy and control over personal data, and inspire reflection on the goals and assumptions embedded in infrastructures for personal data analytics.",
        "cbStatement": "The paper introduces critical design strategies to the area of personal informatics in order to encourage users to reflect on the data that is gathered about their online activity.",
        "bookmarks": 50,
        "keywords": [
            "Personal informatics",
            "critical design",
            "design strategies"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0546-file5.mp4",
        "session": {
            "id": "s274",
            "name": "Privacy"
        },
        "room": "251",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth18162",
                "givenName": "Vera",
                "middleInitial": "D",
                "familyName": "Khovanskaya",
                "email": "vdk9@cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth7663",
                "givenName": "Eric",
                "middleInitial": "P. S.",
                "familyName": "Baumer",
                "email": "ericpsb@cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth2110",
                "givenName": "Dan",
                "familyName": "Cosley",
                "email": "danco@cs.cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth1380",
                "givenName": "Stephen",
                "middleInitial": "A",
                "familyName": "Voida",
                "email": "svoida@cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth2332",
                "givenName": "Geri",
                "familyName": "Gay",
                "email": "gkg1@cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 406,
        "name": "Let’s Get Together: The Formation and Success of Online Creative Collaborations",
        "type": "paper",
        "abstract": "In online creative communities, members work together to produce music, movies, games, and other cultural products. Despite the proliferation of collaboration in these communities, we know little about how these teams form and what leads to their ultimate success. Building on theories of social identity and exchange, we present an exploratory study of an online songwriting community. We analyze four years of longitudinal behavioral data using a novel path-based regression model that accurately predicts and reveals key variables about collab formation. Combined with a large-scale survey of members, we find that communication, nuanced complementary interest and status, and a balanced effort from both parties contribute to successful collaborations. We also discuss several applications of these findings for socio-technical infrastructures that support online creative production. \\ ",
        "cbStatement": "We study an online music community by combining a novel path-based regression analysis of the social network with traditional member surveys, uncovering factors that affect online creative collaborations.",
        "bookmarks": 23,
        "keywords": [
            "Collaboration",
            "computer-supported cooperative work",
            "music composition",
            "online communities",
            "social creativity."
        ],
        "communities": [
            "ux",
            "arts"
        ],
        "video": "chi0548-file5.m4v",
        "session": {
            "id": "s210",
            "name": "Creative Source Unitied: Crowdsourcing used in colaborative creation"
        },
        "room": "bordeaux",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth21746",
                "givenName": "Burr",
                "middleInitial": "H",
                "familyName": "Settles",
                "email": "bsettles@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth2727",
                "givenName": "Steven",
                "middleInitial": "P",
                "familyName": "Dow",
                "email": "spdow@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 407,
        "name": "Looking Past Yesterday’s Tomorrow: Using Futures Studies Methods to Extend the Research Horizon",
        "type": "paper",
        "abstract": "Doing research is, in part, an act of foresight. Even though it is not \\ explicit in many projects, we especially value research that is still \\ relevant five, ten or more years after it is completed. However, \\ published research in the field of interactive computing (and \\ technology research in general) often lacks evidence of systematic \\ thinking about the long-term impacts of current trends.  For example, \\ trends on an exponential curve change much more rapidly than intuition \\ predicts. As a result, research may accidentally emphasize near-term \\ thinking. When thinking about the future is approached systematically, \\ we can critically examine multiple potential futures, expand the set \\ of externalities under consideration, and address both negative and \\ positive forecasts of the future. The field of Futures Studies \\ provides methods that can support analysis of long-term trends, \\ support the identification of new research areas and guide design and \\ evaluation. We survey methods for futuristic thinking and discuss \\ their relationship to Human Computer Interaction. Using the \\ sustainability domain an example, we present a case study of a Futures \\ Studies approach--the Delphi Method. We show how Futures Studies can \\ be incorporated into Human Computer Interaction and highlight future \\ work such as rethinking the role of externalities in the validation \\ process.",
        "cbStatement": "A review of futures studies methods used to forecast and think \\ critically about alternative futures and their relevance for HCI \\ research.",
        "bookmarks": 155,
        "keywords": [
            "Futures studies, Science fiction, Sustainability"
        ],
        "communities": [
            "design",
            "sustainability"
        ],
        "video": "chi0564-file5.mp4",
        "session": {
            "id": "s216",
            "name": "Design and Time: Long-term User Involvment and temporal themes"
        },
        "room": "havane",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth1182",
                "givenName": "Jennifer",
                "familyName": "Mankoff",
                "email": "jmankoff@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth17461",
                "givenName": "Haakon",
                "familyName": "Faste",
                "email": "hfaste@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth1333",
                "givenName": "Jennifer",
                "middleInitial": "A.",
                "familyName": "Rode",
                "email": "Jen@acm.org",
                "primary": {
                    "institution": "Drexel University",
                    "city": "Philadelphia",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 408,
        "name": "Ownership and Control of Point of View in Remote Assistance",
        "type": "paper",
        "abstract": "In this paper we investigate user performance and user behavior, related to the issue of who controls the point of view in a remote assistance scenario. We describe an experiment that examined users completing two different tasks with the aid of a remote gesturing device under two conditions: when control of the camera and gesturing point of view was in the hands of the remote helper, and when it was in the hands of the worker. Results indicate that in general, when most of the knowledge is with the helper, it is preferable to leave control in the hands of the helper. However, these results may depend on the situation and task at hand.",
        "cbStatement": "This work investigates user performance and behavior related to the issue of who controls the point of view of a gesturing device in a remote assistance scenario",
        "bookmarks": 142,
        "keywords": [
            "Control",
            "CSCW",
            "Point of view",
            "Remote gesturing",
            "Remote assistance;"
        ],
        "communities": [],
        "video": "chi0568-file5.mp4",
        "session": {
            "id": "s243",
            "name": "Place meets Engagement"
        },
        "room": "342a",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth7703",
                "givenName": "Joel",
                "familyName": "Lanir",
                "email": "joel.lanir@gmail.com",
                "primary": {
                    "institution": "University of Haifa",
                    "city": "Haifa",
                    "country": "Israel"
                },
                "secondary": {
                    "institution": "IBM Research",
                    "city": "Haifa",
                    "country": "Israel"
                },
                "role": "presenter"
            },
            {
                "id": "auth19724",
                "givenName": "Ran",
                "familyName": "Stone",
                "email": "ranst@il.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "Haifa",
                    "country": "Israel"
                }
            },
            {
                "id": "auth20047",
                "givenName": "Benjamin",
                "familyName": "Cohen",
                "email": "cohen@il.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "Haifa",
                    "country": "Israel"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth20046",
                "givenName": "Pavel",
                "familyName": "Gurevich",
                "email": "pavelg@il.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "Haifa",
                    "country": "Israel"
                }
            }
        ]
    },
    {
        "id": 409,
        "name": "MotionMA: Motion Modelling and Analysis by Demonstration",
        "type": "paper",
        "abstract": "Particularly in sports or physical rehabilitation, users have to perform body movements in a specific manner for the exercises to be most effective. It remains a challenge for experts to specify how to perform such movements so that an automated system can analyse further performances of it. In a user study with 10 participants we show that experts' explicit estimates do not correspond to their performances. To address this issue we present MotionMA, a system that: (1) automatically extracts a model of movements demonstrated by one user, e.g. a trainer, (2) assesses the performance of other users repeating this movement in real time, and (3) provides real-time feedback on how to improve their performance.  We evaluated the system in a second study in which 10 other participants used the system to demonstrate arbitrary movements. Our results demonstrate that MotionMA is able to extract an accurate movement model to spot mistakes and variations in movement execution.",
        "cbStatement": "This work describes MotionMA, a system that extracts a quantitative model of movements and generates an analysis and feedback interface for helping other users perform them.",
        "bookmarks": 183,
        "keywords": [
            "Activity Assessment",
            "Weight Lifting",
            "Motion Modelling",
            "Real-Time User Feedback",
            "Learning by Demonstration"
        ],
        "communities": [
            "design",
            "engineering",
            "ux"
        ],
        "video": "chi0573-file5.mp4",
        "session": {
            "id": "s238",
            "name": "Playing with Body"
        },
        "room": "242b",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth29016",
                "givenName": "Eduardo",
                "familyName": "Velloso",
                "email": "e.velloso@lancaster.ac.uk",
                "primary": {
                    "dept": "School of Computing and Communications",
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "state": "Lancashire",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth11540",
                "givenName": "Andreas",
                "familyName": "Bulling",
                "email": "andreas.bulling@acm.org",
                "primary": {
                    "institution": "Max Planck Institute for Informatics",
                    "city": "Saarbrücken",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth5955",
                "givenName": "Hans",
                "familyName": "Gellersen",
                "email": "hwg@comp.lancs.ac.uk",
                "primary": {
                    "dept": "School of Computing and Communications",
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 410,
        "name": "SideWays: A Gaze Interface for Spontaneous Interaction with Situated Displays",
        "type": "paper",
        "abstract": "Eye gaze is compelling for interaction with situated displays as we naturally use our eyes to engage with them. In this work we present SideWays, a novel person-independent eye gaze interface that supports spontaneous interaction with displays: users can just walk up to a display and immediately interact using their eyes, without any prior user calibration or training. Requiring only a single off-the-shelf camera and lightweight image processing, SideWays robustly detects whether users attend to the centre of the display or cast glances to the left or right. The system supports an interaction model in which attention to the central display is the default state, while \"sidelong glances\" trigger input or actions. The robustness of the system and usability of the interaction model are validated in a study with 14 participants. Analysis of the participants' strategies in performing different tasks provides insights on gaze control strategies for design of SideWays applications.",
        "cbStatement": "Presents a system that uses light weight computer vision techniques for calibration-free eye tracking. The system enables hands-free spontaneous interaction with situated displays using eye gaze.",
        "bookmarks": 177,
        "keywords": [
            "Eye-based Interaction",
            "Eye Tracking",
            "Spontaneous Interaction",
            "Situated Display",
            "Calibration-Free"
        ],
        "communities": [],
        "video": "chi0577-file5.mp4",
        "session": {
            "id": "s249",
            "name": "Large and public Displays"
        },
        "room": "241",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth27171",
                "givenName": "Yanxia",
                "familyName": "Zhang",
                "email": "yazhang@lancaster.ac.uk",
                "primary": {
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth11540",
                "givenName": "Andreas",
                "familyName": "Bulling",
                "email": "andreas.bulling@acm.org",
                "primary": {
                    "institution": "Max Planck Institute for Informatics",
                    "city": "Saarbrücken",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth5955",
                "givenName": "Hans",
                "middleInitial": "W",
                "familyName": "Gellersen",
                "email": "hwg@comp.lancs.ac.uk",
                "primary": {
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 411,
        "name": "Understanding Exergame Users’ Physical Activity, Motivation and Behavior Over Time",
        "type": "paper",
        "abstract": "Effective exergames should increase the proportion of time users regularly spend in moderate to vigorous physical activity. There are currently few studies of exergame systems which evaluate the impact on physical activity over time. Those which do, show increases in light intensity exercise which although valuable, do not increase the proportion of moderate to vigorous activity required for optimal health benefits. Furthermore, longitudinal studies to date have encountered a plateau effect in physical activity as the novelty of the game wears off. This paper suggests how exergame designs based on deeper understandings of player motivations could address these problems. \\  \\ We report on longitudinal patterns of users’ physical activity, motivations and behaviour when using exergames, based on case studies from a seven week long school based field trial. These new insights, interpreted through Bandura’s theory of self efficacy, are of value to designers in the HCI community who wish to motivate users with a range of attitudes towards exercise to undertake regular moderate to vigorous physical activity. \\ ",
        "cbStatement": "A school based exergame intervention analysed through the lens of self-efficacy in order to understand in-game behavior, and provide guidance for affective exergame interventions",
        "bookmarks": 183,
        "keywords": [
            "Exergames",
            "motivation",
            "self-efficacy",
            "behavior change",
            "classroom intervention;"
        ],
        "communities": [
            "health",
            "games",
            "cci"
        ],
        "video": "chi0581-file5.mp4",
        "session": {
            "id": "s283",
            "name": "Exergames, Inclusion"
        },
        "room": "251",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth23094",
                "givenName": "Andrew",
                "familyName": "Macvean",
                "email": "apm8@hw.ac.uk",
                "primary": {
                    "institution": "Heriot-Watt University",
                    "city": "Edinburgh",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth22746",
                "givenName": "Judy",
                "familyName": "Robertson",
                "email": "Judy.Robertson@hw.ac.uk",
                "primary": {
                    "institution": "Heriot-Watt University",
                    "city": "Edinburgh",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 412,
        "name": "AnyType: Provoking Reflection and Exploration with Aesthetic Interaction",
        "type": "paper",
        "abstract": "AnyType is a mobile application that generates unique typefaces from photographs of shapes that people find in their environment. In keeping with the principles of aesthetic interaction, the design of AnyType supports opportunities for surprise, storytelling, and expression. This paper presents data collected from two observational studies of AnyType. In both studies, we found that people appropriated the application to create highly personalized messages. They found inspiration in unexpected locations, created memories from nuanced details in their lives, and creatively explored the design space provided by the system. Drawing from our observations, we discuss possible roles mobile devices could play in people’s personal meaning making, creative process, and discovery, in interaction with elements of their physical environment.",
        "cbStatement": "AnyType generates unique typefaces from photographs of shapes people find in their environment. In keeping with the principles of aesthetic interaction, AnyType supports opportunities for surprise, storytelling, and expression.",
        "bookmarks": 140,
        "keywords": [
            "Aesthetic Interaction",
            "User Experience Design",
            "Mobile Technology",
            "Typography",
            "Self-Expression."
        ],
        "communities": [
            "design",
            "ux",
            "arts"
        ],
        "video": "chi0584-file5.mp4",
        "session": {
            "id": "s242",
            "name": "Mobile 2: Very Moving: reflection in mobile technologies"
        },
        "room": "351",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth24531",
                "givenName": "Laura",
                "familyName": "Devendorf",
                "email": "ldevendorf@ischool.berkeley.edu",
                "primary": {
                    "institution": "University of California, Berkeley",
                    "city": "Berkeley",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth3175",
                "givenName": "Kimiko",
                "familyName": "Ryokai",
                "email": "kimiko@ischool.berkeley.edu",
                "primary": {
                    "institution": "University of California, Berkeley",
                    "city": "Berkeley",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 413,
        "name": "Everyday Activities and Energy Consumption: How Families Understand the Relationship",
        "type": "paper",
        "abstract": "Energy consumption is a growing concern and it is important to inform families of their consumption and how they might reduce it. We conducted an interview study that focuses on the existing routines of families and how they currently understand their power and gas consumption based on standard utility bills.  We also investigated how this understanding ties to their everyday activities as might be recorded on their calendars.  This allowed us to assess calendars as an artifact for energy consumption awareness. Our results show that many people relate changes in energy consumption to high-level effects such as weather and temperature and not necessarily their own everyday activities.  Events on calendars may aid this understanding but people do not currently record enough information on their calendars to make a strong tie.  This suggests that if calendars are to be used as artifacts to aid energy consumption understanding, digital calendars need to provide support to include more energy-related information, including both activities and patterns of consumption.",
        "cbStatement": "Describes a study of how families tie their everyday routines to their understanding of energy consumption.  Outlines how designs can leverage calendars and increase shared knowledge of consumption between family members.",
        "bookmarks": 168,
        "keywords": [
            "Energy consumption",
            "calendars",
            "families"
        ],
        "communities": [
            "design",
            "sustainability"
        ],
        "session": {
            "id": "s259",
            "name": "Energy / Sustainability"
        },
        "room": "blue",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth3090",
                "givenName": "Carman",
                "familyName": "Neustaedter",
                "email": "carmster@gmail.com",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth4608",
                "givenName": "Lyn",
                "familyName": "Bartram",
                "email": "lyn@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth27673",
                "givenName": "Aaron",
                "familyName": "Mah",
                "email": "aa.mahh@gmail.com",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 414,
        "name": "Love it or Hate it!  Interactivity and User Types",
        "type": "paper",
        "abstract": "This paper investigates general and individual evaluations of User Experience (UX) with interactive web sites. A series of studies investigate user judgment on web sites with different interactivity levels over repeated exposures. The more interactive websites produced more positive affect, had better design quality ratings, which improved with exposure, and were preferred. Differences between the more interactive sites indicated overall UX was influenced by users’ preferences for interactive styles, with both sites having enthusiast, potential adopter, and non-adopter users. The implications for models and frameworks of UX are discussed.  ",
        "cbStatement": "Demonstrates a mixed methods approach that identifies the importance of interactivity and repeated exposure in positively influencing UX and shows that different levels of UX can be explained through use types",
        "bookmarks": 20,
        "keywords": [
            "User Experience",
            "quality judgement",
            "affect",
            "interactivity",
            "design features",
            "individual differences. "
        ],
        "communities": [
            "ux"
        ],
        "video": "chi0586-file5.mp4",
        "session": {
            "id": "s273",
            "name": "How We Feel About Websites"
        },
        "room": "bordeaux",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth12593",
                "givenName": "Jennefer",
                "familyName": "Hart",
                "email": "jennefer@talktalk.net",
                "primary": {
                    "institution": "The University of Manchester",
                    "city": "Manchester",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth6328",
                "givenName": "Alistair",
                "middleInitial": "G",
                "familyName": "Sutcliffe",
                "email": "a.g.sutcliffe@manchester.ac.uk",
                "primary": {
                    "institution": "The University of Manchester",
                    "city": "Manchester",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1266",
                "givenName": "Antonella",
                "familyName": "De Angeli",
                "email": "deangeli@disi.unitn.it",
                "primary": {
                    "institution": "University of Trento",
                    "city": "Trento",
                    "state": "Trento",
                    "country": "Italy"
                }
            }
        ]
    },
    {
        "id": 415,
        "name": "Accessible Online Content Creation By End Users",
        "type": "paper",
        "abstract": "Like most online content, user-generated content (UGC) poses accessibility barriers to users with disabilities. However, the accessibility difficulties pervasive in UGC warrant discussion and analysis distinct from other kinds of online content. Content authors, community culture, and the authoring tool itself all affect UGC accessibility. The choices, resources available, and strategies in use to ensure accessibility are different than for other types of online content. We contribute case studies of two UGC communities with accessible content: Wikipedia, where authors focus on access to visual materials and navigation, and an online health support forum where users moderate the cognitive accessibility of posts. Our data demonstrate real world moderation strategies and illuminate factors affecting success, such as community culture. We conclude with recommended strategies for creating a culture of accessibility around UGC.",
        "cbStatement": "End-user generated content is common, yet often not accessibility. Our case studies of online communities that create accessible content, shows the importance of negotiated and community-defined notions of accessibility.",
        "bookmarks": 89,
        "keywords": [
            "Accessibility",
            "User-generated content"
        ],
        "communities": [
            "ux",
            "health"
        ],
        "session": {
            "id": "s296",
            "name": "Content, Creation, and Health"
        },
        "room": "242ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth21890",
                "givenName": "Katie",
                "familyName": "Kuksenok",
                "email": "kuksenok@cs.washington.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "WA",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth23452",
                "givenName": "Michael",
                "familyName": "Brooks",
                "email": "mjbrooks@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth1182",
                "givenName": "Jennifer",
                "familyName": "Mankoff",
                "email": "jmankoff@cs.cmu.edu",
                "primary": {
                    "dept": "HCII",
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 416,
        "name": "Bodily Interaction in the Dark",
        "type": "paper",
        "abstract": "In light of the growing interest in designing for new body-movement based interfaces through somaesthetics and somatic awareness, we created a sound-based interaction using the Microsoft Kinect device, which is performed in the dark. The absence of visual feedback led participants to deeply focus on the movement of their bodies, and to have a different awareness of their bodies and the space around them. The notable difference between performing this inter-action in light and dark suggests that non-visual based interfaces are a fruitful area to explore in somaesthetic interaction.",
        "cbStatement": "Describes a body-centric, sound-based interaction using the Microsoft Kinect device, which is performed in the dark. The interaction is designed and analysed in the context of somaesthetics.",
        "bookmarks": 39,
        "keywords": [
            "Body",
            "movement",
            "awareness",
            "dark",
            "vision",
            "somaesthetics"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0623-file5.mp4",
        "session": {
            "id": "s239",
            "name": "Phyisical Excersion"
        },
        "room": "242b",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth26516",
                "givenName": "Linden",
                "middleInitial": "A.",
                "familyName": "Vongsathorn",
                "email": "linden.v@gmail.com",
                "primary": {
                    "dept": "Sociology",
                    "institution": "University of Oxford",
                    "city": "Oxford",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth6210",
                "givenName": "Kenton",
                "middleInitial": "P",
                "familyName": "O'Hara",
                "email": "v-keohar@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1960",
                "givenName": "Helena",
                "middleInitial": "M.",
                "familyName": "Mentis",
                "email": "hementis@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 417,
        "name": "PixelTone: A Multimodal Interface for Image Editing",
        "type": "paper",
        "abstract": "Photo editing can be a challenging task, and it becomes even more difficult on the small, portable screens of mobile devices that are now frequently used to capture and edit images. To address this problem we present PixelTone, a multimodal photo editing interface that combines speech and direct manipulation. We observe existing image editing practices and derive a set of principles that guide our design. In particular, we use natural language for expressing desired changes to an image, and sketching to localize these changes to specific regions. To support the language commonly used in photo-editing we develop a customized natural language interpreter that maps user phrases to specific image processing operations. Finally, we perform a user study that evaluates and demonstrates the effectiveness of our interface.",
        "cbStatement": "PixelTone is a multimodal photo editing interface that combines speech and direct manipulation.",
        "bookmarks": 88,
        "keywords": [
            "multimodal interfaces",
            "natural language",
            "image editing"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi0627-file5.mp4",
        "session": {
            "id": "s250",
            "name": "Beyond Desktop Interaction"
        },
        "room": "242a",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth25198",
                "givenName": "Gierad",
                "familyName": "Laput",
                "email": "glaput@umich.edu",
                "primary": {
                    "institution": "University of Michigan",
                    "city": "Ann Arbor",
                    "state": "Michigan",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Adobe Research",
                    "city": "San Francisco",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth5854",
                "givenName": "Mira",
                "familyName": "Dontcheva",
                "email": "mirad@adobe.com",
                "primary": {
                    "institution": "Adobe Research",
                    "city": "San Francisco",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth30419",
                "givenName": "Gregg",
                "familyName": "Wilensky",
                "email": "wilensky@adobe.com",
                "primary": {
                    "institution": "Adobe Research",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth30420",
                "givenName": "Walter",
                "familyName": "Chang",
                "email": "wachang@adobe.com",
                "primary": {
                    "institution": "Adobe Research",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth10330",
                "givenName": "Aseem",
                "familyName": "Agarwala",
                "email": "aseem@agarwala.org",
                "primary": {
                    "institution": "Adobe Research",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth34816",
                "givenName": "Jason",
                "familyName": "Linder",
                "email": "linder@adobe.com",
                "primary": {
                    "institution": "Adobe Research",
                    "city": "San Francisco",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth6196",
                "givenName": "Eytan",
                "familyName": "Adar",
                "email": "eadar@umich.edu",
                "primary": {
                    "institution": "University of Michigan",
                    "city": "Ann Arbor",
                    "state": "Michigan",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 418,
        "name": "Electric Materialities and Interactive Technology",
        "type": "paper",
        "abstract": "This paper offers new theoretical and design insights into interactive technology. By initially considering electric technology broadly, our work informs how HCI approaches a range of specific interactive or digital things and materials. Theoretically, we contribute a rigorous analysis of electric technology using the experiential lens of phenomenology. A major result is to characterize electric technology by three forms of materiality: the electric object, its electric materiality, and electric power. In terms of design, we present and analyze novel interactive form prototypes. Our theoretical contributions offer new insight into design artifacts, just as our novel design artifacts help reveal new theoretical insight.",
        "cbStatement": "Characterizes electric technology by three forms of materiality: the electric object, its electric materiality, and electric power. Presents and analyzes novel interactive form prototypes. ",
        "bookmarks": 146,
        "keywords": [
            "Design Theory",
            "interaction design",
            "electricity"
        ],
        "communities": [
            "design"
        ],
        "session": {
            "id": "s246",
            "name": "Touching Experiences: tangible computing & trajectories"
        },
        "room": "351",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth10647",
                "givenName": "James",
                "middleInitial": "J",
                "familyName": "Pierce",
                "email": "jjpierce@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1921",
                "givenName": "Eric",
                "familyName": "Paulos",
                "email": "eric@paulos.net",
                "primary": {
                    "institution": "University of California, Berkeley",
                    "city": "Berkeley",
                    "state": "California",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 419,
        "name": "Does Slacktivism Hurt Activism?: The Effects of Moral Balancing and Consistency in Online Activism",
        "type": "paper",
        "abstract": "In this paper we explore how the decision of partaking in low-cost, low-risk online activism—slacktivism—may affect subsequent civic action. Based on moral balancing and consistency effects, we designed an online experiment to test if signing or not signing an online petition increased or decreased subsequent contribution to a charity. We found that participants who signed the online petition were significantly more likely to donate money to a related charity, demonstrating a consistency effect. We also found that participants who did not sign the petition donated significantly more money to an unrelated charity, demonstrating a moral balancing effect. The results suggest that exposure to an online activism influences individual decision on subsequent civic actions. ",
        "cbStatement": "We examine how simple online activism influence people's likelihood and efforts in a subsequent civic action. The findings have implications for online campaign design.",
        "bookmarks": 52,
        "keywords": [
            "Online Petitions",
            "Consistency",
            "Moral Balancing",
            "Slacktivism"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0635-file5.mp4",
        "session": {
            "id": "s260",
            "name": "Crowdsource Activism Volunteering Citizen Science"
        },
        "room": "bordeaux",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth27718",
                "givenName": "Yu-Hao",
                "familyName": "Lee",
                "email": "leeyuhao@msu.edu",
                "primary": {
                    "institution": "Michigan State Univeristy",
                    "city": "East Lansing",
                    "state": "Michigan",
                    "country": "United States"
                }
            },
            {
                "id": "auth3228",
                "givenName": "Gary",
                "familyName": "Hsieh",
                "email": "garyh@msu.edu",
                "primary": {
                    "institution": "Michigan State Univeristy",
                    "city": "East Lansing",
                    "state": "Michigan",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 420,
        "name": "Motif Simplification: Improving Network Visualization Readability with Fan, Connector, and Clique Glyphs",
        "type": "paper",
        "abstract": "Analyzing networks involves understanding the complex relationships between entities, as well as any attributes they may have. The widely used node-link diagrams excel at this task, but many are difficult to extract meaning from because of the inherent complexity of the relationships and limited screen space. To help address this problem we introduce a technique called motif simplification, in which common patterns of nodes and links are replaced with compact and meaningful glyphs. Well-designed glyphs have several benefits: they (1) require less screen space and layout effort, (2) are easier to understand in the context of the network, (3) can reveal otherwise hidden relationships, and (4) preserve as much underlying information as possible. We tackle three frequently occurring and high-payoff motifs: fans of nodes with a single neighbor, connectors that link a set of anchor nodes, and cliques of completely connected nodes. We contribute design guidelines for motif glyphs; example glyphs for the fan, connector, and clique motifs; algorithms for detecting these motifs; a free and open source reference implementation; and results from a controlled study of 36 participants that demonstrates the effectiveness of motif simplification.",
        "cbStatement": "It is difficult to visualize large networks. Motif simplification reduces network complexity by replacing common, repeating patterns with representative glyphs. Our controlled study shows this is helpful for many tasks.",
        "bookmarks": 43,
        "keywords": [
            "Motif simplification",
            "network visualization",
            "graph drawing",
            "node-link diagram",
            "visual analytics"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0639-file5.mp4",
        "session": {
            "id": "s231",
            "name": "Visualization 1"
        },
        "room": "bordeaux",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth17375",
                "givenName": "Cody",
                "familyName": "Dunne",
                "email": "cdunne@cs.umd.edu",
                "primary": {
                    "dept": "Department of Computer Science and Human-Computer Interaction Lab",
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "secondary": {
                    "dept": "Department of Computer Science and Human-Computer Interaction Lab",
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth3519",
                "givenName": "Ben",
                "familyName": "Shneiderman",
                "email": "ben@cs.umd.edu",
                "primary": {
                    "dept": "Department of Computer Science and Human-Computer Interaction Lab",
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "secondary": {
                    "dept": "Department of Computer Science and Human-Computer Interaction Lab",
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 421,
        "name": "Technology Preferences and Routines for Sharing Health Information during the Treatment of a Chronic Illness",
        "type": "paper",
        "abstract": "When a patient has a chronic illness, such as heart disease or cancer, it can be challenging for distributed family members to stay aware of the patient’s health status. A variety of technologies are available to support health information sharing (e.g., phone, video chat, social media), yet we still do not have a detailed understanding of which technologies are preferred and what challenges people still face when sharing information with them. To explore this, we conducted a mixed-method study—involving a survey and in-depth interviews—with people about their health information sharing routines and preferences for different technologies. Regardless of physical distance between distributed family members, synchronous methods of communication afforded the opportunity to provide affective support while asynchronous methods of communication were deemed to be the least intrusive. With family members adopting certain roles during the treatment of chronic illnesses, our findings suggest the need to design tools that mediate sharing health information across distance and age gaps, with consideration to respecting patient privacy while sharing health information.",
        "cbStatement": "Describes design implications for technologies to support sharing health information within families coping with a chronic illness. Using a mixed-method approach, presents findings outlining affective benefits and costs of communication tools.",
        "bookmarks": 135,
        "keywords": [
            "Health informatics",
            "families",
            "social support",
            "communication"
        ],
        "communities": [
            "design",
            "health"
        ],
        "session": {
            "id": "s295",
            "name": "Health, Information, and Communication"
        },
        "room": "242ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth27684",
                "givenName": "Carolyn",
                "familyName": "Pang",
                "email": "carolyn_pang@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth3090",
                "givenName": "Carman",
                "familyName": "Neustaedter",
                "email": "carmster@gmail.com",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth18172",
                "givenName": "Bernhard",
                "middleInitial": "E.",
                "familyName": "Riecke",
                "email": "ber1@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            },
            {
                "id": "auth27685",
                "givenName": "Erick",
                "familyName": "Oduor",
                "email": "eoduor@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            },
            {
                "id": "auth23759",
                "givenName": "Serena",
                "familyName": "Hillman",
                "email": "shillman@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Surrey",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 422,
        "name": "Distraction Beyond the Driver: Predicting the Effects of In-Vehicle Interaction on Surrounding Traffic",
        "type": "paper",
        "abstract": "Recent studies of driver distraction have reported a number of detrimental effects of in-vehicle interaction on driver performance. This paper examines and predicts the potential effects of such interaction on other vehicles around the driver’s vehicle. Specifically, the paper describes how computational cognitive models can be used to predict the complex interactions among several vehicles driving in a line when one or more of the vehicles’ drivers are performing a secondary task (phone dialing). The results of simulating two distinct car-following scenarios illustrate that in-vehicle interaction by one driver can have significant downstream effects on other drivers, especially with respect to speed deviations relative to a lead vehicle. This work generalizes recent work developing computational evaluation tools for user interfaces in complex domains, and further serves as an example of how user interaction in some domains can have broader effects on the community at large.",
        "cbStatement": "Describes a method for simulating the effects of driver distraction across multiple vehicles. Allows users to rapidly prototype and evaluate in-vehicle interfaces based on their potential for distraction. \\ ",
        "bookmarks": 59,
        "keywords": [
            "Driving",
            "driver distraction",
            "multitasking",
            "cognitive models"
        ],
        "communities": [],
        "video": "chi0645-file5.mp4",
        "session": {
            "id": "s270",
            "name": "Untitled (Automotive and Awareness)"
        },
        "room": "241",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth1886",
                "givenName": "Dario",
                "middleInitial": "D.",
                "familyName": "Salvucci",
                "email": "salvucci@cs.drexel.edu",
                "primary": {
                    "institution": "Drexel University",
                    "city": "Philadelphia",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 423,
        "name": "Health Vlogger-Viewer Interaction in Chronic Illness Management",
        "type": "paper",
        "abstract": "Health video blogs (vlogs) allow individuals with chronic illnesses to share their stories, experiences, and knowledge with the general public. Furthermore, health vlogs help in creating a connection between the vlogger and the viewers. In this work, we present a qualitative study examining the various methods that health vloggers use to establish a connection with their viewers. We found that vloggers used genres to express specific messages to their viewers while using the uniqueness of video to establish a deeper connection with their viewers. Health vloggers also explicitly sought interaction with their viewers. Based on these results, we present design implications to help facilitate and build sustainable communities for vloggers. ",
        "cbStatement": "Health vlogs allow individuals with chronic illnesses to share experiences. We examined methods that vloggers use to connect with viewers. We present design implications that facilitate sustainable communities for vloggers.",
        "bookmarks": 24,
        "keywords": [
            "Health vlogs",
            "YouTube",
            "video blogging",
            "chronic illness management",
            "communication",
            "patient-centered"
        ],
        "communities": [
            "health"
        ],
        "video": "chi0646-file5.mp4",
        "session": {
            "id": "s296",
            "name": "Content, Creation, and Health"
        },
        "room": "242ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth14022",
                "givenName": "Leslie",
                "middleInitial": "S.",
                "familyName": "Liu",
                "email": "lsliu@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth34755",
                "givenName": "Jina",
                "familyName": "Huh",
                "email": "jinahuh@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth34754",
                "givenName": "Tina",
                "familyName": "Neogi",
                "email": "tneogi@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth1581",
                "givenName": "Kori",
                "familyName": "Inkpen",
                "email": "kori@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth1589",
                "givenName": "Wanda",
                "familyName": "Pratt",
                "email": "wpratt@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 424,
        "name": "Métamorphe: Augmenting  Hotkey Usage with Actuated Keys",
        "type": "paper",
        "abstract": "Hotkeys are an efficient method of selecting commands on a keyboard. However, these shortcuts are often underused by users. We present Métamorphe, a novel keyboard with keys that can be individually raised and lowered to promote hotkeys usage. Métamorphe augments the output of traditional keyboards with haptic and visual feedback, and offers a novel design space for user input on raised keys (e.g., gestures such as squeezing or pushing the sides of a key). We detail the implementation of Métamorphe and discuss design factors. We also report two user studies. The first is a user-defined interface study that shows that the new input vocabulary is usable and useful, and provides insights into the mental models that users associate with raised keys. The second user study shows improved eyes-free selection performance for raised keys as well as the surrounding unraised keys.",
        "cbStatement": "Demonstrate the advantages of shape-changing keyboards for command selection. The Metamorphe keyboard offers a novel height-changing mechanism that provides haptic feedback and enables new key gestures.",
        "bookmarks": 186,
        "keywords": [
            "Augmented keyboard",
            "height-changing keys",
            "hotkeys",
            "shape-changing interfaces",
            "user-defined gestures"
        ],
        "communities": [
            "engineering"
        ],
        "video": "chi0650-file5.mp4",
        "session": {
            "id": "s255",
            "name": "Hotkeys / Touch keyboards"
        },
        "room": "241",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth9471",
                "givenName": "Gilles",
                "familyName": "Bailly",
                "email": "gbailly@mpi-inf.mpg.de",
                "primary": {
                    "dept": "Quality and Usability Lab",
                    "institution": "Telekom Innovation Laboratories, TU Berlin",
                    "city": "Berlin",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth14172",
                "givenName": "Thomas",
                "familyName": "Pietrzak",
                "email": "thomas.pietrzak@gmail.com",
                "primary": {
                    "dept": "MINT, LIFL",
                    "institution": "Université de Lille 1",
                    "city": "Lille",
                    "country": "France"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29269",
                "givenName": "Jonathan",
                "familyName": "Deber",
                "email": "jdeber@dgp.toronto.edu",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                }
            },
            {
                "id": "auth3440",
                "givenName": "Daniel",
                "middleInitial": "J",
                "familyName": "Wigdor",
                "email": "daniel@wigdor.com",
                "primary": {
                    "institution": "University of Toronto",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 425,
        "name": "Crowdfunding inside the Enterprise: Employee-Initiatives for Innovation and Collaboration",
        "type": "paper",
        "abstract": "We describe a first experiment in enterprise crowdfunding – i.e., employees allocating money for employee-initiated proposals at an Intranet site, including a trial of this system with 511 employees in IBM Research.  Major outcomes include: employee proposals that addressed diverse indivi-dual and organizational needs; high participation rates; ex-tensive inter-departmental collaboration, including the dis-covery of large numbers of previously unknown collabora-tors; and the development of goals and motivations based on collective concerns at multiple levels of project groups, communities of practice, and the organization as a whole.  We recommend further, comparative research into crowd-funding and other forms of employee-initiated innovations.",
        "cbStatement": "Crowdfunding behind a company firewall showed diverse projects, inter-organizational collaborations, and collaborative motivations. Potential interest for HCI researchers, organizational practitioners, and consultants.",
        "bookmarks": 131,
        "keywords": [
            "Crowdfunding",
            "enterprise",
            "innovation",
            "employee",
            "social;"
        ],
        "communities": [],
        "video": "chi0651-file5.mp4",
        "session": {
            "id": "s201",
            "name": "Enterprise and online communities: the best of both worlds"
        },
        "room": "havane",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth1047",
                "givenName": "Michael",
                "familyName": "Muller",
                "email": "michael_muller@us.ibm.com",
                "primary": {
                    "institution": "IBM",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1825",
                "givenName": "Werner",
                "familyName": "Geyer",
                "email": "werner.geyer@us.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29075",
                "givenName": "Todd",
                "familyName": "Soule",
                "email": "tssoule@us.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "Hawthorne",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth29076",
                "givenName": "Steven",
                "familyName": "Daniels",
                "email": "danields@us.ibm.com",
                "primary": {
                    "institution": "IBM T.J. Watson Research",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth29077",
                "givenName": "Li-Te",
                "familyName": "Cheng",
                "email": "lcheng@ieee.org",
                "primary": {
                    "institution": "IBM Research",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 426,
        "name": "A Multi-Site Field Study of Crowdsourced Contextual Help: Usage and Perspectives of End Users and Software Teams",
        "type": "paper",
        "abstract": "We present a multi-site field study to evaluate LemonAid, a crowdsourced contextual help approach that allows users to retrieve relevant questions and answers by making selections within the interface. We deployed LemonAid on 4 different web sites used by thousands of users and collected data over several weeks, gathering over 1,200 usage logs, 168 exit surveys, and 36 one-on-one interviews. Our results indicate that over 70% of users found LemonAid to be helpful, intuitive, and desirable for reuse. Software teams found LemonAid easy to integrate with their sites and found the analytics data aggregated by LemonAid a novel way of learning about users’ popular questions. Our work provides the first holistic picture of the adoption and use of a crowdsourced contextual help system and offers several insights into the social and organizational dimensions of implementing such help systems for real-world applications.",
        "cbStatement": "We present a field study of a crowdsourced contextual help system deployed on 4 large web sites. Data was collected over several weeks through usage logs, surveys, and interviews. ",
        "bookmarks": 91,
        "keywords": [
            "contextual help",
            "crowdsourced help",
            "field studies",
            "field deployments",
            "help systems",
            "software support=."
        ],
        "communities": [
            "ux"
        ],
        "video": "chi0662-file5.mp4",
        "session": {
            "id": "s209",
            "name": "Power to the People: utalizing crowdsourcing"
        },
        "room": "241",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth11526",
                "givenName": "Parmit",
                "middleInitial": "K",
                "familyName": "Chilana",
                "email": "pchilana@u.washington.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth2712",
                "givenName": "Andrew",
                "middleInitial": "J",
                "familyName": "Ko",
                "email": "ajko@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1537",
                "givenName": "Jacob",
                "middleInitial": "O.",
                "familyName": "Wobbrock",
                "email": "wobbrock@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth1476",
                "givenName": "Tovi",
                "familyName": "Grossman",
                "email": "tovi.grossman@autodesk.com",
                "primary": {
                    "institution": "Autodesk Research",
                    "city": "Toronto",
                    "state": "Ontario",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 427,
        "name": "Large-Scale Participation: A Case Study of a Participatory Approach to Developing a New Public Library",
        "type": "paper",
        "abstract": "In this paper, we present a case study of a participatory project that focuses on interaction in large-scale design, namely, the development of the new Urban Mediaspace Aarhus. This project, which has been under way for ten years, embodies a series of issues that arise when participatory design approaches are applied to large-scale, IT-oriented projects. At the same time, it highlights the issues public knowledge institutions face, when interactive technologies challenge their fundamental roles and practices; by extension, this case offers examples of how these challenges may be explored and addressed through IT-based participatory initiatives. We present a range of such activities carried out during the past ten years, and present the main lessons from the project, based on interviews with three key stakeholders. These lessons focus on how to make participation work in practice, how to align different paradigms of inquiry and practice in a project of this scale, and how to capture and anchor the insights from participatory events to inform the ongoing design process.",
        "cbStatement": "A case study of a participatory large-scale project in the development of a new public library, with a range of activities and the main lessons from the project.",
        "bookmarks": 63,
        "keywords": [
            "Participatory Design",
            "Interaction Design",
            "Large-Scale Projects",
            "Design Methods",
            "Citizen Involvement "
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi0663-file5.mp4",
        "session": {
            "id": "s245",
            "name": "Co-Design: involving propspective users in design"
        },
        "room": "351",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth15835",
                "givenName": "Peter",
                "familyName": "Dalsgaard",
                "email": "dalsgaard@cavi.dk",
                "primary": {
                    "institution": "Aarhus University",
                    "city": "Aarhus",
                    "country": "Denmark"
                },
                "role": "presenter"
            },
            {
                "id": "auth4897",
                "givenName": "Eva",
                "familyName": "Eriksson",
                "email": "eva.eriksson@chalmers.se",
                "primary": {
                    "institution": "Chalmers University of Technology",
                    "city": "Gothenburg",
                    "country": "Sweden"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 428,
        "name": "Design for Forgetting: Disposing of Digital Possessions after a Breakup",
        "type": "paper",
        "abstract": "People are increasingly acquiring huge collections of digital possessions. Despite some pleas for ‘forgetting’, most theorists argue for retaining all these possessions to enhance ‘total recall’ of our everyday lives. However, there has been little exploration of the negative role of digital possessions when people want to forget aspects of their lives. We report on interviews with 24 people about their possessions after a romantic breakup. We found that digital possessions were often evocative and upsetting in this context, leading to distinct disposal strategies with different outcomes. We advance theory by finding strong evidence for the value of intentional forgetting and provide new data about complex practices associated with the disposal of digital possessions. Our findings led to a number of design implications to help people better manage this process, including automatic harvesting of digital possessions, tools for self-control, artifact crafting as sense-making, and digital spaces for shared possessions.",
        "cbStatement": "This paper examines the challenges of digital possessions and their disposal following a romantic breakup. We found that digital possessions are often evocative and upsetting leading to distinct disposal strategies.",
        "bookmarks": 44,
        "keywords": [
            "Autobiographical memories",
            "sense of self",
            "disposal",
            "digital possessions",
            "relationship dissolution",
            "intentional forgetting."
        ],
        "communities": [
            "design"
        ],
        "video": "chi0665-file5.mp4",
        "session": {
            "id": "s244",
            "name": "Studies of the Use of Digital Artifacts"
        },
        "room": "342a",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth5881",
                "givenName": "Corina",
                "familyName": "Sas",
                "email": "c.sas@lancaster.ac.uk",
                "primary": {
                    "dept": "School of Cmputing and Communications",
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth13221",
                "givenName": "Steve",
                "familyName": "Whittaker",
                "email": "swhittak@ucsc.edu",
                "primary": {
                    "dept": "HCI Lab",
                    "institution": "University of California at Santa Cruz",
                    "city": "Santa Cruz",
                    "state": "California",
                    "country": "USA"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 429,
        "name": "3D Object Position using Automatic Viewpoint Transitions",
        "type": "paper",
        "abstract": "This paper presents IUCA (Interaction Using Camera Animations), a new interaction technique for 3D objects manipulation. IUCA allows efficient interaction in a full-resolution perspective view by integrating transients animated transitions to orthographic views into the manipulation task. This provides an interaction in context, with precise object positioning and alignment. An evaluation of the technique shows that,  compared to the classical configurations, IUCA allows to reduce pointing time by 14\\\\% on average. Testing with professional 3D designers and novice users indicate that IUCA is easy to use and to learn; and that users feel comfortable with it.",
        "cbStatement": "IUCA is a new technique for 3D objects manipulation. IUCA proposes to interact in a full-resolution perspective view by integrating transients animated transitions to orthographic views into the manipulation task.  \\ ",
        "bookmarks": 70,
        "keywords": [
            "3D interaction",
            "Four-views configuration",
            "3D modeling",
            "3D pointing",
            "Fitts' law"
        ],
        "communities": [],
        "video": "chi0671-file5.mp4",
        "session": {
            "id": "s251",
            "name": "3D Uis"
        },
        "room": "241",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth10964",
                "givenName": "Michael",
                "familyName": "Ortega",
                "email": "michael.ortega@imag.fr",
                "primary": {
                    "institution": "CNRS",
                    "city": "Grenoble",
                    "country": "France"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 430,
        "name": "Digital Portraits: Photo-sharing After Domestic Violence",
        "type": "paper",
        "abstract": "This paper explores the potential role of photography in re-building of lives after domestic violence. We worked in the context of a women’s centre where women are accessing support after leaving abusive relationships. The paper contributes a feminist participatory arts action research approach to studying photo-sharing practices and helps to frame an understanding of the ongoing tensions in the construction of self with others that the women experience. We argue that the affirmation of new bonds, control in sharing the process of ‘moving on’, and supporting discursive negotiations of privacy are important considerations for design focused on interpersonal social processes around the use of digital technology.",
        "cbStatement": "Taking a feminist arts action research approach, we detail an account of engaging women in photo-sharing who have had experiences of domestic violence, in the early stages of longitudinal participatory research.",
        "bookmarks": 192,
        "keywords": [
            "Photo-sharing",
            "domestic violence",
            "privacy",
            "participation",
            "feminism",
            "action research"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0673-file5.mp4",
        "session": {
            "id": "s262",
            "name": "Crime, Conflicts, and Resolution"
        },
        "room": "blue",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth20164",
                "givenName": "Rachel",
                "middleInitial": "Elizabeth",
                "familyName": "Clarke",
                "email": "r.clarke@newcastle.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth9063",
                "givenName": "Peter",
                "middleInitial": "C",
                "familyName": "Wright",
                "email": "p.c.wright@newcastle.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth8726",
                "givenName": "Madeline",
                "familyName": "Balaam",
                "email": "madeline.balaam@ncl.ac.uk",
                "primary": {
                    "dept": "Culture Lab",
                    "institution": "Newcastle University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth6215",
                "givenName": "John",
                "familyName": "McCarthy",
                "email": "john.mccarthy@ucc.ie",
                "primary": {
                    "institution": "University College Cork",
                    "city": "Cork",
                    "country": "Ireland"
                }
            }
        ]
    },
    {
        "id": 431,
        "name": "W3Touch: Metrics-based Web Page Adaptation for Touch",
        "type": "paper",
        "abstract": "Web designers currently face the increased proliferation and diversity of new touch devices which pose major challenges to the design task. This paper presents W3Touch--an interface instrumentation toolkit for web designers to collect user performance data for different device characteristics in order to help them identify potential design problems for touch interaction. Web designers can visualise the data aggregated by W3Touch and use simple metrics to automate the adaptation process for many different viewing and interaction contexts. In a series of experiments with web designers and users, we show that W3Touch is able to detect interaction problems that are hard to find using conventional methods and demonstrate how the tool was successfully used to automate the desktop-to-mobile migration of Wikipedia as an example.",
        "cbStatement": "W3Touch contributes a new method of adapting user interfaces for touch interaction, supporting automation based on usability metrics and the evidence of interaction problems on different forms of touch devices.",
        "bookmarks": 44,
        "keywords": [
            "Adaptive Interfaces",
            "Touch Interaction",
            "Usability Metrics"
        ],
        "communities": [
            "engineering"
        ],
        "video": "chi0679-file5.mp4",
        "session": {
            "id": "s222",
            "name": "Touch"
        },
        "room": "352ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth18377",
                "givenName": "Michael",
                "familyName": "Nebeling",
                "email": "nebeling@inf.ethz.ch",
                "primary": {
                    "institution": "ETH Zurich",
                    "city": "Zurich",
                    "country": "Switzerland"
                },
                "role": "presenter"
            },
            {
                "id": "auth29092",
                "givenName": "Maximilian",
                "familyName": "Speicher",
                "email": "maximilianspeicher@gmx.de",
                "primary": {
                    "institution": "ETH Zurich",
                    "city": "Zurich",
                    "country": "Switzerland"
                }
            },
            {
                "id": "auth9034",
                "givenName": "Moira",
                "familyName": "Norrie",
                "email": "norrie@inf.ethz.ch",
                "primary": {
                    "institution": "ETH Zurich",
                    "city": "Zurich",
                    "country": "Switzerland"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 432,
        "name": "Shape Switching Mobile Devices-  Explorations in Outfit-Centric Design",
        "type": "paper",
        "abstract": "We present a design exercise illustrating how fashion practices and the fashion design process can be used to create new opportunities both in the mobile domain and in product design, as well as in wearable computing. We investigate the concept of outfit-centric design by extending the support for social and visual interaction with digital devices beyond the currently available shells and stickers, and drawing on the ways in which people vary their dress ensembles. We designed a set of mock-up samples in a local fashion style, as a first step in understanding possible applications of the emerging technology of organic interfaces. Initial user feedback shows how fashion-conscious participants creatively experimented with the set’s variations of shape and color in outfits created from their personal wardrobes, which revealed the importance of the objects’ size and location on the body. It also points out that a lack of integration with the fashion system’s processes reduces the attractiveness of the samples.",
        "cbStatement": "Fashionable people will adore their mobile phones much more, when the devices organically change to a shape and colors that relate  their chosen dressed ensemble for the day. ",
        "bookmarks": 79,
        "keywords": [
            "Fashion",
            "outfit",
            "design",
            "mo¬bile interaction",
            "product de-sign",
            "wearable computing",
            "organic interface",
            "dressing"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0684-file5.mp4",
        "session": {
            "id": "s217",
            "name": "Design Ideation Methods"
        },
        "room": "342a",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth2594",
                "givenName": "Oskar",
                "familyName": "Juhlin",
                "email": "oskarj@dsv.su.se",
                "primary": {
                    "institution": "Mobile Life @ Stockholm University",
                    "city": "Kista",
                    "country": "Sweden"
                },
                "role": "presenter"
            },
            {
                "id": "auth17040",
                "givenName": "Yanqing",
                "familyName": "Zhang",
                "email": "celia@mobilelifecentre.org",
                "primary": {
                    "dept": "Mobile Life@Stockholm University",
                    "institution": "Stockholm University",
                    "city": "Stockholm",
                    "country": "Sweden"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29746",
                "givenName": "Cristine",
                "familyName": "Sundbom",
                "email": "crissy.s@gmail.com",
                "primary": {
                    "dept": "Mobile Life@KTH",
                    "institution": "KTH - Royal Institute of Technology",
                    "city": "Stockholm",
                    "country": "Sweden"
                }
            },
            {
                "id": "auth11627",
                "givenName": "Ylva",
                "familyName": "Fernaeus",
                "email": "fernaeus@kth.se",
                "primary": {
                    "dept": "Mobile Life@Stockholm University",
                    "institution": "Stockholm University",
                    "city": "Stockholm",
                    "country": "Sweden"
                }
            }
        ]
    },
    {
        "id": 433,
        "name": "Consent for All: Revealing the Hidden Complexity of Terms and Conditions",
        "type": "paper",
        "abstract": "Terms and conditions are central in acquiring user consent by service providers. Such documents are frequently highly complex and unreadable, placing doubts on the validity of so called ‘informed consent’. While readability and web accessibility have been major themes for some time in HCI, the core principles have yet to be applied beyond webpage content and are absent from the underpinning terms and conditions. Our concern is that accessible web pages will encourage consent, masking the complexities of the terms of usage. \\   \\ Using the SMOG readability formula and UK Energy services as a case study, we observed that a series of supplier terms and conditions were far beyond what a functionally literate adult could be expected to understand. We also present a browser based plug-in which compares SMOG readability scores to popular books. The intention is to use this plug-in to assist in surfacing the hidden complexities underpinning online consent.  \\ ",
        "cbStatement": "Stimulus paper and plug-in surfacing the readability of web-based terms and conditions. Highlights the role of documents in the online consent process and calls for better readability and design practice.",
        "bookmarks": 96,
        "keywords": [
            "Usability",
            "Consent",
            "Readability",
            "Literacy",
            "SMOG",
            "Energy "
        ],
        "communities": [],
        "video": "chi0686-file5",
        "session": {
            "id": "s275",
            "name": "Consent and Integrity"
        },
        "room": "251",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth29101",
                "givenName": "Ewa",
                "middleInitial": "A",
                "familyName": "Luger",
                "email": "psxel@nottingham.ac.uk",
                "primary": {
                    "dept": "Mixed Reality Lab",
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "state": "Nottinghamshire",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth28023",
                "givenName": "Stuart",
                "familyName": "Moran",
                "email": "stuart.moran@nottingham.ac.uk",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29797",
                "givenName": "Tom",
                "familyName": "Rodden",
                "email": "tom.rodden@nottingham.ac.uk",
                "primary": {
                    "dept": "create",
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 434,
        "name": "Improving Touch Accuracy on Large Tabletops Using Predecessor and Successor",
        "type": "paper",
        "abstract": "Touch interfaces provide great flexibility in designing an UI. However, the actual experience is often frustrating due to bad touch recognition. On small systems, we can analyze yaw, roll, and pitch of the finger to increase touch accuracy for a single touch. On larger systems, we need to take additional factors into account as users have more flexibility for their limb posture and need to aim over larger distances. Thus, we investigated how people perform touch sequences on those large touch surfaces. We show that the relative location of the predecessor of a touch has a significant impact on the orientation and position of the touch ellipsis. \\  \\ We exploited this effect on an off-the-shelf touch display and showed that with only minimal preparation the touch accuracy of standard hardware can be improved by at least 7%, allowing better recognition rates or more UI components on the same screen.",
        "cbStatement": "We explore how  one touch affects the location and orientation of its successor. We show how this can be used to increase touch accuracy on tabletops.",
        "bookmarks": 32,
        "keywords": [
            "touch",
            "tabletops",
            "offset",
            "accuracy",
            "sequence"
        ],
        "communities": [],
        "video": "chi0687-file5.mp4",
        "session": {
            "id": "s223",
            "name": "Table and Floors"
        },
        "room": "352ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth12734",
                "givenName": "Max",
                "familyName": "Möllers",
                "email": "max@cs.rwth-aachen.de",
                "primary": {
                    "institution": "RWTH Aachen University",
                    "city": "Aachen",
                    "state": "NRW",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth29108",
                "givenName": "Norbert",
                "familyName": "Dumont",
                "email": "norbert.dumont@rwth-aachen.de",
                "primary": {
                    "institution": "RWTH Aachen University",
                    "city": "Aachen",
                    "state": "NRW",
                    "country": "Germany"
                }
            },
            {
                "id": "auth29109",
                "givenName": "Stefan",
                "familyName": "Ladwig",
                "email": "stefan.ladwig@psych.rwth-aachen.de",
                "primary": {
                    "institution": "RWTH Aachen University",
                    "city": "Aachen",
                    "state": "NRW",
                    "country": "Germany"
                }
            },
            {
                "id": "auth1497",
                "givenName": "Jan",
                "familyName": "Borchers",
                "email": "borchers@cs.rwth-aachen.de",
                "primary": {
                    "institution": "RWTH Aachen University",
                    "city": "Aachen",
                    "state": "NRW",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 435,
        "name": "HyperSlides: Dynamic Presentation Prototyping",
        "type": "paper",
        "abstract": "Presentations are a crucial form of modern communication, yet there is a dissonance between everyday practices with presentation tools and best practices from the presentation literature. We conducted a grounded theory study to gain a better understanding of the activity of presenting, discovering the potential for a more dynamic, automated, and story-centered approach to prototyping slide presentations that are themselves dynamic in their ability to help presenters rehearse and deliver their story. Our prototype tool for dynamic presentation prototyping, which we call HyperSlides, uses a simple markup language for the creation of hierarchically structured scenes, which are algorithmically transformed into hyperlinked slides of a consistent and minimalist style. Our evaluation suggests that HyperSlides helps idea organization, saves authoring time, creates aesthetic layouts, and supports more flexible rehearsal and delivery than linear slides, at the expense of reduced layout control and increased navigation demands.",
        "cbStatement": "Motivates and evaluates the design of the HyperSlides system for dynamic prototyping of PowerPoint presentations that are themselves dynamic in their ability to help presenters rehearse and deliver their story.",
        "bookmarks": 28,
        "keywords": [
            "Presentations",
            "Slideware",
            "PowerPoint",
            "Grounded Theory"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0688-file5.mp4",
        "session": {
            "id": "s269",
            "name": "Creating and Authoring"
        },
        "room": "241",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth9574",
                "givenName": "Darren",
                "familyName": "Edge",
                "email": "darren.edge@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research Asia",
                    "city": "Beijing",
                    "state": "Beijing",
                    "country": "China"
                },
                "role": "presenter"
            },
            {
                "id": "auth29112",
                "givenName": "Joan",
                "familyName": "Savage",
                "email": "joanmariesavage@gmail.com",
                "primary": {
                    "institution": "Microsoft Research Asia",
                    "city": "Beijing",
                    "state": "Beijing",
                    "country": "China"
                },
                "secondary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                }
            },
            {
                "id": "auth9633",
                "givenName": "Koji",
                "familyName": "Yatani",
                "email": "koji@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research Asia",
                    "city": "Beijing",
                    "state": "Beijing",
                    "country": "China"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 436,
        "name": "HACHIStack: Dual-Layer Photo Touch Sensing for Haptic and Auditory Tapping Interaction",
        "type": "paper",
        "abstract": "We present a novel photo touch sensing architecture, HACHIStack. It can measure the approaching velocity of an object and predict its contact time with the touch screen using two optical sensing layers above the surface. The photo sensing layers form three unique capabilities: high-speed sampling, velocity acquisition, and contact time prediction. This work quantitatively examines these capabilities through two laboratory experiments, and confirms that the capabilities of HACHIStack are sufficient for multimodal interaction, in particular, touch-based interaction with haptic enhancement. We then present three applications with HACHIStack: 1) chromatic percussions (xylophone and glockenspiel) with haptic feedback; 2) no-delay haptic feedback with the sensation of tapping on various simulated materials (e.g., rubber, wood and aluminum); and 3) a virtual piano instrument that allows players to perform weak and strong strokes by changing the tapping velocity.",
        "cbStatement": "Extends photo touch sensor architecture that can measure the approaching velocity and predict its contact time with the surface. Demonstrates its applications including no-delay haptic feedback for tapping interaction.",
        "bookmarks": 142,
        "keywords": [
            "Approaching velocity",
            "HACHIStack",
            "Multimodal interaction",
            "Touch sensor"
        ],
        "communities": [
            "engineering"
        ],
        "video": "chi0701-file5.mp4",
        "session": {
            "id": "s225",
            "name": "Touch, Tangibles, Touch Sensor"
        },
        "room": "352ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth21019",
                "givenName": "Taku",
                "familyName": "Hachisu",
                "email": "hachisu@kaji-lab.jp",
                "primary": {
                    "dept": "The University of Electro-communications/Kajimoto-Lab",
                    "institution": "University",
                    "city": "Choufu",
                    "state": "Choufugaoka",
                    "country": "Japan"
                },
                "secondary": {
                    "institution": "JSPS Research Fellow",
                    "city": "Tokyo",
                    "country": "Japan"
                },
                "role": "presenter"
            },
            {
                "id": "auth14647",
                "givenName": "Hiroyuki",
                "familyName": "Kajimoto",
                "email": "kajimoto@kaji-lab.jp",
                "primary": {
                    "dept": "The University of Electro-communications/Kajimoto-Lab",
                    "institution": "University",
                    "city": "Choufu",
                    "state": "Choufugaoka",
                    "country": "Japan"
                },
                "secondary": {
                    "institution": "Japan Science and Technology Agency",
                    "city": "Tokyo",
                    "country": "Japan"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 437,
        "name": "SpatialEase: Learning Language through Body Motion",
        "type": "paper",
        "abstract": "Games that engage both mind and body by targeting users’ kinesthetic intelligence have the potential to transform the activity of learning across a wide variety of domains. To investigate this potential in the context of second language learning, we have developed SpatialEase: a Kinect game for the body-based learning of language that is grounded in space and motion. In this game, learners respond to audio commands in the second language by moving their bodies in space, while a game mechanic based on distributed cued-recall supports learning over time. Our comparison of SpatialEase with the popular Rosetta Stone software for learner of Mandarin Chinese showed similar learning gains over a single session and generated several key implications for the future design of mixed-modality learning systems.",
        "cbStatement": "Motivates and evaluates the design of the SpatialEase system for the kinesthetic learning of second language constructions grounded in space and motion, leading to implications for mixed-modality learning games.",
        "bookmarks": 27,
        "keywords": [
            "Embodied gaming",
            "Kinesthetic learning",
            "Language learning"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0702-file5.mp4",
        "session": {
            "id": "s238",
            "name": "Playing with Body"
        },
        "room": "242b",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth9574",
                "givenName": "Darren",
                "familyName": "Edge",
                "email": "darren.edge@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research Asia",
                    "city": "Beijing",
                    "state": "Beijing",
                    "country": "China"
                },
                "role": "presenter"
            },
            {
                "id": "auth28194",
                "givenName": "Kai-Yin",
                "familyName": "Cheng",
                "email": "keynes.z@gmail.com",
                "primary": {
                    "institution": "Microsoft Research Asia",
                    "city": "Beijing",
                    "state": "Beijing",
                    "country": "China"
                },
                "secondary": {
                    "institution": "National Taiwan University",
                    "city": "Taipei",
                    "country": "Taiwan"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth19838",
                "givenName": "Michael",
                "familyName": "Whitney",
                "email": "mwhitne6@uncc.edu",
                "primary": {
                    "institution": "Microsoft Research Asia",
                    "city": "Beijing",
                    "state": "Beijing",
                    "country": "China"
                },
                "secondary": {
                    "institution": "University of North Carolina at Charlotte",
                    "city": "Charlotte",
                    "state": "North Carolina",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 438,
        "name": "The Emotional Wellbeing of Researchers: Considerations for Practice",
        "type": "paper",
        "abstract": "As technology progressively pervades all aspects of our lives, members of the HCI community are engaging with increasingly sensitive contexts in their research – for example, end of life, genocide, computer-mediated communication under oppressive regimes. The considerations generated by research in such contexts can go well beyond those addressed by generic ethical approval processes and institutional practice. Whilst it is standard to ensure that the wellbeing of participants is taken into account in research design and the ethical approval process, it is much less common for the researcher’s own emotional wellbeing to be considered explicitly. This paper describes the role that a researcher’s emotions may play in research, and the impact which research in sensitive contexts can have on researchers’ emotional wellbeing and on research validity. A qualitative survey is described which investigated the support mechanisms which HCI researchers have in place in case they are distressed/ troubled as a result of their research. The results of the survey are used, in combination with insights into how other disciplines address the topic, to synthesize suggestions for ways in which the HCI community can proactively incorporate consideration for the emotional wellbeing of the researcher into the research process.",
        "cbStatement": "We consider the impact which research in sensitive contexts can have on researchers’ emotional wellbeing and on research validity, and ways to incorporate consideration for researchers’ wellbeing into research plans.",
        "bookmarks": 160,
        "keywords": [
            "Methodology",
            "reflection",
            "ethics",
            "research governance",
            "validity",
            "participatory design",
            "qualitative research",
            "emotion",
            "End of Life",
            "thanatosensitive design."
        ],
        "communities": [
            "design",
            "ux",
            "health",
            "hci4d"
        ],
        "session": {
            "id": "s278",
            "name": "HCI Ethics"
        },
        "room": "351",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth9400",
                "givenName": "Wendy",
                "familyName": "Moncur",
                "email": "wmoncur@dundee.ac.uk",
                "primary": {
                    "dept": "School of Computing",
                    "institution": "University of Dundee",
                    "city": "Dundee",
                    "country": "United Kingdom"
                },
                "secondary": {
                    "institution": "University of Bath",
                    "city": "Bath",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 439,
        "name": "Using Fake Cursors to Secure On-Screen Password Entry",
        "type": "paper",
        "abstract": "In this paper, we present a concept using fake cursors to disguise on-screen password entry. We performed two user studies with different amounts of dummy cursors and differently colored cursors. The results show that dummy cursors significantly improve security. At the same time, decrease in performance is kept within an acceptable range. Depending on the required degree of security, the studies favor 8 or 16 differently colored cursors as the best trade-off between security and usability.",
        "cbStatement": "Presents a system that uses fake cursors to secure password entry on on-screen keyboards. An evaluation of the system shows that shoulder surfing resistance is significantly improved.",
        "bookmarks": 172,
        "keywords": [
            "Ninja Cursors",
            "Authentication",
            "Security"
        ],
        "communities": [],
        "video": "chi0705-file5.mp4",
        "session": {
            "id": "s276",
            "name": "Authentication"
        },
        "room": "251",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth8064",
                "givenName": "Alexander",
                "familyName": "De Luca",
                "email": "alexander.de.luca@ifi.lmu.de",
                "primary": {
                    "dept": "Media Informatics Group",
                    "institution": "University of Munich (LMU)",
                    "city": "Munich",
                    "state": "Bavaria",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth16502",
                "givenName": "Emanuel",
                "familyName": "von Zezschwitz",
                "email": "emanuel.von.zezschwitz@ifi.lmu.de",
                "primary": {
                    "dept": "Media Informatics Group",
                    "institution": "University of Munich (LMU)",
                    "city": "Munich",
                    "state": "Bavaria",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29125",
                "givenName": "Laurent",
                "familyName": "Pichler",
                "email": "pichlerl@cip.ifi.lmu.de",
                "primary": {
                    "dept": "Media Informatics Group",
                    "institution": "University of Munich (LMU)",
                    "city": "Munich",
                    "state": "Bavaria",
                    "country": "Germany"
                }
            },
            {
                "id": "auth9993",
                "givenName": "Heinrich",
                "familyName": "Hussmann",
                "email": "hussmann@ifi.lmu.de",
                "primary": {
                    "dept": "Media Informatics Group",
                    "institution": "University of Munich (LMU)",
                    "city": "Munich",
                    "state": "Bavaria",
                    "country": "Germany"
                }
            }
        ]
    },
    {
        "id": 440,
        "name": "Back-of-Device Authentication on Smartphones",
        "type": "paper",
        "abstract": "This paper presents BoD Shapes, a novel authentication method for smartphones that uses the back of the device for input. We argue that this increases the resistance to shoulder surfing while remaining reasonably fast and easy-to-use. We performed a user study (n=24) comparing BoD Shapes to PIN authentication, Android grid unlock, and a front version of our system. Testing a front version allowed us to directly compare performance and security measures between front and back authentication. Our results show that BoD Shapes is significantly more secure than the three other approaches. While performance declined, our results show that BoD Shapes can be very fast (up to 1.5 seconds in the user study) and that learning effects have an influence on its performance. This indicates that speed improvements can be expected in long-term use.",
        "cbStatement": "Presents a system that uses gestures on the back of a mobile device to authenticate. Shoulder surfing resistance is significantly improved while remaining reasonably fast and easy to use.",
        "bookmarks": 178,
        "keywords": [
            "Back of device interaction",
            "Authentication",
            "Security"
        ],
        "communities": [],
        "video": "chi0708-file5.mp4",
        "session": {
            "id": "s276",
            "name": "Authentication"
        },
        "room": "251",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth8064",
                "givenName": "Alexander",
                "familyName": "De Luca",
                "email": "alexander.de.luca@ifi.lmu.de",
                "primary": {
                    "dept": "Media Informatics Group",
                    "institution": "University of Munich (LMU)",
                    "city": "Munich",
                    "state": "Bavaria",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth16502",
                "givenName": "Emanuel",
                "familyName": "von Zezschwitz",
                "email": "emanuel.von.zezschwitz@ifi.lmu.de",
                "primary": {
                    "dept": "Media Informatics Group",
                    "institution": "University of Munich (LMU)",
                    "city": "Munich",
                    "state": "Bavaria",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth29010",
                "givenName": "Ngo Dieu Huong",
                "familyName": "Nguyen",
                "email": "ngodieuhuong.nguyen@gmail.com",
                "primary": {
                    "dept": "Media Informatics Group",
                    "institution": "University of Munich (LMU)",
                    "city": "Munich",
                    "state": "Bavaria",
                    "country": "Germany"
                }
            },
            {
                "id": "auth16799",
                "givenName": "Max-Emanuel",
                "familyName": "Maurer",
                "email": "max.maurer@ifi.lmu.de",
                "primary": {
                    "dept": "Media Informatics Group",
                    "institution": "University of Munich (LMU)",
                    "city": "Munich",
                    "state": "Bavaria",
                    "country": "Germany"
                }
            },
            {
                "id": "auth13332",
                "givenName": "Elisa",
                "familyName": "Rubegni",
                "email": "elisa.rubegni@usi.ch",
                "primary": {
                    "institution": "University of Lugano",
                    "city": "Lugano",
                    "country": "Switzerland"
                }
            },
            {
                "id": "auth29153",
                "givenName": "Marcello Paolo",
                "familyName": "Scipioni",
                "email": "marcello.paolo.scipioni@usi.ch",
                "primary": {
                    "dept": "Faculty of Informatics",
                    "institution": "University of Lugano",
                    "city": "Lugano",
                    "country": "Switzerland"
                }
            },
            {
                "id": "auth6506",
                "givenName": "Marc",
                "familyName": "Langheinrich",
                "email": "marc.langheinrich@usi.ch",
                "primary": {
                    "institution": "University of Lugano",
                    "city": "Lugano",
                    "state": "TI",
                    "country": "Switzerland"
                }
            }
        ]
    },
    {
        "id": 441,
        "name": "Critical Perspective on Persuasive Technology Reconsidered",
        "type": "paper",
        "abstract": "Critical researchers in HCI have recently faulted Persuasive Technology (PT) for taking a modernist approach and suggested ways for redirecting research. This paper reflects on this critical perspective and compares it with Habermas’s critical perspective. I claim that the recent critiques of PT are grounded on a narrow and pessimistic concept of modernism, and that Habermas’s works, rarely taken into account in the HCI community, can serve as an alternative lens for reflective analysis and design and can provide a foundation for justifying design decisions while realizing the unfulfilled potentials of PT. Beyond offering critical analysis and reflections, this paper contributes to the HCI field by calling attention to alternative reflective concepts and emerging relevant works. ",
        "cbStatement": "This paper reflects on the critical perspective on persuasive technology and offers an alternative perspective. It contributes to the HCI field by calling attention to alternative reflective concepts and emerging relevant works. ",
        "bookmarks": 83,
        "keywords": [
            "Persuasive Technology",
            "Reflective HCI",
            "Critical Research",
            "Critical Reflection",
            "Modernism"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0718-file5.mp4",
        "session": {
            "id": "s272",
            "name": "Different Perspectives"
        },
        "room": "241",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth11321",
                "givenName": "Fahri",
                "familyName": "Yetim",
                "email": "fahri.yetim@oulu.fi",
                "primary": {
                    "institution": "University of Oulu",
                    "city": "Oulu",
                    "country": "Finland"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 442,
        "name": "Designing for the Living Room: Long-Term User Involvement in a Living Lab",
        "type": "paper",
        "abstract": "Living Labs provide a research infrastructure for long-term user involvement in Participatory Design processes. Users take part in software co-creation during context analysis, for concept development, reflecting on early-stage prototypes and evaluations in the field. In this paper we describe lessons learned from our Living Lab in the area of home entertainment, with 27 participants from 16 households, over a 2.5 year period. We show that this kind of long-term participation of users involves various challenges over the lifetime of the project. We highlight several aspects that need to be considered carefully when setting up such a Living Lab, concerning the selection of participants, maintenance of participants’ motivation, establishment of a trust relationship, and the coordination of collaboration.",
        "cbStatement": "We present lessons learned from a 2.5 year period of a Living Lab project and discuss aspects that need to be considered when setting up such a research framework.",
        "bookmarks": 46,
        "keywords": [
            "Living Lab",
            "participatory design",
            "long-term user study",
            "domestic domain"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi0720-file5.mp4",
        "session": {
            "id": "s216",
            "name": "Design and Time: Long-term User Involvment and temporal themes"
        },
        "room": "havane",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth18249",
                "givenName": "Corinna",
                "familyName": "Ogonowski",
                "email": "corinna.ogonowski@uni-siegen.de",
                "primary": {
                    "dept": "Institute for Information Systems",
                    "institution": "University of Siegen",
                    "city": "Siegen",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth19219",
                "givenName": "Benedikt",
                "familyName": "Ley",
                "email": "benedikt.ley@uni-siegen.de",
                "primary": {
                    "institution": "University of Siegen",
                    "city": "Siegen",
                    "state": "NRW",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth9677",
                "givenName": "Jan",
                "familyName": "Hess",
                "email": "jan.hess@uni-siegen.de",
                "primary": {
                    "institution": "University of Siegen",
                    "city": "Siegen",
                    "state": "NRW",
                    "country": "Germany"
                }
            },
            {
                "id": "auth16112",
                "givenName": "Lin",
                "familyName": "Wan",
                "email": "lin.wan@uni-siegen.de",
                "primary": {
                    "institution": "University of Siegen",
                    "city": "Siegen",
                    "country": "Germany"
                }
            },
            {
                "id": "auth1678",
                "givenName": "Volker",
                "familyName": "Wulf",
                "email": "volker.wulf@uni-siegen.de",
                "primary": {
                    "institution": "University of Siegen",
                    "city": "Siegen",
                    "country": "Germany"
                }
            }
        ]
    },
    {
        "id": 443,
        "name": "Bending the Rules: Bend Gesture Classification for Flexible Displays",
        "type": "paper",
        "abstract": "Bend gestures have a large number of degrees of freedom and therefore offer a rich interaction language. We propose a classification scheme for bend gestures, and explore how users perform these bend gestures along four classification criterion: location, direction, size, and angle. We collected 36 unique bend gestures performed three times by each participant. The results suggest a strong agreement among participants for preferences of location and direction. Size and angle were difficult for users to differentiate. Finally, users performed and perceived two distinct levels of magnitude. We propose recommendations for designing bend gestures with flexible displays. ",
        "cbStatement": "We propose a bend gesture classification scheme and we evaluate how users naturally perform bend gestures on deformable displays with minimal instruction.",
        "bookmarks": 169,
        "keywords": [
            "Deformable User Interface",
            "Flexible Display",
            "Affordance",
            "Bend Gesture",
            "Organic User Interface"
        ],
        "communities": [],
        "video": "chi0722-file5.mp4",
        "session": {
            "id": "s229",
            "name": "Bendable, Flexible"
        },
        "room": "352ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth34608",
                "givenName": "Kristen",
                "familyName": "Warren",
                "email": "kristen_mitchell@carleton.ca",
                "primary": {
                    "institution": "Carleton University",
                    "city": "Ottawa",
                    "state": "Ontario",
                    "country": "Canada"
                }
            },
            {
                "id": "auth32903",
                "givenName": "Jessica",
                "familyName": "Lo",
                "email": "jessica_lo@carleton.ca",
                "primary": {
                    "institution": "Carleton University",
                    "city": "Ottawa",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth32544",
                "givenName": "Vaibhav",
                "familyName": "Vadgama",
                "email": "vaibhav_vadgama@carleton.ca",
                "primary": {
                    "institution": "Carleton University",
                    "city": "Ottawa",
                    "state": "Ontario",
                    "country": "Canada"
                }
            },
            {
                "id": "auth7465",
                "givenName": "Audrey",
                "familyName": "Girouard",
                "email": "audrey_girouard@carleton.ca",
                "primary": {
                    "institution": "Carleton University",
                    "city": "Ottawa",
                    "state": "Ontario",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 444,
        "name": "Kolibri – Tiny and Fast Gestures for Large Pen-based Surfaces",
        "type": "paper",
        "abstract": "Triggering commands on large interactive surfaces is less efficient than on desktop PCs. It requires either large physical movements to reach an interaction area (e.g., buttons) or additional operations to call context menus (e.g., dwell). There is a lack of efficient ways to trigger shortcuts. We introduce Kolibri - a pen-based gesture system that allows fast access of commands on interactive whiteboards. Users can draw tiny gestures (approx. 3 mm) anywhere on the surface to trigger commands without interfering with normal inking. This approach does neither require entering a gesture mode, nor dedicated gesture areas. The implementation relies on off-the-shelf hardware only. We tested the feasibility and explored the properties of this technique with several studies. The results from a controlled experiment show significant benefits of Kolibri comparing to an existing approach.",
        "cbStatement": "We introduce Kolibri - a pen-based gesture system that brings shortcuts to interactive white-boards. Users can draw tiny gestures anywhere on the surface without interfering with normal inking.",
        "bookmarks": 93,
        "keywords": [
            "Large interactive interfaces",
            "pen-input",
            "whiteboard application",
            "small gestures",
            "shortcuts",
            "fluid inking."
        ],
        "communities": [
            "design"
        ],
        "video": "chi0733-file5.mp4",
        "authors": [
            {
                "id": "auth11537",
                "givenName": "Jakob",
                "middleInitial": "F.",
                "familyName": "Leitner",
                "email": "jakob.leitner@fh-hagenberg.at",
                "primary": {
                    "dept": "Media Interaction Lab",
                    "institution": "University of Applied Sciences Upper Austria",
                    "city": "Hagenberg",
                    "country": "Austria"
                },
                "role": "presenter"
            },
            {
                "id": "auth22277",
                "givenName": "Florian",
                "familyName": "Perteneder",
                "email": "florian.perteneder@fh-hagenberg.at",
                "primary": {
                    "dept": "Media Interaction Lab",
                    "institution": "University of Applied Sciences Upper Austria",
                    "city": "Hagenberg",
                    "country": "Austria"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth17706",
                "givenName": "Can",
                "familyName": "Liu",
                "email": "can.liu@fh-hagenberg.at",
                "primary": {
                    "dept": "Media Interaction Lab",
                    "institution": "University of Applied Sciences Upper Austria",
                    "city": "Hagenberg",
                    "country": "Austria"
                }
            },
            {
                "id": "auth22423",
                "givenName": "Christian",
                "familyName": "Rendl",
                "email": "christian.rendl@fh-hagenberg.at",
                "primary": {
                    "dept": "Media Interaction Lab",
                    "institution": "University of Applied Sciences Upper Austria",
                    "city": "Hagenberg",
                    "country": "Austria"
                }
            },
            {
                "id": "auth3937",
                "givenName": "Michael",
                "familyName": "Haller",
                "email": "haller@fh-hagenberg.at",
                "primary": {
                    "dept": "Media Interaction Lab",
                    "institution": "University of Applied Sciences Upper Austria",
                    "city": "Hagenberg",
                    "country": "Austria"
                },
                "secondary": {
                    "dept": "Media Interaction Lab",
                    "institution": "University of Applied Sciences Upper Austria",
                    "city": "Hagenberg",
                    "country": "Austria"
                }
            }
        ]
    },
    {
        "id": 445,
        "name": "Phoneprioception: Enabling Mobile Phones to Infer Where They Are Kept",
        "type": "paper",
        "abstract": "Enabling phones to infer whether they are currently in a pocket, purse or on a table facilitates a range of new inter-actions from placement-dependent notifications setting to preventing “pocket dialing.” We collected data from 693 participants to understand where people keep their phone in different contexts and why. Using this data, we identified three placement personas: Single Place Pat, Consistent Ca-sey, and All-over Alex. Based on these results, we collected two weeks of labeled accelerometer data in-situ from 32 participants. We used this data to build models for inferring phone placement, achieving an accuracy of approximately 85% for inferring whether the phone is in an enclosed loca-tion and for inferring if the phone is on the user. Finally, we prototyped a capacitive grid and a multispectral sensor and collected data from 15 participants in a laboratory to under-stand the added value of these sensors.",
        "cbStatement": "We examined where people keep their phones through interviews and an ESM study and demonstrate that reasonably accurate classifications are possible with industry-standard sensors, improved by several other low-cost sensors.",
        "bookmarks": 121,
        "keywords": [
            "Context awareness",
            "mobile sensors",
            "phone placement"
        ],
        "communities": [],
        "video": "chi0739-file5.mp4",
        "session": {
            "id": "s241",
            "name": "Mobile 1: Mobile Phones: pricing, Emotions, looks, and positioning"
        },
        "room": "241",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth14264",
                "givenName": "Jason",
                "middleInitial": "W",
                "familyName": "Wiese",
                "email": "jwwiese@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth6085",
                "givenName": "T. Scott",
                "familyName": "Saponas",
                "email": "ssaponas@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1511",
                "givenName": "A.J.",
                "middleInitial": "Bernheim",
                "familyName": "Brush",
                "email": "ajbrush@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Redmond",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 446,
        "name": "FlashTouch: Data Communication through Touchscreens",
        "type": "paper",
        "abstract": "FlashTouch is a new technology that enables data communication between touchscreen-based mobile devices and digital peripheral devices. Touchscreen can be used as communication media using visible light and capacitive touch. In this paper, we designed a stylus prototype to describe the concept of FlashTouch. With this prototype, users can easily transfer data from one mobile device to another. It eliminates the complexity associated with data sharing among mobile users, which is currently achieved by online data sharing services or wireless connections for data sharing that need a pairing operation to establish connections between devices. Therefore, it can prove to be of particular significance to people who are not adept at current software services and hardware functions. Finally, we demonstrate the valuable applications in online settlements via mobile device, and data communication for mobile robots.",
        "cbStatement": "FlashTouch is a new technology that enables data communication between touchscreen-based mobile devices and digital peripheral devices using visible light and capacitive touch.",
        "bookmarks": 97,
        "keywords": [
            "Touchscreen based communication",
            "mobile",
            "stylus",
            "data sharing",
            "tangible."
        ],
        "communities": [
            "engineering",
            "ux"
        ],
        "video": "chi0758-file5.mp4",
        "session": {
            "id": "s222",
            "name": "Touch"
        },
        "room": "352ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth22801",
                "givenName": "Masa",
                "familyName": "Ogata",
                "email": "ogatite@gmail.com",
                "primary": {
                    "dept": "Graduate School of Science and Technology",
                    "institution": "Keio University",
                    "city": "Yokohama City",
                    "state": "Kanagawa",
                    "country": "Japan"
                },
                "role": "presenter"
            },
            {
                "id": "auth13921",
                "givenName": "Yuta",
                "familyName": "Sugiura",
                "email": "yuta.sugiura@gmail.com",
                "primary": {
                    "institution": "Keio University",
                    "city": "Yokohama City",
                    "state": "Kanagawa",
                    "country": "Japan"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth11498",
                "givenName": "Hirotaka",
                "familyName": "Osawa",
                "email": "hiro.osa@gmail.com",
                "primary": {
                    "institution": "Keio University",
                    "city": "Yokohama City",
                    "state": "Kanagawa",
                    "country": "Japan"
                }
            },
            {
                "id": "auth7194",
                "givenName": "Michita",
                "familyName": "Imai",
                "email": "michita@ayu.ics.keio.ac.jp",
                "primary": {
                    "institution": "Keio University",
                    "city": "Yokohama City",
                    "state": "Kanagawa",
                    "country": "Japan"
                }
            }
        ]
    },
    {
        "id": 447,
        "name": "Evaluation of Alternative Glyph Designs for Time Series Data in a Small Multiple Setting",
        "type": "paper",
        "abstract": "We present the results of a controlled experiment to investigate the performance of different temporal glyph designs in a small multiple setting. \\ Analyzing many time series at once is a common yet difficult task in many domains, for example in network monitoring. Several visualization techniques have, thus, been proposed in the literature. \\ Among these, iconic displays or glyphs are an appropriate choice  \\ because of their expressiveness and effective use of screen space. \\ Through a controlled experiment, we compare the performance of four glyphs that use different combinations of visual variables to encode two properties of temporal data: a) the position of a data point in time and b) the quantitative value of this data point.  \\ Our results show that depending on tasks and data density, the chosen glyphs performed differently. Line Glyphs are generally a good choice for peak and trend detection tasks but radial encodings are more effective for reading values at specific temporal locations. From our qualitative analysis we also contribute implications for designing temporal glyphs for small multiple settings.",
        "cbStatement": "1. Evaluation of alternative glyph designs for time series data. \\ 2. Design considerations and guidelines for creating glyphs for time series data. ",
        "bookmarks": 31,
        "keywords": [
            "Glyphs",
            "time series",
            "evaluation",
            "small multiples",
            "information visualization"
        ],
        "communities": [],
        "video": "chi0765-file5.mp4",
        "session": {
            "id": "s231",
            "name": "Visualization 1"
        },
        "room": "bordeaux",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth29121",
                "givenName": "Johannes",
                "familyName": "Fuchs",
                "email": "fuchs@dbvis.inf.uni-konstanz.de",
                "primary": {
                    "dept": "University of Konstanz",
                    "institution": "University",
                    "city": "Konstanz",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth29195",
                "givenName": "Fabian",
                "familyName": "Fischer",
                "email": "fabian.fischer@uni-konstanz.de",
                "primary": {
                    "institution": "University",
                    "city": "Konstanz",
                    "country": "Germany"
                }
            },
            {
                "id": "auth14997",
                "givenName": "Florian",
                "familyName": "Mansmann",
                "email": "Florian.Mansmann@uni-konstanz.de",
                "primary": {
                    "dept": "University of Konstanz",
                    "institution": "University",
                    "city": "Konstanz",
                    "country": "Germany"
                }
            },
            {
                "id": "auth34624",
                "givenName": "Enrico",
                "familyName": "Bertini",
                "email": "ebertini@poly.edu",
                "primary": {
                    "institution": "University",
                    "city": "New York",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth5951",
                "givenName": "Petra",
                "familyName": "Isenberg",
                "email": "petra.isenberg@inria.fr",
                "primary": {
                    "dept": "Saclay",
                    "institution": "INRIA",
                    "city": "Orsay",
                    "country": "France"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 448,
        "name": "Improving Navigation-Based File Retrieval",
        "type": "paper",
        "abstract": "Navigating through a file hierarchy is one of the most common methods for accessing files, yet it can be slow and repetitive. New algorithms that predict upcoming file accesses have the potential to improve navigation-based file retrieval, but it is unknown how best to present their  predictions to users. We present three design goals aiming to  improve navigation-based file retrieval interfaces: minimise the time spent at each hierarchical level en route to the target file; reduce the number of levels traversed by providing shortcuts; and promote rehearsal of the retrieval mechanics to facilitate expertise. We introduce three interfaces that augment  standard file browsers based on each of these goals: Icon Highlights give greater prominence to predicted items in the current folder; Hover Menus provide shortcuts to predicted folder content; and Search Directed Navigation uses predictive highlighting to guide users through the hierarchy in response to query terms. Results from a user evaluation show that all three interfaces improve file retrieval times, with Icon Highlights and Hover Menus best suited for frequently accessed items and Search Directed Navigation best suited for infrequent ones. We also show that the benefits are larger when folder content is spatially unstable. Finally, we discuss how the interfaces  could be combined and deployed in existing file browsers.",
        "cbStatement": "Introduces three interfaces to improve navigation-based file retrieval. Empirical studies show they are subjectively preferred and decrease retrieval times for both new and revisited items.",
        "bookmarks": 76,
        "keywords": [
            "Revisitation",
            "prediction",
            "file retrieval",
            "file navigation"
        ],
        "communities": [],
        "video": "chi0769-file5.mp4",
        "session": {
            "id": "s268",
            "name": "Navigating Data"
        },
        "room": "blue",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth22450",
                "givenName": "Stephen",
                "familyName": "Fitchett",
                "email": "stephen.fitchett@pg.canterbury.ac.nz",
                "primary": {
                    "institution": "University of Canterbury",
                    "city": "Christchurch",
                    "country": "New Zealand"
                },
                "role": "presenter"
            },
            {
                "id": "auth1057",
                "givenName": "Andy",
                "familyName": "Cockburn",
                "email": "andy@cosc.canterbury.ac.nz",
                "primary": {
                    "institution": "University of Canterbury",
                    "city": "Christchurch",
                    "country": "New Zealand"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1181",
                "givenName": "Carl",
                "familyName": "Gutwin",
                "email": "gutwin@cs.usask.ca",
                "primary": {
                    "institution": "University of Saskatchewan",
                    "city": "Saskatoon",
                    "state": "Saskatchewan",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 449,
        "name": "Individual User Characteristics and Information Visualization: Connecting the Dots through Eye Tracking",
        "type": "paper",
        "abstract": "There is increasing evidence that users’ characteristics such as cognitive abilities and personality have an impact on the effectiveness of information visualization techniques. This paper investigates the relationship between such characteristics and fine-grained user attention patterns. In particular, we present results from an eye tracking user study involving bar graphs and radar graphs, showing that a user’s cognitive abilities such as perceptual speed and verbal working memory have a significant impact on gaze behavior, both in general and in relation to task difficulty and visualization type. These results are discussed in view of our long-term goal of designing information visualisation systems that can dynamically adapt to individual user characteristics.",
        "cbStatement": "We present results from an eye tracking user study, showing that a user’s cognitive abilities have a significant impact on gaze behavior when performing common information visualization tasks.",
        "bookmarks": 61,
        "keywords": [
            "Adaptive Information Visualization",
            "Eye-tracking",
            "Adaptation",
            "Machine Learning"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi0782-file5.mp4",
        "session": {
            "id": "s235",
            "name": "Gaze"
        },
        "room": "bordeaux",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth22698",
                "givenName": "Dereck",
                "middleInitial": "J",
                "familyName": "Toker",
                "email": "dtoker@cs.ubc.ca",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of British Columbia",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth3704",
                "givenName": "Cristina",
                "familyName": "Conati",
                "email": "conati@cs.ubc.ca",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of British Columbia",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            },
            {
                "id": "auth30179",
                "givenName": "Ben",
                "familyName": "Steichen",
                "email": "steichen@cs.ubc.ca",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of British Columbia",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth13759",
                "givenName": "Giuseppe",
                "familyName": "Carenini",
                "email": "carenini@cs.ubc.ca",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of British Columbia",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 450,
        "name": "Evaluation of Tablet Apps to Encourage Social Interaction in Children with Autism Spectrum Disorders",
        "type": "paper",
        "abstract": "The increasing rates of diagnosis for Autism Spectrum Disorders (ASDs) have brought unprecedented attention to these conditions. Interventions during childhood can increase the likelihood of independent living later in life, but most adults with ASDs who benefited from early intervention do not live independently. There is a need for novel therapies and interventions that can help children with ASDs develop the social skills necessary to live independently. Since the launch of the iPad, there has been a great deal of excitement in the autism community about multitouch tablets and their possible use in interventions. There are hundreds of apps listed as possibly helping children with ASDs, yet there is little empirical evidence that any of them have positive effects. In this paper we present a study on the use of a set of apps from Open Autism Software at an afterschool program for children with ASDs. The apps are designed to naturally encourage positive social interactions through creative, expressive, and collaborative activities. The study compared activities conducted with the apps to similar activities conducted without the apps. We video recorded the activities, and coded children’s behavior. We found that during the study children spoke more sentences, had more verbal interactions, and were more physically engaged with the activities when using the apps. We also found that children made more supportive comments during activities conducted with two of the apps. The results suggest the approach to using apps evaluated in this paper can increase positive social interactions in children with ASDs.",
        "cbStatement": "Comparison of app-based and paper-based activities by children with autism spectrum disorders. Using the apps was associated with increased verbal communication, physical interaction, and supportive comments.",
        "bookmarks": 118,
        "keywords": [
            "Autism",
            "app",
            "tablet",
            "social skills."
        ],
        "communities": [
            "cci"
        ],
        "video": "chi0790-file5.mp4",
        "session": {
            "id": "s293",
            "name": "Autism"
        },
        "room": "blue",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth1924",
                "givenName": "Juan Pablo",
                "familyName": "Hourcade",
                "email": "hourcade@cs.uiowa.edu",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Iowa",
                    "city": "Iowa City",
                    "state": "Iowa",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth29203",
                "givenName": "Stacy",
                "middleInitial": "R",
                "familyName": "Williams",
                "email": "stacy-williams@uiowa.edu",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Iowa",
                    "city": "Iowa City",
                    "state": "Iowa",
                    "country": "United States"
                }
            },
            {
                "id": "auth29204",
                "givenName": "Ellen",
                "middleInitial": "A",
                "familyName": "Miller",
                "email": "ellen-a-miller@uiowa.edu",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Iowa",
                    "city": "Iowa City",
                    "state": "Iowa",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth34611",
                "givenName": "Kelsey",
                "middleInitial": "E",
                "familyName": "Huebner",
                "email": "kelsey.klora@gmail.com",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Iowa",
                    "city": "Iowa City",
                    "state": "Iowa",
                    "country": "United States"
                }
            },
            {
                "id": "auth29205",
                "givenName": "Lucas",
                "middleInitial": "J",
                "familyName": "Liang",
                "email": "liangl99@gmail.com",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Iowa",
                    "city": "Iowa City",
                    "state": "Iowa",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 451,
        "name": "A Study on Icon Arrangement by Smartphone Users",
        "type": "paper",
        "abstract": "The number of available mobile applications is steadily increasing. People have rapidly adopted application stores as means to customize their devices with various functionalities that go beyond communication. Understanding the principles of mobile application usage is crucial for supporting users within this new ecosystem. In this paper, we investigate how people organize applications they have installed on their devices. We asked more than 130 participants for their habits for icon arrangement and collected more than 1,400 screenshots of their devices' menus to further ground our findings. Based on this data we can distinguish five different concepts for arranging icons on smartphone menus, e.g. based on application usage frequency and applications' functional relatedness. Additionally, we investigated how these concepts emerge in relation to frequency of application installations, removals and icon rearrangements, as well as users' experience levels. Finally we discuss implications for the design of smartphone launchers, and highlight differences to icon arrangement on stationary computers.",
        "cbStatement": "This paper studies peoples' arrangements of icons in smartphone menus. From 1,400+ menu screenshots we distill five fundamental concepts for arranging icons. Implications are useful for designing mobile launcher menus.",
        "bookmarks": 80,
        "keywords": [
            "Mobile applications",
            "icon arrangement",
            "user behavior."
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi0803-file5.mp4",
        "session": {
            "id": "s248",
            "name": "Mobiles and more"
        },
        "room": "havane",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth20803",
                "givenName": "Matthias",
                "familyName": "Böhmer",
                "email": "matthias.boehmer@dfki.de",
                "primary": {
                    "institution": "German Research Center for Artificial Intelligence (DFKI)",
                    "city": "Saarbrücken",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth6436",
                "givenName": "Antonio",
                "familyName": "Krüger",
                "email": "krueger@dfki.de",
                "primary": {
                    "institution": "German Research Center for Artificial Intelligence (DFKI)",
                    "city": "Saarbrücken",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 452,
        "name": "Fragmentation and Transition: Understanding Perceptions of Virtual Possessions among Young Adults in Spain, South Korea and the United States",
        "type": "paper",
        "abstract": "People worldwide are increasingly acquiring collections of virtual possessions. While virtual possessions have become ubiquitous, little work exists on how people value and form attachments to these things. To investigate, we conducted a study with 48 young adults from South Korea, Spain and the United States. The study probed on participants’ perceived value of their virtual possessions as compared to their material things, and the comparative similarities and differences across cultures. Findings show that young adults live in unfinished spaces and that they often experience a sense of fragmentation when trying to integrate their virtual possessions into their lives. These findings point to several design opportunities, such as tools for life story-oriented archiving, and insights on better forms of Cloud storage.",
        "cbStatement": "Contributes an investigation of young adults' value construction practices with their virtual possessions in South Korea, Spain and the United States and proposes design opportunities in this emerging design space.",
        "bookmarks": 161,
        "keywords": [
            "Virtual Possessions",
            "Young Adults",
            "Interactive Systems Design",
            "Digital Things",
            "Human-Centered Architectures"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi0805-file5.mp4",
        "session": {
            "id": "s244",
            "name": "Studies of the Use of Digital Artifacts"
        },
        "room": "342a",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth8702",
                "givenName": "William",
                "familyName": "Odom",
                "email": "wodom@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1917",
                "givenName": "John",
                "familyName": "Zimmerman",
                "email": "johnz@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1028",
                "givenName": "Jodi",
                "familyName": "Forlizzi",
                "email": "forlizzi@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth28903",
                "givenName": "Ana",
                "familyName": "López Higuera",
                "email": "analopezgr@gmail.com",
                "primary": {
                    "dept": "Cognitive Ergonomics Group - Faculty of Psychology",
                    "institution": "University of Granada",
                    "city": "Granada",
                    "state": "Granada",
                    "country": "Spain"
                }
            },
            {
                "id": "auth28832",
                "givenName": "Mauro",
                "familyName": "Marchitto",
                "email": "maurom@correo.ugr.es",
                "primary": {
                    "dept": "Cognitive Ergonomics Group - Faculty of Psychology",
                    "institution": "University of Granada",
                    "city": "Granada",
                    "country": "Spain"
                }
            },
            {
                "id": "auth28894",
                "givenName": "José",
                "familyName": "Cañas",
                "email": "delagado@ugr.es",
                "primary": {
                    "dept": "Cognitive Ergonomics Group-Faculty of Psychology",
                    "institution": "University of Granada",
                    "city": "Granada",
                    "country": "Spain"
                }
            },
            {
                "id": "auth4583",
                "givenName": "Youn-kyung",
                "familyName": "Lim",
                "email": "younlim@kaist.ac.kr",
                "primary": {
                    "dept": "Department of Industrial Design",
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "state": "Chung-Cheong Nam do",
                    "country": "Republic of Korea"
                }
            },
            {
                "id": "auth2587",
                "givenName": "Tek-Jin",
                "familyName": "Nam",
                "email": "tjnam@kaist.ac.kr",
                "primary": {
                    "dept": "Department of Industrial Design",
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "state": "Chung-Cheong Nam do",
                    "country": "Republic of Korea"
                }
            },
            {
                "id": "auth16083",
                "givenName": "Da-jung",
                "familyName": "Kim",
                "email": "jung1118@kaist.ac.kr",
                "primary": {
                    "dept": "Department of Industrial Design",
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                }
            },
            {
                "id": "auth16466",
                "givenName": "Moon-Hwan",
                "familyName": "Lee",
                "email": "munani86@kaist.ac.kr",
                "primary": {
                    "dept": "Industrial design",
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                }
            },
            {
                "id": "auth17788",
                "givenName": "Yeoreum",
                "familyName": "Lee",
                "email": "skyreum@kaist.ac.kr",
                "primary": {
                    "institution": "Department of Industrial Design, KAIST",
                    "city": "Daejeon, ",
                    "country": "Korea, Republic of"
                }
            },
            {
                "id": "auth25877",
                "givenName": "Yea-kyung",
                "familyName": "Row",
                "email": "emilie0225@kaist.ac.kr",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                }
            },
            {
                "id": "auth25230",
                "givenName": "Jinmin",
                "familyName": "Seok",
                "email": "yes_iamjm@kaist.ac.kr",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                }
            },
            {
                "id": "auth27760",
                "givenName": "Bokyung",
                "familyName": "Sohn",
                "email": "bk308@kaist.ac.kr",
                "primary": {
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "country": "Republic of Korea"
                }
            },
            {
                "id": "auth28740",
                "givenName": "Heather",
                "familyName": "Moore",
                "email": "heather.moore@vodafone.com",
                "primary": {
                    "dept": "Research & Development",
                    "institution": "Vodafone Group Services",
                    "city": "Duesseldorf",
                    "country": "Germany"
                }
            }
        ]
    },
    {
        "id": 453,
        "name": "The Design and Field Observation of a Haptic Notification System for Timing Awareness During Oral Presentations",
        "type": "paper",
        "abstract": "To moderate oral presentations a chair must manage time, and communicate time parameters to speakers through a variety of means. But speakers often miss time cues, chairs cannot confirm their receipt, and the broken dialogue can be a sideshow for the audience. We developed HaNS, a wireless wrist-worn chair-speaker Haptic Notification System that delivers tactile cues for time-managing oral presentations, and performed field observations at university research seminars and two mid-sized academic conferences (input from 66 speakers, 21 chairs, and 65 audience members). Results indicate that HaNS can improve a user’s awareness of time, facilitate chair-speaker coordination, and reduce distraction of speaker and audience through its private communication channel. Eliminating overruns will require improvement in speaker ‘internal’ control, which our results suggest HaNS can also support given practice. We conclude with design guidelines for both conference-deployed and personal timing tools, using touch or another notification modality.",
        "cbStatement": "A novel presentation timing approach (automated tactile cues augment chair-speaker communication) is explored with iterative design and observation in live conference settings. Qualitative evaluation generates stakeholder needs and design recommendations.",
        "bookmarks": 114,
        "keywords": [
            "Oral presentation",
            "field study",
            "vibrotactile",
            "wearable haptics"
        ],
        "communities": [
            "design",
            "engineering",
            "ux"
        ],
        "video": "chi0806-file5.mp4",
        "session": {
            "id": "s228",
            "name": "Tactile Presentation Theory"
        },
        "room": "blue",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth22439",
                "givenName": "Diane",
                "familyName": "Tam",
                "email": "diane.tam@gmail.com",
                "primary": {
                    "institution": "University of British Columbia",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth2152",
                "givenName": "Karon",
                "middleInitial": "E.",
                "familyName": "MacLean",
                "email": "maclean@cs.ubc.ca",
                "primary": {
                    "institution": "University of British Columbia",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1428",
                "givenName": "Joanna",
                "familyName": "McGrenere",
                "email": "joanna@cs.ubc.ca",
                "primary": {
                    "institution": "University of British Columbia",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            },
            {
                "id": "auth28460",
                "givenName": "Katherine",
                "middleInitial": "J.",
                "familyName": "Kuchenbecker",
                "email": "kuchenbe@seas.upenn.edu",
                "primary": {
                    "institution": "University of Pennsylvania",
                    "city": "Philadelphia",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 454,
        "name": "Augmented Endurance: Controlling Fatigue while Handling Objects by Affecting Weight Perception using Augmented Reality",
        "type": "paper",
        "abstract": "The main contribution of this paper is to develop a method for alleviating fatigue during handling medium-weight objects and augmenting our endurance by affecting our weight perception with augmented reality technology.  \\ To assist people to lift medium-weight objects without a complex structure or various costs, we focus on the phenomenon that our weight perception during handling objects is affected by visual properties.  \\ Our hypothesis is that this illusionary effect in weight perception can be applied to reduce fatigue while handling medium-weight objects without mechatronics-based physical assistance. \\  \\ In this paper, we propose an augmented reality system that changes the brightness value of an object in order to reduce fatigue while handling the object.  \\ We conducted two fundamental experiments to investigate the effectiveness of the proposed system.  \\ Our results suggested that the system eliminates the need to use excess energy for handling objects and reduces fatigue during the handling task.",
        "cbStatement": "\"Augmented Endurance\" reveals the implicit effect of augmented reality on our perception of weight and realizes a method to utilize it for human interfaces.",
        "bookmarks": 18,
        "keywords": [
            "Cross-modal Interaction",
            "Augmented Reality",
            "Weight Perception",
            "Assistance for Physical Work"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0813-file5.mp4",
        "session": {
            "id": "s296",
            "name": "Content, Creation, and Health"
        },
        "room": "242ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth29217",
                "givenName": "Yuki",
                "familyName": "Ban",
                "email": "ban@cyber.t.u-tokyo.ac.jp",
                "primary": {
                    "institution": "The University of Tokyo",
                    "city": "Tokyo",
                    "country": "Japan"
                },
                "role": "presenter"
            },
            {
                "id": "auth10762",
                "givenName": "Takuji",
                "familyName": "Narumi",
                "email": "narumi@cyber.t.u-tokyo.ac.jp",
                "primary": {
                    "institution": "The University of Tokyo",
                    "city": "Tokyo",
                    "country": "Japan"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29961",
                "givenName": "Tatsuya",
                "familyName": "Fujii",
                "email": "fujii@cyber.t.u-tokyo.ac.jp",
                "primary": {
                    "institution": "The University of Tokyo",
                    "city": "Tokyo",
                    "country": "Japan"
                }
            },
            {
                "id": "auth23858",
                "givenName": "Sho",
                "familyName": "Sakurai",
                "email": "sho@cyber.t.u-tokyo.ac.jp",
                "primary": {
                    "dept": "Graduate School of Engineering",
                    "institution": "The University of Tokyo",
                    "city": "Tokyo",
                    "state": "Tokyo",
                    "country": "Japan"
                }
            },
            {
                "id": "auth29962",
                "givenName": "Jun",
                "familyName": "Imura",
                "email": "imura@cyber.t.u-tokyo.ac.jp",
                "primary": {
                    "institution": "The University of Tokyo",
                    "city": "Tokyo",
                    "country": "Japan"
                }
            },
            {
                "id": "auth18220",
                "givenName": "Tomohiro",
                "familyName": "Tanikawa",
                "email": "tani@cyber.t.u-tokyo.ac.jp",
                "primary": {
                    "institution": "The University of Tokyo",
                    "city": "Tokyo",
                    "country": "Japan"
                }
            },
            {
                "id": "auth14758",
                "givenName": "Michitaka",
                "familyName": "Hirose",
                "email": "hirose@cyber.rcast.u-tokyo.ac.jp",
                "primary": {
                    "institution": "The University of Tokyo",
                    "city": "Bunkyo-ku",
                    "country": "Japan"
                }
            }
        ]
    },
    {
        "id": 455,
        "name": "Tweeting for Class: Co-Construction as a Means for Engaging Students in Lectures",
        "type": "paper",
        "abstract": "Motivating students to be active learners is a perennial problem in education, and is particularly challenging in lectures where instructors typically prepare content in ad-vance with little direct student participation. We describe our experience using Twitter as a tool for student “co-construction” of lecture materials. Students were required to post a tweet prior to each lecture related to that day’s topic, and these tweets – consisting of questions, examples and reflections – were incorporated into the lecture slides and notes.  Students reported that they found lectures including their tweets in the class slides to be engaging, interactive and relevant, and nearly 90% of them recommended we use our co-construction approach again.",
        "cbStatement": "We present a case study of students in a lecture course using Twitter to contribute instructional content. Results show that students enjoyed this and primarily contributed examples and asked questions.",
        "bookmarks": 21,
        "keywords": [
            "Education",
            "Twitter",
            "Engagement",
            "Lecture",
            "Co-construction."
        ],
        "communities": [],
        "video": "chi0815-file5.mp4",
        "session": {
            "id": "s286",
            "name": "Design for the Classroom"
        },
        "room": "251",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth29499",
                "givenName": "Jeremy",
                "familyName": "Birnholtz",
                "email": "jeremyb@northwestern.edu",
                "primary": {
                    "institution": "Northwestern University",
                    "city": "Evanston",
                    "state": "Illinois",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth2114",
                "givenName": "Jeff",
                "middleInitial": "T",
                "familyName": "Hancock",
                "email": "jth34@cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth17441",
                "givenName": "Daniela",
                "familyName": "Retelny",
                "email": "dretelny12@me.com",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 456,
        "name": "I am What I Eat: Identity & Critical Thinking in an Online Health Forum for Kids",
        "type": "paper",
        "abstract": "As kids encounter food advertisements, it is important that they be able to critically evaluate the message’s claims, the healthiness of the promoted product and their desire for it. To explore how technology might help kids develop these skills, we created an online forum called TalkBack that encourages children to critically analyze the messaging in food ads and their attitudes towards marketed foods. We evaluated TalkBack with twenty-eight middle school students in a summer camp program. We discuss how participants appeared to project and protect their sense of self through their interaction with TalkBack. We also describe the limited analytic depth of their forum contributions and suggest directions for HCI research that attempts to encourage critical thinking and health promotion in adolescents.",
        "cbStatement": "We discuss the design and evaluation of an online forum—TalkBack—that encourages children to critically analyze the messaging in food advertisements and their attitudes towards marketed foods. ",
        "bookmarks": 44,
        "keywords": [
            "CSCW",
            "health",
            "nutrition",
            "kids",
            "identity",
            "online community"
        ],
        "communities": [
            "health"
        ],
        "session": {
            "id": "s263",
            "name": "Food"
        },
        "room": "351",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth34756",
                "givenName": "Andrea",
                "middleInitial": "Grimes",
                "familyName": "Parker",
                "email": "a.parker@neu.edu",
                "primary": {
                    "dept": "College of Computer & Information Science",
                    "institution": "Northeastern University",
                    "city": "Boston",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "secondary": {
                    "dept": "Bouvé College of Health Sciences",
                    "institution": "Northeastern University",
                    "city": "Boston",
                    "state": "Massachusetts",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth29915",
                "givenName": "Ian",
                "familyName": "McClendon",
                "email": "imcclendon@gatech.edu",
                "primary": {
                    "dept": "School of Interactive Computing, GVU Center",
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            },
            {
                "id": "auth27833",
                "givenName": "Catherine",
                "familyName": "Grevet",
                "email": "cgrevet@gatech.edu",
                "primary": {
                    "dept": "School of Interactive Computing, GVU Center",
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            },
            {
                "id": "auth29916",
                "givenName": "Victoria",
                "familyName": "Ayo",
                "email": "vayo3@gatech.edu",
                "primary": {
                    "dept": "School of Interactive Computing, GVU Center",
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            },
            {
                "id": "auth29917",
                "givenName": "WonTaek",
                "familyName": "Chung",
                "email": "wchung8@gatech.edu",
                "primary": {
                    "dept": "School of Interactive Computing, GVU Center",
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            },
            {
                "id": "auth34757",
                "givenName": "Veda",
                "familyName": "Johnson",
                "email": "vjohn01@emory.edu",
                "primary": {
                    "dept": "Department of Pediatrics",
                    "institution": "Emory University",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            },
            {
                "id": "auth1040",
                "givenName": "Elizabeth",
                "middleInitial": "D",
                "familyName": "Mynatt",
                "email": "mynatt@cc.gatech.edu",
                "primary": {
                    "dept": "School of Interactive Computing, GVU Center",
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 457,
        "name": "I See You There! Developing Identity-Preserving Embodied Interaction for Museum Exhibits",
        "type": "paper",
        "abstract": "Museums are increasingly embracing technologies that provide highly-individualized and highly-interactive experiences to visitors. With embodied interaction experiences, increased localization accuracy supports greater nuance in interaction design, but there is usually a tradeoff between fast, accurate tracking and the ability to preserve the identity of users. Customization of experience relies on the ability to detect the identity of visitors, however. We present a method that combines fine-grained indoor tracking with robust preservation of the unique identities of multiple users. Our model merges input from an RFID reader with input from a commercial camera-based tracking system. We developed a probabilistic Bayesian model to infer at run-time the correct identification of the subjects in the camera’s field of view. This method, tested in a lab and at a local museum, requires minimal modification to the exhibition space, while addressing several identity-preservation problems for which many indoor tracking systems do not have robust solutions. ",
        "cbStatement": "Describes a system that merges input from RFID and Kinect using a probabilistic model: combines fine-grained tracking with identity preservation, supporting the design of personalized embodied interaction for museum exhibits",
        "bookmarks": 102,
        "keywords": [
            "Localization",
            "Identification",
            "Tracking",
            "Ambient Displays",
            "RFID",
            "Cameras",
            "Embodied Interaction",
            "Museum Exhibits"
        ],
        "communities": [],
        "video": "chi0830-file5.mp4",
        "session": {
            "id": "s237",
            "name": "Bodies Matter"
        },
        "room": "bordeaux",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth24483",
                "givenName": "Francesco",
                "familyName": "Cafaro",
                "email": "fcafar2@uic.edu",
                "primary": {
                    "institution": "University of Illinois at Chicago",
                    "city": "Chicago",
                    "state": "Illinois",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth29225",
                "givenName": "Alessandro",
                "familyName": "Panella",
                "email": "apanel2@uic.edu",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Illinois at Chicago",
                    "city": "Chicago",
                    "state": "Illinois",
                    "country": "United States"
                }
            },
            {
                "id": "auth6900",
                "givenName": "Leilah",
                "middleInitial": "B.",
                "familyName": "Lyons",
                "email": "llyons@uic.edu",
                "primary": {
                    "institution": "University of Illinois at Chicago",
                    "city": "Chicago",
                    "state": "Illinois",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30391",
                "givenName": "Jessica",
                "familyName": "Roberts",
                "email": "jrober31@uic.edu",
                "primary": {
                    "institution": "University of Illinois at Chicago",
                    "city": "Chicago",
                    "state": "Illinois",
                    "country": "United States"
                }
            },
            {
                "id": "auth29226",
                "givenName": "Josh",
                "familyName": "Radinsky",
                "email": "joshuar@uic.edu",
                "primary": {
                    "institution": "University of Illinois at Chicago",
                    "city": "Chicago",
                    "state": "Illinois",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 458,
        "name": "A Value Sensitive Action-Reflection Model: Evolving a Co-Design Space with Stakeholder and Designer Prompts",
        "type": "paper",
        "abstract": "We introduce a design method for evolving a co-design space to support stakeholders untrained in design. Specifically, the purpose of the method is to expand and shape a co-design space so that stakeholders, acting as designers, focus not only on the form and function of a tool being envisioned but also on the social context of its use and values that lie with individuals, groups, and societies. The method introduces value sensitive stakeholder prompts and designer prompts into a co-design process, creating a particular kind of reflection-on-action cycle. The prompts provide a means for bringing empirical data on values and theoretical perspective into the co-design process. We present the method in terms of a general model, the Value Sensitive Action-Reflection Model; place the model within discourse on co-design spaces; and illustrate the model with a discussion of its application in a lo-fi prototyping activity around safety for homeless young people. We conclude with reflections on the model and method.",
        "cbStatement": "We introduce the Value Sensitive Action-Reflection Model: a co-design method focus on the social context of use and values that lie with individuals, groups, and societies.",
        "bookmarks": 138,
        "keywords": [
            "Co-design",
            "creativity",
            "design method",
            "Envisioning Cards",
            "homeless young people",
            "mobile technologies",
            "prototyping",
            "reflection-on-action",
            "safety",
            "security",
            "Value Sensitive Action-Reflection Model",
            "value scenarios",
            "value sensitive design"
        ],
        "communities": [
            "design"
        ],
        "session": {
            "id": "s245",
            "name": "Co-Design: involving propspective users in design"
        },
        "room": "351",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth14093",
                "givenName": "Daisy",
                "familyName": "Yoo",
                "email": "dyoo@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth34653",
                "givenName": "Alina",
                "familyName": "Huldtgren",
                "email": "alina@huldtgren.com",
                "primary": {
                    "institution": "Delft University of Technology",
                    "city": "Delft",
                    "country": "The Netherlands"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth21547",
                "givenName": "Jill",
                "middleInitial": "Palzkill",
                "familyName": "Woelfer",
                "email": "woelfj@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth3907",
                "givenName": "David",
                "middleInitial": "G",
                "familyName": "Hendry",
                "email": "dhendry@u.washington.edu",
                "primary": {
                    "institution": "University of Washington ",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth1585",
                "givenName": "Batya",
                "familyName": "Friedman",
                "email": "batya@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 459,
        "name": "Probing Bus Stop for Insights on Transit Co-design",
        "type": "paper",
        "abstract": "Social computing provides a new way for citizens to engage with their public service. Our research investigates how social computing might support citizens co-design their transit service. We conducted a field study with public transit riders, exploring the issues and controversies that reveal conflicting communities. Our analyses revealed three insights. First, encourage citizens to share what they see as the rationale for current service offerings. Second, encourage citizens to share the consequences of current services and of proposed changes and new designs. Third, focus on producing a shared citizen and service provider understanding of what the goals and mission of the public service should be.",
        "cbStatement": "We investigate how social computing might support citizens co-design their transit service. We conducted a field study with public transit riders, exploring the issues and controversies that reveal conflicting communities.",
        "bookmarks": 162,
        "keywords": [
            "Co-design",
            "service design",
            "transit",
            "public service",
            "social computing",
            "political design",
            "contestational design",
            "eGovernment"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "session": {
            "id": "s245",
            "name": "Co-Design: involving propspective users in design"
        },
        "room": "351",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth14093",
                "givenName": "Daisy",
                "familyName": "Yoo",
                "email": "dyoo@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1917",
                "givenName": "John",
                "familyName": "Zimmerman",
                "email": "johnz@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth4305",
                "givenName": "Tad",
                "familyName": "Hirsch",
                "email": "thirsch@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 460,
        "name": "Echoes From the Past: How Technology Mediated Reflection Improves Well-Being",
        "type": "paper",
        "abstract": "As people document more of their lives online, some recent systems are encouraging people to later revisit those recordings, a practice we’re calling technology-mediated reflection (TMR). Since we know that unmediated reflection benefits psychological well-being, we explored whether and how TMR affects well-being. We built Echo, a smartphone application for recording everyday experiences and reflecting on them later. We conducted three system deployments with 44 users who generated over 12,000 recordings and reflections. We found that TMR improves well-being as assessed by four psychological metrics. By analyzing the content of these entries we discovered two mechanisms that explain this improvement. We also report benefits of very long-term TMR.",
        "cbStatement": "We explored technology mediated reminiscence (TMR) by building Echo, a novel smartphone application for recording and reflecting on everyday experiences. Three deployments with 44 users show TMR improves well-being.",
        "bookmarks": 34,
        "keywords": [
            "Memory",
            "well-being",
            "reflection",
            "recording",
            "technology mediated reflection"
        ],
        "communities": [
            "design",
            "engineering",
            "ux",
            "health"
        ],
        "video": "chi0857-file5.mp4",
        "session": {
            "id": "s290",
            "name": "Technologies for Life 2"
        },
        "room": "242ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth1129",
                "givenName": "Ellen",
                "familyName": "Isaacs",
                "email": "ellen@izix.com",
                "primary": {
                    "institution": "Palo Alto Research Center (PARC)",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth29242",
                "givenName": "Artie",
                "familyName": "Konrad",
                "email": "akonrad@ucsc.edu",
                "primary": {
                    "dept": "HCI Lab",
                    "institution": "University of California, Santa Cruz",
                    "city": "Santa Cruz",
                    "state": "California",
                    "country": "Santa Cruz"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth34676",
                "givenName": "Alan",
                "familyName": "Walendowski",
                "email": "walendo@bitsmith.com",
                "primary": {
                    "dept": "UX Innovations",
                    "institution": "Samsung Research America",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth34677",
                "givenName": "Thomas",
                "familyName": "Lennig",
                "email": "tlennig@ucsc.edu",
                "primary": {
                    "dept": "HCI Lab",
                    "institution": "University of California at Santa Cruz ",
                    "city": "Santa Cruz",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth30706",
                "givenName": "Victoria",
                "familyName": "Hollis",
                "email": "vhollis@ucsc.edu",
                "primary": {
                    "dept": "HCI Lab",
                    "institution": "University of California at Santa Cruz ",
                    "city": "Santa Cruz",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth13221",
                "givenName": "Steve",
                "familyName": "Whittaker",
                "email": "swhittak@ucsc.edu",
                "primary": {
                    "dept": "HCI Lab",
                    "institution": "University of California at Santa Cruz",
                    "city": "Santa Cruz",
                    "state": "California",
                    "country": "USA"
                }
            }
        ]
    },
    {
        "id": 461,
        "name": "Reifying Social Movement Trajectories",
        "type": "paper",
        "abstract": "In this paper we describe the development of a novel paper-digital \\ interface for recording movement trajectories, designed to \\ assist ethnographers and ethologists in analysis of social \\ movement. While we focus on development of a system to aid analysis of \\ elephant movement, the resulting interaction techniques and facilities \\ are quite general. The paper highlights how our design evolved to \\ balance the goals of researchers, their current practices, and the challenges of \\ integrating the relatively unconstrained world of pen and paper with \\ the relatively constrained world of digital systems.",
        "cbStatement": "We describe the development of a novel paper-digital interface for recording movement trajectories, designed to assist ethnographers and ethologists in analysis of social \\ movement.",
        "bookmarks": 33,
        "keywords": [
            "Paper-Digital Interfaces;Digital Ethnography;Ethology"
        ],
        "communities": [],
        "video": "chi0858-file5.mp4",
        "session": {
            "id": "s280",
            "name": "Evaluation Methods 2"
        },
        "room": "351",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth13506",
                "givenName": "Adam",
                "familyName": "Fouse",
                "email": "afouse@cogsci.ucsd.edu",
                "primary": {
                    "institution": "University of California, San Diego",
                    "city": "La Jolla",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth7764",
                "givenName": "Nadir",
                "familyName": "Weibel",
                "email": "weibel@ucsd.edu",
                "primary": {
                    "institution": "University of California, San Diego",
                    "city": "La Jolla",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30238",
                "givenName": "Christine",
                "familyName": "Johnson",
                "email": "johnson@cogsci.ucsd.edu",
                "primary": {
                    "institution": "University of California, San Diego",
                    "city": "La Jolla",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth3038",
                "givenName": "James",
                "middleInitial": "D.",
                "familyName": "Hollan",
                "email": "hollan@cogsci.ucsd.edu",
                "primary": {
                    "institution": "University of California, San Diego",
                    "city": "La Jolla",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 462,
        "name": "How Groups of Users Associate Wireless Devices",
        "type": "paper",
        "abstract": "Group association, the process of connecting a group of devices, opens up new opportunities for users to spontaneously share resources. Research has shown numerous techniques and protocols for group association; however, what people intuitively do to associate a group of devices remains an open question. We contribute a study of eliciting device association techniques from groups of non-technical people. In all, we collected and analysed 496 techniques from 61 participants. Our results show that mobility and physicality of devices influence how people perceive groups association. We present a complete set of user-defined techniques with subjective ratings and popularity scores. We examined people's rationale and the effects of different device form factors. We analysed the techniques based on the roles that users assume with respect to device association. Our findings draw out insights from the perspective of users for design of group association.",
        "cbStatement": "Presents a guessability study of eliciting device association techniques from groups of non-technical users. Can inform designers of how people conceptualise device association in group scenarios.",
        "bookmarks": 150,
        "keywords": [
            "Spontaneous Interaction",
            "Pairing",
            "Device Association",
            "Input Techniques",
            "Wireless",
            "Guessability Study",
            "Group"
        ],
        "communities": [],
        "video": "chi0867-file5.mp4",
        "authors": [
            {
                "id": "auth16255",
                "givenName": "Ming Ki",
                "familyName": "Chong",
                "email": "mingki@acm.org",
                "primary": {
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth5955",
                "givenName": "Hans",
                "middleInitial": "W",
                "familyName": "Gellersen",
                "email": "hwg@comp.lancs.ac.uk",
                "primary": {
                    "institution": "Lancaster University",
                    "city": "Lancaster",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 463,
        "name": "The Many Faces of Facebook: Experiencing Social Media as Performance, Exhibition, and Personal Archive",
        "type": "paper",
        "abstract": "The growing use of social media means that an increasing amount of people’s lives are visible online. We draw from Goffman’s theatrical metaphor and Hogan’s exhibition ap-proach to explore how people manage their personal collec-tion of social media data over time. We conducted a quali-tative study of 13 participants to reveal their day-to-day decision-making about producing and curating digital traces on Facebook. Their goals and strategies showed that people experience the Facebook platform as consisting of three different functional regions: a performance region for man-aging recent data and impression management, an exhibi-tion region for longer term presentation of self-image, and a personal region for archiving meaningful facets of life. Further, users’ need for presenting and archiving data in these three regions is mediated by temporality. These find-ings trigger a discussion of how to design social media that support these dynamic and sometimes conflicting needs.",
        "cbStatement": "We bring new perspectives to the design of social media by drawing from Goffman’s theatrical metaphor and Hogan’s exhibition approach to explore how people manage social media data over time. ",
        "bookmarks": 146,
        "keywords": [
            "Reminiscing",
            "personal archives",
            "curation",
            "identity",
            "exhibition"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi0883-file5.mp4",
        "session": {
            "id": "s205",
            "name": "Look how popular I am: managing social media platforms"
        },
        "room": "blue",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth16348",
                "givenName": "Xuan",
                "familyName": "Zhao",
                "email": "xz298@cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30400",
                "givenName": "Niloufar",
                "familyName": "Salehi",
                "email": "nsalehi@ce.sharif.edu",
                "primary": {
                    "dept": "Computer Engineering Department",
                    "institution": "Sharif University of Technology",
                    "city": "Tehran",
                    "country": "Iran, Islamic Republic of"
                }
            },
            {
                "id": "auth30401",
                "givenName": "Sasha",
                "familyName": "Naranjit",
                "email": "shn22@cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth30402",
                "givenName": "Sara",
                "familyName": "Alwaalan",
                "email": "Sara.waalan@gmail.com",
                "primary": {
                    "institution": "King Saud University",
                    "city": "Riyadh",
                    "country": "Saudi Arabia"
                }
            },
            {
                "id": "auth1380",
                "givenName": "Stephen",
                "familyName": "Voida",
                "email": "svoida@cornell.edu",
                "primary": {
                    "dept": "Information Science",
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "NY",
                    "country": "United States"
                }
            },
            {
                "id": "auth2110",
                "givenName": "Dan",
                "familyName": "Cosley",
                "email": "drc44@cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "New York",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 464,
        "name": "uTouch: Sensing Touch Gestures on Unmodified LCDs",
        "type": "paper",
        "abstract": "Current solutions for enabling touch interaction on existing non-touch LCD screens require adding additional sensors to the interaction surface. We present uTouch, a system that detects and classifies touches and hovers without any modification to the display, and without adding any sensors to the user. Our approach utilizes existing signals in an LCD that are amplified when a user brings their hand near or touches the LCD’s front panel. These signals are coupled onto the power lines, where they appear as electromagnetic interference (EMI) which can be sensed using a single device connected elsewhere on the power line infrastructure. We validate our approach with an 11 user, 8 LCD study, and demonstrate a real-time system.",
        "cbStatement": "We developed a system that allows any LCD or LED monitors to be converted into a touch sensitive surface without instrunmenting the user or installing the sensors on the monitor.",
        "bookmarks": 106,
        "keywords": [
            "LCD",
            "touch",
            "capacitive sensing",
            "EMI"
        ],
        "communities": [
            "engineering"
        ],
        "video": "chi0886-file5.mp4",
        "session": {
            "id": "s226",
            "name": "Haptics"
        },
        "room": "352ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth27363",
                "givenName": "Ke-Yu",
                "familyName": "Chen",
                "email": "kychen@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "WA",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth16033",
                "givenName": "Gabe",
                "middleInitial": "A",
                "familyName": "Cohn",
                "email": "gabecohn@uw.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth15958",
                "givenName": "Sidhant",
                "familyName": "Gupta",
                "email": "sidhant@cs.washington.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth4536",
                "givenName": "Shwetak",
                "middleInitial": "N",
                "familyName": "Patel",
                "email": "shwetak@cs.washington.edu",
                "primary": {
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 465,
        "name": "TOBY: Early Intervention in Autism through Technology",
        "type": "paper",
        "abstract": "We describe TOBY Playpad, an early intervention program for children with Autism Spectrum Disorder (ASD). TOBY teaches the teacher -- the parent -- during the crucial period following diagnosis, which often coincides with no access to formal therapy. We reflect on TOBY's evolution from table-top aid for flashcards to an iPad app covering a syllabus of 326 activities across 51 skills known to be deficient for ASD children, such imitation, joint attention and language. The design challenges unique to TOBY are the need to adapt to marked differences in each child's skills and rate of development (a trait of ASD) and teach parents unfamiliar concepts core to behavioural therapy, such as reinforcement, prompting, and fading. We report on three trials that successively decrease oversight and increase parental autonomy, and demonstrate clear evidence of learning. TOBY's uniquely intertwined Natural Environment Tasks are found to be effective for children and popular with parents.",
        "cbStatement": "We describe an innovative iPad application for early intervention in autism named TOBY (Therapy Outcome By You). Field trials results are also presented to validate the framework.",
        "bookmarks": 95,
        "keywords": [
            "Autism",
            "early intervention",
            "therapy",
            "wait-list",
            "TOBY"
        ],
        "communities": [
            "design",
            "ux",
            "health",
            "cci"
        ],
        "video": "chi0888-file5.mp4",
        "session": {
            "id": "s293",
            "name": "Autism"
        },
        "room": "blue",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth29715",
                "givenName": "Svetha",
                "familyName": "Venkatesh",
                "email": "svetha.venkatesh@deakin.edu.au",
                "primary": {
                    "dept": "Centre for Pattern Recognition and Data Analytics",
                    "institution": "Deakin University",
                    "city": "Geelong",
                    "state": "Victoria",
                    "country": "Australia"
                },
                "role": "presenter"
            },
            {
                "id": "auth29716",
                "givenName": "Stewart",
                "familyName": "Greenhill",
                "email": "s.greenhill@curtin.edu.au",
                "primary": {
                    "dept": "Department of Computing, Curtin University",
                    "institution": "Curtin University",
                    "city": "Perth",
                    "state": "Western Australia",
                    "country": "Australia"
                }
            },
            {
                "id": "auth29265",
                "givenName": "Dinh",
                "middleInitial": "Q",
                "familyName": "Phung",
                "email": "dinh.phung@deakin.edu.au",
                "primary": {
                    "dept": "Faculty of Science and Technology",
                    "institution": "Deakin University",
                    "city": "Geelong",
                    "state": "Victoria",
                    "country": "Australia"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29717",
                "givenName": "Thi",
                "familyName": "Duong",
                "email": "thi.duong@deakin.edu.au",
                "primary": {
                    "dept": "Centre for Pattern Recognition and Data Analytics",
                    "institution": "Deakin University",
                    "city": "Geelong",
                    "state": "Victoria",
                    "country": "Australia"
                }
            },
            {
                "id": "auth14652",
                "givenName": "Brett",
                "familyName": "Adams",
                "email": "b.adams@curtin.edu.au",
                "primary": {
                    "dept": "Department of Computing",
                    "institution": "Curtin University",
                    "city": "Perth",
                    "state": "Western Australia",
                    "country": "Australia"
                }
            }
        ]
    },
    {
        "id": 466,
        "name": "Materials, Materiality, and Media",
        "type": "paper",
        "abstract": "In HCI, and especially in interaction design, the material aspect of interactions is currently emphasized. Nevertheless, it is challenging to theoretically frame the variety of digital or immaterial, and physical materials. In order to contribute to this materiality discourse, we reflect on McLuhan’s work on media analysis and on Latour’s Actor-Network Theory in this paper. Both emphasize the active role of the material – be it media or any other kind of non-human actors – in the interplay with the human. Thus, we establish junctures between their findings and materials, as used in interaction design in HCI. We discuss McLuhan’s claim to focus on new sensory effects and ways of interaction brought forth by new media. Furthermore, we illustrate how describing the connections between materials, designers, and users in terms of Latour’s Actor-Networks can be beneficial for interaction design. Finally, we discuss the respective methodology and its relation to research through design.",
        "cbStatement": "Reflects on Marshall McLuhan’s media analysis, as well as Bruno Latour’s Actor-Network Theory regarding materials in HCI interaction design. Presents transferred ideas and junctures for the materiality discourse. ",
        "bookmarks": 196,
        "keywords": [
            "Actor-network theory",
            "design",
            "materiality",
            "materials",
            "media theory"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0895-file5.mp4",
        "session": {
            "id": "s240",
            "name": "Hedonism, narrative, materiality & Media (This that and the other)"
        },
        "room": "342a",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth24356",
                "givenName": "Verena",
                "familyName": "Fuchsberger",
                "email": "verena.fuchsberger@sbg.ac.at",
                "primary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                },
                "role": "presenter"
            },
            {
                "id": "auth16954",
                "givenName": "Martin",
                "familyName": "Murer",
                "email": "martin.murer@sbg.ac.at",
                "primary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth3460",
                "givenName": "Manfred",
                "familyName": "Tscheligi",
                "email": "manfred.tscheligi@sbg.ac.at",
                "primary": {
                    "institution": "University of Salzburg",
                    "city": "Salzburg",
                    "country": "Austria"
                }
            }
        ]
    },
    {
        "id": 467,
        "name": "Studying Spatial Memory and Map Navigation Performance on Projector Phones with Peephole Interaction",
        "type": "paper",
        "abstract": "Smartphones are useful personal assistants and omnipresent communication devices. However, collaboration is not among their strengths. With the advent of embedded projectors this might change. We conducted a study with 56 participants to find out if map navigation and spatial memory performance among users and observers can be improved by using a projector phone with a peephole interface instead of a smartphone with its touchscreen interface. Our results show that users performed map navigation equally well on both interfaces. Spatial memory performance, however, was 41% better for projector phone users. Moreover, observers of the map navigation on the projector phone were 25% more accurate when asked to recall locations of points of interest after they watched a user performing map navigation.",
        "cbStatement": "Uses a map navigation task and compares users’ navigation performance with touch screen interaction to peephole interaction, users’ location recall performance, and observers’ location recall performance.",
        "bookmarks": 83,
        "keywords": [
            "Map navigation",
            "spatial memory",
            "peephole interaction",
            "touch interaction",
            "handheld projector"
        ],
        "communities": [
            "ux"
        ],
        "video": "chi0900-file5.mp4",
        "session": {
            "id": "s211",
            "name": "Designs on Design 1: Exploring Design Approaches and Constructs"
        },
        "room": "bordeaux",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth14504",
                "givenName": "Bonifaz",
                "familyName": "Kaufmann",
                "email": "bonifaz.kaufmann@aau.at",
                "primary": {
                    "institution": "Alpen-Adria Universität Klagenfurt",
                    "city": "Klagenfurt",
                    "country": "Austria"
                },
                "role": "presenter"
            },
            {
                "id": "auth4563",
                "givenName": "David",
                "familyName": "Ahlström",
                "email": "david.ahlstroem@aau.at",
                "primary": {
                    "institution": "Alpen-Adria Universität Klagenfurt",
                    "city": "Klagenfurt",
                    "country": "Austria"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 468,
        "name": "Squaring the Circle: How Framing Influences User Behavior around a Seamless Cylindrical Display",
        "type": "paper",
        "abstract": "Recent research has presented large public displays in novel non-flat shapes such as spheres, curved planes and cylinders, and looked at the influence of the form factor on user behavior. Yet, the basic shape cannot be considered in isolation when interpreting the behavior of passers-by around such displays. In this paper we investigate two further display factors, framedness and seamlessness, that have to be considered in conjunction with the form factor to understand user behavior in front of large non-flat displays. We present the findings from a field study with an interactive column display and take a closer look at how these factors influence actor and bystander behavior. Our results show that rectangular frames act as a sort of funnel for user position and can easily override effects of the non-flat shape on user position and interaction, even though the users didn’t recall the presence of these frames.",
        "cbStatement": "Analyzes user behavior around a cylindrical and seamless interactive column display in the wild. Helps to better understand how framing influences user positions around more complex non-planar display shapes.",
        "bookmarks": 184,
        "keywords": [
            "Public Displays",
            "Non-flat Displays",
            "Seamless",
            "Framing",
            "Form Factor",
            "Audience Behavior"
        ],
        "communities": [],
        "video": "chi0910-file5.mp4",
        "session": {
            "id": "s247",
            "name": "Displays in public space"
        },
        "room": "241",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth16862",
                "givenName": "Gilbert",
                "familyName": "Beyer",
                "email": "gilbert.beyer@ifi.lmu.de",
                "primary": {
                    "institution": "University of Munich (LMU)",
                    "city": "Munich",
                    "state": "Bavaria",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth29147",
                "givenName": "Florian",
                "familyName": "Köttner",
                "email": "koettner@cip.ifi.lmu.de",
                "primary": {
                    "institution": "University of Munich (LMU)",
                    "city": "Munich",
                    "state": "Bavaria",
                    "country": "Germany"
                }
            },
            {
                "id": "auth18066",
                "givenName": "Manuel",
                "familyName": "Schiewe",
                "email": "manuel.schiewe@fokus.fraunhofer.de",
                "primary": {
                    "institution": "Fraunhofer FOKUS",
                    "city": "Berlin",
                    "state": "Berlin",
                    "country": "Germany"
                }
            },
            {
                "id": "auth17823",
                "givenName": "Ivo",
                "familyName": "Haulsen",
                "email": "ivo.haulsen@fokus.fraunhofer.de",
                "primary": {
                    "institution": "Fraunhofer FOKUS",
                    "city": "Berlin",
                    "state": "Berlin",
                    "country": "Germany"
                }
            },
            {
                "id": "auth4538",
                "givenName": "Andreas",
                "familyName": "Butz",
                "email": "butz@ifi.lmu.de",
                "primary": {
                    "institution": "University of Munich (LMU)",
                    "city": "Munich",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 469,
        "name": "The Roles of Touch during Phone Conversations: Long-Distance Couples’ Use of POKE in Their Homes",
        "type": "paper",
        "abstract": "We report the roles of touch during phone conversations by observing long-distance couples’ one month use of POKE in their homes. POKE enables users to deliver touches through an inflatable surface on the front of the device that receives index finger pressure inputs on the back of another device, while allowing the callers to maintain a conventional phone-calling posture. After a month of use by three couples, we found unexpected roles of touch in that it supported the couples in developing and sharing their tactile vocabularies by applying POKE during various conversational situations. Moreover, the findings confirmed the roles that touch play in face-to-face communication. In particular, POKE was useful for expressing and understanding emotions, resolving conversations smoothly by replacing the words, feeling close to the partner at a distance, and concentrating on the phone conversations. We conclude by discussing the unused situations, privacy issues, and usable targets to improve POKE as a way of future tactile phone conversations.",
        "cbStatement": "Describes the roles of touch during phone conversations by observing couples’ one month use of POKE in their homes. The results show a potential new application for tactile phone conversations.",
        "bookmarks": 127,
        "keywords": [
            "Role of touch",
            "tactile phone call",
            "tactile vocabulary",
            "field trial;"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi0912-file5.mp4",
        "session": {
            "id": "s228",
            "name": "Tactile Presentation Theory"
        },
        "room": "blue",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth12877",
                "givenName": "Young-Woo",
                "familyName": "Park",
                "email": "pyw@kaist.ac.kr",
                "primary": {
                    "dept": "Department of Industrial Design",
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "state": "Chung-Cheong Nam do",
                    "country": "Republic of Korea"
                },
                "role": "presenter"
            },
            {
                "id": "auth29284",
                "givenName": "Kyoung-Min",
                "familyName": "Baek",
                "email": "km.baek@kaist.ac.kr",
                "primary": {
                    "dept": "Department of Industrial Design",
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "state": "Chung-Cheong Nam do",
                    "country": "Republic of Korea"
                }
            },
            {
                "id": "auth2587",
                "givenName": "Tek-Jin",
                "familyName": "Nam",
                "email": "tjnam@kaist.ac.kr",
                "primary": {
                    "dept": "Department of Industrial Design",
                    "institution": "KAIST (Korea Advanced Institute of Science and Technology)",
                    "city": "Daejeon",
                    "state": "Chung-Cheong Nam do",
                    "country": "Republic of Korea"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 470,
        "name": "Job Opportunities through Entertainment: Virally Spread Speech-Based Services for Low-Literate Users",
        "type": "paper",
        "abstract": "We explore how telephone-based services might be mass adopted by low-literate users in the developing world. We focus on speech and push-button dialog systems requiring neither literacy nor training. Building on the success of Polly, a simple telephone-based voice manipulation and forwarding system that was first tested in 2011, we report on its first large-scale sustained deployment. In 24/7 operation in Pakistan since May 9, 2012, as of mid-September Polly has spread to 85,000 users, engaging them in 495,000 interactions, and is continuing to spread to 1,000 new people daily. It has also attracted 27,000 people to a job search service, who in turn listened 279,000 times to job ads and forwarded them 22,000 times to their friends. We report users’ activity over time and across demographics, analyze user behavior within several randomized controlled trials, and describe lessons learned regarding spread, scalability and sustainability of telephone-based speech-based services.",
        "cbStatement": "A speech-based entertainment service spread virally to low-literate Pakistani telephone users, exceeding 85,000 users and 495,000 calls in four months, while spreading low-skill job opportunities to 27,000 of them.",
        "bookmarks": 183,
        "keywords": [
            "Speech Interfaces",
            "illiteracy",
            "low-literate",
            " cellular phones",
            "viral",
            "job search",
            "mobile phones",
            "telephone",
            "entertainment",
            "ICT4D",
            "HCI4D",
            "information services",
            "communication services",
            "low-skill jobs"
        ],
        "communities": [
            "hci4d"
        ],
        "video": "chi0913-file5.mp4",
        "session": {
            "id": "s258",
            "name": "ICT4D"
        },
        "room": "242ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth22841",
                "givenName": "Agha Ali",
                "familyName": "Raza",
                "email": "araza@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "PA",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth30325",
                "givenName": "Farhan",
                "familyName": "Ul Haq",
                "email": "farhan.haq@lums.edu.pk",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "Lahore University of Management Sciences",
                    "city": "Lahore",
                    "state": "Punjab",
                    "country": "Pakistan"
                }
            },
            {
                "id": "auth30327",
                "givenName": "Zain",
                "familyName": "Tariq",
                "email": "zain.tariq@lums.edu.pk",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "Lahore University of Management Sciences",
                    "city": "Lahore",
                    "state": "Punjab",
                    "country": "Pakistan"
                }
            },
            {
                "id": "auth30328",
                "givenName": "Mansoor",
                "familyName": "Pervaiz",
                "email": "mansoor@ccs.neu.edu",
                "primary": {
                    "dept": "College of Computer and Information Science",
                    "institution": "Northeastern University",
                    "city": "Boston",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth23299",
                "givenName": "Samia",
                "familyName": "Razaq",
                "email": "samiarazaqkhan@gmail.com",
                "primary": {
                    "institution": "Lahore University of Management Sciences",
                    "city": "Lahore ",
                    "state": "Punjab",
                    "country": "Pakistan"
                }
            },
            {
                "id": "auth14562",
                "givenName": "Umar",
                "familyName": "Saif",
                "email": "umar@lums.edu.pk",
                "primary": {
                    "institution": "Lahore University of Management Sciences",
                    "city": "Lahore",
                    "state": "Punjab",
                    "country": "Pakistan"
                }
            },
            {
                "id": "auth5167",
                "givenName": "Roni",
                "familyName": "Rosenfeld",
                "email": "roni.rosenfeld@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 471,
        "name": "Listen to it yourself!  Evaluating Usability of \"What's Around Me?\" for the Blind",
        "type": "paper",
        "abstract": "Although multiple GPS-based navigation applications exist for the visually impaired, these are typically poorly suited for in-situ exploration, require cumbersome hardware, lack support for widely accessible geographic databases, or do not take advantage of advanced functionality such as spatialized audio rendering.  These shortcomings led to our development of a novel spatial awareness application that leverages the capabilities of a smartphone coupled with worldwide geographic databases and spatialized audio rendering to convey surrounding points of interest.  This paper describes the usability evaluation of our system through a task-based study and a longer-term deployment, each conducted with six blind users in real settings.   \\ The findings highlight the importance of testing in ecologically valid contexts over sufficient periods to face real-world challenges, including balancing quality versus quantity for audio information, overcoming limitations imposed by sensor accuracy and quality of database information, and paying appropriate design attention to physical interaction with the device.",
        "cbStatement": "We present the results of the usability evaluation, conducted in realistic settings, of a novel spatial awareness smartphone application that conveys surrounding points of interest to the blind.  ",
        "bookmarks": 31,
        "keywords": [
            "Mobile interface",
            "audio feedback",
            "visually impaired"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "chi0917-file5.mp4",
        "session": {
            "id": "s292",
            "name": "Blindness and Design"
        },
        "room": "242ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth26702",
                "givenName": "Sabrina",
                "middleInitial": "A.",
                "familyName": "Panëels",
                "email": "s.paneels@gmail.com",
                "primary": {
                    "institution": "McGill University",
                    "city": "Montréal",
                    "state": "Québec",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth15815",
                "givenName": "Adriana",
                "familyName": "Olmos",
                "email": "adriana.olmos@mac.com",
                "primary": {
                    "institution": "McGill University",
                    "city": "Montreal",
                    "state": "Quebec",
                    "country": "Canada"
                }
            },
            {
                "id": "auth29496",
                "givenName": "Jeffrey",
                "middleInitial": "R.",
                "familyName": "Blum",
                "email": "jeffbl@cim.mcgill.ca",
                "primary": {
                    "institution": "McGill University",
                    "city": "Montréal",
                    "state": "Quebec",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth4933",
                "givenName": "Jeremy",
                "middleInitial": "R",
                "familyName": "Cooperstock",
                "email": "jer@cim.mcgill.ca",
                "primary": {
                    "institution": "McGill University",
                    "city": "Montreal",
                    "state": "Quebec",
                    "country": "Canada"
                }
            }
        ]
    },
    {
        "id": 472,
        "name": "Designing Mobile Health Technology for Bipolar Disorder: A Field Trial of the MONARCA System",
        "type": "paper",
        "abstract": "An increasing number of pervasive healthcare systems are being designed, that allow people to monitor and get feedback on their health and wellness. To address the challenges of self-management of mental illnesses, we have developed the MONARCA system – a personal monitoring system for bipolar patients. We conducted a 14 week field trial in which 12 patients used the system, and we report findings focusing on their experiences. The results were positive; compared to using paper-based forms, the adherence to self-assessment improved; the system was considered very easy to use; and the perceived usefulness of the system was high. Based on this study, the paper discusses three HCI questions related to the design of personal health technologies; how to design for disease awareness and self-treatment, how to ensure adherence to personal health technologies, and the roles of different types of technology platforms.",
        "cbStatement": "We conducted a 14 week field trial of the MONARCA system with 12 patients, reporting on their experiences. Furthermore, the paper discusses three questions regarding design of personal health technologies.",
        "bookmarks": 130,
        "keywords": [
            "Bipolar disorder",
            "mental health",
            "personal health systems",
            "mobile application"
        ],
        "communities": [
            "health"
        ],
        "video": "chi0923-file5.mp4",
        "session": {
            "id": "s297",
            "name": "Desing in a Psychiatric Setting"
        },
        "room": "242ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth1962",
                "givenName": "Jakob",
                "middleInitial": "E.",
                "familyName": "Bardram",
                "email": "bardram@itu.dk",
                "primary": {
                    "dept": "Pervasive Interaction Technology Lab",
                    "institution": "IT University of Copenhagen",
                    "city": "Copenhagen",
                    "country": "Denmark"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth22465",
                "givenName": "Mads",
                "familyName": "Frost",
                "email": "madsf@itu.dk",
                "primary": {
                    "dept": "Pervasive Interaction Technology Lab",
                    "institution": "IT University of Copenhagen",
                    "city": "Copenhagen",
                    "country": "Denmark"
                },
                "role": "presenter"
            },
            {
                "id": "auth29299",
                "givenName": "Károly",
                "familyName": "Szántó",
                "email": "ksza@itu.dk",
                "primary": {
                    "dept": "Pervasive Interaction Technology Lab",
                    "institution": "IT University of Copenhagen",
                    "city": "Copenhagen",
                    "country": "Denmark"
                }
            },
            {
                "id": "auth29300",
                "givenName": "Maria",
                "familyName": "Faurholt-Jepsen",
                "email": "maria.faurholtjepsen@regionh.dk",
                "primary": {
                    "dept": "Psychiatric Center Copenhagen",
                    "institution": "University Hospital of Copenhagen",
                    "city": "Copenhagen",
                    "country": "Denmark"
                }
            },
            {
                "id": "auth29301",
                "givenName": "Maj",
                "familyName": "Vinberg",
                "email": "maj.vinberg@regionh.dk",
                "primary": {
                    "dept": "Psychiatric Center Copenhagen",
                    "institution": "University Hospital of Copenhagen",
                    "city": "Copenhagen",
                    "country": "Denmark"
                }
            },
            {
                "id": "auth29302",
                "givenName": "Lars Vedel",
                "familyName": "Kessing",
                "email": "lars.vedel.kessing@regionh.dk",
                "primary": {
                    "dept": "Psychiatric Center Copenhagen",
                    "institution": "University Hospital of Copenhagen",
                    "city": "Copenhagen",
                    "country": "Denmark"
                }
            }
        ]
    },
    {
        "id": 473,
        "name": "Exploring the Effects of Space and Place on Engagement with an Interactive Installation",
        "type": "paper",
        "abstract": "Very little research has concurrently explored the influence of both physical space and social context (or place) on the way people engage with a public interactive display. We addressed this issue with a novel approach: studying how people engaged with the same interactive installation in ten situations with varying spatial and social properties. The main finding across these studies is that place trumps space: a conducive social context could overcome a poor physical space and encourage interaction; conversely, an inappropriate social context could inhibit interaction in spaces that might normally facilitate engagement. We discuss this finding in terms of the salience of the display within the space, the visibility of incidental interactions with the installation, the different understandings of place that people can have in the same location and the role of emergent champions and comperes in encouraging interaction.",
        "cbStatement": "We studied how people engaged with the same interactive installation in ten situations with varying spatial and social properties. The main finding across these studies is that place trumps space",
        "bookmarks": 135,
        "keywords": [
            "Public display",
            "situated display",
            "space",
            "place",
            "interaction"
        ],
        "communities": [],
        "video": "chi0927-file5.mp4",
        "session": {
            "id": "s243",
            "name": "Place meets Engagement"
        },
        "room": "342a",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth34760",
                "givenName": "Imeh",
                "familyName": "Akpan",
                "email": "imeh.akpan.11@ucl.ac.uk",
                "primary": {
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth10037",
                "givenName": "Paul",
                "familyName": "Marshall",
                "email": "paul.marshall@ucl.ac.uk",
                "primary": {
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth23632",
                "givenName": "Jon",
                "familyName": "Bird",
                "email": "jon.bird@ucl.ac.uk",
                "primary": {
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth25553",
                "givenName": "Daniel",
                "familyName": "Harrison",
                "email": "d.harrison.11@ucl.ac.uk",
                "primary": {
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 474,
        "name": "Creating and Analyzing Stereoscopic 3D Graphical User Interfaces in Digital Games",
        "type": "paper",
        "abstract": "Creating graphical user interfaces (GUI) for stereoscopic 3D (S3D) games is a difficult choice between visual comfort and effect. We present a S3D Game GUI Design Space and a list of S3D-specific attributes that emphasizes integrating visually comfortable interfaces into the game world, story and S3D view. To showcase our approach, we created two GUI concepts and evaluated them with 32 users. Our results show quality improvements for a combination of bottom position and visual attachment for a menu. In a referencing interface, placing the reference near to the target depth significantly improved perceived quality, game integration, and increased presence. These results confirm the need to create S3D GUIs with perceptual constraints in mind, demonstrating the potential to extend the user experience. Additionally, our design space offers a formal and flexible way to create new effects in S3D GUIs.",
        "cbStatement": "Supports GUI designers with a design space to create stereoscopic 3D GUIs for games. Our evaluation shows that perceptual, spatial and diegetic integration provide helpful constraints for influencing user experience.",
        "bookmarks": 82,
        "keywords": [
            "Stereoscopic 3D",
            "game",
            "graphical user interface",
            "design space",
            "depth",
            "user experience",
            "presence",
            "visual 3D quality"
        ],
        "communities": [
            "design",
            "ux",
            "games"
        ],
        "video": "chi0930-file5.mp4",
        "session": {
            "id": "s251",
            "name": "3D Uis"
        },
        "room": "241",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth12906",
                "givenName": "Jonas",
                "familyName": "Schild",
                "email": "jonas.schild@uni-due.de",
                "primary": {
                    "institution": "University of Duisburg-Essen",
                    "city": "Duisburg",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth29944",
                "givenName": "Liane",
                "familyName": "Bölicke",
                "email": "liane.boelicke@stud.uni-due.de",
                "primary": {
                    "institution": "University of Duisburg-Essen",
                    "city": "Duisburg",
                    "country": "Germany"
                }
            },
            {
                "id": "auth9759",
                "givenName": "Joseph J.",
                "middleInitial": "J",
                "familyName": "LaViola Jr.",
                "email": "jjl@cs.ucf.edu",
                "primary": {
                    "institution": "University of Central Florida",
                    "city": "Orlando",
                    "state": "Florida",
                    "country": "United States"
                }
            },
            {
                "id": "auth22440",
                "givenName": "Maic",
                "familyName": "Masuch",
                "email": "maic.masuch@uni-due.de",
                "primary": {
                    "institution": "University of Duisburg-Essen",
                    "city": "Duisburg",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 475,
        "name": "Instagram at the Museum: Communicating the Museum Experience through Social Photo Sharing",
        "type": "paper",
        "abstract": "The everyday use of smartphones with high quality built-in cameras has lead to an increase in museum visitors’ use of these devices to document and share their museum experiences. In this paper, we investigate how one particular photo sharing application, Instagram, is used to communicate visitors’ experiences while visiting a museum of natural history. Based on an analysis of 222 instagrams created in the museum, as well as 14 interviews with the visitors who created them, we unpack the compositional resources and concerns contributing to the creation of instagrams in this particular context. By re-categorizing and re-configuring the museum environment, instagrammers work to construct their own narratives from their visits. These findings are then used to discuss what emerging multimedia practices imply for the visitors’ engagement with and documentation of museum exhibits. Drawing upon these practices, we discuss the connection between online social media dialogue and the museum site. ",
        "cbStatement": "Analyzing both instagrams and practices of instagramming, we examine the resources and concerns that shape the user-driven creation, organisation and sharing of social, multi-layered, aesthetic documents of museum experiences.",
        "bookmarks": 129,
        "keywords": [
            "Social Media",
            "Museum Studies",
            "Museum of Natural Histo-ry",
            "Instagram",
            "Photography",
            "Camera Phones",
            "Smartphones."
        ],
        "communities": [],
        "video": "chi0940-file5.mp4",
        "session": {
            "id": "s244",
            "name": "Studies of the Use of Digital Artifacts"
        },
        "room": "342a",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth2400",
                "givenName": "Alexandra",
                "familyName": "Weilenmann",
                "email": "alexandra.weilenmann@ituniv.se",
                "primary": {
                    "dept": "Department of Applied IT",
                    "institution": "University of Gothenburg",
                    "city": "Gothenburg",
                    "country": "Sweden"
                },
                "role": "presenter"
            },
            {
                "id": "auth26929",
                "givenName": "Thomas",
                "familyName": "Hillman",
                "email": "thomas.hillman@gu.se",
                "primary": {
                    "dept": "Department of Education, Communication and Learning",
                    "institution": "University of Gothenburg",
                    "city": "Gothenburg",
                    "country": "Sweden"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth29775",
                "givenName": "Beata",
                "familyName": "Jungselius",
                "email": "beataj@chalmers.se",
                "primary": {
                    "dept": "Department of Applied IT",
                    "institution": "University of Gothenburg",
                    "city": "Gothenburg",
                    "country": "Sweden"
                }
            }
        ]
    },
    {
        "id": 476,
        "name": "Use of an Agile Bridge in the Development of Assistive Technology",
        "type": "paper",
        "abstract": "Engaging with end users in the development of assistive technologies remains one of the major challenges for researchers and developers in the field of accessibility and HCI. Developing usable software systems for people with complex disabilities is problematic, software developers are wary of using user-centred design, one of the main methods by which usability can be improved, due to concerns about how best to work with adults with complex disabilities, in particular Severe Speech and Physical Impairments (SSPI) and how to involve them in research. This paper reports on how the adoption of an adapted agile approach involving the incorporation of a user advocate on the research team helped in meeting this challenge in one software project and offers suggestions for how this could be used by other development teams. ",
        "cbStatement": "In this paper we present a means for adults with complex communication disabilities to be involved in the User-Centred Design process through the use of a user advocate",
        "bookmarks": 160,
        "keywords": [
            "Severe Speech and Physical Impairments",
            "Assistive Technology",
            "User Centred Design",
            "Agile Methodology"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0941-file5.mp4",
        "session": {
            "id": "s264",
            "name": "Novel Programming"
        },
        "room": "351",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth10701",
                "givenName": "Suzanne",
                "familyName": "Prior",
                "email": "s.prior@abertay.ac.uk",
                "primary": {
                    "dept": "Arts Media and Computing Games",
                    "institution": "University of Abertay Dundee",
                    "city": "Dundee",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth19192",
                "givenName": "Annalu",
                "familyName": "Waller",
                "email": "awaller@computing.dundee.ac.uk",
                "primary": {
                    "institution": "University of Dundee",
                    "city": "Dundee",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth30008",
                "givenName": "Thilo",
                "familyName": "Kroll",
                "email": "t.kroll@dundee.ac.uk",
                "primary": {
                    "dept": "Nursing and Midwifery",
                    "institution": "University of Dundee",
                    "city": "Dundee",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth30009",
                "givenName": "Rolf",
                "familyName": "Black",
                "email": "rolfblack@computing.dundee.ac.uk",
                "primary": {
                    "dept": "School of Computing",
                    "institution": "University of Dundee",
                    "city": "Dundee",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 477,
        "name": "A Text Message a Day Keeps the Pulmonologist Away",
        "type": "paper",
        "abstract": "The goal of this study was to extend and replicate an SMS health intervention for pediatric asthma patients. This intervention was designed using the Health Belief Model (HBM). Thirty patients were randomly assigned to one of three conditions. In the Knowledge condition patients were queried about their asthma knowledge every other day. In the Knowledge and Symptoms condition patients received a daily text message. They were queried about their symptoms and knowledge of asthma on alternate days. The Control group received no texts. Our main finding is that daily text messages lead to improved health outcomes.  \\  \\ We explain our results in the context of interview data and the HBM. We conclude by suggesting that the HBM can be used to inform and evaluate system design for chronic care beyond asthma and by considering the role that replication studies can play in HCI research.  \\ ",
        "cbStatement": "This paper encourages the use of ubiquitous technology for the primary stakeholder, and  promotes designing technology to both replicate and extend results by using a social theory of behavior change.",
        "bookmarks": 132,
        "keywords": [
            "Asthma",
            "RCT",
            "SMS",
            "text message",
            "RepliCHI"
        ],
        "communities": [
            "health"
        ],
        "session": {
            "id": "s295",
            "name": "Health, Information, and Communication"
        },
        "room": "242ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth29936",
                "givenName": "Tae-Jung",
                "familyName": "Yun",
                "email": "tj.yun@samsung.com",
                "primary": {
                    "institution": "Samsung Electronics",
                    "city": "Suwon",
                    "country": "Republic of Korea"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth18125",
                "givenName": "Rosa I.",
                "middleInitial": "I.",
                "familyName": "Arriaga",
                "email": "arriaga@cc.gatech.edu",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 478,
        "name": "Age-Related Performance Issues for PIN and Face-Based Authentication Systems",
        "type": "paper",
        "abstract": "Graphical authentication systems typically claim to be more usable than PIN or password-based systems, but these claims often follow limited, single-stage paradigm testing on a young, student population.  We present a more demanding test paradigm in which multiple codes are learned and tested over a three-week period.  We use this paradigm with two user populations, comparing the performance of younger and older adults.  We first establish baseline performance in a study in which populations of younger and older adults learn PIN codes and we follow this with a second study in which younger and older adults use two face-based graphical authentication systems employing young faces vs. old faces as code components.    As expected, older adults show relatively poor performance when compared to younger adults, irrespective of the authentication material, but this age-related deficit can be markedly reduced by the introduction of age-appropriate faces. We conclude firstly that this paradigm provides a good basis for the future evaluation of memory-based authentication systems and secondly that age-appropriate face-based authentication is viable in the security marketplace.",
        "cbStatement": "A PIN system and a face-based graphical system were evaluated with younger and older adults. Old benefitted from own-age faces most while young performed well with faces overall.",
        "bookmarks": 17,
        "keywords": [
            "Graphical codes",
            "usable security",
            "authentication",
            "older adults"
        ],
        "communities": [],
        "video": "chi0948-file5.m4v",
        "session": {
            "id": "s289",
            "name": "Technologies for Life"
        },
        "room": "242ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth12634",
                "givenName": "James",
                "familyName": "Nicholson",
                "email": "james.nicholson@northumbria.ac.uk",
                "primary": {
                    "institution": "Northumbria University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth15158",
                "givenName": "Lynne",
                "familyName": "Coventry",
                "email": "lynne.coventry@northumbria.ac.uk",
                "primary": {
                    "institution": "Northumbria University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1325",
                "givenName": "Pam",
                "familyName": "Briggs",
                "email": "p.briggs@unn.ac.uk",
                "primary": {
                    "institution": "Northumbria University",
                    "city": "Newcastle upon Tyne",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 479,
        "name": "Picode: Inline Photos Representing Posture Data in Source Code",
        "type": "paper",
        "abstract": "Current programming environments use textual or symbolic representations. While these representations are appropriate for describing logical processes, they are not appropriate for representing raw values such as human and robot posture data, which are necessary for handling gesture input and controlling robots. To address this issue, we propose Picode, a text-based development environment integrated with visual representations: photos of human and robots. With Picode, the user first takes a photo to bind it to posture data. S/he then drag-and-drops the photo into the code editor, where it is displayed as an inline image. A preliminary in-house user study implied positive effects of taking photos on the programming experience.",
        "cbStatement": "Picode is a text-based development environment augmented with inline photos of human and robots. They contain richer context information than mere posture data, and enhance the programming experience.",
        "bookmarks": 136,
        "keywords": [
            "Development Environment",
            "Inline Photo",
            "Posture Data"
        ],
        "communities": [
            "design",
            "engineering",
            "games"
        ],
        "video": "chi0951-file5.mp4",
        "session": {
            "id": "s230",
            "name": "Uis for Software Development"
        },
        "room": "blue",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth12563",
                "givenName": "Jun",
                "familyName": "Kato",
                "email": "arc@digitalmuseum.jp",
                "primary": {
                    "institution": "The University of Tokyo",
                    "city": "Bunkyo-ku",
                    "state": "Tokyo",
                    "country": "Japan"
                },
                "role": "presenter"
            },
            {
                "id": "auth11617",
                "givenName": "Daisuke",
                "familyName": "Sakamoto",
                "email": "d.sakamoto@gmail.com",
                "primary": {
                    "institution": "The University of Tokyo",
                    "city": "Bunkyo-ku",
                    "state": "Tokyo",
                    "country": "Japan"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1051",
                "givenName": "Takeo",
                "familyName": "Igarashi",
                "email": "takeo@acm.org",
                "primary": {
                    "institution": "The University of Tokyo",
                    "city": "Bunkyo-ku",
                    "state": "Tokyo",
                    "country": "Japan"
                }
            }
        ]
    },
    {
        "id": 480,
        "name": "Reveal-it!: The Impact of a Social Visualization Projection on Public Awareness and Discourse",
        "type": "paper",
        "abstract": "Public displays and projections are becoming increasingly available in various informal urban settings. However, their potential impact on informing and engaging citizens on relevant issues has still been largely unexplored. In this paper, we show that visualizations displayed in public settings are able to increase social awareness and discourse by exposing underlying patterns in data that is submitted by citizens. We thus introduce the design and evaluation of Reveal-it!, a public, interactive projection that facilitates the comparison of the energy consumptions of individuals and communities. Our in-the-wild deployment in three distinct physical locations provided insights into: 1) how people responded to this form of display in different contexts; 2) how it influenced people’s perception and discussion of individual and communal data; and 3) the implications for a public visualization as a tool for increasing awareness and discourse. We conclude by discussing emerging participant behaviors, as well as some challenges involved in facilitating a socially motivated crowd-sourced visualization in the public context.  ",
        "cbStatement": "This paper investigates the challenges for a public visualization of a socially-relevant dataset, for the goal of changing the civic awareness of onlookers, through the evaluation of three real-world case studies.",
        "bookmarks": 51,
        "keywords": [
            "public display",
            "urban screen",
            "urban visualization",
            "energy consumption",
            "sustainability",
            "in-the-wild study",
            "awareness, reflection",
            "captology",
            "persuasive computing",
            "evaluation."
        ],
        "communities": [
            "design"
        ],
        "video": "chi0966-file5.mp4",
        "session": {
            "id": "s203",
            "name": "Smart City: use social media for and in the public domain"
        },
        "room": "havane",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth15457",
                "givenName": "Nina",
                "familyName": "Valkanova",
                "email": "nina.valkanova@gmail.com",
                "primary": {
                    "dept": "Music Technology Group",
                    "institution": "Universitat Pompeu Fabra",
                    "city": "Barcelona",
                    "country": "Spain"
                },
                "role": "presenter"
            },
            {
                "id": "auth14721",
                "givenName": "Sergi",
                "familyName": "Jorda",
                "email": "sergi.jorda@upf.edu",
                "primary": {
                    "dept": "Music Technology Group",
                    "institution": "Universitat Pompeu Fabra",
                    "city": "Barcelona",
                    "country": "Spain"
                }
            },
            {
                "id": "auth5628",
                "givenName": "Martin",
                "familyName": "Tomitsch",
                "email": "martin.tomitsch@sydney.edu.au",
                "primary": {
                    "institution": "Design Lab - Faculty of Architecture, Design & Planning, The University of Sydney",
                    "city": "Sydney",
                    "state": "NSW",
                    "country": "Australia"
                }
            },
            {
                "id": "auth24420",
                "givenName": "Andrew",
                "familyName": "Vande Moere",
                "email": "andrew.vandemoere@asro.kuleuven.be",
                "primary": {
                    "dept": "Research x Design - Department of Architecture, Urbanism and Planning",
                    "institution": "KU Leuven - University of Leuven",
                    "city": "Leuven",
                    "country": "Belgium"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 481,
        "name": "Imaging the Body: Embodied Vision in Minimally Invasive Surgery",
        "type": "paper",
        "abstract": "Recent years have seen the possibilities of new imaging and interaction technologies for minimally invasive surgery such as touchless interaction and high definition renderings of three-dimensional anatomy. With this paper we take a step back to review the historical introduction and assimilation of imaging technologies in the surgical theatre in parallel with the productive and cross-referential nature of surgical practice and image use. We present findings from a field study of image use during neurosurgery where we see that the work to see medical images is highly constructed and embodied with the action of manipulating the body. This perspective lends itself to a discussion of the directions for new imaging interaction technologies.",
        "cbStatement": "Presents findings concerning the constructed and embodied use of images during neurosurgery. Lends itself to a discussion of the directions for new imaging interaction technologies. ",
        "bookmarks": 58,
        "keywords": [
            "Embodiment",
            "Vision",
            "Movement",
            "Health",
            "Surgery",
            "Imaging."
        ],
        "communities": [
            "health"
        ],
        "video": "chi0981-file5.mp4",
        "session": {
            "id": "s294",
            "name": "The Clinical Setting"
        },
        "room": "242ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth1960",
                "givenName": "Helena",
                "middleInitial": "M.",
                "familyName": "Mentis",
                "email": "mentis@acm.org",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth2037",
                "givenName": "Alex",
                "middleInitial": "S",
                "familyName": "Taylor",
                "email": "ast@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 482,
        "name": "Seeing Movement Qualities",
        "type": "paper",
        "abstract": "With the increased availability of movement based interactive devices there is a growing interest in exploring the potential design space for engaging movement-based interactions. This has led to the exploration of different ways to sense and model movement such as Laban Movement Analysis’ Effort qualities. However, little is understood in how movement qualities are perceived and experienced by users.  We explored this in an interactive improvisational dance performance setting.  From video analysis with a Laban Movement expert and post-performance interviews with audience members, we discuss the differences in how a movement quality was perceived.  From these findings, we discuss implications for further efforts in designing interactive movement-based systems that strive to capitalize on movement qualities.",
        "cbStatement": "Presents fieldwork on mechanisms of user perceptions of movement qualities. Lends to implications for further efforts in designing interactive movement-based systems that strive to capitalize on movement qualities.",
        "bookmarks": 157,
        "keywords": [
            "Movement qualities",
            "Laban",
            "Vision",
            "Kinect"
        ],
        "communities": [
            "design"
        ],
        "video": "chi0982-file5.mp4",
        "session": {
            "id": "s239",
            "name": "Phyisical Excersion"
        },
        "room": "242b",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth1960",
                "givenName": "Helena",
                "middleInitial": "M.",
                "familyName": "Mentis",
                "email": "mentis@acm.org",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth20149",
                "givenName": "Carolina",
                "familyName": "Johansson",
                "email": "carolina.v.b.johansson@gmail.com",
                "primary": {
                    "institution": "Mobile Life @ Stockholm University",
                    "city": "Kista",
                    "country": "Sweden"
                },
                "secondary": {
                    "institution": "Interactive Institute",
                    "city": "Kista",
                    "country": "Sweden"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 483,
        "name": "Authoring Personal Histories: Exploring the Timeline as a Framework for Meaning Making",
        "type": "paper",
        "abstract": "It has been argued that technologies for ‘memory’ should be designed to support creativity and meaning building, rather than the passive capture of cues for remembering [25]. We report findings from a study inspired by this insight, in which older people made personal digital timelines using a new tool called Project Greenwich. We explore how the constraints of the timeline metaphor offer a framework for authoring, and examine how timelines can be used to underpin meaning building in relation to personal content. We highlight the importance of making, this being a vehicle for connecting with others in the present, and a potential means of emphasizing those elements of the past felt to be most salient when looking back.",
        "cbStatement": "We present a study of how older people made digital timelines using Project Greenwich. We explore how the constraints of the timeline metaphor offer a framework for authoring and making.",
        "bookmarks": 159,
        "keywords": [
            "Memory",
            "authorship",
            "recipient design",
            "legacy",
            "craft",
            "making",
            "storytelling",
            "older adults",
            "Project Greenwich."
        ],
        "communities": [],
        "session": {
            "id": "s269",
            "name": "Creating and Authoring"
        },
        "room": "241",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth21165",
                "givenName": "Elizabeth",
                "middleInitial": "A",
                "familyName": "Thiry",
                "email": "exn152@psu.edu",
                "primary": {
                    "institution": "Pennsylvania State University",
                    "city": "University Park",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth2278",
                "givenName": "Siân",
                "middleInitial": "E",
                "familyName": "Lindley",
                "email": "sianl@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth8851",
                "givenName": "Richard",
                "familyName": "Banks",
                "email": "rbanks@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth2003",
                "givenName": "Tim",
                "familyName": "Regan",
                "email": "timregan@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 484,
        "name": "Screenfinity: Extending the Perception Area of Content on Very Large Public Displays",
        "type": "paper",
        "abstract": "We propose and validate a model of the perception area of content on public displays in order to predict from where users can read. From this model, we derive Screenfinity, a technique to rotate, translate, and zoom content in order to enable reading while passing by very large displays. Screenfinity is comfortable to read when close, supports different content for different users, does not waste screen real estate and allows expert passers-by to read content while walking. A laboratory study shows that expert users are able to perceive content when it moves. A field study evaluates the effect of Screenfinity on novice users in an ecologically valid setting. We find 1) first time users can read content without slowing down or stopping; 2) Passers-by stopping did so to explore the technology. Users explore the interaction, the limits of the system, manipulate the technology, and look behind the screen.",
        "cbStatement": "Presents a model for the perception area of visual interfaces, and a novel public display increasing the perception area and allowing interaction while walking. Useful for designers of large displays.",
        "bookmarks": 17,
        "keywords": [
            "Large public displays",
            "perception area",
            "visual acuity"
        ],
        "communities": [
            "design",
            "ux",
            "games"
        ],
        "video": "chi0985-file5.mp4",
        "session": {
            "id": "s247",
            "name": "Displays in public space"
        },
        "room": "241",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth29687",
                "givenName": "Constantin",
                "familyName": "Schmidt",
                "email": "der.conni@gmail.com",
                "primary": {
                    "dept": "Quality and Usability Lab",
                    "institution": "Telekom Innovation Laboratories, TU Berlin",
                    "city": "Berlin",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth13650",
                "givenName": "Jörg",
                "familyName": "Müller",
                "email": "joerg.mueller@tu-berlin.de",
                "primary": {
                    "institution": "University of the Arts",
                    "city": "Berlin",
                    "country": "Germany"
                },
                "secondary": {
                    "dept": "Quality and Usability Lab",
                    "institution": "Telekom Innovation Laboratories, TU Berlin",
                    "city": "Berlin",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth9471",
                "givenName": "Gilles",
                "familyName": "Bailly",
                "email": "gillesbailly1@gmail.com",
                "primary": {
                    "dept": "Quality and Usability Lab",
                    "institution": "Telekom Innovation Laboratories, TU Berlin",
                    "city": "Berlin",
                    "country": "Germany"
                }
            }
        ]
    },
    {
        "id": 485,
        "name": "Using Redundancy to Detect Human Error",
        "type": "paper",
        "abstract": "Number entry is a common task in many domains. In safety-critical environments such as air traffic control or on hospital wards, incorrect number entry can have serious harmful consequences. Research has investigated how interface designs can help prevent users from making number entry errors. In this paper, we present an experimental evaluation of two possible interface designs aimed at helping users detect number entry errors using the idea of a checksum: an additional (redundant) number that is related to the to-be-entered numbers in such a way that it is sufficient to verify the correctness of the checksum, as opposed to checking each of the entered numbers. The first interface requires users to check their own work with the help of the checksum; the second requires the user to enter the checksum along with the other numbers so that the system can do the checking. In each case, two numbers needed to be entered, while the third number served as a checksum. With the first interface, users caught only 36% of their errors. The second interface resulted in all errors being caught, but the need to enter the checksum increased entry time by 46%. When participants were allowed to choose between the two interfaces, they chose the second interface in only 12% of the cases. Although these results cannot be generalized to other specific contexts, the results illustrate the strengths and weaknesses of each way of using checksums to catch number entry errors. Hence our study can serve as a starting point for efforts to improve each method.",
        "cbStatement": "We explore ways in which a checksum may be used to prevent number entry errors. We look at two methods for implementing the system and highlight the benefits of each.",
        "bookmarks": 148,
        "keywords": [
            "Number entry",
            "Checksums",
            "Error detection",
            "Redundancy"
        ],
        "communities": [
            "health"
        ],
        "video": "chi0988-file5.mp4",
        "session": {
            "id": "s241",
            "name": "Mobile 1: Mobile Phones: pricing, Emotions, looks, and positioning"
        },
        "room": "241",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth25728",
                "givenName": "Sarah",
                "familyName": "Wiseman",
                "email": "sarah.wiseman.10@ucl.ac.uk",
                "primary": {
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth7532",
                "givenName": "Anna",
                "middleInitial": "L",
                "familyName": "Cox",
                "email": "anna.cox@ucl.ac.uk",
                "primary": {
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth6475",
                "givenName": "Duncan",
                "middleInitial": "P",
                "familyName": "Brumby",
                "email": "Brumby@cs.ucl.ac.uk",
                "primary": {
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth22034",
                "givenName": "Sandy",
                "middleInitial": "J J",
                "familyName": "Gould",
                "email": "s.gould@cs.ucl.ac.uk",
                "primary": {
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth30023",
                "givenName": "Sarah",
                "familyName": "O'Carroll",
                "email": "ocarroll.sarah@gmail.com",
                "primary": {
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 486,
        "name": "SidePoint: A Peripheral Knowledge Panel for Presentation Slide Authoring",
        "type": "paper",
        "abstract": "Presentation authoring is an important activity, but often requires the secondary task of collecting the information and media necessary for both slides and speech. Integration of implicit search and peripheral displays into presentation authoring tools may reduce the effort to satisfy not just active needs the author is aware of, but also latent needs that she is not aware of until she encounters content of perceived value. We develop SidePoint, a peripheral panel that supports presentation authoring by showing concise knowledge items relevant to the slide content. We study SidePoint as a technology probe to examine the benefits and issues associated with peripheral knowledge panels for presentation authoring. Our results show that peripheral knowledge panels have the potential to satisfy both types of needs in ways that transform presentation authoring for the better. ",
        "cbStatement": "Implements an implicit search and peripheral panel system for presentation authoring by showing concise knowledge items relevant to the slide content, and investigates the benefits and issues of such peripheral knowledge panels.",
        "bookmarks": 142,
        "keywords": [
            "Presentation authoring",
            "peripheral displays",
            "natural language processing"
        ],
        "communities": [],
        "video": "chi0990-file5.mp4",
        "session": {
            "id": "s234",
            "name": "Video"
        },
        "room": "bordeaux",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth22733",
                "givenName": "Yefeng",
                "familyName": "Liu",
                "email": "yefeng.liu84@gmail.com",
                "primary": {
                    "institution": "Waseda University",
                    "city": "Tokyo",
                    "country": "Japan"
                }
            },
            {
                "id": "auth9574",
                "givenName": "Darren",
                "familyName": "Edge",
                "email": "darren.edge@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research Asia",
                    "city": "Beijing",
                    "state": "Beijing",
                    "country": "China"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth9633",
                "givenName": "Koji",
                "familyName": "Yatani",
                "email": "koji@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research Asia",
                    "city": "Beijing",
                    "state": "Beijing",
                    "country": "China"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 487,
        "name": "SIG: NVI (Non-Visual Interaction)",
        "type": "SIG",
        "abstract": "In recent years there has been a surge in the development of non-visual interaction techniques targeting two application areas: making content accessible to visually impaired people, and supporting minimal attention user interfaces for situationally impaired users. This SIG aims to bring together the community of researchers working around non-visual interaction techniques for people of all abilities. It will unite members of this burgeoning community in a lively discussion and brainstorming session. Attendees will work to identify and report current and future research challenges as well as new research avenues. ",
        "bookmarks": 114,
        "keywords": [
            "Non-visual interaction",
            "eyes-free interaction",
            "visual impairment",
            "situational impairment",
            "accessibility",
            "haptic",
            "audio",
            "thermal",
            "gestural interaction"
        ],
        "communities": [],
        "video": "si0102-file3.mp4",
        "session": {
            "id": "s170",
            "name": "SIG: NVI (Non-Visual Interaction)"
        },
        "room": "361",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth25138",
                "givenName": "Anke",
                "familyName": "Brock",
                "email": "anke.brock@irit.fr",
                "primary": {
                    "dept": "IRIT",
                    "institution": "University Toulouse 3 & CNRS",
                    "city": "Toulouse",
                    "country": "France"
                },
                "secondary": {
                    "dept": "PsyClé",
                    "institution": "Aix Marseille University",
                    "city": "Aix Marseille ",
                    "country": "France"
                }
            },
            {
                "id": "auth24613",
                "givenName": "Slim",
                "familyName": "Kammoun",
                "email": "slim.kammoun@irit.fr",
                "primary": {
                    "institution": "IRIT, CNRS & University of Toulouse",
                    "city": "Toulouse",
                    "country": "France"
                }
            },
            {
                "id": "auth12589",
                "givenName": "Hugo",
                "familyName": "Nicolau",
                "email": "hman@vimmi.inesc-id.pt",
                "primary": {
                    "institution": "INESC-ID",
                    "city": "Lisbon",
                    "country": "Portugal"
                }
            },
            {
                "id": "auth6014",
                "givenName": "Tiago",
                "familyName": "Guerreiro",
                "email": "tjvg@di.fc.ul.pt",
                "primary": {
                    "institution": "University of Lisbon",
                    "city": "Lisbon",
                    "country": "Portugal"
                }
            },
            {
                "id": "auth8212",
                "givenName": "Shaun",
                "familyName": "Kane",
                "email": "skane@umbc.edu",
                "primary": {
                    "institution": "University of Maryland, Baltimore County",
                    "city": "Baltimore",
                    "state": "Maryland",
                    "country": "United States"
                }
            },
            {
                "id": "auth22064",
                "givenName": "Christophe",
                "familyName": "Jouffrais",
                "email": "Jouffrais@irit.fr",
                "primary": {
                    "dept": "IRIT",
                    "institution": "University Toulouse 3 & CNRS",
                    "city": "Toulouse",
                    "country": "France"
                }
            }
        ]
    },
    {
        "id": 488,
        "name": "SIG NIME: Music, Technology, and Human-Computer Interaction",
        "type": "SIG",
        "abstract": "This SIG intends to investigate the ongoing dialogue between music technology and the field of human-computer interaction. Our specific aims are to consider major findings of  musical interface research over recent years and discuss how these might best be conveyed to CHI researchers interested but not yet active in this area, as well as to consider how to stimulate future collaborations between music technology and CHI research communities. \\ ",
        "bookmarks": 162,
        "keywords": [
            "Music",
            "Art",
            "Technology",
            "Interactive",
            "Interface",
            "HCI"
        ],
        "communities": [
            "design",
            "ux",
            "games",
            "arts"
        ],
        "video": "si0104-file3.mp4",
        "session": {
            "id": "s162",
            "name": "SIG NIME: Music, Technology, and Human-Computer Interaction"
        },
        "room": "362/363",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth23475",
                "givenName": "Frederic",
                "familyName": "Bevilacqua",
                "email": "frederic.bevilacqua@ircam.fr",
                "primary": {
                    "institution": "IRCAM",
                    "city": "Paris",
                    "country": "France"
                }
            },
            {
                "id": "auth1763",
                "givenName": "Sidney",
                "familyName": "Fels",
                "email": "ssfels@ece.ubc.ca",
                "primary": {
                    "institution": "University of British Columbia",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            },
            {
                "id": "auth31380",
                "givenName": "Alexander",
                "familyName": "Jensenius",
                "email": "a.r.jensenius@imv.uio.no",
                "primary": {
                    "institution": "University of Oslo",
                    "city": "Oslo",
                    "country": "Norway"
                }
            },
            {
                "id": "auth1769",
                "givenName": "Michael",
                "familyName": "Lyons",
                "email": "michael.lyons@gmail.com",
                "primary": {
                    "institution": "Ritsumeikan University",
                    "city": "Kyoto",
                    "country": "Japan"
                }
            },
            {
                "id": "auth31381",
                "givenName": "Norbert",
                "familyName": "Schnell",
                "email": "Norbert.Schnell@ircam.fr",
                "primary": {
                    "institution": "IRCAM",
                    "city": "Paris",
                    "country": "France"
                }
            },
            {
                "id": "auth6018",
                "givenName": "Atau",
                "familyName": "Tanaka",
                "email": "a.tanaka@gold.ac.uk",
                "primary": {
                    "institution": "Goldsmiths, University of London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 489,
        "name": "A new Perspective for the Games and Entertainment Community",
        "type": "SIG",
        "abstract": "Games and Entertainment has become an important area for researchers in Human-Computer Interaction. The community has grown dramatically in the past three years. During CHI 2012 a two-day workshop on Games User Research was held, and a growing number of game-oriented submissions shows the increasing importance of the field. In 2013 the successful Student Games Competition will continue and we plan to program engaging game experiences during CHI 2013. The games and entertainment community is the only community that got the agreement of the Conference Management Committee of SIGCHI to extend existence beyond the initial three years. The Games and Entertainment Community is thus extended for the years 2014 and following. It is of immense importance for the community to have the possibility to discuss new perspectives for the Games and Entertainment Community in a SIG.",
        "bookmarks": 85,
        "keywords": [
            "entertainment",
            "games",
            "future perspectives"
        ],
        "communities": [
            "games"
        ],
        "video": "si0105-file3.m4v",
        "session": {
            "id": "s163",
            "name": "A new Perspective for the Games and Entertainment Community"
        },
        "room": "361",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth5971",
                "givenName": "Regina",
                "familyName": "Bernhaupt",
                "email": "Regina.Bernhaupt@irit.fr",
                "primary": {
                    "institution": "IRIT, University Paul Sabatier, Toulouse III",
                    "city": "Toulouse",
                    "country": "France"
                },
                "secondary": {
                    "institution": "ruwido",
                    "city": "Neumarkt",
                    "country": "Austria"
                }
            },
            {
                "id": "auth1461",
                "givenName": "Katherine",
                "familyName": "Isbister",
                "email": "katherine.isbister@gmail.com",
                "primary": {
                    "institution": "Polytechnic Institute of New York University",
                    "city": "Brooklyn",
                    "state": "New York",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 490,
        "name": "Designing Interactive Secure System: CHI 2013 Special Interest Group",
        "type": "SIG",
        "abstract": "Despite a growing interest in the design and engineering of interactive secure systems, there is also a noticeable amount of fragmentation.  This has led to a lack of awareness about what research is currently being carried out, and misunderstandings about how different fields can contribute to the design of usable and secure systems.  By drawing interested members of the CHI community from design, user experience, engineering, and HCI Security, this SIG will take the first steps towards creating a research agenda for interactive secure system design.  In the SIG, we will summarise recent initiatives to develop a research programme in interactive secure system design, network members of the CHI community with an interest in this research area, and initiate a roadmap towards addressing identified research challenges and building an interactive secure system design community. ",
        "bookmarks": 106,
        "keywords": [
            "Design;Usable Security;Methods;Tools"
        ],
        "communities": [
            "design",
            "engineering",
            "ux"
        ],
        "video": "si0106-file3.mp4",
        "session": {
            "id": "s165",
            "name": "Designing Interactive Secure System: CHI 2013 Special Interest Group"
        },
        "room": "361",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth11775",
                "givenName": "Shamal",
                "familyName": "Faily",
                "email": "shamal.faily@cs.ox.ac.uk",
                "primary": {
                    "institution": "University of Oxford",
                    "city": "Oxford",
                    "state": "Oxfordshire",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth31433",
                "givenName": "Lizzie",
                "familyName": "Coles-Kemp",
                "email": "lizzie.coles-kemp@rhul.ac.uk",
                "primary": {
                    "dept": "Information Security Group",
                    "institution": "Royal Holloway",
                    "city": "Egham",
                    "state": "Surrey",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth14149",
                "givenName": "Paul",
                "familyName": "Dunphy",
                "email": "paul.dunphy@ncl.ac.uk",
                "primary": {
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth24156",
                "givenName": "Mike",
                "familyName": "Just",
                "email": "mike.just@gcu.ac.uk",
                "primary": {
                    "institution": "Glasgow Caledonian University",
                    "city": "Glasgow",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth17781",
                "givenName": "Yoko",
                "familyName": "Akama",
                "email": "yoko.akama@rmit.edu.au",
                "primary": {
                    "institution": "RMIT University ",
                    "city": "Melbourne",
                    "state": "Victoria",
                    "country": "Australia"
                }
            },
            {
                "id": "auth8064",
                "givenName": "Alexander",
                "familyName": "De Luca",
                "email": "alexander.de.luca@ifi.lmu.de",
                "primary": {
                    "dept": "Media Informatics Group",
                    "institution": "University of Munich (LMU)",
                    "city": "Munich",
                    "state": "Bavaria",
                    "country": "Germany"
                }
            }
        ]
    },
    {
        "id": 491,
        "name": "Research-Practice Interaction: Building Bridges, Closing the Gap",
        "type": "SIG",
        "abstract": "Previous work in the CHI community has identified and explored gaps between theory and practice in HCI research [2]. The recently formed SIGCHI Community on Research-Practice Interaction aims to help bridge the gap between research and practice, by for example supporting practitioner-friendly dissemination of results, and serving as a conduit for feedback from practitioners to researchers. This SIG is an opportunity for interested CHI attendees to meet members of the SIGCHI RPI community, and engage in discussions on RPI issues including the CHI format, dissemination of results, and supporting practice-based research",
        "bookmarks": 83,
        "keywords": [
            "Research-Practice Interaction",
            "dissemination",
            "practice-based research"
        ],
        "communities": [
            "ux"
        ],
        "video": "si0108-file3.mp4",
        "session": {
            "id": "s164",
            "name": "Research-Practice Interaction: Building Bridges, Closing the Gap"
        },
        "room": "361",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth9178",
                "givenName": "Elizabeth",
                "familyName": "Buie",
                "email": "elizabeth.buie@northumbria.ac.uk",
                "primary": {
                    "dept": "School of Design",
                    "institution": "Northumbria University",
                    "city": "Newcastle upon Tyne",
                    "state": "Tyne and Wear",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth26124",
                "givenName": "Clare",
                "familyName": "Hooper",
                "email": "cjh06r@ecs.soton.ac.uk",
                "primary": {
                    "dept": "Electronics & Computer Science",
                    "institution": "University of Southampton",
                    "city": "Southampton",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth8832",
                "givenName": "Aaron",
                "familyName": "Houssian",
                "email": "aaronh@gmail.com",
                "primary": {
                    "institution": "Philips Research",
                    "city": "Eindhoven",
                    "country": "The Netherlands"
                },
                "secondary": {
                    "institution": "Delft University of Technology",
                    "city": "Delft",
                    "country": "The Netherlands"
                }
            }
        ]
    },
    {
        "id": 492,
        "name": "Visions and Visioning in CHI: CHI 2013 Special Interest Group Meeting",
        "type": "SIG",
        "abstract": "There are many visions that touch on the future of human computer interaction from a trans-human future to a post-technological UI. However visions related to the progress of technology are not new. Creative and insightful visionaries from Denis Diderot to Vannevar Bush have been postulating visions of possible futures or technology for centuries. Some idealised views end up discredited with advances in knowledge, while others now appear remarkably prescient. The question is, do visions and the process of creating them have a place in CHI, or are they simply flights of fancy? \\  \\ This SIG meeting provides a forum for visionaries; researchers and practitioners looking to consider the place and importance of visions within CHI. Can visions, the process of visioning and forming new visions help us refine, advance or develop new research or forms of interaction. And if visions are important to us, then are they part of the regular academic process? If so, should CHI provide venues for publishing new visions? \\  \\ ",
        "bookmarks": 53,
        "keywords": [
            "Visions",
            "Visioning "
        ],
        "communities": [],
        "video": "si0109-file3.mp4",
        "session": {
            "id": "s166",
            "name": "Visions and Visioning in CHI"
        },
        "room": "362/363",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth17243",
                "givenName": "Aaron",
                "familyName": "Quigley",
                "email": "aquigley@st-andrews.ac.uk",
                "primary": {
                    "dept": "School of Computer Science",
                    "institution": "University of St Andrews",
                    "city": "St Andrews",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth5257",
                "givenName": "Alan",
                "familyName": "Dix",
                "email": "alan@hcibook.com",
                "primary": {
                    "dept": "School of Computer Science",
                    "institution": "University of Birmingham",
                    "city": "Birmingham",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth1688",
                "givenName": "Wendy",
                "familyName": "Mackay",
                "email": "mackay@lri.fr",
                "primary": {
                    "institution": "INRIA",
                    "city": "Paris",
                    "country": "France"
                }
            },
            {
                "id": "auth2008",
                "givenName": "Hiroshi",
                "familyName": "Ishii",
                "email": "ishii@media.mit.edu",
                "primary": {
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth9521",
                "givenName": "Jürgen",
                "familyName": "Steimle",
                "email": "steimle@media.mit.edu",
                "primary": {
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 493,
        "name": "Automotive User Interface Research Moves into Fast Lane",
        "type": "SIG",
        "abstract": "This SIG will explore issues related to the design of in-vehicle human-computer interfaces. A modern vehicle’s human-computer interface often facilitates the basic operation of the vehicle, but also provides more advanced features, such as assistive cruise control and lane keeping. Furthermore, today’s drivers and passengers frequently use brought-in devices, in order to access navigation instructions, and use non-driving related types of digital information such as social media. The SIG will explore how in-vehicle interfaces can facilitate safe interactions for all of the occupants of the vehicle, and how they can take advantage of connected vehicle technologies. ",
        "bookmarks": 25,
        "keywords": [
            "Automotive Industry",
            "Cars",
            "Vehicular Information Systems",
            "Car Entertainment",
            "Driver Information Systems",
            "Driver Interaction",
            "Special Interest Group"
        ],
        "communities": [
            "design",
            "engineering",
            "ux",
            "games"
        ],
        "session": {
            "id": "s167",
            "name": "Automotive User Interface Research Moves into Fast Lane"
        },
        "room": "362/363",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth7363",
                "givenName": "Susanne",
                "familyName": "Boll",
                "email": "susanne.boll@informatik.uni-oldenburg.de",
                "primary": {
                    "dept": "Computer Science",
                    "institution": "University of Oldenburg",
                    "city": "Oldenburg",
                    "country": "Germany"
                }
            },
            {
                "id": "auth5504",
                "givenName": "Andrew",
                "familyName": "Kun",
                "email": "andrew.kun@unh.edu",
                "primary": {
                    "institution": "University of New Hampshire",
                    "city": "Durham",
                    "state": "New Hampshire",
                    "country": "United States"
                }
            },
            {
                "id": "auth5227",
                "givenName": "Peter",
                "familyName": "Fröhlich",
                "email": "froehlich@ftw.at",
                "primary": {
                    "institution": "FTW Telecommunications Research Center",
                    "city": "Vienna",
                    "state": "Vienna",
                    "country": "Austria"
                }
            },
            {
                "id": "auth34996",
                "givenName": "James",
                "familyName": "Foley",
                "email": "james.foley@tema.toyota.com",
                "primary": {
                    "dept": "Collaborative Safety Research Center",
                    "institution": "Toyota Technical Center U.S.A, Inc.",
                    "city": "Woodridge",
                    "state": "Michigan",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 494,
        "name": "CHI 2013 Human Work Interaction Design (HWID) SIG: Past History and Future Challenges",
        "type": "SIG",
        "abstract": "In this SIG we aim to introduce the IFIP 13.6 Human Work Interaction Design (HWID) approach to the CHI audience. The HWID working group aims at establishing relationships between extensive empirical work-domain studies and HCI design. We invite participants from industry and academia with an interest on empirical work analysis, HCI, interaction design and usability and user experience in work situations and in the workplace. This SIG is a vital step towards creating a CHI2014 workshop on this topic.",
        "bookmarks": 154,
        "keywords": [
            "contextual analysis",
            "human work analysis",
            "human work interaction design",
            "interaction design",
            "work analysis",
            "work-domain based empirical studies"
        ],
        "communities": [
            "design",
            "engineering",
            "management",
            "ux"
        ],
        "video": "si0112-file3.mp4",
        "session": {
            "id": "s168",
            "name": "CHI 2013 Human Work Interaction Design (HWID) SIG: Past History and Future Challenges"
        },
        "room": "362/363",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth2091",
                "givenName": "Torkil",
                "familyName": "Clemmensen",
                "email": "tc.itm@cbs.dk",
                "primary": {
                    "institution": "Copenhagen Business School",
                    "city": "Frederiksberg",
                    "country": "Denmark"
                }
            },
            {
                "id": "auth5675",
                "givenName": "Pedro",
                "familyName": "Campos",
                "email": "pcampos@uma.pt",
                "primary": {
                    "institution": "University of Madeira",
                    "city": "Funchal",
                    "country": "Portugal"
                }
            },
            {
                "id": "auth27488",
                "givenName": "Dinesh",
                "familyName": "Katre",
                "email": "dineshkatre@yahoo.co.in",
                "primary": {
                    "institution": "C-DAC",
                    "city": "Pune",
                    "state": "Maharashtra",
                    "country": "India"
                }
            },
            {
                "id": "auth21227",
                "givenName": "Jose",
                "familyName": "Nocera",
                "email": "jose.abdelnour-nocera@uwl.ac.uk",
                "primary": {
                    "institution": "University of West London",
                    "city": "london",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth21967",
                "givenName": "Arminda",
                "familyName": "Lopes",
                "email": "aglopes@ipcb.pt",
                "primary": {
                    "institution": "Instituto Politecnico de Castelo Branco",
                    "city": "Castelo Branco",
                    "country": "Portugal"
                }
            },
            {
                "id": "auth19268",
                "givenName": "Rikke",
                "familyName": "Orngreen",
                "email": "rior@dpu.dk",
                "primary": {
                    "institution": "Aarhus University",
                    "city": "Aarhus",
                    "country": "Denmark"
                }
            },
            {
                "id": "auth1261",
                "givenName": "Shailey",
                "familyName": "Minocha",
                "email": "shailey.minocha@open.ac.uk",
                "primary": {
                    "dept": "Centre for Research in Computing",
                    "institution": "The Open University",
                    "city": "Milton Keynes",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 495,
        "name": "Science vs. Science: the Complexities of Interdisciplinary Research",
        "type": "SIG",
        "abstract": "Human-Computer Interaction and Web Science are radically interdisciplinary fields, but what does this mean in practical terms? Undertaking research (and writing papers) that encompass multiple disciplinary perspectives and methods is a serious challenge and it is difficult to maintain conferences that fairly review and host contributions from multiple disciplines. \\  \\ The colocation of the ACM WebSci conference with CHI in Paris, offers an unusual opportunity to bring these two communities together. Previous discussions have considered how to conduct interdisciplinary work that bridges HCI/WebSci with specific areas. Our objective is to provide a space for interested researchers from both communities to share their views and approaches to tackling the tensions and complexities associated with interdisciplinary work, whatever fields are being bridged.",
        "bookmarks": 114,
        "keywords": [
            "Interdisciplinary work",
            "multiple epistemologies",
            "methodology"
        ],
        "communities": [
            "design",
            "ux",
            "arts"
        ],
        "video": "si0113-file3.mp4",
        "session": {
            "id": "s173",
            "name": "Science vs. Science: the Complexities of Interdisciplinary Research"
        },
        "room": "362/363",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth26124",
                "givenName": "Clare",
                "familyName": "Hooper",
                "email": "cjh06r@ecs.soton.ac.uk",
                "primary": {
                    "dept": "Electronics and Computer Science",
                    "institution": "University of Southampton",
                    "city": "Southampton",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth10059",
                "givenName": "David",
                "familyName": "Millard",
                "email": "dem@soton.ac.uk",
                "primary": {
                    "dept": "Electronics and Computer Science",
                    "institution": "University of Southampton",
                    "city": "Southampton",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth9911",
                "givenName": "Jill",
                "familyName": "Fantauzzacoffin",
                "email": "jill@gatech.edu",
                "primary": {
                    "dept": "Digital Media Department ",
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            },
            {
                "id": "auth3442",
                "givenName": "Joseph 'Jofish'",
                "familyName": "Kaye",
                "email": "jofish@jofish.com",
                "primary": {
                    "institution": "Yahoo! Research",
                    "city": "Sunnyvale",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 496,
        "name": "HCI for Peace Ideathon",
        "type": "SIG",
        "abstract": "Computers are increasingly mediating the way people make decisions, including those that can have an effect on conflict and peace. In addition, recent research provides empirical data on the factors that affect the likelihood of armed conflict. These conditions provide an unprecedented opportunity to the human-computer interaction community to play a role in preventing, de-escalating, and recovering from conflicts. This SIG will be the first opportunity for CHI attendees to meet during the main part of the conference, share their ideas, and provide concrete ways to move forward with this line of research.",
        "bookmarks": 94,
        "keywords": [
            "Peace",
            "conflict",
            "social media",
            "mobile devices."
        ],
        "communities": [],
        "video": "si0114-file3.mp4",
        "session": {
            "id": "s171",
            "name": "HCI for Peace Ideathon"
        },
        "room": "362/363",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth1924",
                "givenName": "Juan Pablo",
                "familyName": "Hourcade",
                "email": "hourcade@cs.uiowa.edu",
                "primary": {
                    "institution": "University of Iowa",
                    "city": "Iowa City",
                    "state": "Iowa",
                    "country": "United States"
                }
            },
            {
                "id": "auth8695",
                "givenName": "Lisa",
                "familyName": "Nathan",
                "email": "lisa.nathan@ubc.ca",
                "primary": {
                    "institution": "University of British Columbia",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            },
            {
                "id": "auth1330",
                "givenName": "Panayiotis",
                "familyName": "Zaphiris",
                "email": "panayiotis.zaphiris@cut.ac.cy",
                "primary": {
                    "institution": "Cyprus University of Technology",
                    "city": "Limassol",
                    "country": "Cyprus"
                }
            },
            {
                "id": "auth11842",
                "givenName": "Massimo",
                "familyName": "Zancanaro",
                "email": "zancana@fbk.eu",
                "primary": {
                    "institution": "FBK-irst",
                    "city": "Trento",
                    "state": "-",
                    "country": "Italy"
                }
            },
            {
                "id": "auth21532",
                "givenName": "Evangelos",
                "familyName": "Kapros",
                "email": "ekapros@tcd.ie",
                "primary": {
                    "institution": "Trinity College, The University of Dublin",
                    "city": "Dublin",
                    "country": "Ireland"
                }
            },
            {
                "id": "auth1074",
                "givenName": "John",
                "familyName": "Thomas",
                "email": "jcthomas@us.ibm.com",
                "primary": {
                    "institution": "IBM T. J. Watson Research ",
                    "city": "Yorktown Heights",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth1285",
                "givenName": "Daniela",
                "familyName": "Busse",
                "email": "daniela.busse@gmail.com",
                "primary": {
                    "dept": "SISA",
                    "institution": "Samsung",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 497,
        "name": "HCI with Sports",
        "type": "SIG",
        "abstract": "Recent advances in cheap sensor technology has made technology support for sports and physical exercise increasingly commonplace, which is evident from the growing popularity of heart rate monitors and GPS sports watches. This rise of technology to support sports activities raises many interaction issues, such as how to interact with these devices while moving and physically exerting. This special interest group brings together industry practitioners and researchers who are interested in designing and understanding human-computer interaction where the human is being physically active, engaging in exertion activities. Fitting with the theme, this special interest group will be “run” while running: participants will be invited to a jog together during which we will discuss technology interaction that is specific to being physically active whilst being physically active ourselves.",
        "bookmarks": 19,
        "keywords": [
            "Exertion interface",
            "exergames",
            "sports",
            "exercise"
        ],
        "communities": [
            "design",
            "health",
            "games"
        ],
        "video": "si0115-file3.mp4",
        "session": {
            "id": "s169",
            "name": "HCI with Sports"
        },
        "room": "361",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth2060",
                "givenName": "Florian",
                "familyName": "Mueller",
                "email": "floyd@floydmueller.com",
                "primary": {
                    "dept": "Exertion Games Lab",
                    "institution": "RMIT University",
                    "city": "Melbourne",
                    "country": "Australia"
                }
            },
            {
                "id": "auth10580",
                "givenName": "Rohit",
                "familyName": "Khot",
                "email": "rohit.a.khot@gmail.com",
                "primary": {
                    "dept": "Exertion Games Lab",
                    "institution": "RMIT University",
                    "city": "Melbourne",
                    "state": "Victoria",
                    "country": "Australia"
                }
            },
            {
                "id": "auth25990",
                "givenName": "Alan",
                "familyName": "Chatham",
                "email": "alan.chatham@gmail.com",
                "primary": {
                    "dept": "Exertion Games Lab",
                    "institution": "RMIT University ",
                    "city": "Melbourne",
                    "country": "Australia"
                },
                "secondary": {
                    "dept": "Human Computer Interaction Institute",
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            },
            {
                "id": "auth29369",
                "givenName": "Sebastiaan",
                "familyName": "Pijnappel",
                "email": "spijnappel@gmail.com",
                "primary": {
                    "dept": "Exertion Games Lab",
                    "institution": "RMIT University",
                    "city": "Melbourne",
                    "state": "Victoria",
                    "country": "Australia"
                }
            },
            {
                "id": "auth24086",
                "givenName": "Cagdas \"Chad\"",
                "familyName": "Toprak",
                "email": "chad@exertiongameslab.org",
                "primary": {
                    "institution": "RMIT University",
                    "city": "Melbourne",
                    "country": "Australia"
                }
            },
            {
                "id": "auth7924",
                "givenName": "Joe",
                "familyName": "Marshall",
                "email": "jqm@cs.nott.ac.uk",
                "primary": {
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 498,
        "name": "Changing Perspectives on Sustainability: Healthy Debate or Divisive Factions?",
        "type": "SIG",
        "abstract": "This year’s Sustainability SIG invites participants to apply the conference theme “changing perspectives” to sustainability research and practice within the human computer interaction community. As the number of sustainability-oriented endeavors in the field continues to grow, so does the number of critiques on the work undertaken. Perspectives continue to shift concerning how the HCI community “should” attend to the monumental ecosystem changes societies face in the coming decades. For such an enormous problem, is it best to concentrate our limited resources (time, money, people) on compatible approaches in order to build on each other’s findings? Do recent critiques risk sundering a nascent community of scholars? Or is it misguided to privilege a limited number of approaches to addressing a complex, problematic situation? ",
        "bookmarks": 162,
        "keywords": [
            "Sustainability",
            "Sustainability Community."
        ],
        "communities": [
            "sustainability"
        ],
        "video": "si0116-file3.mp4",
        "session": {
            "id": "s180",
            "name": "Changing Perspectives on Sustainability: Healthy Debate or Divisive Factions?"
        },
        "room": "362/363",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth1285",
                "givenName": "Daniela",
                "familyName": "Busse",
                "email": "daniela.busse@gmail.com",
                "primary": {
                    "institution": "Samsung",
                    "city": "San Jose",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth24223",
                "givenName": "Samuel",
                "familyName": "Mann",
                "email": "samuel.mann@op.ac.nz",
                "primary": {
                    "institution": "Otago Polytechnic",
                    "city": "Dunedin",
                    "country": "New Zealand"
                }
            },
            {
                "id": "auth8695",
                "givenName": "Lisa",
                "familyName": "Nathan",
                "email": "lisa.nathan@ubc.ca",
                "primary": {
                    "institution": "University of British Columbia",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            },
            {
                "id": "auth24484",
                "givenName": "Chris",
                "familyName": "Preist",
                "email": "cpreist@compsci.bristol.ac.uk",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Bristol",
                    "city": "Bristol",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 499,
        "name": "UrbanIXD :: Designing Human Interactions In The Networked City",
        "type": "SIG",
        "abstract": "Interaction Design, in an urban context, is an increasingly important field of research. City populations are currently in a state of rapid flux. Conurbations are fast becoming a hybrid of the physical environment and the digital datasphere. How we, as physical beings, will connect with, interpret and adapt this increasing dataflow residing in our cities is already becoming a significant research question. The SIG organisers will frame the discussion through a human–centred view of the concerns, experiences and behaviours that may occur in cities of the future. By adopting an approach of Thinking and Doing it is hoped that the SIG will act as a catalyst for community building.",
        "bookmarks": 9,
        "keywords": [
            "Urban Interaction Design"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "si0117-file3.mp4",
        "session": {
            "id": "s172",
            "name": "UrbanIXD :: Designing Human Interactions In The Networked City"
        },
        "room": "361",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth26337",
                "givenName": "Michael",
                "familyName": "Smyth",
                "email": "m.smyth@napier.ac.uk",
                "primary": {
                    "institution": "Edinburgh Napier University",
                    "city": "Edinburgh",
                    "state": "Midlothian",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth12184",
                "givenName": "Ingi",
                "familyName": "Helgason",
                "email": "i.helgason@napier.ac.uk",
                "primary": {
                    "institution": "Edinburgh Napier University",
                    "city": "Edinburgh",
                    "state": "Midlothian",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth10318",
                "givenName": "Martin",
                "familyName": "Brynskov",
                "email": "brynskov@imv.au.dk",
                "primary": {
                    "institution": "Aarhus University",
                    "city": "Aarhus",
                    "country": "Denmark"
                }
            },
            {
                "id": "auth31586",
                "givenName": "Ivica",
                "familyName": "Mitrovic",
                "email": "ivica@umas.hr",
                "primary": {
                    "dept": "Arts Academy",
                    "institution": "University of Split",
                    "city": "Split",
                    "country": "Croatia"
                }
            },
            {
                "id": "auth10879",
                "givenName": "Gianluca",
                "familyName": "Zaffiro",
                "email": "gianluca.zaffiro@telecomitalia.it",
                "primary": {
                    "institution": "Telecom Italia",
                    "city": "Turin",
                    "country": "Italy"
                }
            }
        ]
    },
    {
        "id": 500,
        "name": "The Role of Engineering Work in CHI",
        "type": "SIG",
        "abstract": "The Engineering community faces a number of issues around its role in the larger CHI community and its contribution to SIGCHI-sponsored conferences. This SIG aims to stimulate discussion and attention on the work of researchers interested in the engineering aspects of HCI. It is the forum to report progress on key issues, identify objectives for the near future, and develop plans to address them.",
        "bookmarks": 74,
        "keywords": [
            "Engineering HCI, User Interface Software and Technologies, Intelligent Interfaces"
        ],
        "communities": [
            "engineering"
        ],
        "video": "si0118-file3.mp4",
        "session": {
            "id": "s174",
            "name": "The Role of Engineering Work in CHI"
        },
        "room": "362/363",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth1060",
                "givenName": "Philippe",
                "familyName": "Palanque",
                "email": "palanque@irit.fr",
                "primary": {
                    "institution": "University of Toulouse",
                    "city": "Toulouse",
                    "country": "France"
                }
            },
            {
                "id": "auth1464",
                "givenName": "Fabio",
                "familyName": "Paternò",
                "email": "fabio.paterno@isti.cnr.it",
                "primary": {
                    "institution": "CNR-ISTI",
                    "city": "Pisa",
                    "country": "Italy"
                }
            },
            {
                "id": "auth2720",
                "givenName": "Jeffrey",
                "familyName": "Nichols",
                "email": "jwnichols@us.ibm.com",
                "primary": {
                    "institution": "IBM Research",
                    "city": "San Josè",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth4103",
                "givenName": "Nuno",
                "familyName": "Nunes",
                "email": "njn@uma.pt",
                "primary": {
                    "dept": "Madeira-ITI",
                    "institution": "University of Madeira",
                    "city": "Funchal",
                    "state": "Madeira",
                    "country": "Portugal"
                }
            },
            {
                "id": "auth1085",
                "givenName": "Brad",
                "familyName": "Myers",
                "email": "bam@cs.cmu.edu",
                "primary": {
                    "institution": "Carnegie Mellon University",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 501,
        "name": "On Top of the User Experience Wave – How is Our Work Changing?",
        "type": "SIG",
        "abstract": "The field of Human-Computer Interaction has evolved over three decades, from human factors and usability to user experience. But what has changed in practice, in the approaches and methods we use? Has anything changed other than the names of the teams within organizations? And what might be coming next? In this SIG, we discuss how the work of HCI professionals has changed over the years and explore the future of their work.",
        "bookmarks": 158,
        "keywords": [
            "User experience",
            "Usability",
            "Human factors"
        ],
        "communities": [
            "ux"
        ],
        "video": "si0122-file3.mp4",
        "session": {
            "id": "s175",
            "name": "On Top of the User Experience Wave – How is Our Work Changing?"
        },
        "room": "362/363",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth1950",
                "givenName": "Virpi",
                "familyName": "Roto",
                "email": "virpi.roto@aalto.fi",
                "primary": {
                    "institution": "Aalto University",
                    "city": "Helsinki",
                    "country": "Finland"
                }
            },
            {
                "id": "auth31324",
                "givenName": "Arnie",
                "familyName": "Lund",
                "email": "lund@ge.com",
                "primary": {
                    "institution": "GE Global Research",
                    "city": "San Ramon",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 502,
        "name": "Human Computer Interaction for Development (HCI4D)",
        "type": "SIG",
        "abstract": "We are proposing a SIG designed for Human-Computer Interaction for Development (HCI4D) Community. It is designed to foster further collaboration, dissemination of research results and findings from practitioners, as well as to promote discussion of how we can both learn from each other and from those we serve in underserved communities wherever they may be.",
        "bookmarks": 59,
        "keywords": [
            "HCI4D",
            "International Development",
            "ICT4D,UCD4ID",
            "Community Design",
            "Participatory Design",
            "HCD4D."
        ],
        "communities": [
            "ux",
            "sustainability",
            "cci",
            "hci4d"
        ],
        "video": "si0123-file3.mp4",
        "session": {
            "id": "s176",
            "name": "Human Computer Interaction for Development (HCI4D)"
        },
        "room": "362/363",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth11397",
                "givenName": "Ban",
                "familyName": "Al-Ani",
                "email": "balani@ics.uci.edu",
                "primary": {
                    "institution": "University of California, Irvine",
                    "city": "Irvine",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth10458",
                "givenName": "Melissa",
                "familyName": "Densmore",
                "email": "mho@ischool.berkeley.edu",
                "primary": {
                    "dept": "Technology for Emerging Markets",
                    "institution": "Microsoft Research India",
                    "city": "Bangalore ",
                    "country": "India"
                }
            },
            {
                "id": "auth1287",
                "givenName": "Edward",
                "familyName": "Cutrell",
                "email": "cutrell@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research India",
                    "city": "Bangalore",
                    "state": "Karnataka",
                    "country": "India"
                }
            },
            {
                "id": "auth1041",
                "givenName": "Rebecca",
                "familyName": "Grinter",
                "email": "beki@cc.gatech.edu",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            },
            {
                "id": "auth1074",
                "givenName": "John",
                "familyName": "Thomas",
                "email": "jcthomas@us.ibm.com",
                "primary": {
                    "institution": "IBM T. J. Watson Research ",
                    "city": "Yorktown Heights",
                    "state": "New York",
                    "country": "United States"
                }
            },
            {
                "id": "auth2902",
                "givenName": "Andy",
                "familyName": "Dearden",
                "email": "a.m.dearden@shu.ac.uk",
                "primary": {
                    "institution": "Sheffield Hallam University",
                    "city": "Sheffield",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth3375",
                "givenName": "Matthew",
                "familyName": "Kam",
                "email": "kam.matt@gmail.com",
                "primary": {
                    "dept": "International Development Program",
                    "institution": "American Institutes for Research",
                    "city": "Washington",
                    "state": "D.C.",
                    "country": "United States"
                }
            },
            {
                "id": "auth16276",
                "givenName": "Anicia",
                "familyName": "Peters",
                "email": "anpeters@iastate.edu",
                "primary": {
                    "institution": "Iowa State University",
                    "city": "Ames",
                    "state": "Iowa",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 503,
        "name": "Digital Art: Challenging Perspectives",
        "type": "SIG",
        "abstract": "In this SIG for the Digital Arts Community, we respond to the conference theme of changing perspectives by offering challenging perspectives. The challenge comes in a two-way exchange between Digital Art and HCI. On the one side we have the making of new and unique forms, i.e. synthesis. Whilst on the other, we have knowledge-making grounded in the human sciences and engineering, in other words, predicting and validating analysis. In this SIG session we will provoke a discussion on these contrasting challenging perspectives. How does knowledge emerge between synthesis and analysis?",
        "bookmarks": 109,
        "keywords": [
            "Digital Art",
            "Evaluation",
            "Critique"
        ],
        "communities": [
            "arts"
        ],
        "video": "si0124-file3.mp4",
        "session": {
            "id": "s179",
            "name": "Digital Art: Challenging Perspectives"
        },
        "room": "362/363",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth1240",
                "givenName": "David",
                "familyName": "England",
                "email": "d.england@ljmu.ac.uk",
                "primary": {
                    "institution": "Liverpool John Moores University",
                    "city": "Liverpool",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth9911",
                "givenName": "Jill",
                "familyName": "Fantauzzacoffin",
                "email": "jill@gatech.edu",
                "primary": {
                    "dept": "Digital Media Department ",
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            },
            {
                "id": "auth3338",
                "givenName": "Thecla",
                "familyName": "Schiphorst",
                "email": "thecla@sfu.ca",
                "primary": {
                    "institution": "Simon Fraser University",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                }
            },
            {
                "id": "auth3848",
                "givenName": "Celine",
                "familyName": "Latulipe",
                "email": "clatulip@uncc.edu",
                "primary": {
                    "institution": "University of North Carolina at Charlotte",
                    "city": "Charlotte",
                    "state": "North Carolina",
                    "country": "United States"
                }
            },
            {
                "id": "auth5214",
                "givenName": "Linda",
                "familyName": "Candy",
                "email": "linda@lindacandy.com",
                "primary": {
                    "institution": "University of Technology, Sydney",
                    "city": "Sydney",
                    "country": "Australia"
                }
            }
        ]
    },
    {
        "id": 504,
        "name": "Enhancing the Research Infrastructure for Child-Computer Interaction",
        "type": "SIG",
        "abstract": "The child-computer interaction community has been steadily adding research infrastructure over the past 20 years through books, the Interaction Design and Children conference, being a featured community at CHI, through an official IFIP group, and more recently through a journal. In this SIG we will discuss the next steps to further strengthen the research infrastructure in this research community with the goals of improving the quality of the research, enhancing research resources, and increasing the impact of the field in industry and education.",
        "bookmarks": 7,
        "keywords": [
            "Children",
            "research infrastructure",
            "community."
        ],
        "communities": [
            "cci"
        ],
        "video": "si0125-file3.mp4",
        "session": {
            "id": "s177",
            "name": "Enhancing the Research Infrastructure for Child-Computer Interaction"
        },
        "room": "362/363",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth2823",
                "givenName": "Janet C",
                "familyName": "Read",
                "email": "jcread@uclan.ac.uk",
                "primary": {
                    "institution": "University of Central Lancashire",
                    "city": "Preston",
                    "state": "Lancashire",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth1924",
                "givenName": "Juan Pablo",
                "familyName": "Hourcade",
                "email": "hourcade@cs.uiowa.edu",
                "primary": {
                    "institution": "University of Iowa",
                    "city": "Iowa City",
                    "state": "Iowa",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 505,
        "name": "Managing UX Teams",
        "type": "SIG",
        "abstract": "This SIG will serve two purposes:  as a forum to share the results from previous CHI management workshops and current trends, and also as a forum for the management community to discuss topics of interest.",
        "bookmarks": 1,
        "keywords": [
            "User Experience",
            "Management",
            "Organizations",
            "Design",
            "Research",
            "Practice",
            "Method",
            "Technique"
        ],
        "communities": [
            "management",
            "ux"
        ],
        "session": {
            "id": "s178",
            "name": "Managing UX Teams"
        },
        "room": "362/363",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth13615",
                "givenName": "Janice",
                "familyName": "Rohn",
                "email": "janicerohn@yahoo.com",
                "primary": {
                    "institution": "Leads360",
                    "city": "El Segundo",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth14979",
                "givenName": "Carola",
                "familyName": "Thompson",
                "email": "carolafthompson@gmail.com",
                "primary": {
                    "institution": "zSpace",
                    "city": "Sunnyvale",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 506,
        "name": "Consumer Engagement in Health Technologies Special Interest Group",
        "type": "SIG",
        "abstract": "How do we keep consumers engaged in using health technologies?  We welcome all researchers and practitioners who are interested in this question to join us for a spirited discussion, hosted by the CHI Health Community.",
        "bookmarks": 112,
        "keywords": [
            "Health",
            "Medicine",
            "Wellness",
            "Fitness",
            "Health Informatics"
        ],
        "communities": [
            "health"
        ],
        "video": "si0128-file3.mp4",
        "session": {
            "id": "s181",
            "name": "Consumer Engagement in Health Technologies Special Interest Group"
        },
        "room": "361",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth14539",
                "givenName": "Karen",
                "familyName": "Cheng",
                "email": "kgcheng@uci.edu",
                "primary": {
                    "institution": "University of California, Irvine",
                    "city": "Irvine",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth7579",
                "givenName": "Kelly",
                "familyName": "Caine",
                "email": "caine@clemson.edu",
                "primary": {
                    "dept": "School of Computing",
                    "institution": "Clemson University",
                    "city": "Clemson",
                    "state": "South Carolina",
                    "country": "United States"
                }
            },
            {
                "id": "auth1589",
                "givenName": "Wanda",
                "familyName": "Pratt",
                "email": "wpratt@uw.edu",
                "primary": {
                    "dept": "The Information School",
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                },
                "secondary": {
                    "dept": "Department of Biomedical Informatics and Medical Education",
                    "institution": "University of Washington",
                    "city": "Seattle",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth8281",
                "givenName": "Kay",
                "familyName": "Connelly",
                "email": "connelly@indiana.edu",
                "primary": {
                    "institution": "Indiana University Bloomington",
                    "city": "Bloomington",
                    "state": "Indiana",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 507,
        "name": "The Impact of Interface Affordances on Human Ideation, Problem Solving and Inferential Reasoning",
        "type": "TOCHI",
        "abstract": "Two studies investigated how computer interface affordances influence basic cognition, including ideational fluency, problem solving, and inferential reasoning. In one study comparing interfaces with different input capabilities, students expressed 56% more nonlinguistic representations (diagrams, symbols, numbers) when using pen interfaces. A linear regression confirmed that nonlinguistic communication directly mediated a substantial increase (38.5%) in students’ ability to produce appropriate science ideas. In contrast, students expressed 41% more linguistic content when using a keyboard-based interface, which mediated a drop in science ideation. A follow-up study pursued the question of how interfaces that prime nonlinguistic communication so effectively facilitate cognition. This study examined the relation between students’ expression of nonlinguistic representations and their inference accuracy when using analogous digital and non-digital pen tools. Perhaps surprisingly, the digital pen interface stimulated construction of more diagrams, more correct Venn diagrams, and more accurate domain inferences. Students’ construction of multiple diagrams to represent a problem also directly suppressed overgeneralization errors, the most common inference failure. These research results reveal that computer interfaces have communications affordances, which elicit communication patterns that can substantially stimulate or impede basic cognition. Implications are discussed for designing new digital tools for thinking, with an emphasis on nonlinguistic and especially spatial representations that are most poorly supported by current keyboard-based interfaces. ",
        "cbStatement": "Computer input capabilities have communications affordances that can substantially facilitate people’s ability to produce ideas, solve problems correctly, and make accurate inferences about information, with the magnitude of improvement 9-38%.",
        "bookmarks": 115,
        "keywords": [
            "Pen interfaces",
            "Educational interfaces",
            "Affordances",
            "Thinking tools",
            ""
        ],
        "communities": [
            "design"
        ],
        "session": {
            "id": "s217",
            "name": "Design Ideation Methods"
        },
        "room": "342a",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth1170",
                "givenName": "Sharon",
                "middleInitial": "L.",
                "familyName": "Oviatt",
                "email": "oviatt@incaadesigns.org",
                "primary": {
                    "institution": "Incaa Designs",
                    "city": "Winslow",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth32638",
                "givenName": "Adrienne",
                "familyName": "Cohen",
                "email": "adrienne.o.cohen@gmail.com",
                "primary": {
                    "institution": "Duke University",
                    "city": "Durham",
                    "state": "North Carolina",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth32639",
                "givenName": "Andrea",
                "familyName": "Miller",
                "email": "afroasianpoet@gmail.com",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth32640",
                "givenName": "Kumi",
                "familyName": "Hodge",
                "email": "khodge@stanford.edu",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth32641",
                "givenName": "Ariana",
                "familyName": "Mann",
                "email": "mann@mit.edu",
                "primary": {
                    "institution": "Massachusetts Institute of Technology",
                    "city": "Cambridge",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 508,
        "name": "Two-Part Models Capture the Impact of Gain on Pointing Performance",
        "type": "TOCHI",
        "abstract": "We establish that two-part models of pointing performance (Welford’s model) describe pointing on a computer display signiﬁcantly better than traditional one-part models (Fitts’s Law). We explore the space of pointing models and describe how independent contributions of movement amplitude and target width to pointing time can be captured in a parameter k. Through a reanalysis of data from related work we demonstrate that one-part formulations are fragile in describing pointing performance, and that this fragility is present for various devices and techniques. We show that this same data can be signiﬁcantly better described using two-part models. Finally, we demonstrate through further analysis of previous work and new experimental data that k increases linearly with gain. Our primary contribution is the demonstration that Fitts’s Law is more limited in applicability than previously appreciated, and that more robust models, such as Welford’s formulation, should be adopted in many cases of practical interest.",
        "cbStatement": "The paper provides empirical evidence of limitations in Fitts's Law and demonstrates how a two-part formulation by Welford's provides a model that naturally takes into account control-display gain.",
        "bookmarks": 142,
        "keywords": [
            "Fitts;Welford;gain;interaction techniques;large displays;pointing"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "session": {
            "id": "s252",
            "name": "Pointing and Fitts Law"
        },
        "room": "241",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth27909",
                "givenName": "Garth",
                "familyName": "Shoemaker",
                "email": "garths@cs.ubc.ca",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of British Columbia",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "role": "presenter"
            },
            {
                "id": "auth17533",
                "givenName": "Takayuki",
                "familyName": "Tsukitani",
                "email": "tsukitani.takayuki@ist.osaka-u.ac.jp",
                "primary": {
                    "institution": "Osaka University",
                    "city": "Osaka",
                    "country": "Japan"
                }
            },
            {
                "id": "auth1879",
                "givenName": "Yoshifumi",
                "familyName": "Kitamura",
                "email": "kitamura@riec.tohoku.ac.jp",
                "primary": {
                    "institution": "Tohoku University",
                    "city": "Sendai",
                    "country": "Japan"
                }
            },
            {
                "id": "auth1965",
                "givenName": "Kellogg",
                "middleInitial": "S.",
                "familyName": "Booth",
                "email": "ksbooth@cs.ubc.ca",
                "primary": {
                    "institution": "University of British Columbia",
                    "city": "Vancouver",
                    "state": "British Columbia",
                    "country": "Canada"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 509,
        "name": "What Does Touch Tell Us About Emotions in Touchscreen-Based Gameplay?",
        "type": "TOCHI",
        "abstract": "The increasing number of people playing games on touch-screen mobile phones raises the question of whether touch behaviours reflect players’ emotional states. This prospect would not only be a valuable evaluation indicator for game designers, but also for real-time personalization of the game experience. Psychology studies on acted touch behaviour show the existence of discriminative affective profiles. In this paper, finger-stroke features during gameplay on an iPod were extracted and their discriminative power analysed. Machine learning algorithms were used to build systems for automatically discriminating between four emotional states (Excited, Relaxed, Frustrated, Bored), two levels of arousal and two levels of valence. Accuracy reached between 69% and 77% for the four emotional states, and higher results (~89%) were obtained for discriminating between two levels of arousal and two levels of valence. We conclude by discussing the factors relevant to the generalization of the results to applications other than games.",
        "cbStatement": "The paper contributes a method to automatically recognize users’ emotional states from their touch behaviour in touch-based computer games.  It also discusses its generalization to other types of applications. ",
        "bookmarks": 1,
        "keywords": [
            "Automatic emotion recognition, affective touch, touch, touch-based computer games"
        ],
        "communities": [
            "ux",
            "games"
        ],
        "video": "to0102-file1.mp4",
        "session": {
            "id": "s290",
            "name": "Technologies for Life 2"
        },
        "room": "242ab",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth32642",
                "givenName": "Yuan",
                "familyName": "Gao",
                "email": "gaoyuan0117@gmail.com",
                "primary": {
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth7706",
                "givenName": "Nadia",
                "familyName": "Bianchi-Berthouze",
                "email": "n.berthouze@ucl.ac.uk",
                "primary": {
                    "institution": "University College London",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth24132",
                "givenName": "Hongying",
                "familyName": "Meng",
                "email": "hongying.meng@brunel.ac.uk",
                "primary": {
                    "institution": "Brunel University",
                    "city": "London",
                    "state": "Middlesex",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 510,
        "name": "Embodied Cognition And The Magical Future Of Interaction Design",
        "type": "TOCHI",
        "abstract": "The theory of embodied cognition can provide HCI practitioners and theorists with new ideas about interaction and new principles for better designs.  I support this claim with four ideas about cognition: 1) interacting with tools changes the way we think and perceive – tools, when manipulated, are soon absorbed into the body schema, and this absorption leads to fundamental changes in the way we perceive and conceive of our environments; 2) we think with our bodies not just with our brains; 3) we know more by doing than by seeing – there are times when physically performing an activity is better than watching someone else perform the activity, even though our motor resonance system fires strongly during other person observation; 4) there are times when we literally think with things.  These four ideas have major implications for interaction design, especially the design of tangible, physical, context aware, and telepresence systems.",
        "cbStatement": "Explores what world-class choreography and dance teaches us about embodied cognition & creativity.  Explains how bodies absorb tools and how bodies and things are used for thinking.   ",
        "bookmarks": 123,
        "keywords": [
            "Embodied Cognition",
            " Interaction",
            "Distributed Cognition",
            "Tangible Interfaces "
        ],
        "communities": [
            "design"
        ],
        "session": {
            "id": "s213",
            "name": "Embodied Interaction (and Thinking) Design"
        },
        "room": "251",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth4629",
                "givenName": "David",
                "familyName": "Kirsh",
                "email": "kirsh@ucsd.edu",
                "primary": {
                    "institution": "University of California, San Diego",
                    "city": "San Diego",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 511,
        "name": "\"Without the Clutter of Unimportant Words\": Descriptive Keyphrases for Text Visualization",
        "type": "TOCHI",
        "abstract": "Keyphrases aid the exploration of text collections by communicating salient aspects of documents and are often used to create effective visualizations of text. While prior work in HCI and visualization has proposed a variety of ways of presenting keyphrases, less attention has been paid to selecting the best descriptive terms. In this article, we investigate the statistical and linguistic properties of keyphrases chosen by human judges and determine which features are most predictive of high-quality descriptive phrases. Based on 5,611 responses from 69 graduate students describing a corpus of dissertation abstracts, we analyze characteristics of human-generated keyphrases, including phrase length, commonness, position, and part of speech. Next, we systematically assess the contribution of each feature within statistical models of keyphrase quality. We then introduce a method for grouping similar terms and varying the specificity of displayed phrases so that applications can select phrases dynamically based on the available screen space and current context of interaction. Precision-recall measures find that our technique generates keyphrases that match those selected by human judges. Crowdsourced ratings of tag cloud visualizations rank our approach above other automatic techniques. Finally, we discuss the role of HCI methods in developing new algorithmic techniques suitable for user-facing applications.",
        "cbStatement": "We study how people summarize text using descriptive phrases, develop a novel algorithm for extracting keyphrases, and demonstrate how our algorithms enable novel text visualization designs.",
        "bookmarks": 59,
        "keywords": [
            "keyphrases",
            "visualization",
            "interaction",
            "text summarization"
        ],
        "communities": [],
        "session": {
            "id": "s233",
            "name": "Text Visualization"
        },
        "room": "bordeaux",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth16428",
                "givenName": "Jason",
                "familyName": "Chuang",
                "email": "jcchuang@cs.stanford.edu",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth17166",
                "givenName": "Christopher",
                "middleInitial": "D",
                "familyName": "Manning",
                "email": "manning@cs.stanford.edu",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth2167",
                "givenName": "Jeffrey",
                "familyName": "Heer",
                "email": "jheer@cs.stanford.edu",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 512,
        "name": "Designing a Multi-Slate Reading Environment to Support Active Reading Activities",
        "type": "TOCHI",
        "abstract": "Despite predictions of the paperless office, most knowledge workers and students still rely heavily on paper in most of their document practices. Research has shown that paper's dominance can be attributed to the fact that it supports a broad range of these users' diverse reading requirements. Our analysis of the literature suggests that a new class of reading device consisting of an interconnected environment of thin and lightweight electronic slates could potentially unify the distinct advantages of e-books, PCs, and tabletop computers to offer an electronic reading solution providing functionality comparable to, or even exceeding, that of paper. This article presents the design and construction of such a system. In it, we explain how data can be mapped to slates, detail interactions for linking the slates, and describe tools that leverage the connectivity between slates. A preliminary study of the system indicates that such a system has the potential of being an electronic alternative to paper.",
        "cbStatement": "Researchers have identified numerous requirements for systems aiming to support active reading. We survey these requirements and present interactions for a multi-slate reading environment that address them in a comprehensive manner.",
        "bookmarks": 180,
        "keywords": [
            "e-reading",
            "multiple slates",
            "tablets",
            "active reading",
            " distributed user interface"
        ],
        "communities": [],
        "video": "to0105-file1.mp4",
        "session": {
            "id": "s218",
            "name": "Multi-device Interaction"
        },
        "room": "352ab",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth6000",
                "givenName": "Nicholas",
                "middleInitial": "Y",
                "familyName": "Chen",
                "email": "nchen@microsoft.com",
                "primary": {
                    "institution": "University of Maryland",
                    "city": "College Park",
                    "state": "Maryland",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth1483",
                "givenName": "François",
                "middleInitial": "V",
                "familyName": "Guimbretière",
                "email": "francois@cs.cornell.edu",
                "primary": {
                    "institution": "Cornell University",
                    "city": "Ithaca",
                    "state": "NY",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1515",
                "givenName": "Abigail",
                "middleInitial": "J",
                "familyName": "Sellen",
                "email": "asellen@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 513,
        "name": "All you Need is Love: Current Strategies of Mediating Intimate Relationships through Technology",
        "type": "TOCHI",
        "abstract": "A wealth of evidence suggests that love, closeness, and intimacy — in short relatedness—are important for people’s psychological well-being. Nowadays, however, couples are often forced to live apart. Accordingly, there has been a growing and flourishing interest in designing technologies that mediate (and create) a feeling of relatedness when being separated, beyond the explicit verbal communication and simple emoticons available technologies offer. This article provides a review of 143 published artifacts (i.e., design concepts, technologies). Based on this, we present six strategies used by designers/researchers to create a relatedness experience: Awareness, expressivity, physicalness, gift giving, joint action, and memories. We understand those strategies as starting points for the experience-oriented design of technology.",
        "cbStatement": "There is a growing interest in creating a \"relatedness\" experience through technology. Our review of 143 artifacts revealed six strategies designer/researcher use: Awareness, expressivity, physicalness, gift giving, joint action, memories.",
        "bookmarks": 186,
        "keywords": [
            "Experience design",
            "emotional communication",
            "intimate relationships",
            "relatedness",
            "interaction design",
            "review",
            "long-distance relationships"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "to0106-file1.mp4",
        "session": {
            "id": "s212",
            "name": "Designs on Design 2: Exploring Design Approaches and Constructs"
        },
        "room": "bordeaux",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth16094",
                "givenName": "Marc",
                "familyName": "Hassenzahl",
                "email": "marc.hassenzahl@folkwang-uni.de",
                "primary": {
                    "institution": "Folkwang University of the Arts",
                    "city": "Essen",
                    "country": "Germany"
                },
                "role": "presenter"
            },
            {
                "id": "auth32648",
                "givenName": "Stephanie",
                "familyName": "Heidecker",
                "email": "stephanie.heidecker@folkwang-uni.de",
                "primary": {
                    "institution": "Folkwang University of the Arts",
                    "city": "Essen",
                    "country": "Germany"
                }
            },
            {
                "id": "auth23061",
                "givenName": "Kai",
                "familyName": "Eckoldt",
                "email": "kai.eckoldt@folkwang-uni.de",
                "primary": {
                    "institution": "Folkwang University of the Arts",
                    "city": "Essen",
                    "country": "Germany"
                }
            },
            {
                "id": "auth9991",
                "givenName": "Sarah",
                "familyName": "Diefenbach",
                "email": "sarah.diefenbach@folkwang-uni.de",
                "primary": {
                    "institution": "Folkwang University of the Arts",
                    "city": "Essen",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth32647",
                "givenName": "Uwe",
                "familyName": "Hillmann",
                "email": "uwe.hillmann@telekom.de",
                "primary": {
                    "dept": "User Driven Innovation",
                    "institution": "Telekom Innovation Laboratories",
                    "city": "Berlin",
                    "country": "Germany"
                }
            }
        ]
    },
    {
        "id": 514,
        "name": "Enabling the Blind to See Gestures",
        "type": "TOCHI",
        "abstract": "Human embodied discourse involves gesture and speech. Mathematics instruction involves communication using speech and graphical presentation. Vision gives sighted students `embodiment awareness' to keep communication situated between visual material and speech. For blind students, haptic fingertip reading of embossed material can replace visual material. We developed a  Haptic Deictic System to furnish blind students with awareness of the instructor’s deictic gestures. Our studies show that the HDS can support learning in inclusive classrooms comprising both blind and sighted students. We developed analysis methodologies to ascertain how theHDS supports embodied discourse. The HDS was advantageous to all parties increasing learning opportunities, mutual understanding and engagement. \\ ",
        "cbStatement": " \\ Our contributions are on the understanding of how gestural interaction may be designed as part of a multimodal system and on applying Durish's embodiment theory to solving practical issues. \\ ",
        "bookmarks": 112,
        "keywords": [
            "Assistive Technology",
            "Blind",
            "Haptic"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "to0107-file1.mp4",
        "session": {
            "id": "s292",
            "name": "Blindness and Design"
        },
        "room": "242ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth5129",
                "givenName": "Francis",
                "familyName": "Quek",
                "email": "quek@cs.vt.edu",
                "primary": {
                    "institution": "Virginia Polytechnic Institute and State University",
                    "city": "Blacksburg",
                    "state": "Virginia",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth32649",
                "givenName": "Francisco",
                "middleInitial": "CMB",
                "familyName": "Oliveira",
                "email": "Fran.mb.oliveira@gmail.com",
                "primary": {
                    "dept": "Computer Science ",
                    "institution": "Ceará State University ",
                    "city": "Fortaleza",
                    "state": "Ceara",
                    "country": "Brazil"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 515,
        "name": "Backtracking Events as Indicators of Usability Problems in Creation-Oriented Applications",
        "type": "TOCHI",
        "abstract": "A diversity of user goals and strategies make creation-oriented applications such as word processors or photo-editors difﬁcult to comprehensively test. Evaluating such applications requires testing a large pool of participants to capture the diversity of experience, but traditional usability testing can be prohibitively expensive. To address this problem, this article contributes a new usability evaluation method called backtracking analysis, designed to automate the process of detecting and characterizing usability problems in creation-oriented applications. The key insight is that interaction breakdowns in creation-oriented applications often manifest themselves in backtracking operations that can be automatically logged (e.g., undo and erase operations). Backtracking analysis synchronizes these events to contextual data such as screen capture video, helping the evaluator to characterize speciﬁc usability problems. The results from three experiments demonstrate that backtracking events can be effective indicators of usability problems in creationoriented applications, and can yield a cost-effective alternative to traditional laboratory usability testing.",
        "cbStatement": "Three experiments demonstrate that backtracking events such as undo are useful indicators of usability problems for creation-oriented applications. This insight yields a new cost-effective usability evaluation method, backtracking analysis.",
        "bookmarks": 95,
        "keywords": [
            "Usability Testing",
            "Backtracking Analysis",
            "Undo",
            "Cost-Effectiveness"
        ],
        "communities": [
            "ux"
        ],
        "video": "to0108-file1.mp4",
        "session": {
            "id": "s281",
            "name": "Automated Usability / Evaluation Methods"
        },
        "room": "351",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth6816",
                "givenName": "David",
                "familyName": "Akers",
                "email": "dakers@pugetsound.edu",
                "primary": {
                    "institution": "University of Puget Sound",
                    "city": "Tacoma",
                    "state": "WA",
                    "country": "United States"
                },
                "secondary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "CA",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1089",
                "givenName": "Robin",
                "familyName": "Jeffries",
                "email": "jeffries@google.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                }
            },
            {
                "id": "auth11448",
                "givenName": "Matthew",
                "familyName": "Simpson",
                "email": "msimpson@google.com",
                "primary": {
                    "institution": "Google, Inc.",
                    "city": "Mountain View",
                    "state": "California",
                    "country": "United States"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1143",
                "givenName": "Terry",
                "familyName": "Winograd",
                "email": "winograd@cs.stanford.edu",
                "primary": {
                    "institution": "Stanford University",
                    "city": "Palo Alto",
                    "state": "California",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 516,
        "name": "An Empirical Study of the“Prototype Walkthrough”: A Studio-Based Activity for HCI Education",
        "type": "TOCHI",
        "abstract": "For over a century, studio-based instruction has served as an effective pedagogical model in architecture and fine arts education. Because of its design orientation, human-computer interaction (HCI) education is an excellent venue for studio-based instruction. In an HCI course, we have been exploring a studio-based learning activity called the prototype walkthrough, in which a student project team simulates its evolving user interface prototype while a student audience member acts as a test user. The audience is encouraged to ask questions and provide feedback. We have observed that prototype walkthroughs create excellent conditions for learning about user interface design. In order to better understand the educational value of the activity, we performed a content analysis of a video corpus of 16 prototype walkthroughs held in two HCI courses. We found that the prototype walkthrough discussions were dominated by relevant design issues. Moreover, mirroring the justification behavior of the expert instructor, students justified over 80 percent of their design statements and critiques, with nearly one-quarter of those justifications having a theoretical or empirical basis. Our findings suggest that PWs provide valuable opportunities for students to actively learn HCI design by participating in authentic practice, and provide insight into how such opportunities can be best promoted.",
        "cbStatement": "Presents video analysis of the prototype walkthrough, a studio-based learning activity for HCI education. Results suggest that the activity provides valuable opportunities for students to actively learn HCI design.",
        "bookmarks": 91,
        "keywords": [
            "HCI education",
            "studio-based learning and instruction",
            "prototype walkthrough",
            "desgin crit, user interface design",
            "video analysis"
        ],
        "communities": [],
        "video": "to0109-file1.mp4",
        "session": {
            "id": "s217",
            "name": "Design Ideation Methods"
        },
        "room": "342a",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth8478",
                "givenName": "Christopher",
                "familyName": "Hundhausen",
                "email": "hundhaus@wsu.edu",
                "primary": {
                    "dept": "School of Electrical Engineering and Computer Science",
                    "institution": "Washington State University",
                    "city": "Pullman",
                    "state": "Washington",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth32654",
                "givenName": "Dana",
                "familyName": "Fairbrother",
                "email": "danafairbrother@gmail.com",
                "primary": {
                    "dept": "College of Education",
                    "institution": "Washington State University",
                    "city": "Pullman",
                    "state": "Washington",
                    "country": "United States"
                }
            },
            {
                "id": "auth10321",
                "givenName": "Marian",
                "familyName": "Petre",
                "email": "m.petre@open.ac.uk",
                "primary": {
                    "institution": "The Open University",
                    "city": "Milton Keynes",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 517,
        "name": "Co-Narrating a Conflict: An Interactive Tabletop to Facilitate Attitudinal Shifts",
        "type": "TOCHI",
        "abstract": "A multi-user tabletop interface was designed to support reconciliation of a conflict aimed at shifting hostile attitudes and achieving a greater understanding of another viewpoint. The interface provided a setting for face-to-face shared narration and support for the management of disagreements. The interface allows escalation and de-escalation of the conflict emerging in the shared narration and requires that participants perform joint actions when a contribution to the story is to be removed from the overall narration. A between-subjects experiment compared the tabletop interface and a desktop multimedia interface with mixed pairs (male Israeli-Jewish and Palestinian-Arab youth). The results demonstrated that the experience with the tabletop interface appears to be motivating and, most important, produce at least a short term shift of attitude toward the other.",
        "cbStatement": "A tabletop designed to support reconciliation of a conflict allows escalation and de-escalation during shared narration. An experiment with Israeli-Jewish and Palestinian-Arab demonstrated a shift of attitude toward the other. \\  \\ ",
        "bookmarks": 79,
        "keywords": [
            "Face-to-face collaboration",
            "tabletop interaction",
            "narration",
            "conflict escalation and de-escalation"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "to0110-file1.mp4",
        "session": {
            "id": "s206",
            "name": "Colaborative Technology: I share, you share, we share"
        },
        "room": "havane",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth11842",
                "givenName": "Massimo",
                "familyName": "Zancanaro",
                "email": "zancana@fbk.eu",
                "primary": {
                    "institution": "FBK-irst",
                    "city": "Trento",
                    "state": "-",
                    "country": "Italy"
                },
                "role": "presenter"
            },
            {
                "id": "auth10266",
                "givenName": "Oliviero",
                "familyName": "Stock",
                "email": "stock@fbk.eu",
                "primary": {
                    "institution": "FBK-IRST",
                    "city": "Povo",
                    "state": "Trentino",
                    "country": "Italy"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth32656",
                "givenName": "Zvi",
                "familyName": "Eisikovits",
                "email": "zvi@soc.haifa.ac.il",
                "primary": {
                    "institution": "University of Haifa",
                    "city": "Haifa",
                    "country": "Israel"
                }
            },
            {
                "id": "auth32657",
                "givenName": "Chaya",
                "familyName": "Koren",
                "email": "salsterk@study.haifa.ac.il",
                "primary": {
                    "institution": "University of Haifa",
                    "city": "Haifa",
                    "country": "Israel"
                }
            },
            {
                "id": "auth24138",
                "givenName": "Patrice (Tamar)",
                "middleInitial": "L",
                "familyName": "Weiss",
                "email": "tamar@research.haifa.ac.il",
                "primary": {
                    "institution": "University of Haifa",
                    "city": "Haifa",
                    "country": "Israel"
                }
            }
        ]
    },
    {
        "id": 518,
        "name": "ExoBuilding: Physiologically Driven Adaptive Architecture",
        "type": "TOCHI",
        "abstract": "Our surroundings are becoming infused with sensors measuring a variety of data streams about the environment, people and objects. Such data can be used to make the spaces that we inhabit responsive and interactive. Personal data in its different forms are one important data stream that such spaces are designed to respond to. In turn, one stream of personal data currently attracting high levels of interest in the HCI community is physiological data (e.g., heart rate, electrodermal activity), but this has seen little consideration in building architecture or the design of responsive environments. In this context, we developed a prototype mapping a single occupant’s respiration to its size and form, while it also sonifies their heartbeat. The result is a breathing building prototype, formative trials of which suggested that it triggers behavioral and physiological adaptations in inhabitants without giving them instructions and it is perceived as a relaxing experience. In this paper, we present and discuss the results of a controlled study of this prototype, comparing three conditions: the static prototype, regular movement and sonification and a biofeedback condition, where the occupant’s physiological data directly drives the prototype and presents this data back to them. The study confirmed that the biofeedback condition does indeed trigger behavioral changes and changes in participants’ physiology, resulting in lower respiration rates as well as higher respiration amplitudes, respiration to heart rate coherence and lower frequency heart rate variability. Self-reported state of relaxation is more dependent on inhabitant preferences, their knowledge of physiological data and whether they found space to ‘let go’. We conclude with a discussion of ExoBuilding as an immersive but also sharable biofeedback training interface and the wider potential of this approach to making buildings adapt to their inhabitants.",
        "cbStatement": "The study of ExoBuilding demonstrates how this prototypical building, exposing respiration and heart beat, changes respiratory behaviour of its inhabitants and how it effects their state of relaxation.",
        "bookmarks": 31,
        "keywords": [
            "Adaptive Architecture",
            "Physiological Data",
            "Biofeedback"
        ],
        "communities": [
            "design",
            "ux",
            "arts"
        ],
        "video": "to0111-file1.mp4",
        "session": {
            "id": "s239",
            "name": "Phyisical Excersion"
        },
        "room": "242b",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Thursday",
        "authors": [
            {
                "id": "auth2912",
                "givenName": "Holger",
                "middleInitial": "M",
                "familyName": "Schnädelbach",
                "email": "holger.schnadelbach@nottingham.ac.uk",
                "primary": {
                    "dept": "Mixed Reality Lab, Computer Science",
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth32659",
                "givenName": "Ainojie",
                "familyName": "Irune",
                "email": "aai@cs.nott.ac.uk",
                "primary": {
                    "dept": "Mixed Reality Lab, Computer Science",
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth4812",
                "givenName": "David",
                "middleInitial": "S",
                "familyName": "Kirk",
                "email": "david.kirk@ncl.ac.uk",
                "primary": {
                    "institution": "Newcastle University",
                    "city": "Newcastle Upon Tyne",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth16989",
                "givenName": "Kevin",
                "familyName": "Glover",
                "email": "ktg@cs.nott.ac.uk",
                "primary": {
                    "dept": "Mixed Reality Lab, Computer Science",
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth13297",
                "givenName": "Patrick",
                "middleInitial": "R",
                "familyName": "Brundell",
                "email": "pat.brundell@nottingham.ac.uk",
                "primary": {
                    "dept": "Mixed Reality Lab, Computer Science",
                    "institution": "The University of Nottingham",
                    "city": "Nottingham",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 519,
        "name": "Embedded Interaction: the accomplishment of actions in everyday and video-mediated environments",
        "type": "TOCHI",
        "abstract": "A concern with 'embodied action' has informed both the analysis of everyday action through technologies and also suggested ways of designing innovative systems. In this paper, we consider how these two programmes, the analysis of everyday embodied interaction on the one hand, and the analysis of technically-mediated embodied interaction on the other, are interlinked. We draw on studies of everyday interaction to reveal how embodied conduct is embedded in the environment. We then consider a collaborative technology that attempts to provide a coherent way of presenting life-sized embodiments of participants alongside particular features of the environment. These analyses suggest that conceptions of embodied action should take account of the interactional accomplishment of activities and how these are embedded in the material environment. ",
        "cbStatement": "This paper suggests how interactional studies of everyday interaction can both help shape the development of complex technologies for collaboration and also be informed by experiments with prototype systems.",
        "bookmarks": 83,
        "keywords": [
            "Media spaces",
            "video-mediated interaction",
            "reference",
            "embedded interaction"
        ],
        "communities": [],
        "video": "to0112-file1.mp4",
        "authors": [
            {
                "id": "auth1157",
                "givenName": "Paul",
                "middleInitial": "K",
                "familyName": "Luff",
                "email": "Paul.Luff@kcl.ac.uk",
                "primary": {
                    "dept": "Department of Management",
                    "institution": "King's College, London",
                    "city": "London",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth10010",
                "givenName": "Marina",
                "familyName": "Jirotka",
                "email": "marina.jirotka@cs.ox.ac.uk",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Oxford",
                    "city": "Oxford",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth7086",
                "givenName": "Naomi",
                "familyName": "Yamashita",
                "email": "naomiy@acm.org",
                "primary": {
                    "institution": "NTT Communication Science Laboratories",
                    "city": "Soraku-gun",
                    "state": "Kyoto",
                    "country": "Japan"
                }
            },
            {
                "id": "auth2965",
                "givenName": "Hideaki",
                "familyName": "Kuzuoka",
                "email": "kuzuoka@iit.tsukuba.ac.jp",
                "primary": {
                    "institution": "University of Tsukuba",
                    "city": "Tsukuba",
                    "state": "Ibaraki",
                    "country": "Japan"
                }
            },
            {
                "id": "auth31274",
                "givenName": "Christian",
                "familyName": "Heath",
                "email": "christian.heath@kcl.ac.uk",
                "primary": {
                    "dept": "Department of Management",
                    "institution": "King's College, London",
                    "city": "London",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth13393",
                "givenName": "Grace",
                "familyName": "Eden",
                "email": "grrace.eden@gmail.com",
                "primary": {
                    "dept": "Department of Computer Science",
                    "institution": "University of Oxford",
                    "city": "Oxford",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 520,
        "name": "Strong Concepts: Intermediate-level Knowledge in Interaction Design Research",
        "type": "TOCHI",
        "abstract": "Design-oriented research practices create opportunities to construct knowledge that is more abstracted than particular instances, without aspiring to be at the scope of generalized theories. We propose an intermediate design knowledge form that we name strong concepts with the following properties: generative, carries a core design idea, cuts across particular use situations and even application domains; concerns interactive behaviour, not static appearance; is a design element, a part of an artefact, and at the same time speaks of a use practice and behaviour over time; and finally, residing on an abstraction level above particular instances. We exemplify with two strong concepts: social navigation and seamfulness, and discuss how these fulfil criteria we might have on knowledge, such as being contestable, defensible and substantive. Our aim is to foster an academic culture of discursive knowledge construction of intermediate-level knowledge and how it can be produced and assessed in design-oriented HCI research.",
        "cbStatement": "Design-oriented research can construct knowledge that is more abstracted than particular instances, without being at the scope of generalized theories. We propose an intermediate design knowledge form: strong concepts.",
        "bookmarks": 149,
        "keywords": [
            "Design research",
            "strong concepts",
            "social navigation",
            "seamfulness",
            "bare-skin connection"
        ],
        "communities": [
            "design"
        ],
        "video": "to0113-file1.mp4",
        "session": {
            "id": "s214",
            "name": "Design Research, Paradigm and Theory"
        },
        "room": "havane",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth3543",
                "givenName": "Kristina",
                "familyName": "Höök",
                "email": "kia@sics.se",
                "primary": {
                    "dept": "Mobile Life @ KTH",
                    "institution": "KTH - Royal Institute of Technology",
                    "city": "Stockholm",
                    "country": "Sweden"
                },
                "role": "presenter"
            },
            {
                "id": "auth4355",
                "givenName": "Jonas",
                "familyName": "Löwgren",
                "email": "Jonas.Lowgren@mah.se",
                "primary": {
                    "dept": "Malmö University",
                    "institution": "School of Arts and Communication",
                    "city": "Malmö",
                    "country": "Sweden"
                }
            }
        ]
    },
    {
        "id": 521,
        "name": "Beyond Recommendations: Local Review Websites and Their Impact",
        "type": "TOCHI",
        "abstract": "Online review websites have enabled new interactions between companies and their customers. In this paper we draw on interviews with users, reviewers, and establishments to explore how local review websites can change interactions around local places. Review websites such as Yelp and Tripadvisor allow customers to ‘pre-visit’ establishments and areas of a city before an actual visit. The collection of a large numbers of user generated reviews has also created a new genre of writing - with reviewers gaining considerable pleasure from passing on word-of-mouth and influencing others’ choices. Reviews also offer a new channel of communication between establishments, customers and competitors. We discuss how review websites can be designed to cater for a broader range of interactions around reviews beyond a focus on recommendations.",
        "cbStatement": "Study of how reviews are used on the Yelp and Tripadvisor websites, develops new implications for recommendation systems.",
        "bookmarks": 123,
        "keywords": [
            "Reviews, Local Experts",
            "Yelp",
            "TripAdvisor",
            "Tourism",
            "Choice",
            "Recommendations"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "to0115-file1.mp4",
        "session": {
            "id": "s267",
            "name": "Shopping and Tagging"
        },
        "room": "241",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth1785",
                "givenName": "Barry",
                "familyName": "Brown",
                "email": "barry@mobilelifecentre.org",
                "primary": {
                    "institution": "Mobile Life @ Stockholm University",
                    "city": "Kista",
                    "country": "Sweden"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 522,
        "name": "User-Experience from an Inference Perspective",
        "type": "TOCHI",
        "abstract": "In many situations, people make judgments on the basis of incomplete information, inferring unavailable attributes from available ones. These inference processes may also well operate when judgments about a product’s user-experience are made. To examine this, an inference model of user-experience, based on Hassenzahl and Monk’s [2010], was explored in three studies using Web sites. All studies supported the model’s predictions and its stability, with hands-on experience, different products, and different usage modes (action mode versus goal mode). Within a unified framework of judgment as inference [Kruglanski et al. 2007], our approach allows for the integration of the effects of a wide range of information sources on judgments of user-experience.",
        "cbStatement": "The research provides consistent evidence for how people infer specific user-experience attributes of an interactive product from other attributes or broader evaluations, such as beauty or an overall evaluation.  ",
        "bookmarks": 111,
        "keywords": [
            "user-experience",
            "model",
            "inference perspective",
            "beauty",
            "aesthetics"
        ],
        "communities": [
            "ux"
        ],
        "video": "to0116-file1.mp4",
        "session": {
            "id": "s273",
            "name": "How We Feel About Websites"
        },
        "room": "bordeaux",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth16154",
                "givenName": "Paul",
                "familyName": "van Schaik",
                "email": "p.van-schaik@tees.ac.uk",
                "primary": {
                    "institution": "Teesside University",
                    "city": "Middlesbrough",
                    "state": "Cleveland",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth16094",
                "givenName": "Marc",
                "familyName": "Hassenzahl",
                "email": "marc.hassenzahl@folkwang-uni.de",
                "primary": {
                    "institution": "Folkwang University of the Arts",
                    "city": "Essen",
                    "country": "Germany"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth14852",
                "givenName": "Jonathan",
                "familyName": "Ling",
                "email": "jonathan.ling@sunderland.ac.uk",
                "primary": {
                    "dept": "Faculty of Applied Sciences",
                    "institution": "University of Sunderland",
                    "city": "Sunderland",
                    "state": "Tyne and Wear",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 523,
        "name": "Study of Polynomial Mapping Functions in Video-Oculography Eye Trackers",
        "type": "TOCHI",
        "abstract": "Gaze-tracking data have been used successfully in the design of new input devices and as an observational technique in usability studies. Polynomial-based Video-Oculography (VOG) systems are one of the most attractive gaze estimation methods thanks to their simplicity and ease of implementation. Although the functionality of these systems is generally acceptable, there has been no thorough comparative study to date of how the mapping equations affect the final system response. After developing a taxonomic classification of calibration functions, we examined over 400,000 models and evaluated the validity of several conventional assumptions. Our rigorous experimental procedure enabled us to optimize the calibration process for a real VOG gaze-tracking system and halve the calibration time while avoiding a detrimental effect on the accuracy or tolerance to head movement. Finally, a geometry-based method is implemented and tested. The results and performance is compared with those obtained by the general purpose expressions.",
        "cbStatement": "In this study we enlighten one of the most employed and least explored techniques for gaze estimation in eye-tracking systems. We obtain a sort of precise and simpler alternative equations. ",
        "bookmarks": 89,
        "keywords": [
            "\"Eye-tracking",
            "gaze-tracking",
            "video-oculography",
            "calibration",
            "multiple linear regression",
            "geometry-based methods\""
        ],
        "communities": [
            "engineering",
            "ux",
            "health"
        ],
        "video": "to0117-file1.mp4",
        "session": {
            "id": "s235",
            "name": "Gaze"
        },
        "room": "bordeaux",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth32662",
                "givenName": "Juan J.",
                "middleInitial": "J.",
                "familyName": "Cerrolaza",
                "email": "juanjose.cerrolaza@unavarra.es",
                "primary": {
                    "dept": "Department of Electrical and Electronic Engineering",
                    "institution": "Public University of Navarra",
                    "city": "Pamplona",
                    "state": "Navarra",
                    "country": "Spain"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth32663",
                "givenName": "Arantxa",
                "familyName": "Villanueva",
                "email": "avilla@unavarra.es",
                "primary": {
                    "dept": "Department of Electrical and Electronic Engineering",
                    "institution": "Public University of Navarra",
                    "city": "Pamplona",
                    "state": "Navarra",
                    "country": "Spain"
                },
                "role": "presenter"
            },
            {
                "id": "auth32664",
                "givenName": "Rafael",
                "familyName": "Cabeza",
                "email": "rcabeza@unavarra.es",
                "primary": {
                    "dept": "Department of Electrical and Electronic Engineering",
                    "institution": "Public University of Navarra",
                    "city": "Pamplona",
                    "state": "Navarra",
                    "country": "Spain"
                }
            }
        ]
    },
    {
        "id": 524,
        "name": "Supporting Personal Narrative for Children with Complex Communication Needs",
        "type": "TOCHI",
        "abstract": "Children with complex communication needs who use voice output communication aids seldom engage in extended conversation. The “How was School today. . . ?” system has been designed to enable such children to talk about their school day. The system uses data-to-text technology to generate narratives from sensor data. Observations, interviews and prototyping were used to ensure that stakeholders were involved in the design of the system. Evaluations with three children showed that the prototype system, which automatically generates utterances, has the potential to support disabled individuals to participate better in interactive conversation. Analysis of a conversational transcript and observations indicate that the children were able to access relevant conversation and had more control in the conversation in comparison to their usual interactions where control lay mainly with the speaking partner. Further research to develop an improved, more rugged system that supports users with different levels of language ability is now underway.",
        "cbStatement": "“How was School today. . . ?” uses sensor based data-to-text technology to generate personal narratives. Children with cerebral palsy are able to tell parents about their school day.",
        "bookmarks": 118,
        "keywords": [
            "Augmentative and Alternative Communication",
            "Personal Narrative",
            "Language Development,",
            "Accessibility",
            "Assistive Technology",
            "Disability",
            "Cerebral Palsy",
            "Scanning Selection",
            "Single-Switch Input"
        ],
        "communities": [
            "health",
            "cci"
        ],
        "video": "to0118-file1.mp4",
        "session": {
            "id": "s327",
            "name": "Children"
        },
        "room": "bordeaux",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Wednesday",
        "authors": [
            {
                "id": "auth30009",
                "givenName": "Rolf",
                "familyName": "Black",
                "email": "rolfblack@computing.dundee.ac.uk",
                "primary": {
                    "institution": "University of Dundee",
                    "city": "Dundee",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth19192",
                "givenName": "Annalu",
                "familyName": "Waller",
                "email": "awaller@computing.dundee.ac.uk",
                "primary": {
                    "institution": "University of Dundee",
                    "city": "Dundee",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth32678",
                "givenName": "Ross",
                "familyName": "Turner",
                "email": "ross.turner@data2text.com",
                "primary": {
                    "institution": "Data2Text",
                    "city": "Aberdeen",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth11512",
                "givenName": "Ehud",
                "familyName": "Reiter",
                "email": "e.reiter@abdn.ac.uk",
                "primary": {
                    "institution": "University of Aberdeen",
                    "city": "Aberdeen",
                    "country": "United Kingdom"
                }
            }
        ]
    },
    {
        "id": 525,
        "name": "A Predictive Speller Controlled by a Brain-Computer Interface Based on Motor Imagery",
        "type": "TOCHI",
        "abstract": "Persons suffering from motor disorders have limited possibilities to communicate and normally require assistive technologies to fulfill this primary need. Promising means to provide basic communication abilities to subjects affected by severe motor impairments are brain-computer interfaces (BCIs), i.e., systems that directly translate brain signals into device commands bypassing any muscle or nerve mediation. To date, the use of BCIs for effective verbal communication is yet an open issue - primarily due to the low rates of information transfer that can be achieved with this technology. Still, the performance of BCI spelling applications can be considerably improved by a smart user interface design and by the adoption of Natural Language Processing (NLP) techniques for text prediction.  The objective of this work is to suggest an approach and a user interface for BCI spelling applications combining state-of-the-art BCI and NLP techniques to maximize the overall communication rate of the system. The BCI paradigm adopted is motor imagery, i.e., when the subject imagines to move a certain part of the body, he/she produces modifications to specific brain rhythms that are detected in real-time through an electroencephalogram and translated into commands for a spelling application. By maximizing the overall communication rate our approach is twofold: on one hand we maximize the information transfer rate from the control signal, on the other side we optimize the way this information is employed for the purpose of verbal communication. The achieved results are satisfactory and comparable with the latest works reported in literature on motor-imagery BCI spellers. For the three subjects tested we obtained a spelling rate of respectively 3 char/min, 2.7 char/min and 2 char/min.",
        "cbStatement": "Persons suffering from severe motor disorders have limited possibilities to communicate. We present a speller, based on a brain-computer interface, improved by a smart UI and a text predictor.",
        "bookmarks": 68,
        "keywords": [
            "Speller",
            "Brain-Computer Interface",
            "Text prediction"
        ],
        "communities": [
            "health"
        ],
        "video": "to0120-file1.mp4",
        "session": {
            "id": "s271",
            "name": "Brain Interfaces"
        },
        "room": "342a",
        "starTime": "14:00",
        "endTime": "15:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth32685",
                "givenName": "Tiziano",
                "familyName": "D'Albis",
                "email": "tiziano.dalbis@gmail.com",
                "primary": {
                    "dept": "Dipartimento di Elettronica e Informazione",
                    "institution": "Politecnico di Milano",
                    "city": "Milan",
                    "country": "Italy"
                }
            },
            {
                "id": "auth32686",
                "givenName": "Rossella",
                "familyName": "Blatt",
                "email": "rossellablatt@gmail.com",
                "primary": {
                    "dept": "Dipartimento di Elettronica e Informazione",
                    "institution": "Politecnico di Milano",
                    "city": "Milan",
                    "country": "Italy"
                }
            },
            {
                "id": "auth32684",
                "givenName": "Roberto",
                "familyName": "Tedesco",
                "email": "roberto.tedesco@polimi.it",
                "primary": {
                    "dept": "MultiChancePoliTeam",
                    "institution": "Politecnico di Milano",
                    "city": "Milan",
                    "state": "MI",
                    "country": "Italy"
                }
            },
            {
                "id": "auth32687",
                "givenName": "Licia",
                "familyName": "Sbattella",
                "email": "licia.sbattella@polimi.it",
                "primary": {
                    "dept": "Dipartimento di Elettronica e Informazione",
                    "institution": "Politecnico di Milano",
                    "city": "Milan",
                    "country": "Italy"
                },
                "role": "presenter"
            },
            {
                "id": "auth32688",
                "givenName": "Matteo",
                "familyName": "Matteucci",
                "email": "matteucci@elet.polimi.it",
                "primary": {
                    "dept": "Dipartimento di Elettronica e Informazione",
                    "institution": "Politecnico di Milano",
                    "city": "Milan",
                    "country": "Italy"
                }
            }
        ]
    },
    {
        "id": 526,
        "name": "Moving and Making Strange: An Embodied Approach to Movement-based Interaction Design",
        "type": "TOCHI",
        "abstract": "There is growing interest in designing for movement-based interactions with technology, now that various sensing technologies are available enabling a range of movement possibilities from gestural to whole-body interactions. We present a design methodology of Moving and Making Strange, an approach to movement- based interaction design that recognizes the central role of the body and movement in lived cognition. The methodology was developed through a series of empirical projects, each focusing on different conceptions of movement available within motion-sensing interactive, immersive spaces. The methodology offers designers a set of principles, perspectives, methods and tools for exploring and testing movement-related design concepts. It is innovative for the inclusion of the perspective of the mover, together with the traditional perspectives of the observer and the machine. Making strange is put forward as an important tactic for rethinking how to approach the design of movement-based interaction.",
        "cbStatement": "We offer a methodology for the design and evaluation of movement-based interactions with technology, where the felt experience of moving is valued along with the perspectives of observer and machine.",
        "bookmarks": 163,
        "keywords": [
            "movement-based interaction",
            "design methods"
        ],
        "communities": [
            "design"
        ],
        "session": {
            "id": "s213",
            "name": "Embodied Interaction (and Thinking) Design"
        },
        "room": "251",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth5378",
                "givenName": "Lian",
                "familyName": "Loke",
                "email": "lian.loke@sydney.edu.au",
                "primary": {
                    "institution": "The University of Sydney",
                    "city": "Sydney",
                    "state": "New South Wales",
                    "country": "Australia"
                },
                "role": "presenter"
            },
            {
                "id": "auth12108",
                "givenName": "Toni",
                "familyName": "Robertson",
                "email": "Toni.Robertson@uts.edu.au",
                "primary": {
                    "institution": "University of Technology, Sydney",
                    "city": "Sydney",
                    "state": "NSW",
                    "country": "Australia"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 527,
        "name": "Interaction Design for and with the Lived Body: Some Implications of Merleau-Ponty’s Phenomenology",
        "type": "TOCHI",
        "abstract": "In 2001, Paul Dourish proposed the term Embodied Interaction to describe a new paradigm for Interaction Design that focuses on the physical, bodily and social aspects of our interaction with digital technology. Dourish used Merleau-Ponty’s phenomenology of perception as the theoretical basis for his discussion of the bodily nature of embodied interaction. This paper extends Dourish’s work to introduce the human-computer interaction community to ideas related to Merleau-Ponty’s concept of the lived body. It also provides a detailed analysis of two related topics: (1) Embodied Perception: the active and embodied nature of perception, including the body’s ability to extent its sensory apparatus through digital technology; and (2) Kinaesthetic Creativity: the body’s ability to relate in a direct and creative fashion with the “feel” dimension of interactive products during the design process.",
        "cbStatement": "The body as experienced by the user has to a large extent been absent in HCI. The paper exemplifies how the field can benefit from Merleau-Ponty’s phenomenology of the body. \\  \\ ",
        "bookmarks": 82,
        "keywords": [
            "Interaction Design",
            "Embodied Interaction",
            "Embodied Perception",
            "Kinaesthetic Creativity",
            "Phenomenology",
            "The lived body",
            "Merleau-Ponty"
        ],
        "communities": [
            "design",
            "ux"
        ],
        "video": "to0123-file1.mp4",
        "session": {
            "id": "s213",
            "name": "Embodied Interaction (and Thinking) Design"
        },
        "room": "251",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth2696",
                "givenName": "Dag",
                "familyName": "Svanaes",
                "email": "dags@idi.ntnu.no",
                "primary": {
                    "dept": "Department of Computer and Information Science",
                    "institution": "Norwegian University of Science and Technology",
                    "city": "Trondheim",
                    "country": "Norway"
                },
                "secondary": {
                    "dept": "Interaction Design Group",
                    "institution": "IT University of Copenhagen",
                    "city": "Copenhagen",
                    "state": "N/A",
                    "country": "Denmark"
                },
                "role": "presenter"
            }
        ]
    },
    {
        "id": 528,
        "name": "Enriching Archaeological Parks with Contextual Sounds and Mobile Technology",
        "type": "TOCHI",
        "abstract": "The importance of cultural heritage in forging a sense of identity is becoming increasingly evident. Information and communication technologies have a great potential to promote a greater awareness and appreciation of cultural heritage. This paper presents some findings on how mobile technology can be used to foster a better understanding of an archaeological site by reconstructing the ancient environment and life. Children aged 11-13 years old are the target of our research. To motivate and engage them, a pervasive educational game has been developed and implemented in Explore!, a system aimed at supporting children exploring sites of cultural interest. Special attention has been devoted to the design of a soundscape that may improve players’ navigation in degraded physical environments and enrich their overall experience. A field study indicated that children judged their experience both useful and entertaining: not only did they enjoy playing the game but they also learned historical notions and facts related to ancient Roman life. Contextual sounds were found to have a facilitating effect on space navigation, reducing the need for map reading and improving spatial orientation. This work provides insights into the design of educational games for use with cultural heritage and a model to enrich historical sites through the creation of soundscapes which can help visitors to navigate a site and feel its historical atmosphere.",
        "cbStatement": "Explore! is an educational pervasive game for pupils exploring sites of cultural interest. The soundscape model implemented in Explore! helps visitors to navigate a site and feel its historical atmosphere.",
        "bookmarks": 145,
        "keywords": [
            "Digital augmentation",
            "cultural heritage",
            "educational game",
            "field study",
            "user experience"
        ],
        "communities": [
            "design",
            "cci"
        ],
        "video": "to0124-file1.mp4",
        "session": {
            "id": "s242",
            "name": "Mobile 2: Very Moving: reflection in mobile technologies"
        },
        "room": "351",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth10132",
                "givenName": "Carmelo",
                "familyName": "Ardito",
                "email": "ardito@di.uniba.it",
                "primary": {
                    "dept": "Dipartimento di Informatica",
                    "institution": "University of Bari",
                    "city": "Bari",
                    "country": "Italy"
                },
                "role": "presenter"
            },
            {
                "id": "auth8375",
                "givenName": "Maria Francesca",
                "familyName": "Costabile",
                "email": "costabile@di.uniba.it",
                "primary": {
                    "dept": "Dipartimento di Informatica",
                    "institution": "University of Bari",
                    "city": "Bari",
                    "country": "Italy"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth1266",
                "givenName": "Antonella",
                "familyName": "De Angeli",
                "email": "deangeli@disi.unitn.it",
                "primary": {
                    "institution": "University of Trento",
                    "city": "Trento",
                    "state": "Trento",
                    "country": "Italy"
                }
            },
            {
                "id": "auth8439",
                "givenName": "Rosa",
                "familyName": "Lanzilotti",
                "email": "lanzilotti@di.uniba.it",
                "primary": {
                    "dept": "Dipartimento di Informatica",
                    "institution": "University of Bari",
                    "city": "Bari",
                    "country": "Italy"
                }
            }
        ]
    },
    {
        "id": 529,
        "name": "Window Brokers: Collaborative Display Space Control",
        "type": "TOCHI",
        "abstract": "As users travel from place to place, they can encounter display servers, that is, machines which supply a collaborative content-sharing environment. Users need a way to control how content is arranged on these display spaces. The software for controlling these display spaces should be consistent from display server to display server. However, display servers could be controlled by institutions which may not allow for the control software to be installed. This article introduces the window broker protocol which allows users to carry familiar control techniques on portable personal devices and use the control technique on any display server without installing the control software on the display server. This article also discusses how the window broker protocol mitigates some security risks that arise from potentially malicious display servers.",
        "cbStatement": "Take collaborative control of a display space you do not own in a familiar, platform-independent way without transmitting new software to the display or other participating devices.",
        "bookmarks": 71,
        "keywords": [
            "User Interfaces",
            "Design",
            "Algorithms",
            "Performance",
            "Human Factors",
            "Security",
            "Wireless sensor networks",
            "media access control",
            "multi-channel",
            "radio interference",
            "time synchronization"
        ],
        "communities": [
            "design",
            "engineering",
            "ux"
        ],
        "video": "to0125-file1.mp4",
        "session": {
            "id": "s249",
            "name": "Large and public Displays"
        },
        "room": "241",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Monday",
        "authors": [
            {
                "id": "auth9848",
                "givenName": "Richard",
                "middleInitial": "B",
                "familyName": "Arthur",
                "email": "startether@startether.com",
                "primary": {
                    "dept": "Computer Science Department",
                    "institution": "Brigham Young University",
                    "city": "Provo",
                    "state": "Utah",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth1870",
                "givenName": "Dan",
                "middleInitial": "R",
                "familyName": "Olsen",
                "email": "olsen@cs.byu.edu",
                "primary": {
                    "dept": "Computer Science Department",
                    "institution": "Brigham Young University",
                    "city": "Provo",
                    "state": "Utah",
                    "country": "United States"
                },
                "role": "backupPresenter"
            }
        ]
    },
    {
        "id": 530,
        "name": "Teamwork Errors in Trauma Resuscitation",
        "type": "TOCHI",
        "abstract": "Human errors in trauma resuscitation can have cascading effects leading to poor patient outcomes. To determine the nature of teamwork errors, we conducted an observational study in a trauma center over a two-year period. While eventually successful in treating the patients, trauma teams had problems tracking and integrating information in a longitudinal trajectory, which resulted in inefficiencies and near-miss errors. As an initial step in system design to support trauma teams, we proposed a model of teamwork and a novel classification of team errors. Four types of team errors emerged from our analysis: communication \\ errors, vigilance errors, interpretation errors, and management errors. Based on these findings, we identified key information structures to support team cognition and decision making. We believe that displaying \\ these information structures will support distributed cognition of trauma teams. Our findings have broader applicability to other collaborative and dynamic work settings that are prone to human error.",
        "cbStatement": "Proposes a model of teamwork and a classification of team errors based on an observational study of emergency medical teams. Identifies key information structures for computerized support of team cognition.",
        "bookmarks": 105,
        "keywords": [
            "Team errors",
            "Medical error",
            "Collocated teams",
            "Distributed cognition",
            "System requirements",
            "Trauma resuscitation",
            "Healthcare"
        ],
        "communities": [
            "design",
            "health"
        ],
        "video": "to0127-file1.mp4",
        "session": {
            "id": "s294",
            "name": "The Clinical Setting"
        },
        "room": "242ab",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth5448",
                "givenName": "Aleksandra",
                "familyName": "Sarcevic",
                "email": "aleksarc@drexel.edu",
                "primary": {
                    "institution": "Drexel University",
                    "city": "Philadelphia",
                    "state": "Pennsylvania",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth32701",
                "givenName": "Ivan",
                "familyName": "Marsic",
                "email": "marsic@ece.rutgers.edu",
                "primary": {
                    "institution": "Rutgers University",
                    "city": "New Brunswick",
                    "state": "New Jersey",
                    "country": "United States"
                }
            },
            {
                "id": "auth32702",
                "givenName": "Randall",
                "middleInitial": "S.",
                "familyName": "Burd",
                "email": "RBurd@childrensnational.org",
                "primary": {
                    "dept": "Division of Trauma and Burn Surgery",
                    "institution": "Children's National Medical Center",
                    "city": "Washington",
                    "state": "District of Columbia",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 531,
        "name": "Physical Activity Motivating Games: Be Active and Get Your Own Reward",
        "type": "TOCHI",
        "abstract": "People's daily lives have become increasingly sedentary, with extended periods of time being spent in front of a host of electronic screens for learning, work, and entertainment. We present research into the use of an adaptive persuasive technology, which introduces bursts of physical activity into a traditionally sedentary activity – computer game playing. Our game design approach leverages the playfulness and addictive nature of computer games to motivate players to engage  \\ in mild physical activity. The design allows players to gain virtual in-game rewards in return for performing real physical activity captured by sensory devices. This paper presents a two-stage analysis of the activity-motivating game design approach applied to a prototype game. Initially, we detail the overall acceptance of active games discovered when trialling the technology with 135 young players. Results showed that players performed more activity without negatively affecting their perceived enjoyment of the playing experience. The analysis did discover, however, a lack of balance between the amounts of physical activity carried out by players with various gaming skills, which prompted a subsequent investigation into adaptive techniques for balancing the amount of physical activity performed by players. An evaluation of additional 90 players showed that adaptive techniques successfully overcame the gaming skills dependence and achieved more balanced activity levels. Overall, this work positions activity-motivating games as an approach that can potentially change the way players interact with computer games and lead to healthier lifestyles. ",
        "cbStatement": "We present a game design that leverages the playfulness of games to motivate players to perform mild physical activity. This design can potentially change the way players interact with games.",
        "bookmarks": 109,
        "keywords": [
            "health;persuasion;personalization;children;exercise"
        ],
        "communities": [
            "health",
            "games"
        ],
        "session": {
            "id": "s283",
            "name": "Exergames, Inclusion"
        },
        "room": "251",
        "starTime": "16:00",
        "endTime": "17:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth13925",
                "givenName": "Shlomo",
                "familyName": "Berkovsky",
                "email": "shlomo.berkovsky@nicta.com.au",
                "primary": {
                    "institution": "National ICT Australia",
                    "city": "Sydney",
                    "country": "Australia"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth14444",
                "givenName": "Jill",
                "familyName": "Freyne",
                "email": "jill.freyne@csiro.au",
                "primary": {
                    "institution": "CSIRO",
                    "city": "Sydney",
                    "country": "Australia"
                },
                "role": "presenter"
            },
            {
                "id": "auth32708",
                "givenName": "Mac",
                "familyName": "Coombe",
                "email": "mac.coombe@csiro.au",
                "primary": {
                    "institution": "CSIRO",
                    "city": "Sydney",
                    "country": "Australia"
                }
            }
        ]
    },
    {
        "id": 532,
        "name": "“Spindex” (Speech Index) Enhances Menus on Touch Screen Devices with Tapping, Wheeling, and Flicking",
        "type": "TOCHI",
        "abstract": "Users interact with many electronic devices via menus such as auditory or visual menus. Auditory menus can either complement or replace visual menus. We investigated how advanced auditory cues enhance auditory menus on a smartphone, with tapping, wheeling, and flicking input gestures. The study evaluated a spindex (speech index), in which audio cues inform users where they are in a menu; 122 undergraduates navigated through a menu of 150 songs. Study variables included auditory cue type (text-to-speech alone or TTS plus spindex), visual display mode (on or off), and input gesture (tapping, wheeling, or flicking). Target search time and subjective workload were lower with spindex than without for all input gestures regardless of visual display mode. The spindex condition was rated subjectively higher than plain speech. The effects of input method and display mode on navigation behaviors were analyzed with the two-stage navigation strategy model. Results are discussed in relation to attention theories and in terms of practical applications. ",
        "cbStatement": "Advanced auditory cues (spindex) enhance multimodal and auditory menus on a smartphone, making user inputs via tapping, wheeling, and flicking gestures more efficient, faster, and more enjoyable.",
        "bookmarks": 150,
        "keywords": [
            "Auditory Menus",
            "Spindex",
            "Touch Screen",
            "Input Gestures",
            "Mobile Devices"
        ],
        "communities": [
            "design",
            "ux",
            "games"
        ],
        "video": "to0129-file1.mp4",
        "session": {
            "id": "s219",
            "name": "Mobile Gestures and Grasp"
        },
        "room": "352ab",
        "starTime": "11:00",
        "endTime": "12:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth10648",
                "givenName": "Myoung Hoon",
                "familyName": "Jeon",
                "email": "philart@gmail.com",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                },
                "secondary": {
                    "dept": "Cognitive and Learning Sciences",
                    "institution": "Michigan Technological University",
                    "city": "Houghton",
                    "state": "Michigan",
                    "country": "United States"
                }
            },
            {
                "id": "auth6071",
                "givenName": "Bruce",
                "middleInitial": "N.",
                "familyName": "Walker",
                "email": "bruce.walker@psych.gatech.edu",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                },
                "role": "presenter"
            },
            {
                "id": "auth32717",
                "givenName": "Abhishek",
                "familyName": "Srivastava",
                "email": "abhisriv87@gatech.edu",
                "primary": {
                    "institution": "Georgia Institute of Technology",
                    "city": "Atlanta",
                    "state": "Georgia",
                    "country": "United States"
                }
            }
        ]
    },
    {
        "id": 533,
        "name": "On the Naturalness of Touchless: Putting the “Interaction” Back into NUI",
        "type": "TOCHI",
        "abstract": "After many decades of research, the ability to interact with technology through touchless gestures and sensed body movements is becoming an everyday reality. These technologies form part of a broader suite of innovations that have come to be characterised as Natural User Interfaces. While the narrative of NUI serves a number of useful purposes, it also raises some concerns that make it increasingly important to examine the conceptual work being performed by this moniker and how these frame approaches to design and engineering in particular ways. Often the arguments made situate the locus of naturalness in the gestural interface alone, treating the issue as a representational concern. But in doing this, attention is perhaps less focused on the in situ and embodied aspects of interaction with such technologies. Drawing on examples of gestural interaction in the diverse settings of surgery and urban screen gaming, we consider naturalness as an occasioned property of action that social actors actively manage and produce together in situ through their interaction with each other and the material world. ",
        "cbStatement": "Using examples of gestural interaction from surgery and urban screen gaming, we discuss the notion of naturalness in NUI narratives as an occasioned property of interaction rather than inherent property of an interface.",
        "bookmarks": 152,
        "keywords": [
            "touchless interaction, natural user interface, gesture"
        ],
        "communities": [
            "design",
            "ux",
            "health",
            "games"
        ],
        "session": {
            "id": "s213",
            "name": "Embodied Interaction (and Thinking) Design"
        },
        "room": "251",
        "starTime": "9:00",
        "endTime": "10:20",
        "day": "Tuesday",
        "authors": [
            {
                "id": "auth6210",
                "givenName": "Kenton",
                "middleInitial": "P",
                "familyName": "O'Hara",
                "email": "oharakenton@gmail.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                },
                "secondary": {
                    "institution": "University of Bristol",
                    "city": "Bristol",
                    "country": "United Kingdom"
                },
                "role": "presenter"
            },
            {
                "id": "auth5139",
                "givenName": "Richard",
                "familyName": "harper",
                "email": "r.harper@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                }
            },
            {
                "id": "auth1960",
                "givenName": "Helena",
                "middleInitial": "M.",
                "familyName": "Mentis",
                "email": "helena.mentis@gmail.com",
                "primary": {
                    "dept": "Department of Surgery",
                    "institution": "Harvard Medical School",
                    "city": "Boston",
                    "state": "Massachusetts",
                    "country": "United States"
                }
            },
            {
                "id": "auth1515",
                "givenName": "Abigail",
                "middleInitial": "J",
                "familyName": "Sellen",
                "email": "asellen@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                },
                "role": "backupPresenter"
            },
            {
                "id": "auth2037",
                "givenName": "Alex",
                "middleInitial": "S",
                "familyName": "Taylor",
                "email": "ast@microsoft.com",
                "primary": {
                    "institution": "Microsoft Research",
                    "city": "Cambridge",
                    "country": "United Kingdom"
                }
            }
        ]
    }
]